{
  "hash": "0c6d6ad5b06e73731af87e228a9c2215",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 2: Statistical inference & hypothesis testing\"\nsubtitle: \"<span style='font-size:2em;'> Practice session covering topics discussed in Lecture 2 </span>\"\nauthor: \"<a href='https://r4biostats.com/me.html' style='color:#72aed8;font-weight:600;'>M. Chiara Mimmi, Ph.D.</a>&ensp;|&ensp;Università degli Studi di Pavia\"\ndate: 2024-07-25\ndate-format: long\ncode-link: true\nformat:\n  revealjs:\n    smaller: true\n    scrollable: true\n    theme: ../../theme/slidesMine.scss # QUARTO LOOKS IN SAME FOLDER \n#    logo: imgs_slides/mitgest_logo.png\n    footer: '[R 4 Biostatistics](https://r4biostats.com/) | MITGEST::training(2024)'\n#    footer: <https://lulliter.github.io/R4biostats/lectures.html>\n## ------------- x salvare come PDF \n    standalone: false\n    ## -------Produce a standalone HTML file with no external dependencies,\n    embed-resources: true\n    transition: fade\n    background-transition: fade\n    highlight-style: ayu-mirage\n    slide-number: true\n    fig-cap-location: top\n    # fig-format: svg\n    pdf-separate-fragments: false\n    # fig-align: center\nexecute:\n  # Quarto pre code blocks do not echo their source code by default\n  echo: true\n  include: true\n  freeze: auto\nbibliography: ../../bib/R4biostats.bib\ncsl: ../../bib/apa-6th-edition.csl \nsuppress-bibliography: true\n---\n\n\n\n## GOAL OF TODAY'S PRACTICE SESSION\n\n[Consolidate understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.]{style=\"color:#77501a\"}\n\n<br><br>\n\n#### Lecture 2: topics \n\n+ **Purpose and foundations of inferential statistics**\n  <!-- + Probability and random variables  -->\n  <!-- + Meaningful probability distributions -->\n  <!-- + Sampling distributions and Central Limit Theorem -->\n  <!-- + Confidence Intervals -->\n+ **Getting to know the “language” of hypothesis testing**\n  <!-- + The null and alternative hypothesis -->\n  <!-- + The probability of error? (*α* or \"significance level\") -->\n  <!-- + The *p-value* probability and tests interpretation -->\n  <!-- + Effective vs statistical significance -->\n  <!-- + Types of errors (Type 1 and Type 2) -->\n+ **Hypothesis testing**\n  + review examples\n  \n  <!-- + Comparing sample mean to a hypothesized population mean (Z test & t test) -->\n  <!-- + Comparing two independent sample means (t test) -->\n  <!-- + Comparing sample means from 3 or more groups (ANOVA) <!-- (esempio metabolomica Catanzaro?) -->  \n+ **A closer look at testing assumptions** \n  + more examples dealing with assumptions' violation\n\n  <!-- + Testing two groups that are *not* independent  -->\n  <!-- + Testing if the data are *not* normally distributed: non-parametric tests -->\n  <!-- + Testing samples *without* homogeneous variance of observations -->\n    \n\n# R ENVIRONMENT SET UP & DATA\n\n## Needed R Packages\n::: {style=\"font-size: 80%;\"}\n+ We will use functions from packages `base`, `utils`, and `stats` (pre-installed and pre-loaded) \n+ We will also use the packages below (specifying `package::function` for clarity).\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load pckgs for this R session\n\n# General \nlibrary(fs)           # file/directory interactions\nlibrary(here)         # tools find your project's files, based on working directory\nlibrary(janitor)      # tools for examining and cleaning data\nlibrary(dplyr)        # {tidyverse} tools for manipulating and summarising tidy data \nlibrary(forcats)      # {tidyverse} tool for handling factors\nlibrary(tidyr)        # Tidy Messy Data       \n\n# Statistics\nlibrary(BSDA)         # Basic Statistics and Data Analysis   \nlibrary(rstatix)      # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)          # Companion to Applied Regression\nlibrary(multcomp)     # Simultaneous Inference in General Parametric Models \n\n# Plotting\nlibrary(ggplot2)      # {tidyverse} tools for plotting\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details  \nlibrary(ggpubr)       # 'ggplot2' Based Publication Ready Plots \nlibrary(patchwork)    # Functions for \"\"Grid\" Graphics\"composing\" plots \nlibrary(viridis)      # Colorblind-Friendly Color Maps for R \nlibrary(ggthemes)     # Extra Themes, Scales and Geoms for 'ggplot2'\n```\n:::\n\n\n\n\n# DATASETS FOR TODAY\n\n::: {style=\"font-size: 80%;\"}\nFor the most part, we will refer to a real clinical dataset (for which a *Creative Commons license* was granted) discussed in two articles (also open access) :  \n\n+ Ahmad, T., Munir, A., Bhatti, S. H., Aftab, M., & Raza, M. A. (2017). ***Survival analysis of heart failure patients: A case study***. PLOS ONE, 12(7), e0181001. [https://doi.org/10.1371/journal.pone.0181001](https://doi.org/10.1371/journal.pone.0181001)\n+ Chicco, D., & Jurman, G. (2020). ***Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone***. BMC Medical Informatics and Decision Making, 20(1), 16. [https://doi.org/10.1186/s12911-020-1023-5](https://doi.org/10.1186/s12911-020-1023-5)\n:::\n\n## [Importing from project folder (previously downloaded file)]{.r-fit-text}\n\nYou can access the dataset either:  \n\n+ From the UC Irvine Machine Learning Repository [Heart Failure Clinical Records](https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records)\n+ From the workshop website: use function `here` to specify the complete path of the input data folder\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nheart_failure <- read.csv(file = here::here(\"practice\", \"data_input\", \"02_datasets\",\n                                      \"heart_failure_clinical_records_dataset.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n```\n:::\n\n \n\n::: {.callout-tip}\nMake sure to match your own folder structure! \n:::\n\n# INSPECTING THE \"HEART FAILURE\" DATASET\n\n## [What are the variables and their levels of measurement?]{.r-fit-text}\n\n::: {style=\"font-size: 70%;\"}\nThe data, with medical records of **299 heart failure patient**, were collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad (Punjab, Pakistan), during April–December 2015. See @tbl-heart_vars [@chicco_machine_2020, p.3].\n:::\n\n![](../../images/HEART_FAIL_vars.png){#tbl-heart_vars} \n\n\n## Look into the dataset just loaded in the R environment\n\nRecall some `base R` functions from Lab 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What variables are included in this dataset?\ncolnames(heart_failure)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"age\"                      \"anaemia\"                 \n [3] \"creatinine_phosphokinase\" \"diabetes\"                \n [5] \"ejection_fraction\"        \"high_blood_pressure\"     \n [7] \"platelets\"                \"serum_creatinine\"        \n [9] \"serum_sodium\"             \"sex\"                     \n[11] \"smoking\"                  \"time\"                    \n[13] \"DEATH_EVENT\"             \n```\n\n\n:::\n\n```{.r .cell-code}\n# How many observations & variables?\nnrow(heart_failure)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 299\n```\n\n\n:::\n\n```{.r .cell-code}\n# How many rows & columns?\ndim(heart_failure)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 299  13\n```\n\n\n:::\n:::\n\n\n## [Inspect the dataframe structure (`base R`)]{.r-fit-text}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What does the dataframe look like?\nstr(heart_failure)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t299 obs. of  13 variables:\n $ age                     : num  75 55 65 50 65 90 75 60 65 80 ...\n $ anaemia                 : int  0 0 0 1 1 1 1 1 0 1 ...\n $ creatinine_phosphokinase: int  582 7861 146 111 160 47 246 315 157 123 ...\n $ diabetes                : int  0 0 0 0 1 0 0 1 0 0 ...\n $ ejection_fraction       : int  20 38 20 20 20 40 15 60 65 35 ...\n $ high_blood_pressure     : int  1 0 0 0 0 1 0 0 0 1 ...\n $ platelets               : num  265000 263358 162000 210000 327000 ...\n $ serum_creatinine        : num  1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ...\n $ serum_sodium            : int  130 136 129 137 116 132 137 131 138 133 ...\n $ sex                     : int  1 1 1 1 0 1 1 1 0 1 ...\n $ smoking                 : int  0 0 1 0 0 1 0 1 0 1 ...\n $ time                    : int  4 6 7 7 8 8 10 10 10 10 ...\n $ DEATH_EVENT             : int  1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n:::\n\n\n## [Inspect the dataframe structure (`skimr`)]{.r-fit-text}\n\nRemember the `skimr` function `skim`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# some variables \nheart_failure %>% skimr::skim( age, DEATH_EVENT ) \n\n# the whole dataframe\nheart_failure %>% skimr::skim() \n```\n:::\n\n\n<br><br>\n\n::: {.callout-warning icon=false}\n## {{< bi terminal-fill color=rgba(155,103,35,1.00) >}} You try...\nRun `skimr::skim()` on your own either on the whole dataset or on any specific variable\n:::\n\n+ notice there are no (missing values) `NAs` in any of the variables\n\n## [Recode some variables for later ease of analysis]{.r-fit-text} \n\n::: {style=\"font-size: 85%;\"}\nI may need some variables coded as `factor` (e.g. categorical variables for plotting), and, while I am at it, I can add clearer labels for the variables' levels. Here, we are:\n\n+ using tidyverse packages `dplyr` and `forcats`\n+ adding new (recoded) variables called *\"`oldname_f`\"* \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nheart_failure <-heart_failure %>% \n  dplyr::mutate(DEATH_EVENT_f = as.factor(DEATH_EVENT) %>%\n                  forcats::fct_recode(\"died\" = \"1\", \"survived\" = \"0\")) %>% \n  dplyr::mutate(sex_f = as.factor(sex) %>%\n                  forcats::fct_recode(\"male\" = \"1\", \"female\" = \"0\"))\n\n# check \ntable(heart_failure$DEATH_EVENT_f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nsurvived     died \n     203       96 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(heart_failure$sex_f)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nfemale   male \n   105    194 \n```\n\n\n:::\n:::\n\n\n\n## [Some more dummy variables recoded as factor]{.r-fit-text}\n\n::: {style=\"font-size: 70%;\"}\n[Mostly for illustration: it's totally fine (if not preferable) to keep these as binary [0,1] variables]\n\n  + It's worth learning the useful function `dplyr::across`^[This is a bit more [advanced](https://dplyr.tidyverse.org/articles/colwise.html), but it will save a lot of typing in some situations...], which allows to iteratively transform several columns at once!\n  \n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Recode as factor with levels \"yes\" (= 1), \"no\" (= 0)\nfct_cols = c(\"anaemia\", \"diabetes\", \"high_blood_pressure\", \"smoking\" )\n\nheart_failure <- heart_failure  %>% \n  ## ---- 1st create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    # let's introduce `across` function \n    dplyr::across(\n      # Columns to transform\n      .cols = all_of(fct_cols), \n      # Functions to apply to each col  \n      .fns =  ~as.factor (.x),\n      # new name to apply where \"{.col}\" stands for the selected column\n      .names = \"{.col}_f\")) %>% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      # Columns to transform 2 conditions \n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      # Functions to apply to each col(different syntax)\n      .fns = ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))\n```\n:::\n\n\n \n## [(Small digression on `dplyr::across`)]{.r-fit-text}\n\n::: {style=\"font-size: 80%;\"}\nNotice how `dplyr::across(.cols = ..., .fns = ..., .names = ...)` has these arguments:\n\n1. `.cols =` to select the columns which we want to transform (i.e. `fct_cols`)\n    + with help from `tidyselect` functions: `all_of`, `ends_with`, and `matches`\n2.  `.fns = ~function(.x)` to specify the `function`\n            <!-- .fns =  as.factor,  -->\n            <!-- .fns =  function (x) as.factor (x),  -->\n            <!-- .fns =  ~as.factor (.x), -->\n    + where `~function(.x)` uses the \"anonymous function\" syntax of the `tidyverse`\n    + and `.x` inside the function is a \"stand in\" for *each of the columns selected*\n3. [*optional*] `.names =` to name the new cols created using `{.col}` in place of each of the transformed columns\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5,12|6,13|8\"}\n## ---- 1st create new cols as \"factor versions\" of old cols\nheart_failure <- heart_failure  %>% \n  dplyr::mutate(\n    dplyr::across(\n      .cols = all_of(fct_cols), \n      .fns = ~as.factor (.x), \n      # (optional)\n      .names = \"{.col}_f\")) %>% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      .fns =  ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))\n```\n:::\n\n\n\n# [VISUAL DATA EXPLORATION FOR THE \"HEART FAILURE\"]{.r-stretch}\n\n**CONTINUOUS VARIABLES**\n \n## Why is visual exploration important?\n\n::: {style=\"font-size: 90%;\"}\n+ Gaining insight on the variables (range, outliers, missing data)\n+ Preliminary check of assumptions for parametric hypothesis testing:\n  + normally distributed outcome variables?\n  + homogeneity of variance across groups? \n\nLet's explore the **Heart failure dataset** with some data visualization...\n\n+ Following the referenced articles (which were mostly interested in predict mortality based on patients' characteristics), we will take the categorical, binary variable `DEATH_EVENT_f` as our main criterion to split the sample (into *survived* and *dead* patients) to explore any significant difference between groups in terms of means of known quantitative features.   \n+ We will look at both:\n  + **continuous variables** in the dataset (with the Probability Density Function (PDF))\n  + **discrete variables** in the dataset (with the Probability Mass Function (PMF))\n:::\n\n\n\n\n  \n## Age \n\nIntroducing the handy R package `patchwork` which lets us compose different plots in a very simple and intuitive way\n\n  + (check it out with `??patchwork`)\n\n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\nage <-ggplot(heart_failure,aes(x = age ))+\n  geom_histogram(binwidth = 5, color = \"white\", fill = \"grey\",alpha = 0.5)+\n  geom_vline(aes(xintercept = mean(age)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Age Distribution\" )+\n  scale_x_continuous(breaks = seq(40,100,5))  \n\nage2 <-ggplot(heart_failure, aes(x = age, fill = DEATH_EVENT_f))+\n  geom_histogram(binwidth = 5, position = \"identity\",alpha = 0.5,color = \"white\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT == 0])), color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT==1])), color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  labs(title =  \"Age Distribution by group (Death Event)\")+\n  scale_x_continuous(breaks = seq(40,100,5))\n\n# patchwork\nlibrary(patchwork) # The Composer of Plots\nage + age2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![As the age increases, the incidence of death event seems to increase](slides_lab02_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n## Creatinine Phosphokinase (CPK) \n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\ncpk <- ggplot(heart_failure,aes(x = creatinine_phosphokinase))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title = \"Creatinine phosphokinase (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\ncpk2 <- ggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\")\n\ncpk + cpk2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![This definitely doesn't look like a normal distribution!](slides_lab02_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n\n## Ejection Fraction  \n\n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\nejf <- ggplot(heart_failure,aes(x = ejection_fraction))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  geom_vline(aes(xintercept = mean(ejection_fraction)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Ejection Fraction (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nejf2 <- ggplot(heart_failure,aes(x = ejection_fraction,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Ejection Fraction (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nejf + ejf2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![This also doesn’t look like a normal distribution... and there is a remarkable change in the *probability density function* (PDF) shape when we introduce the grouping variable](slides_lab02_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n## Platelets\n\n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\n# normalize the var for readability \nheart_failure  <-  heart_failure %>%  dplyr::mutate(plat_norm = platelets/1000) \n\nplat <- ggplot(heart_failure,aes(x = plat_norm))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  geom_vline(aes(xintercept = mean(plat_norm)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution)\",\n       y = \"Density\", x = \"Sample platelet count (in 10^3 µL)\") \n\nplat2 <- ggplot(heart_failure,aes(x = plat_norm,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution) by group (Death Event)\",\n       caption = \"(Sample platelet count in 10^3 µL)\") \n \nplat + plat2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![Here the probability distributions resemble a Normal one and we observe more uniformity in the mean/variance across the 2 groups](slides_lab02_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n## Serum Creatinine\n\n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\nser_cr <- ggplot(heart_failure,aes(x = serum_creatinine))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  geom_vline(aes(xintercept = mean(serum_creatinine)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Creatinine (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nser_cr2 <- ggplot(heart_failure,aes(x = serum_creatinine,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Serum Creatinine (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_cr + ser_cr2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![Another continuous random variable with a non-normal distribution (long right tails) and a seemingly important difference in variance between the groups. ](slides_lab02_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n## Serum Sodium\n\n\n::: {.cell .fig-cap-location-bottom output-location='slide'}\n\n```{.r .cell-code}\nser_sod <- ggplot(heart_failure,aes(x = serum_sodium))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  geom_vline(aes(xintercept = mean(serum_sodium)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Sodium (density distribution)\" )\n\nser_sod2 <- ggplot(heart_failure,aes(x = serum_sodium,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  labs(title =  \"Serum Sodium (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_sod + ser_sod2 + plot_layout(ncol = 1)\n```\n\n::: {.cell-output-display}\n![Same as above, except for the long left tails...](slides_lab02_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n<!-- # PURPOSE AND FOUNDATIONS OF INFERENTIAL STATISTICS -->\n\n<!-- ## Probability and random variables -->\n\n<!-- ## Meaningful probability distributions -->\n\n<!-- ## Sampling distributions and Central Limit Theorem -->\n\n<!-- ## Confidence Intervals -->\n  \n<!-- # GETTING TO KNOW THE “LANGUAGE” OF HYPOTHESIS TESTING -->\n\n<!-- ## The null and alternative hypothesis -->\n\n<!-- ## The probability of error? (*α* or \"significance level\") -->\n\n<!-- ## The *p-value* probability and tests interpretation -->\n\n<!-- ## Effective vs statistical significance -->\n\n<!-- ## Types of errors (Type 1 and Type 2) -->\n\n\n# [VISUAL DATA EXPLORATION FOR THE \"HEART FAILURE\"]{.r-stretch}\n\n**DISCRETE VARIABLES**\n \n## Anaemia\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nanem <- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = anaemia_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\") +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Anaemia\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Anemia\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nanem\n```\n\n::: {.cell-output-display}\n![There seems to be a greater incidence of anaemia in group 'died'](slides_lab02_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n\n## Diabetes\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\ndiab <- ggplot(heart_failure, \n               aes(x = forcats::fct_infreq(DEATH_EVENT_f ), fill = diabetes_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Diabetes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Diabetes\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\ndiab\n```\n\n::: {.cell-output-display}\n![](slides_lab02_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n## Smoking\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nsmok <- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = smoking_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Patient smokes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients who smoke\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nsmok\n```\n\n::: {.cell-output-display}\n![](slides_lab02_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n## High blood pressure\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nhbp <- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = high_blood_pressure_f ))+\n  geom_bar(position = \"dodge\")+\n    ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has high blood pressure\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with High blood pressure\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nhbp\n```\n\n::: {.cell-output-display}\n![There is also a greater incidence of high blood pressure in group 'died'](slides_lab02_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n# HYPOTHESIS TESTNG - some examples - \n\nLet's continue to explore data from the **heart failure patients' dataset**, but this time using **hypothesis testing** as we learned in Lecture 2. We will do two types of test:\n\n1. Comparing a sample **against a *hypothetical* general population** \n2. Testing if mean variables' **differences between the two groups of patients** (those who survived after heart failure event and those who didn't) is statistically significant \n \n\n# --- EXAMPLE A  --- \n\n**(1 sample | n > 30 |  Z test)**\n\n## [Comparing sample mean to a hypothesized population mean (with Z test)]{.r-fit-text}\n\n::: {style=\"font-size: 90%;\"}\nStating the above hypotheses more formally:\n\n**What is the population Total Platelet Count (TPC) mean for all people who suffered  of heart failure ($𝝁_{HF}$)?** \n\n+ $𝑯_𝟎$ : there is no difference in mean TPC between patients who suffered heart failure and the general population  \n  + $𝝁_{HF}$ = 236 -> hypothesis of no effect or (“no difference”) \n\n+ $𝑯_𝒂$ : there is a difference in mean TPC between patients who have suffered heart failure and the general population (“some effect”). This can be formalized as either:\n  + $𝝁_{HF}$ < 236 (one-sided test), or  \n  + $𝝁_{HF}$ > 236 (one-sided test), or\n  + $𝝁_{HF}$ ≠ 236 (two-sided test) \n:::  \n\n## [1. Question: How does the mean platelets count in the patients’ sample compare against a reference population?]{.r-fit-text}\n \n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# compute mean & sd for plot\nmean_plat_p <- round(mean(heart_failure$plat_norm), digits = 1)\nsd_plat_p <- round(sd(heart_failure$plat_norm), digits = 1)\n \nheart_failure %>% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.0085, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.0085, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/µL)\") \n```\n\n::: {.cell-output-display}\n![For a general population, the Total Platelet Count (TPL) has 𝛍=236 (1000 /µL) and 𝛔= 59 (1000 /µL). Below is the sample distribution:](slides_lab02_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n::: aside\nGeneral population data taken from the literature [See @wongsaengsak_significance_2019].\n:::  \n\n## 2.a Computation of the test statistic \n::: {style=\"font-size: 90%;\"}\nIn this case, we have: \n\n+ a large sample $(n > 100)$\n+ a known $𝛔^𝟐$ (of the reference population)\n+ the observed sample mean $\\bar{x}$ and sample sd $s$. \n\nSo we can compute: \n\n$𝒁_{calc}=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}$\n\n+ ✍🏻 Let's do it \"by hand\" first to see the steps \n\n::: {.cell}\n\n```{.r .cell-code}\n# General Population of reference \nmu <- 236 \nsigma  <- 59\n# Sample of HF patients\nn <- 299\nx_HF <- mean(heart_failure$plat_norm)         #    263.358\ns_HF <- sd(heart_failure$plat_norm)           #    97.80424\n# IF large sample & KNOWN pop variance \nstd_err_HF <- sigma /sqrt(n)                  # 3.412058\nz_calc_HF <-  (x_HF - mu) / std_err_HF        # 8.018043\n```\n:::\n\n:::\n\n## 2.b Computation of the p-value associated to the test statistic  \n\nTo find the **p-value** associated with a z-score in R, we can use the `pnorm()` function, which uses the following syntax:\n\n  + `q`: The z-score\n  + `mean`: The mean of the normal distribution. Default is 0.\n  + `sd`: The standard deviation of the normal distribution. Default is 1.\n  + `lower.tail`: \n    + If TRUE, the probability to the left of q in the normal distribution is returned \n    + If FALSE, the probability to the right is returned. Default is TRUE.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Left-tailed test\np_value_l <- stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = TRUE) \n# Right-tailed test\np_value_r <- stats::pnorm(z_calc_HF, mean = 0, sd = 1,lower.tail = FALSE) \n# Two-tailed test  (our case)\np_value_two <- 2*stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = FALSE)  \n```\n:::\n\n\n## 2.c Computation of the p-value associated to the test statistic  \n\n+ 👩🏻‍💻 Let's see how this could be done using an R function `BSDA::z.test`\n\n::: {.cell}\n\n```{.r .cell-code}\nz_test_summary <- BSDA::z.test(x = heart_failure$plat_norm,   \n             alternative='two.sided', \n             mu=236, \n             sigma.x=59, \n             conf.level=.95)\nz_test_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne-sample z-Test\n\ndata:  heart_failure$plat_norm\nz = 8.018, p-value = 1.074e-15\nalternative hypothesis: true mean is not equal to 236\n95 percent confidence interval:\n 256.6705 270.0455\nsample estimates:\nmean of x \n  263.358 \n```\n\n\n:::\n:::\n\n\nSame results! \n\n## 3. Results and interpretation\n\n1.  Based on the critical region, the calculated test statistic `z_calc_HF = 8.0180` falls in the CRITICAL REGION (well beyond the critical point) \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# given \nz_critical  <- c(-1.96, +1.96) # (Z score corresponding to 𝛼  = 0.05)\n# Check \nz_calc_HF > z_critical \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE\n```\n\n\n:::\n:::\n\n\n2.  Based on the p-value, `p_value_two = 1.07443e-15` is much much smaller than $\\alpha$  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check\np_value_two <  0.05\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n**DECISION**: we reject the Null Hypothesis (basically we conclude that it is extremely unlikely that the sample we drew could have occurred just by chance). So the test indicates that, indeed, there is a difference between heart failure patients and the general population in terms of average platelets count.\n\n# --- EXAMPLE B --- \n\n**(1 sample | n < 30 | t test)**\n\n## Comparing sample mean to a hypothesized population mean (with t test)\n\n::: {style=\"font-size: 80%;\"}\nSame question, but with a *smaller sample* to work on (this varies, but generally it means $n < 30$). Imagine the patients were only observed over a **follow-up period of 21 days**, and also let's assume we don't know the population’s variance\n\nStating the hypothesis more formally:\n\n**What is the population Total Platelet Count (TPC) mean for all people who suffered  of heart failure ($𝝁_{HF21d}$) in the past 21 days or less?** \n\n+ $𝑯_𝟎$ : there is no difference in mean TPC between patients who suffered heart failure (visited in 21 days) and the general population  \n  + $𝝁_{HF21d}$ = 236 -> hypothesis of no effect or (“no difference”) \n\n+ $𝑯_𝒂$ : there is a difference in mean TPC between patients who have suffered heart failure and the general population (“some effect”). This can be formalized as:\n  + $𝝁_{HF21d}$ ≠ 236 (two-sided test) \n\n:::\n\n\n## [1. Question: How does the mean platelets count in the patients’ sample compare against a reference population?]{.r-fit-text}\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# normalize the var for readability \nheart_21d  <-  heart_failure %>%  dplyr::mutate(plat_norm = platelets/1000) %>% \n  filter(time <= 21)                                # 23 obs \n# compute mean & sd for plot\nmean_plat_p <- round(mean(heart_21d$plat_norm), digits = 1)\nsd_plat_p <- round(sd(heart_21d$plat_norm), digits = 1)\n \nheart_21d %>% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.014, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.014, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/µL)\") \n```\n\n::: {.cell-output-display}\n![For a general population, the Total Platelet Count (TPL) has 𝛍=236 (1000 /µL) and 𝛔= 59 (1000 /µL). Below is the smaller sample distribution:](slides_lab02_files/figure-revealjs/unnamed-chunk-25-1.png){width=960}\n:::\n:::\n\n\n\n## 2.a Picking the suitable test   \n\nIn this case, we have: \n\n+ a \"small\"  sample $n = 23$\n+ an unknown $𝛔^𝟐$ (of the reference population)\n+ We obtained the sample mean $\\bar{x}$ and sample sd $s$. \n\nSo we can compute: \n\n$t_{calc} =\\frac{\\bar{x}-\\mu}{\\frac{s_\\bar{x}}{\\sqrt{n-1}}}$\n\n\n\n## 2.b Computation of the test statistic \n\n::: {style=\"font-size: 80%;\"}\n\n+ Option 1: Let's compute the t test \"by hand\" ✍🏻\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# General Population of reference \nmu_pop <- 236 \n\n# SAMPLE HF patients follow up less 21 days \nheart_21d <- heart_failure %>% filter(time <= 21) \n\nn_21d <- nrow(heart_21d)                            # 23\nx_HF_21d <- mean(heart_21d$plat_norm)               # 251.5094\ns_HF_21d <- sd(heart_21d$plat_norm)                 # 102.7341\ndf_HF_21d <- n_21d-1                                # 22   \n\n# IF SMALL sample UNKNOWN sigma\nstd_err_HF_21d <- s_HF_21d /sqrt(n_21d -1)        # 21.90298\nt_calc <-  (x_HF_21d - mu_pop) / std_err_HF_21d   # 0.7080951\n```\n:::\n\n\n+ Option 2:  Let's compute the t test  with `stats::t.test` 👩🏻‍💻\n\n::: {.cell}\n\n```{.r .cell-code}\nt_stat_HF_21d_v2 <- stats::t.test(x = heart_21d$plat_norm,\n                                  mu = mu_pop,\n                                  alternative = \"two.sided\")\n# extract t_calc from results df\nt_calc_v2  <- t_stat_HF_21d_v2[[\"statistic\"]][[\"t\"]] # 0.7240093\n```\n:::\n\n\n::: {.aside}\nThere is a small difference in the `t_calc ≠ t_calc_v2` due to the fact that I use the Bessel's correction `n-1` in the **sample standard deviation formula** denominator, while the R function uses `n`\n:::\n\n::: \n\n\n## [2.c Computation of the p-value associated to the test statistic]{.r-fit-text} \n\n::: {style=\"font-size: 75%;\"}\n+ Option 1:  \"by hand\" ✍🏻\n\nTo find the **p-value** associated with a t-score in R, we can use the `pt(q, df, lower.tail = TRUE)` function, which uses the following syntax:\n\n  + `q`: The t-score\n  + `df`: The degrees of freedom\n  + `lower.tail`: \n     + TRUE  to calculate the probability to the left of q which is called as left-tailed test \n     + FALSE as right-tailed test.\n     \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Option 1 \n# -- Left-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = TRUE)\n\n# -- Right-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = FALSE) \n\n# -- Two-tailed test  (our case)\np_value_t_test <- 2*pt(t_calc, df_HF_21d, lower.tail = FALSE) # 0.4863214\n```\n:::\n\n\n+ Option 2: from results of `stats::t.test` 👩🏻‍💻\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---- Option 2 \n# extract  p_value from results df\np_value_v2  <- t_stat_HF_21d_v2[[\"p.value\"]] # 0.4766892\n```\n:::\n\n:::\n\n## 3. Results and interpretation\n\n::: {style=\"font-size: 80%;\"}\n1.  Based on the critical region, `t_calc ≃ 0.71` is smaller than the t critical value, i.e. it falls within the region of acceptance, so he null hypothesis is not rejected\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#find two-tailed t critical values\n\nt_crit_two <- qt(p=.05/2, df=22, lower.tail=FALSE)    # 2.073873\n# Compare t score against t critical    \nt_calc > t_crit_two  # FALSE \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n2.  Based on the p-value, `p_value ≃ 0.48` is larger than $\\alpha$, i.e. the probability of observing a test statistic (assuming  $H_0$ is true) is quite large\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check \np_value_t_test <  0.05  # FALSE \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n**DECISION**: we FAIL to reject $H_0$. So the test indicates that there is not a statistically significant difference between heart failure patients visited within 21 days and the general population in terms of average platelets count.\n\n::: {.callout-note}\nWhat changed testing a sample with smaller `n`, instead of a large one? \n\n<!-- small n >>> bigger se >>> smaller t calc >>> weaker evidence to reject the null -->\n:::\n\n:::\n\n\n\n# --- EXAMPLE C  --- \n**(2 samples | t test)**\n\n## [Comparing two independent sample means (t test)]{.r-fit-text}\n\n::: {style=\"font-size: 80%;\"}\nThis time, we investigate if there might be an actual difference in the Platelet Count means **between the patients who died and the patients who survived** heart failure.\n\nStating the above hypotheses more formally:\n\n**Is there a statistically significant difference between the mean values of two groups?** \n\n+ $𝑯_𝟎$ : The two population means are equal\n  + $𝝁_𝟏 = 𝝁_𝟎 ⟺ 𝝁_𝟏−𝝁_𝟎=𝟎$  \n+ $𝑯_𝒂$ : There is a mean difference between the two groups in the population. Possible directional difference formulation (two-tailed, left-tailed, right-tailed) \n  + $𝝁_𝟏≠𝝁_𝟎  ⟺ 𝝁_𝟏−𝝁_𝟎≠𝟎$ (the two population means are not equal)\n  + $𝝁_𝟏 < 𝝁_𝟎  ⟺ 𝝁_𝟏−𝝁_𝟎<𝟎$ (population 1 mean is less than population 0 mean)\n  + $𝝁_𝟏 > 𝝁_𝟎  ⟺ 𝝁_𝟏−𝝁_𝟎>𝟎$  (population 1 mean is greater than population 0 mean)\n\n:::\n\n## [Comparing two independent sample means (t test) (cont.)]{.r-fit-text}\n\n[1. Question: Is there a statistically significant difference between the Platelet Counts in the patients who died v. survived heart failure?]{.r-fit-text}\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# boxplot by group\nheart_failure %>% \n  ggplot(mapping = aes(y = plat_norm, x = DEATH_EVENT_f, fill = DEATH_EVENT_f)) +\n  geom_boxplot(alpha=0.5)+ \n  #geom_violin(alpha=0.5) +\n  geom_point(position = position_jitter(width = 0.1), size = 0.5)+ \n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))  +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        legend.position = \"none\",\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\")) + \n  labs(title = \"Boxplot of Total Platelet Count (TPL), grouping by DEATH_EVENT [0,1]\",\n       x = \"\", y  = \"Platelet count (1000 /µL)\")\n```\n\n::: {.cell-output-display}\n![There seems to be no major difference in the two groups](slides_lab02_files/figure-revealjs/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n## 2. Verify the assumptions for independent t-test\n\n1. The 2 samples (“died” and “survived”) must be independent ✅\n2. The dependent variable is scaled in intervals (Platelets Count in 10^3 \"/µL\") ✅\n3. The dependent variable is normally distributed (Platelets Count in 10^3 \"/µL\") ✅\n  + (If not, use *non parametric* test)  \n4. The variance within the 2 groups should be similar ❓\n  + (If not, perform Welch’s t-test) \n\n## [Preliminary Fisher's F test to check for variance equality]{.r-stretch}\n\n+ We can compute the Fisher test \"by hand\" ✍🏻 \n\n::: {.cell}\n\n```{.r .cell-code}\n## -- data by group\nn_died <- nrow(heart_failure[heart_failure$DEATH_EVENT == 1 ,])\nmean_died <- mean(heart_failure [ heart_failure$DEATH_EVENT == 1,  \"plat_norm\"])\nsd_died <- sd(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\nvar_died <- var(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\n\nn_survived <- nrow(heart_failure[heart_failure$DEATH_EVENT == 0, ])\nmean_survived <- mean(heart_failure [ heart_failure$DEATH_EVENT == 0,  \"plat_norm\"])\nsd_survived <- sd(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\nvar_survived <- var(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\n\n## -- F TEST\nF_ratio <- var_died / var_survived\nF_ratio  # 1.020497 \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.020497\n```\n\n\n:::\n:::\n\n\n## [Preliminary Fisher's F test to check for variance equality (.cont)]{.r-stretch}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## -- Define the critical value of F distribution for a risk of alpha = 0.05\n# qf(p=.05, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # RIGHT-Tailed\n# qf(0.95, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # LEFT- Tailed \nqf(c(0.025, 0.975), df1 = n_died-1, df2 = n_survived-1) # TWO-Tailed \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6994659 1.3987233\n```\n\n\n:::\n\n```{.r .cell-code}\n## --Compute the exact p-value (two-tailed )\np_value_f <- 2 * (1 - pf(F_ratio, df1 = (n_died-1), df2 = (n_survived-1))) \np_value_f\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8914982\n```\n\n\n:::\n:::\n\n\nA test statistic (F) of 1.02 is obtained, with degrees of freedom 95 and 202. \n\nThe p-value is 0.89, greater than the p-value threshold of 0.05. This suggests **we can not reject the null hypothesis of equal variances**. \n\nThe variance within the 2 groups should be similar ✅  --> we can run a t-test.\n\n## 3.a Computation of t test statistic  \n\n::: {style=\"font-size: 80%;\"}\nSince we verified the required assumptions, the test method is the independent (two-sample) t-test. In this case, we have: \n\n+ a large sample $(𝐧_𝟏 +𝐧_𝟐 > 100)$\n+ the population variance(s) are unknown, but we can assume = variances in 2 groups  \n+ $standard\\, error$ of the means' difference is obtained as **pooled estimate standard deviation of the sampling distribution of the difference**\n\nSo we can compute: $t_{calc} = \\frac{Difference\\,Between\\,Sample\\,means}{Std.\\,Err.\\,of\\,the\\,difference} = \\frac{\\bar{x_1} -\\bar{x_2}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}}+\\frac{s_{2}^{2}}{n_{2}}}}$\n::: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1 - compute difference of sample means\nmean_diff <- (mean_died - mean_survived) # -10.27645 \n\n# Step 2 - Compute associated t-statistics\n# pooled std error \npooled_stderror <- sqrt(sd_died^2/(n_died ) + sd_survived^2/(n_survived )) \n# pooled std error corrected\npooled_stderror_corr <- sqrt(sd_died^2/(n_died-1) + sd_survived^2/(n_survived-1)) \n\n###  t statistic  \nt_calc <- (mean_died - mean_survived) / pooled_stderror_corr \n```\n:::\n\n\n## 3.b Computation of the p-value associated to the t statistic  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 3 - degrees of freedom\n# n1 + n2 - number of estimated parameters (2 means)\nd_f <- n_died + n_survived - 1 - 1 # 297\n\n# Step 4 - Deduced p-value\np_value <- 2 * pt(t_calc, df = d_f) # 0.4009635\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4009635\n```\n\n\n:::\n:::\n\n\n## 4. Results and interpretation\n::: {style=\"font-size: 80%;\"}\n1.  Looking at the confidence interval of the difference, the `sample mean_diff` is well inside the 95% CI of = population mean \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_diff\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -10.27645\n```\n\n\n:::\n\n```{.r .cell-code}\n# CI of the means difference \nCI_lower <- mean_diff + qt(.025, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_lower\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -34.32074\n```\n\n\n:::\n\n```{.r .cell-code}\nCI_upper <- mean_diff + qt(.975, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_upper\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.76785\n```\n\n\n:::\n:::\n\n\n2. As for the p-value, `p_value = 0.40` is  bigger than threshold probability $\\alpha$  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check \np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4009635\n```\n\n\n:::\n\n```{.r .cell-code}\np_value <  0.05  # FALSE \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n**DECISION**: So, we  fail to reject the null hypothesis of equal populations means of TPC. So the test indicates that we do not have sufficient evidence to say that the mean counts of platelets in between these two populations is different.\n:::\n\n# --- EXAMPLE D  --- \n\n<!-- (esempio metabolomica Catanzaro?) -->  \n    \n**(3+ samples |  ANOVA test)**\n\n## Comparing sample means from 3 or more groups (ANOVA)\n\nIn this example, we adopt the ANOVA (“Analysis Of Variance”) test, i.e. an extension of the previous test, but examined how means of a variable differ across 3 or more groups. We will use **‘one- way’ ANOVA**, which serves when there is only one explanatory variable (“treatment”) with 3 or more levels, and only one level of treatment is applied for a given subject. \n\nFor this particular case, we use another realistic dataset showing the survival times of 33 laboratory mice  with thymic leukemia who were randomly divided into 3 groups: \n\n  + 1st group received Treatment 1\n  + 2nd group received Treatment 2\n  + 3rd group as Control\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load new dataset\nmice <- readxl::read_excel(here::here(\"practice\",\"data_input\",\n                                      \"02_datasets\",\"mice_exe_ANOVA.xlsx\"))\n```\n:::\n\n\n\n## [1. Question: Is there a statistically significant difference between the mean values of the k populations? ]{.r-fit-text}\n\nDefining the question formally: \n\n+ $𝑯_𝟎$ : $𝝁_𝟏 = 𝝁_𝟐 =  𝝁_3$  all 3 population means are equal\n+ $𝑯_𝒂$ : at least one of  $(𝝁_𝟏,𝝁_𝟐,𝝁_3)$ is not equal to the other means     \n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# boxplot by group\nmice %>% \nggplot(., aes(x = group, y = surv_days, fill = group)) +\n  geom_boxplot() + \n  scale_fill_viridis(discrete = TRUE, alpha=0.6, option=\"A\") +\n  geom_jitter(color=\"black\", size=0.4, alpha=0.9) +\n  # theme_minimal() +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\"),\n        legend.position = \"none\",\n        ) + \n  labs(title = \"Visually check mean and variance in populations' samples\" ) + \n  ylab(label = \"Survival (# days\") + xlab(label = \"\")\n```\n\n::: {.cell-output-display}\n![The boxplot suggests that the 3 groups might have some fairly different distributions](slides_lab02_files/figure-revealjs/unnamed-chunk-40-1.png){width=960}\n:::\n:::\n\n\n## 2. Verify the assumptions for one-way ANOVA\n\nThe dependent variable is on a metric scale. In the case of the analysis of variance, the independent variable (factor) has at least three levels. \n\nAssumptions for the results of a one-way ANOVA to be valid:\n\n1. **Independence of observations** – The observations in each group are independent of each other and the observations within groups were obtained by a random sample. ✅\n2. **Normally-distributed response variable** – The values of the dependent variable follow a normal distribution. ❓\n3. **Homogeneity of variance** – The variances of the populations that the samples come from are equal. ❓\n\n## [Preliminary check for normality (visual)]{.r-stretch}\n\n2. **Normally-distributed response variable**  ✅ \n\n  + (confirmed by visual inspection )\n \n\n::: {.cell}\n::: {.cell-output-display}\n![](slides_lab02_files/figure-revealjs/unnamed-chunk-41-1.png){width=960}\n:::\n:::\n\n\n\n## [Preliminary check for normality (test) with `stats::shapiro.test`]{.r-stretch}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk Normality Test to verify normality  \n# option 1 \nstats::shapiro.test(mice[mice$group == \"Control\", \"surv_days\", drop=TRUE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Control\", \"surv_days\", drop = TRUE]\nW = 0.99374, p-value = 0.9989\n```\n\n\n:::\n\n```{.r .cell-code}\nstats::shapiro.test(mice[mice$group == \"Treatment 1\", \"surv_days\", drop=TRUE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 1\", \"surv_days\", drop = TRUE]\nW = 0.95716, p-value = 0.6106\n```\n\n\n:::\n\n```{.r .cell-code}\nstats::shapiro.test(mice[mice$group == \"Treatment 2\", \"surv_days\", drop=TRUE])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 2\", \"surv_days\", drop = TRUE]\nW = 0.97921, p-value = 0.9601\n```\n\n\n:::\n:::\n\n\n## [Preliminary check for normality (test) with `rstatix::shapiro_test`]{.r-stretch}\n\n_(same thing, but using a different R function)_\n\n2. **Normally-distributed response variable** – ✅ \n  + (confirmed by Shapiro-Wilk normality test)\n\n[The null hypothesis of this test is **$H_0$ = “sample distribution is normal”** ] \n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk Normality Test to verify normality  \n# option 2 (all 3 groups at once)\nmice %>%\n  dplyr::group_by(group) %>%\n  rstatix::shapiro_test(surv_days)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  group       variable  statistic     p\n  <chr>       <chr>         <dbl> <dbl>\n1 Control     surv_days     0.994 0.999\n2 Treatment 1 surv_days     0.957 0.611\n3 Treatment 2 surv_days     0.979 0.960\n```\n\n\n:::\n:::\n\n\n## [Preliminary check variance equality ]{.r-stretch}\n::: {style=\"font-size: 85%;\"}\n3. **Homogeneity of variance** – ✅ \n  + (Besides visual inspection, confirmed  by Levene test for variance equality)\n\n[The null hypothesis **$H_0$ = several groups have the same variance** (possible variance differences occur only by chance, since there are small differences in each sampling)]\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Levene test for variance equality\nlevene <- mice %>%                               # name of the data\n  car::leveneTest(surv_days ~ as.factor(group),   # continuous DV ~  group IV\n                  data = .,            # pipe the data from above\n                  center = mean)       # default is median \nlevene\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df F value Pr(>F)\ngroup  2  0.1721 0.8427\n      30               \n```\n\n\n:::\n:::\n\n\nNo evidence of violations of HOV were found, since the p-value for the Levene test (= 0.8427157) is greater than .05, then the variances are not significantly different from each other (i.e., the homogeneity assumption of the variance is met). \n:::\n\n## [3 Computation of ANOVA F-ratio]{.r-fit-text} \n\nANOVA in R can be done in several ways.\n\nSince it's quite straightforward, let's do all the steps by hand first. We need to obtain the needed \"ingredients\" to calculate the F-ratio: \n\n$$𝑭_{calc}=\\frac{Mean\\, Square\\, Between}{Mean, Square\\, Within}=  \\frac{MSB}{MSW} = \\frac{\\frac{SSB}{df1}}{\\frac{SSW}{df2}} $$\n\n## [3.a Computation of ANOVA F-ratio (\"by hand\")]{.r-fit-text} \n::: {style=\"font-size: 80%;\"}\n+ Option 1: Let's compute the ANOVA test \"by hand\" ✍🏻 \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary statistics\nmice_calc <- mice %>% \n  dplyr::mutate(mean_all = mean(surv_days),\n         sd_all = sd (surv_days),\n         dfw = 33-3, # df1 = n-k\n         dfb = 3-1, # df2 = K−1 \n         group_f = as.factor(group)\n         ) %>% \n  dplyr::group_by(group) %>% \n  dplyr::mutate(n_group = n(),\n         mean_group = mean(surv_days),\n         sd_group = sd (surv_days)) %>% \n  ungroup() %>% \n  mutate (ST = (surv_days - mean_all)^2,\n          SW = (surv_days - mean_group)^2,\n          SB = (mean_group - mean_all)^2)\n\n# Sum of Squares \nSST <- sum(mice_calc$ST)\nSSB <- sum(mice_calc$SB)\nSSW <- sum(mice_calc$SW)\ndfw <- 33-3  # df2\ndfb <- 3-1 # df1\n\n# calculated F statistic \nF_calc <- (SSB/dfb)/(SSW/dfw) # 5.65\n# F critical value\nF_crit <- qf(p = 0.01, df1 = 2, df2 = 30, lower.tail = FALSE) # 5.390346\n```\n:::\n\n:::\n\n## [3.b Computation of ANOVA F-ratio (with R functions)]{.r-fit-text} \n\n::: {style=\"font-size: 90%;\"}\nThat was just to show how to build it step-by-step (🤓), but we don't have to! We have alternative R functions that can do ANOVA for us:\n\n+ Option 2: With the `stats::aov` followed by the command `summary` 👩🏻‍💻\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_1 <- stats::aov(surv_days ~ group_f,\n                 data = mice_calc)\nsummary(aov_1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \ngroup_f      2  434.6  217.32   5.652 0.00826 **\nResiduals   30 1153.4   38.45                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n+ Option 3: With the `stats::oneway.test()` function 👩🏻‍💻\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov_2 <- stats::oneway.test(surv_days ~ group_f,\n            data = mice_calc,\n            # assuming equal variances\n            var.equal = TRUE)\naov_2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne-way analysis of means\n\ndata:  surv_days and group_f\nF = 5.6522, num df = 2, denom df = 30, p-value = 0.008258\n```\n\n\n:::\n:::\n\n \n:::\n\n\n## 4. Results and interpretation\n \nAll 3 options have given the same results, i.e., `F-ratio = 5.652` and a  `p-value = 0.00826`\n\n\n**DECISION**: Given that the p-value is smaller than 0.05, we reject the null hypothesis, so we reject the hypothesis that all means are equal. Therefore, we can conclude that *at least one* group is different than the others in mean number of survival days.\n\n\n::: {.callout-note}\nHave you seen the kind of notation `Pr(>F) 0.00826 **` before (as in the output of the `stats::aov` function)?  \n:::\n\n\n# A CLOSER LOOK AT TESTING ASSUMPTIONS \n\n# --- EXAMPLE E  --- \n\n\n## [Testing two groups that are *not* independent]{.r-fit-text}\n\nLet's introduce another toy dataset just for demonstration purposes: imagine a statistics test is administered to the *same* group of 12 students **before and after** attending a workshop 😉. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# toy dataset for paired groups\ngrades <- data.frame(\n  before = c(16, 5, 15, 2, 14, 15, 4, 7, 15, 6, 7, 14),\n  after = c(19, 18, 9, 17, 8, 7, 16, 19, 20, 9, 11, 18)\n)\n```\n:::\n\n\nWe may reshape the dataframe into the long form using `tidyr::pivot_longer` (for plotting)\n\n::: {.cell}\n\n```{.r .cell-code}\n# reshape into long form\ngrades_long <- grades %>% \n  dplyr::mutate(id = row_number()) %>%\n  tidyr::pivot_longer(cols = before:after, \n                      names_to = \"time\", \n                      values_to = \"grade\") %>% \n  dplyr::group_by(id) %>% \n  # recode time as factor \n  dplyr::mutate(time_f = as_factor(time ))  %>% \n  # reorder time_ levels  \n  dplyr::mutate(time_f =  fct_relevel(time_f, \"after\", after =  1))\n```\n:::\n\n\n## [1. Question: Is the difference between two PAIRED samples statistically significant?]{.r-fit-text} \n\n\n::: {.cell}\n::: {.cell-output-display}\n![What a successful workshop! 😁](slides_lab02_files/figure-revealjs/unnamed-chunk-50-1.png){width=960}\n:::\n:::\n\n\n## [2 Hypotehsis for the PAIRED t-test for dependent samples]{.r-fit-text}  \n\n::: {style=\"font-size: 90%;\"}\nIn this example, it is clear that the two samples are not independent since the same 12 students took the test before and after the workshop.\n\nGiven that the normality assumption is NOT violated (and given the small sample size), we use the **paired t-test**, with the following hypotheses:\n\n+ $𝑯_𝟎$ : mean grades before and after the workshop are equal\n+ $𝑯_𝒂$ : mean grades before and after the workshop are different\n\n:::\n\n## [2 Computation of the PAIRED t-test for dependent samples]{.r-fit-text}   \n\n\n<!-- ```{r} -->\n<!-- # # Wilcoxon signed-rank test  -->\n<!-- # test <- stats::wilcox.test(grades_long$grade ~ grades_long$time_f, -->\n<!-- #                            paired = TRUE) -->\n<!-- # # results -->\n<!-- # test -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- # paired t test  -->\n<!-- n = 12 -->\n<!-- grades_diff <- grades %>%  -->\n<!--   # diff of each pair -->\n<!--   mutate (diff = after-before) -->\n<!-- # the mean value x̄diff is then calculated.  -->\n<!-- x_diff <- mean(grades_diff$diff) # 4.5  -->\n<!-- sd_diff <- sd(grades_diff$diff) # 7.840744 -->\n<!-- stderr <- sd_diff / sqrt(n) # 2.263428 -->\n<!-- t_calc <- (x_diff - 0)/stderr # 1.877683 -->\n<!-- df <- n-1  # 11 -->\n\n<!-- ``` -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_stat_paired <- stats::t.test(x = grades$before,\n                               y = grades$after, \n                               mu = 0, \n                               alternative = \"two.sided\",\n                               paired = TRUE\n)\nt_stat_paired\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  grades$before and grades$after\nt = -1.8777, df = 11, p-value = 0.08718\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -9.2317713  0.7317713\nsample estimates:\nmean difference \n          -4.25 \n```\n\n\n:::\n\n```{.r .cell-code}\n# extract t_calc from results df\nt_calc_pair   <- t_stat_paired[[\"statistic\"]][[\"t\"]] # -1.877683\np_value_pair   <- t_stat_paired[[\"p.value\"]] # 0.08717703\n```\n:::\n\n\n\n## 3. Results and interpretation\n\nWe obtain the test statistic, the p-value and a reminder of the hypothesis tested.\n\nThe calculated **t value** is -1.8776829 The **p-value** is 0.087177. Therefore, at the 5% significance level, **we do not reject the null hypothesis** that the statistics' grades are similar before and after the workshop (😭).\n\n\n## Bonus function! \n\nIt is worth mentioning the `ggstatsplot` package, which combines plots representing the distribution for each group—and the results of the statistical test displayed in the subtitle of the plot. \n\nBelow we check out the `ggwithinstats()` function for *paired samples.*\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# load package\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details\n\n# plot with statistical results\ngrades_long %>% \n  # must ungroup the dataframe or it will give an error\n  ungroup () %>% \n  ggstatsplot::ggwithinstats(.,\n                             x = time_f ,\n                             y = grade ,\n                             type = \"parametric\", # for t test \n                             centrality.plotting = FALSE # remove median\n  )\n```\n\n::: {.cell-output-display}\n![The test results are rendered with the plot!](slides_lab02_files/figure-revealjs/unnamed-chunk-52-1.png){width=960}\n:::\n:::\n\n\n# --- EXAMPLE F  --- \n\n**(2 samples no normal | Wilcoxon Rank Sum Test)**\n\n## Testing samples *without* normality assumption\n\nLet’s go back to the HEART FAILURE dataset but looking at the levels of **Creatinine Phosphokinase (CPK)** in the blood, an enzyme that might indicate a heart failure or injury\n\n\n## [1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?]{.r-fit-text}\n\nDefining the question formally: \n\n+ $𝑯_𝟎$ : $𝝁_{CPK-died} = 𝝁_{CPK-surv}$  there is no difference in mean CPK between patients who suffered heart failure  and died  versus patients who survived after heart failure\n\n+ $𝑯_𝒂$ : $𝝁_{CPK-died} ≠ 𝝁_{CPK-surv}$  there is a difference in mean CPK between patients who suffered heart failure  and died  versus patients who survived after heart failure (two-sided test)   \n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  guides(fill = \"none\") +\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\") + \n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))\n```\n\n::: {.cell-output-display}\n![The density plot suggests non normality of the variable distribution](slides_lab02_files/figure-revealjs/unnamed-chunk-53-1.png){width=960}\n:::\n:::\n\n\n## [Preliminary check for normality (visual)]{.r-stretch}\n\n+ **Normally-distributed response variable** - ❌\n\n**QQ plot** (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. A 45-degree reference line is also plotted. In a QQ plot, each observation is plotted as a single dot. \n  \n  + If the data are normal, the dots should form a straight line.\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n# visual verification with QQ plot \nggpubr::ggqqplot( \n  heart_failure$creatinine_phosphokinase, \n  title = \"QQ plot for CPK levels in blood\",\n  xlab =\"Theoretical\", ylab = \"Sample (CPK)\")\n```\n\n::: {.cell-output-display}\n![In a QQ plot, if the data are normal, the dots should follow a straight line.](slides_lab02_files/figure-revealjs/unnamed-chunk-54-1.png){width=960}\n:::\n:::\n\n\n\n## [Preliminary check for normality (test) with `rstatix::shapiro_test`]{.r-stretch}\n\n(same thing, but using a different R function)\n\n+ **Normally-distributed response variable** - ❌\n  + (NOT normality confirmed by Shapiro-Wilk normality test)\n\n[The null hypothesis of this test is **$H_0$ = “sample distribution(s) is/are normal”** ] \n\nGiven the p-value we reject the null hypothesis\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro-Wilk Normality Test to verify normality  \nheart_failure %>%\n  dplyr::group_by(DEATH_EVENT_f) %>%\n  rstatix::shapiro_test(creatinine_phosphokinase)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  DEATH_EVENT_f variable                 statistic        p\n  <fct>         <chr>                        <dbl>    <dbl>\n1 survived      creatinine_phosphokinase     0.628 8.51e-21\n2 died          creatinine_phosphokinase     0.439 1.99e-17\n```\n\n\n:::\n:::\n\n\n## [3. Computation of the Wilcoxon Rank Sum test statistic]{.r-fit-text} \n\nThe **Wilcoxon Rank Sum test** is considered to be the nonparametric equivalent to the **two-sample independent t-test**\n\nIts ASSUMPTIONS are:\n\n+ Ordinal or Continuous dependent variable: e.g. CPK levels ✅\n+ Independence: All of the observations from both groups are independent of each other ✅\n+ Shape: The shapes of the distributions for the two groups are roughly the same ✅\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrs_res <- wilcox.test(creatinine_phosphokinase ~ DEATH_EVENT, # immagino 0, 1\n                   data = heart_failure ,\n                   exact = FALSE, \n                   alternative = \"two.sided\" )\nwrs_res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  creatinine_phosphokinase by DEATH_EVENT\nW = 9460, p-value = 0.684\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n::: aside\nThe **Wilcoxon Rank Sum test** is equivalent to the **Mann-Whitney U test** to compare two independent samples. Different software use one or the other.\n\n:::\n\n## [4. Results and interpretation]{.r-fit-text}\n\nRESULTS: since the test statistic is `W = 9460` and the corresponding `p-value is 0.684 > 0.05`, we fail to reject the null hypothesis.\n\nINTERPRETATION: We do not have sufficient evidence to say that CPK levels for dead patients is different than that of survived patients $𝝁_{CPK-died} ≠ 𝝁_{CPK-surv}$ at some statistically significant level)\n\n# --- EXAMPLE G  --- \n\n**(2 samples no HOV | t test with the Welch correction  )**\n\n## Testing samples *without* homogeneous variance of observations assumption\n\n## [1. Question: Is there a statistically significant difference between serum sodium levels in the blood of the survivors v. those who died after heart failure?]{.r-fit-text}\n\nDefining the question formally: \n\n+ $𝑯_𝟎$ : $𝝁_{sersod-died} = 𝝁_{sersod-surv}$  there is no difference in mean serum sodium between patients who suffered heart failure  and died  versus patients who survived after heart failure\n\n+ $𝑯_𝒂$ : $𝝁_{sersod-died} ≠ 𝝁_{sersod-surv}$  there is a difference in mean serum sodium between patients who suffered heart failure  and died  versus patients who survived after heart failure (two-sided test)   \n\n\n## [Preliminary check “HOV” assumption (visual)]{.r-stretch}\n\n::: {style=\"font-size: 85%;\"}\n+ **Homogeneity of Variance assumption** - ❌\nPlotting the data offers some graphical intuition that the variance of observations in the two groups seem not homogenous\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\n#Compute means and 95% confidence intervals\nswstats <- heart_failure %>%\n  group_by(DEATH_EVENT_f) %>%\n  summarise(count = n(),\n    mean = mean(serum_sodium,na.rm=TRUE),\n    stddev = sd(serum_sodium, na.rm=TRUE),\n    meansd_l = mean - stddev,\n    meansd_u = mean + stddev)\n\n#The complete script with some styling added\nggplot(swstats, aes(x=DEATH_EVENT_f, y=mean)) + \n  geom_point(colour = \"black\" , size = 2) +\n  #Now plotting the individual data points before the mean values\n  geom_point(data=heart_failure, aes(x=DEATH_EVENT_f, y=serum_sodium, colour = DEATH_EVENT_f), \n             position = position_jitter() ) +\n  scale_colour_manual(values = c(\"#999999\",\"#d8717b\") ) +\n  #Add the error bars\n  geom_errorbar(aes(ymin = meansd_l, ymax = meansd_u), width=0.2, color = \"black\") +\n  labs(title = \"Mean (-/+SD) serum sodium (mEq/L) by group\", x = \"\", y = \"Serum Sodium\") +\n  guides(fill = \"none\")  +\n  coord_flip() +\n  labs(title =  \"Serum Sodium means and 95% confidence intervals by group (Death Event)\") + \n  theme(legend.position=\"none\",plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))\n```\n\n::: {.cell-output-display}\n![](slides_lab02_files/figure-revealjs/unnamed-chunk-57-1.png){width=960}\n:::\n:::\n\n\n:::\n\n## [Preliminary check “HOV” assumption (test)]{.r-stretch}\n\nIt is always best to use an actual test, so we use also the **Fisher's F test** to verify equal variances of Serum Sodium concentration in the two groups. [In this test **$H_0$ = “the ratio of variances is equal to 1”**] \n\n\n::: {.cell}\n\n```{.r .cell-code}\nf_test_res <- stats::var.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] ,\n                              heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0])\nf_test_res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nF = 1.5769, num df = 95, denom df = 202, p-value = 0.007646\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.127401 2.254466\nsample estimates:\nratio of variances \n          1.576922 \n```\n\n\n:::\n:::\n\n\nGiven the `p-value = 0.007646` (smaller than $\\alpha$) we reject the null hypothesis, hence the HOV assumption for the t test does not hold. \n\n\n## [2 Computation of the t test with the Welch correction]{.r-fit-text} \n\n::: {style=\"font-size: 85%;\"}\nWe can still run the **t test but with Welch correction**, i.e. the unequal variance condition is compensated by lowering the df. In fact the documentation (`?t.test`), reads:\n\n  + If `var.equal = TRUE`, then the pooled variance is used to estimate the variance\n  + Otherwise (`var.equal = FALSE`), the Welch  approximation to the degrees of freedom is used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# With Welch correction (on by default) Unequal variance is compensated by lowering df\nt_test_w <- t.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1], \n                   heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0],\n                   # here we specify the situation\n                   var.equal = FALSE,\n                   paired = FALSE, alternative = \"two.sided\") \n\nt_test_w\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nt = -3.1645, df = 154.01, p-value = 0.001872\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.9914879 -0.6920096\nsample estimates:\nmean of x mean of y \n 135.3750  137.2167 \n```\n\n\n:::\n:::\n\n\n:::\n\n## [3. Results and interpretation]{.r-fit-text}\n\n\nRESULTS: since the test statistic is `t = -3.1645 (with df = 154.01)` and the corresponding `p-value is 0.001872 < 0.05`, we reject the null hypothesis.\n\nINTERPRETATION: We therefore have sufficient evidence to say that the level of serum sodium levels for dead patients is significantly different than that of survived patients $𝝁_{sersod-died} ≠ 𝝁_{sersod-surv}$  \n\n\n## Final thoughts/recommendations\n\n::: {style=\"font-size: 85%;\"}\n\n+ There are often **many ways to do the same thing in R** (which is both a blessing and a curse in open source software). *Which should you choose?* It depends on the situation, but you may want to consider:\n\n  + how recent/popular/well maintained is a `{package}` (this affects its stability) \n  + the more a function abstracts away complexity, the easier it is to use interactively, but the harder it gets to handle inside your own custom functions\n  + different function outputs may be more/less suitable for your analysis/publication requirements (check out your peers' choices!)\n  + *(Always **read the documentation** to assess all of the above)* \n\n+ With easy equations, breaking them down \"by hand\" (at least once!) can really help you understand them\n\n+ It may seem a lot of work to write R code the first time 🥵 (e.g. for a publication-ready plot), but the good news is **once you wrote a script, you will be able to easily re-use it in many more instances** 🙌🏻 😃 \n\n+ **Sample size `n` has a very powerful impact** on classical hypothesis testing results! More on this later...\n \n:::\n  \n \n<!-- # FOUNDATIONS OF INFERENCE -->\n\n<!-- (lo lascerei x lab \\# 2) -->\n\n",
    "supporting": [
      "slides_lab02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}