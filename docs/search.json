[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course Description & Objectives",
    "section": "",
    "text": "This is an intensive course originally designed for students and researchers dealing with biological datasets to help them consolidate their practical understanding of frequently implemented data analysis and statistical modeling for academic research purposes. This course focuses on empowering participants to conduct end-to-end data analyses, guiding them through reproducible data storage, cleaning, exploration, analysis, and interpretation cycle.\nBeyond the conceptual foundations, participants engage in hands-on coding sessions in the R software with real-world datasets and solved questions, validating in practice the skills needed to confidently acquire and communicate insights throughout the analytical process.\nParticular emphasis is placed on developing an understanding of the statistical methods used, when to apply them, and how to interpret them, in close connection to ‚Äúreal life‚Äù situations for a research scientists."
  },
  {
    "objectID": "syllabus.html#module-1-introduction-to-and-data-analysis",
    "href": "syllabus.html#module-1-introduction-to-and-data-analysis",
    "title": "Course Description & Objectives",
    "section": "Module 1: Introduction to  and data analysis",
    "text": "Module 1: Introduction to  and data analysis\n\nIntroduction to reproducible end-to-end analysis using R\n\nWhy use R?\nPrinciples of reproducible analysis with R + RStudio\nR objects, functions, packages\n\nDiscussion of different variable types (qualitative, quantitative) and levels of measurement (nominal, ordinal, interval, ratio)\n\nPrinciples of ‚Äútidy data‚Äù\nIntroduction to data cleaning and manipulation methods\n\nDescriptive statistics\n\nUnivariate analysis\nMeasures of central tendency, measures of variability (or spread), and frequency distributions\n\nVisual data exploration\n\nIntroduction to ggplot2 package for making graphs in R"
  },
  {
    "objectID": "syllabus.html#module-2-statistical-inference-and-classical-hypothesis-testing",
    "href": "syllabus.html#module-2-statistical-inference-and-classical-hypothesis-testing",
    "title": "Course Description & Objectives",
    "section": "Module 2: Statistical inference and classical hypothesis testing",
    "text": "Module 2: Statistical inference and classical hypothesis testing\n\nPurpose and foundations of inferential statistics\n\nProbability and random variables\nMeaningful probability distributions\nSampling distributions and Central Limit Theorem\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing\n\nThe null and alternative hypothesis\nThe probability of error? (Œ± or ‚Äúsignificance level‚Äù)\nThe p-value probability and tests interpretation\nConfidence Intervals\nTypes of errors (Type 1 and Type 2)\nEffective vs statistical significance\n\nHypothesis tests examples\n\nComparing sample mean to a hypothesized population mean (Z test & t test)\nComparing two independent sample means (t test)\nComparing sample means from 3 or more groups (ANOVA)\n\nA closer look at testing assumptions (with examples)\n\nTesting two groups that are not independent\nTesting if the data are not normally distributed: non-parametric tests\nTesting samples without homogeneous variance of observations"
  },
  {
    "objectID": "syllabus.html#module-3-modeling-correlation-and-regression",
    "href": "syllabus.html#module-3-modeling-correlation-and-regression",
    "title": "Course Description & Objectives",
    "section": "Module 3: Modeling correlation and regression",
    "text": "Module 3: Modeling correlation and regression\n\nTesting and summarizing relationship between 2 variables (correlation)\n\nPearson \\(r\\) analysis (parametric)\n\n(numerical variables)\n\nSpearman‚Äôs test (not parametric)\n\nMeasures of association\n\nChi-Square Test of Independence\n\n(categorical variables)\n\nFisher‚Äôs Exact Test\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\nIntroduction of regression based statistical methods\n\nSimple linear regression models\nMultiple Linear Regression models\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised and Unsupervised algorithms"
  },
  {
    "objectID": "syllabus.html#module-4-causal-analysis-essentials",
    "href": "syllabus.html#module-4-causal-analysis-essentials",
    "title": "Course Description & Objectives",
    "section": "Module 4: Causal analysis essentials",
    "text": "Module 4: Causal analysis essentials\n\nRecall the essential features of experimental study designs\n\nLearning the vocabulary of causal analysis\n\nGet a visual intuition of causal pathways, including challenging elements:\n\nCollider variables\nConfounder variables\nMediator variables\n\nDiscuss the correct causal model to capture the association among exposure, outcome and other covariates, (including challenging ones)\nDefine causal outcomes and choosing the appropriate ‚Äúestimands‚Äù:\n\nATE, ATT, or ATU?\n\nDevise statistical methods to estimate ATE, ATT, and ATU based on research question and (sub)population of interest"
  },
  {
    "objectID": "syllabus.html#module-5-introduction-to-machine-learning",
    "href": "syllabus.html#module-5-introduction-to-machine-learning",
    "title": "Course Description & Objectives",
    "section": "Module 5: Introduction to machine learning",
    "text": "Module 5: Introduction to machine learning\n\nIntroduction to Machine Learning\nShifting the emphasis on empirical prediction\nDistinction between supervised & unsupervised algorithms\n\nSupervised ML Examples\n\nLogistic regression ‚Äì for classification\nClassification and regression trees (CART) ‚Äì for prediction\nRandom forest classification ‚Äì for prediction\n\nUnsupervised ML Examples\n\nK-means clustering ‚Äì for clustering\nPCA ‚Äì for dimensionality reduction\nPLS-Discriminant Analysis ‚Äì ‚Äúsupervised‚Äù alternative to PCA performing simultaneous dimensionality reduction and classification"
  },
  {
    "objectID": "syllabus.html#module-6-bonus-topics",
    "href": "syllabus.html#module-6-bonus-topics",
    "title": "Course Description & Objectives",
    "section": "Module 6: Bonus topics",
    "text": "Module 6: Bonus topics\n\nIntroduction to MetaboAnalyst software\n\nOverview of a useful, R-based resources for metabolomics\nIllustrative workflow with MetaboAnalyst\n\nElements of statistical Power Analysis\n\nBrief review of hypothesis testing framework (from Module 2)\nReview of type I and type II decision errors, contextualizing them in experimental settings\nUnderstanding the test‚Äôs statistical power in connection to the effect size of an experiment"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#lab-5",
    "href": "practice/practice_slides/slides_lab05.html#lab-5",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Lab # 5",
    "text": "Lab # 5\n\n\n\nIn this Lab session, we will focus on Machine Learning (ML), as introduced in Lecture 5\nWe will review examples of both supervised and unsupervised ML algorithms\n\n\nSupervised ML algorithms examples:\n\nLogistic regression\nClassification and regression trees (CART)\nüå≥ Random Forest classifier\n\n\n\nUnsupervised ML algorithms examples:\n\nK-means Clustering\nPCA for dimension reduction\n\n\n(optional) PLS-DA for classification, a supervised ML alternative to PCA"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#acknowledgements",
    "href": "practice/practice_slides/slides_lab05.html#acknowledgements",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "üü† ACKNOWLEDGEMENTS",
    "text": "üü† ACKNOWLEDGEMENTS\nThe examples and datasets in this Lab session follow very closely two sources:\n\nThe tutorial on ‚ÄúData Analytics with R‚Äù by: Brian Machut, Nathan Cornwell\nThe tutorial on ‚ÄúPrincipal Component Analysis (PCA) in R‚Äù by: Statistics Globe"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab05.html#needed-r-packages",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\noptions(scipen = 999)\n# --- General \nlibrary(here)     # tools find your project's files, based on working directory\nlibrary(dplyr)    # A Grammar of Data Manipulation\nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(magrittr) # A Forward-Pipe Operator for R \nlibrary(readr)    # A Forward-Pipe Operator for R \nlibrary(tidyr)    # Tidy Messy Data\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\n\n# ---Plotting & data visualization\nlibrary(ggplot2)      # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(scatterplot3d) # 3D Scatter Plot\n\n# --- Statistics\nlibrary(MASS)       # Support Functions and Datasets for Venables and Ripley's MASS\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\nlibrary(FactoMineR) # Multivariate Exploratory Data Analysis and Data Mining\nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)        # Companion to Applied Regression\nlibrary(ROCR)       # Visualizing the Performance of Scoring Classifiers\n\n# --- Tidymodels (meta package)\nlibrary(rsample)    # General Resampling Infrastructure  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regression-review",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regression-review",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regression: review",
    "text": "Logistic regression: review\n\n\n\nLogistic regression is a classification model used with a binary response variable, e.g.:\n\n\nyes|no, or 0|1, or True|False in a survey question;\n\nsuccess|failure in a clinical trial experiment;\n\nbenign|malignant in a biopsy experiment.\n\n\nLogistic regression is a type of Generalized Linear Model (GLM): a more flexible version of linear regression that can work also for categorical response variables or count data (e.g.¬†poisson regression).\nWhen logistic regression fits the coefficients \\(\\beta_0\\), \\(\\beta_1\\), ‚Ä¶, \\(\\beta_k\\) to the data, it minimizes errors using the Maximum Likelihood Estimation method (as opposed to linear regression‚Äôs Least Squares Error Estimation method)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regression-logit-function",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regression-logit-function",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regression: logit function",
    "text": "Logistic regression: logit function\n\nIf we have predictor variables like \\(x_{1,i}\\), \\(x_{2,i}\\), ‚Ä¶, \\(x_{k,i}\\) and a binary response variable \\(y_i\\) (where \\(y_i = 0\\) or \\(y_i = 1\\)), we need a ‚Äúspecial‚Äù function to transform the expected value of the response variable into the \\([0,1]\\) outcome we‚Äôre trying to predict. \nThe logit function (of the GLM family) helps us determine the coefficients \\(\\beta_0\\), \\(\\beta_1\\), ‚Ä¶, \\(\\beta_k\\) that best fit this sort of data and it is defined as: \\[\nlogit (p_i) = \\ln\\left( \\frac{p_i}{1-p_i} \\right)= \\beta_0 + \\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i}\n\\] where \\(p_i\\) is the probability that \\(y_i = 1\\) \nVia the inverse-logit function (logistic), we solve for the probability \\(p_i\\), given values of the predictor variables, like so:\n\\[\nP(y_i = 1 | x_{1,i}, \\ldots, x_{k,i} ) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i})}}\n\\]\n\n\n\n[Predicting probabilities without a logit function could give values over 1, which doesn‚Äôt make sense.]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#dataset-on-heart-disease-heart_data",
    "href": "practice/practice_slides/slides_lab05.html#dataset-on-heart-disease-heart_data",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Dataset on Heart Disease (heart_data)",
    "text": "Dataset on Heart Disease (heart_data)\nName: heart_data.csvDocumentation: Toy dataset prepared for teaching purposes. See reference on the data here Data Analytics with RSampling details: This dataset contains 10,000 observations on 4 variables.\n\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nheart_data &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"05_datasets\",\n                                      \"heart_data.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#heart_data-variables-with-description",
    "href": "practice/practice_slides/slides_lab05.html#heart_data-variables-with-description",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nheart_data variables with description",
    "text": "heart_data variables with description\n\n\n\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nheart_disease\nint\nwhether an individual has heart disease (1 = yes; 0 = no)\n\n\ncoffee_drinker\nint\nwhether an individual drinks coffee regularly (1 = yes; 0 = no)\n\n\nfast_food_spend\ndbl\na numerical field corresponding to the annual spend of each individual on fast food\n\n\nincome\ndbl\na numerical field corresponding to the individual‚Äôs annual income"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#heart_data-dataset-splitting",
    "href": "practice/practice_slides/slides_lab05.html#heart_data-dataset-splitting",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nheart_data dataset splitting",
    "text": "heart_data dataset splitting\nIn Machine Learning, it is good practice to split the data into training and testing sets.\n\nWe will use the training set (70%) to fit the model and then the testing set (30%) to evaluate the model‚Äôs performance.\n\n\nset.seed(123)\n\n# Obtain 2 sub-samples from the dataset: training and testing\nsample  &lt;-  sample(c(TRUE, FALSE), nrow(heart_data), replace = TRUE , prob = c(0.7, 0.3) )\nheart_train  &lt;-  heart_data[sample,]\nheart_test  &lt;-  heart_data[!sample,]\n\n\nWhich results in:\n\n\n# check the structure of the resulting datasets\ndim(heart_train)\n\n[1] 7048    4\n\ndim(heart_test)\n\n[1] 2952    4"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#convert-binary-variables-to-factors",
    "href": "practice/practice_slides/slides_lab05.html#convert-binary-variables-to-factors",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Convert binary variables to factors",
    "text": "Convert binary variables to factors\nBefore examining the training dataset heart_train, we converting the binary variables heart_disease and coffee_drinker to factors (for better readability).\n\nheart_train &lt;- heart_train %&gt;% \n  # convert to factor with levels \"Yes\" and \"No\"\n  mutate(heart_disease = factor(heart_disease, levels = c(0, 1),\n                                labels = c(\"No_HD\", \"Yes_HD\")),\n         coffee_drinker = factor(coffee_drinker, levels = c(0, 1),\n                                 labels = c(\"No_Coffee\", \"Yes_Coffee\")) \n  )\n\n# show the first 5 rows of the dataset\nheart_train[1:5,]\n\n  heart_disease coffee_drinker fast_food_spend    income\n1         No_HD      No_Coffee        1823.816 44361.625\n3         No_HD      No_Coffee        2683.873 31767.139\n6         No_HD     Yes_Coffee        2298.971  7491.559\n7         No_HD      No_Coffee        2063.783 24905.227\n9         No_HD      No_Coffee        2902.645 37468.529"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plotting-y-by-x1-continuous-variable",
    "href": "practice/practice_slides/slides_lab05.html#plotting-y-by-x1-continuous-variable",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plotting Y by X1 (continuous variable)",
    "text": "Plotting Y by X1 (continuous variable)\nWe now examine visualize the relationship between the binary outcome variable heart_disease and the continuous predictor variable fast_food_spend.\n\n\ngeom_jitter adds a bit of randomness to the points to avoid overplotting.\n\ngeom_boxplot shows the distribution of the continuous variable by the binary outcome variable.\n\n\n# plot the distribution of heart disease status by fast food spend\nheart_train %&gt;% \n  ggplot(aes(x = heart_disease, y = fast_food_spend, fill = heart_disease)) + \n  geom_jitter(aes(fill = heart_disease), alpha = 0.3, shape = 21, width = 0.25) +  \n  scale_color_manual(values = c(\"#005ca1\", \"#9b2339\")) + \n  scale_fill_manual(values = c(\"#57b7ff\", \"#e07689\")) + \n  geom_boxplot(fill = NA, color = \"black\", linewidth = .7) + \n  coord_flip() +\n    theme(plot.title = element_text(size = 13,face=\"bold\", color = \"#873c4a\"),\n        axis.text.x = element_text(size=12,face=\"italic\"), \n        axis.text.y = element_text(size=12,face=\"italic\"),\n        legend.position = \"none\") + \n  labs(title = \"Fast food expenditure by heart disease status\") + \n  xlab(\"Heart Disease (Y/N)\") + \n  ylab(\"Annual Fast Food Spend\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plotting-y-by-x1-continuous-variable-output",
    "href": "practice/practice_slides/slides_lab05.html#plotting-y-by-x1-continuous-variable-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plotting Y by X1 (continuous variable)",
    "text": "Plotting Y by X1 (continuous variable)\n\n\n+ The boxplots indicate that subjects with heart disease (HD =1) seem to spend higher amounts on fast food  + Also, this sample has many more subjects without heart disease (HD = 0) than with heart disease (HD = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plotting-y-by-x2-discrete-variable",
    "href": "practice/practice_slides/slides_lab05.html#plotting-y-by-x2-discrete-variable",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plotting Y by X2 (discrete variable)",
    "text": "Plotting Y by X2 (discrete variable)\n\nThen we examine the relationship between the binary outcome variable heart_disease and the binary predictor variable coffee_drinker.\n\nwe use the handy count function from dplyr to count occurrences in categorical variable(s) combinations.\n\n\n# Dataset manipulation\nheart_train %&gt;% \n  # count the unique values per each group from 2 categorical variables' combinations\n  dplyr::count(heart_disease, coffee_drinker, name = \"count_by_group\") %&gt;% \n  dplyr::group_by(coffee_drinker) %&gt;% \n  dplyr::mutate(\n    total_coffee_class = sum(count_by_group),\n    proportion = count_by_group / total_coffee_class) %&gt;% \n  dplyr::ungroup() %&gt;% \n  # filter only those with heart disease\n  dplyr::filter(heart_disease == \"Yes_HD\") %&gt;% \n# Plot  \n  ggplot(aes(x = coffee_drinker, y = proportion, fill = coffee_drinker)) + \n  geom_bar(stat = \"identity\") + \n  scale_fill_manual(values = c(\"#57b7ff\", \"#e07689\")) + \n  theme_minimal() +\n  ylab(\"Percent with Heart Disease\") +\n  xlab(\"Coffee Drinker (Y/N)\") +\n  ggtitle(\"Figure 3: Percent of Coffee Drinkers with Heart Disease\") +\n  labs(fill = \"Coffee Drinker\") + \n  scale_y_continuous(labels = scales::percent)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plotting-y-by-x2-discrete-variable-output",
    "href": "practice/practice_slides/slides_lab05.html#plotting-y-by-x2-discrete-variable-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plotting Y by X2 (discrete variable)",
    "text": "Plotting Y by X2 (discrete variable)\n\n\nAlso drinking coffee seems associated to a higher likelihood of heart disease (HD =1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#linear-regression-wouldnt-work",
    "href": "practice/practice_slides/slides_lab05.html#linear-regression-wouldnt-work",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nLinear regression wouldn‚Äôt work!",
    "text": "Linear regression wouldn‚Äôt work!\n\n\nIn principle, we could use a linear regression model to study likelihood of having Heart Disease in relation to risk factors: \\[ Y = \\beta_0 + \\beta_1 \\cdot \\text{(US\\$ Spent Fast Food)} + \\beta_2 \\cdot \\text{(Coffee Drinker = YES)} \\]\nBut we‚Äôll see why the logistic regression model is a better option.\n\n\\[ \\log \\left( \\frac{p}{1-p} \\right) = \\beta_0 + \\beta_1 \\cdot \\text{(US\\$ Spent Fast Food)} + \\beta_2 \\cdot \\text{(Coffee Drinker = YES)} \\]\n\nLet‚Äôs compare the 2 models (for simplicity, we ignore the coffee_drinker variable for now.):\n\n\n# --- 1) Linear regression model\nlinear_mod &lt;- lm(heart_disease ~ fast_food_spend# + coffee_drinker\n                 , data = heart_data)\n# --- 2) Logistic regression model\nlogit_mod &lt;- glm(heart_disease ~ fast_food_spend# + coffee_drinker\n                 , data = heart_data, family = \"binomial\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#compute-alternative-models-predictions",
    "href": "practice/practice_slides/slides_lab05.html#compute-alternative-models-predictions",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Compute alternative models‚Äô predictions",
    "text": "Compute alternative models‚Äô predictions\n\nWe can now extract the coefficients from the linear regression and logistic models, then estimate the predicted outcomes from these models: lin_pred, logit_pred, and logistic_pred (i.e.¬†the conversion form log(odds) to probability).\n\n# --- 1) Extract coefficients from linear regression model\nintercept_lin &lt;- coef(linear_mod)[1]\nfast_food_spend_lin &lt;- coef(linear_mod)[2]\ncoffee_drinker_lin &lt;- coef(linear_mod)[3]\n\n# --- 2) Extract coefficients from logit regression model\nintercept_logit &lt;- coef(logit_mod)[1]\nfast_food_spend_logit &lt;- coef(logit_mod)[2]\ncoffee_drinker_logit &lt;- coef(logit_mod)[3]\n\n# --- Estimate predicted data from different models   \nheart_data &lt;- heart_data %&gt;%\n  mutate(\n    # Convert outcome variable to factor\n    heart_disease_factor = factor(heart_disease, \n                                  labels = c(\"No Disease (Y=0)\", \"Disease (Y=1)\")),\n    # 1) Linear model prediction\n    lin_pred = intercept_lin + fast_food_spend_lin * fast_food_spend, \n    # 2) Logit model prediction\n    logit_pred = intercept_logit + fast_food_spend_logit * fast_food_spend,  coffee_drinker,\n    # 3) Convert logit to probability (logistic model prediction)\n    logistic_pred = 1 / (1 + exp(-logit_pred)) \n    ) %&gt;%\n  arrange(fast_food_spend)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plot-alternative-models-outcomes",
    "href": "practice/practice_slides/slides_lab05.html#plot-alternative-models-outcomes",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plot alternative models‚Äô outcomes",
    "text": "Plot alternative models‚Äô outcomes\nWe can also plot the predicted outcomes from the 3 models to see how they differ.\n\n\n# --- Plot  \nggplot(heart_data, aes(x = fast_food_spend)) +\n  # Actual dataset observations (Y=0, Y=1 ) using `color =`\n  geom_jitter(aes(y = heart_disease, color = heart_disease_factor), \n              width = 200, height = 0.03, alpha = 0.75, size = 2, shape = 16) + \n  # Models' predictions (smooth trends)\n  geom_smooth(aes(y = lin_pred, color = \"Linear Regression\"), method = \"lm\", se = FALSE, \n              linewidth = 1.25, linetype = \"dashed\") +\n  geom_smooth(aes(y = logit_pred, color = \"Logit (Log-Odds)\"), method = \"lm\", se = FALSE, \n              linewidth = 1.25, linetype = \"dotdash\") +\n  geom_smooth(aes(y = logistic_pred, color = \"Logistic Regression\"), method = \"glm\", \n              method.args = list(family = \"binomial\"), se = FALSE, \n              linewidth = 1.25, linetype = \"solid\") +\n  # Separate legends: color for dots, color for lines\n  scale_color_manual(name = \"Actual Y values & Prediction Models\", \n                     values = c(\"No Disease (Y=0)\" = \"#A6A6A6\", \"Disease (Y=1)\" = \"#4c4c4c\",\n                                \"Linear Regression\" = \"#d02e4c\",\"Logit (Log-Odds)\" = \"#239b85\", \n                                \"Logistic Regression\" = \"#BD8723\")) +\n  # Define scales for the axes\n  scale_x_continuous(breaks = seq(0, 6500, by = 500), limits = c(0, 6500), expand = c(0, 0))+\n  scale_y_continuous(breaks = seq(-3, 3, by = .25)) +\n  coord_cartesian(ylim = c(-1.25,1.25), xlim = c(0, 6500))  + theme_minimal() +\n  labs(title = \"Comparing Linear and Logistic Regression Predictions v. actual Y values\",\n       #subtitle = \"(For simplicity, only fast food spend is considered)\",\n       y = \"Y = Heart disease [0,1]\", x = \"Fast food spend [US$/yr]\", color = \"Actual Y values and Predictions\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#plot-alternative-models-outcomes-output",
    "href": "practice/practice_slides/slides_lab05.html#plot-alternative-models-outcomes-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Plot alternative models‚Äô outcomes",
    "text": "Plot alternative models‚Äô outcomes\n\n\n+ (The actual data points are shown as the grey dots) + The linear model predicts values that are ‚â† 0 and 1, which poorly fit the actual data  + The logit model predicts log(odds) ranging from -Inf to +Inf, which is not interpretable  + The logistic model squeezes probabilities between 0 and 1, which fits the data better"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#linear-regression-didnt-work",
    "href": "practice/practice_slides/slides_lab05.html#linear-regression-didnt-work",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nLinear regression didn‚Äôt work!",
    "text": "Linear regression didn‚Äôt work!\n\n\nBesides the poor fit, recall linear regression models implies certain assumptions:\n\n\nLinear relationship between Y and the predictors X1 and X2\n\n\nResiduals must be 1) approximately normally distributed and 2) uncorrelated \n\n\nHomoscedasticity: residuals should have constant variance\n\nNon collinearity: predictor variables should not be highly correlated with each other\n\n\n\n\n\nAssumptions that are not met in this case\n\n\n# diagnostic plots\npar(mfrow=c(2,2))\nplot(linear_mod)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#linear-regression-didnt-work-output",
    "href": "practice/practice_slides/slides_lab05.html#linear-regression-didnt-work-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nLinear regression didn‚Äôt work!",
    "text": "Linear regression didn‚Äôt work!\n\n\n\nFigure¬†1: Diagnostic plots for a hypothetical linear regression model üëéüèª"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#fitting-a-logistic-regression-model",
    "href": "practice/practice_slides/slides_lab05.html#fitting-a-logistic-regression-model",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Fitting a logistic regression model",
    "text": "Fitting a logistic regression model\n\nNow that we are convinced‚Ä¶\n‚Ä¶let‚Äôs fit instead a logistic regression model to the heart_train data using:\n\nthe glm function for Generalized Linear Models,\n\nwith argument family = binomial to specify logistic regression which will use logit as the link function,\nhere we employ all the 3 predictor variables in the dataset (after ~).\n\n\n\n\n\n\n# Fit a logistic regression model\nheart_model &lt;- glm(heart_disease ~ coffee_drinker + fast_food_spend + income,\n                   data = heart_train, \n                   family = binomial(link = \"logit\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#model-summary-and-coefficients",
    "href": "practice/practice_slides/slides_lab05.html#model-summary-and-coefficients",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Model summary and coefficients\n",
    "text": "Model summary and coefficients\n\n\n\n\nTable¬†1 (next) shows the model output, with the coefficient estimate for each predictor.\n\nThe broom::tidy function converts the model summary into a more readable data frame.\nThe odds ratio (= exponentiated coefficient estimate) is more interpretable than the coefficient itself.\n\n\n\n\n# Convert model's output summary into data frame\nheart_model_coef &lt;- broom::tidy(heart_model) %&gt;% \n  # improve readability of significance levels\n  dplyr::mutate('signif. lev.' = case_when(\n    `p.value` &lt; 0.001 ~ \"***\",\n    `p.value` &lt; 0.01 ~ \"**\",\n    `p.value` &lt; 0.05 ~ \"*\",\n    TRUE ~ \"\"))%&gt;%\n  # add odds ratio column\n  dplyr::mutate(odds_ratio = exp(estimate)) %&gt;%\n  dplyr::relocate(odds_ratio, .after = estimate) %&gt;%\n  dplyr::mutate(across(where(is.numeric), ~ round(.x, 4))) %&gt;%\n  # format as table\n  knitr::kable() %&gt;% \n  # reduce font size\n  kable_styling(font_size = 20) %&gt;% \n  # add table title\n  kableExtra::add_header_above(c(\"Logistic Regression Analysis of Heart Disease Risk Factors\"= 7))\n\nheart_model_coef"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#model-summary-and-coefficients-output",
    "href": "practice/practice_slides/slides_lab05.html#model-summary-and-coefficients-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Model summary and coefficients\n",
    "text": "Model summary and coefficients\n\n\n\nTable¬†1: Logistic regression model output  + estimates of coefficients are in the form of natural logarithm of the odds (log (odds)) of the event happening (Heart Disease)  + a positive estimate indicates an increase in the odds of having Heart Desease  + a negative estimate indicates a decrease in the odds of having Heart Desease  + odds ratio = the exponentiated coefficient estimate \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression Analysis of Heart Disease Risk Factors\n\n\n\nterm\nestimate\nodds_ratio\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n\n(Intercept)\n-11.0554\n0.0000\n0.6040\n-18.3051\n0.0000\n***\n\n\ncoffee_drinkerYes_Coffee\n-0.7296\n0.4821\n0.2910\n-2.5071\n0.0122\n*\n\n\nfast_food_spend\n0.0024\n1.0024\n0.0001\n20.6018\n0.0000\n***\n\n\nincome\n0.0000\n1.0000\n0.0000\n-0.2299\n0.8182"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#interpreting-the-logistic-coefficients",
    "href": "practice/practice_slides/slides_lab05.html#interpreting-the-logistic-coefficients",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Interpreting the logistic coefficients",
    "text": "Interpreting the logistic coefficients\n\n\n\n\n\n\nterm\nestimate\nodds_ratio\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n(Intercept)\n-11.0554\n0.0000\n0.6040\n-18.3051\n0.0000\n***\n\n\ncoffee_drinkerYes_Coffee\n-0.7296\n0.4821\n0.2910\n-2.5071\n0.0122\n*\n\n\nfast_food_spend\n0.0024\n1.0024\n0.0001\n20.6018\n0.0000\n***\n\n\nincome\n0.0000\n1.0000\n0.0000\n-0.2299\n0.8182\n\n\n\n\n\n\n\n\n\nIntercept: gives the log-odds of heart disease when all predictor variables are zero. This is not generally interpreted, but the highly negative value suggests very low probability of heart disease in the sample of reference.\n\n(If interpreted) the intercept term -11.0554 would translate as probability \\(P =  e^{-11.0554} / (1 + e^{-11.0554}) = 0.00002\\) or \\(0.002\\%\\).\n‚Ä¶which means: when \\(\\text{coffee_drinker} = NO\\), and \\(\\text{fast_food_spend} = 0\\), and \\(\\text{income} = 0\\), the probability of heart disease is as low as \\(0.002\\%\\).\n\n\n\n\n\nIncome: Based on a p-value = 0.8182, we conclude that income is not significantly associated with heart disease. (Anyhow, the odds ratio of ‚âà1 would suggest no change in odds based on income.)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#the-coefficient-of-fast-food",
    "href": "practice/practice_slides/slides_lab05.html#the-coefficient-of-fast-food",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "The coefficient of fast food $$ üçîüçü",
    "text": "The coefficient of fast food $$ üçîüçü\n\n\n\n\n\n\nterm\nestimate\nodds_ratio\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n(Intercept)\n-11.0554\n0.0000\n0.6040\n-18.3051\n0\n***\n\n\nfast_food_spend\n0.0024\n1.0024\n0.0001\n20.6018\n0\n***\n\n\n\n\n\n\n\n\n\n\nThe positive coefficient of Fast Food Annual Spending (US$), 0.0024 (highly statistically significant as p-value = 0.0000), suggests a positive association with heart disease.\n\nThis means that for each additional \\(\\Delta X_1 = +1 \\; US\\$\\) spent on fast food annually:\n\nthe log(odds) of heart disease increases by: \\(\\Delta \\log(\\text{odds}) = \\beta_{1} \\times \\Delta X_1 = 0.0024 \\times 1 = 0.0024\\)\nthe odds of heart disease (with spending) increase by a factor of: \\(OR = e^{0.0024} \\approx 1.0024\\) (compared to without spending).\n\n\n\n\nThe probability of heart disease is computed using the logistic function: \\(P_{HD=1} = \\frac{e^{\\beta_0 + (\\beta_1 \\times X_1)}}{1 + e^{\\beta_0 + (\\beta_1 \\times X_1)}}\\)\n\nSolving for \\(\\beta_0 = -11.0554\\), \\(\\beta_1 = 0.0024\\) and \\(X_1 = 1\\) gives:\n\n\\[P_{HD=1} = \\frac{e^{-11.0554 + (0.0024 \\times 1)}}{1 + e^{-11.0554 + (0.0024 \\times 1)}} = 0.00001583981\\]\n\n\nwhich indicates a probability of heart disease is as low as \\(0.00159\\%\\) when fast_food_spend \\(= 1\\; US\\$\\)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#the-coefficient-of-fast-food-1",
    "href": "practice/practice_slides/slides_lab05.html#the-coefficient-of-fast-food-1",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "The coefficient of fast food $$ üçîüçü",
    "text": "The coefficient of fast food $$ üçîüçü\n\n\n\n\n\n\nterm\nestimate\nodds_ratio\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n(Intercept)\n-11.0554\n0.0000\n0.6040\n-18.3051\n0\n***\n\n\nfast_food_spend\n0.0024\n1.0024\n0.0001\n20.6018\n0\n***\n\n\n\n\n\n\n\nHowever, considering that this is annual spending, we should use a more adequate scale!\n\nFor example, for an additional \\(\\Delta X_1 = +100 \\; US\\$\\) spent on fast food annually:\n\nthe log(odds) of heart disease increases by: \\(\\Delta \\log(\\text{odds}) = \\beta_{1} \\times \\Delta X_1 = 0.0024 \\times 100 = 0.24\\)\nthe odds of heart disease (with spending) increase by a factor of: \\(OR = e^{0.24} \\approx 1.271\\) (compared to without spending).\n\n\n\n\nThe probability of heart disease is computed using the logistic function: \\(P_{HD=1} = \\frac{e^{\\beta_0 + (\\beta_1 \\times X_1)}}{1 + e^{\\beta_0 + (\\beta_1 \\times X_1)}}\\)\n\nSolving for \\(\\beta_0 = -11.0554\\), \\(\\beta_1 = 0.0024\\) and and \\(X_1 = 100\\) gives:\\[P_{HD=1} = \\frac{e^{-11.0554 + (0.0024 \\times 100)}}{1 + e^{-11.0554 + (0.0024 \\times 100)}} \\approx 0.00002008\\]\nwhich (this time) indicates a (still very low probability) of heart disease at \\(0.002008\\%\\) when fast_food_spend \\(= 100\\; US\\$\\)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#the-coefficient-of-coffee-drinking",
    "href": "practice/practice_slides/slides_lab05.html#the-coefficient-of-coffee-drinking",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "The coefficient of coffee drinking ‚òïÔ∏è",
    "text": "The coefficient of coffee drinking ‚òïÔ∏è\n\n\n\n\n\n\nterm\nestimate\nodds_ratio\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n(Intercept)\n-11.0554\n0.0000\n0.604\n-18.3051\n0.0000\n***\n\n\ncoffee_drinkerYes_Coffee\n-0.7296\n0.4821\n0.291\n-2.5071\n0.0122\n*\n\n\n\n\n\n\n\nThe negative coefficient of Coffee Drinker (=YES), -0.7296 expressed in log-odds, means that coffee drinking is associated with lower odds of having heart disease.\n\nTransforming the estimate into odds ratio, we obtain \\(0.48 = 48\\%\\), which tells that coffee-drinkers have 0.48 (or 48%) lower odds than non-coffee drinkers to experience heart disease (holding all other predictors fixed). \\[ \\text{Odds Ratio} = e^{-0.7296} = 0.48 \\]\n\nAlternatively, we could say that non-coffee drinkers have \\(1-0.48 = 0.52 = 52\\%\\) higher odds of having heart disease compared to coffee drinkers.\n\n\nThis effect is statistically significant as p-value = 0.0122."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#wait-is-drinking-coffee-good-or-bad",
    "href": "practice/practice_slides/slides_lab05.html#wait-is-drinking-coffee-good-or-bad",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Wait, is drinking coffee good or bad? ü§î",
    "text": "Wait, is drinking coffee good or bad? ü§î\nOur plot above showed that there was a higher proportion of coffee drinkers with heart disease as compared to non coffee drinkers. However, our model just told us that coffee drinking is associated with a decrease in the likelihood of having heart disease. \nHow can that be‚ùì  It‚Äôs because coffee_drinking and fast__food_spend are correlated so, on it‚Äôs own, it would appear as if coffee drinking were associated with heart disease, but this is only because coffee drinking is also associated with fast food spend, which our model tells us is the real contributor to heart disease."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#making-predictions-from-logistic-regression-model",
    "href": "practice/practice_slides/slides_lab05.html#making-predictions-from-logistic-regression-model",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Making predictions from logistic regression model",
    "text": "Making predictions from logistic regression model\n\n# Make predictions\nheart_train$heart_disease_pred &lt;- predict(heart_model, type = \"response\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#converting-predictions-into-classifications",
    "href": "practice/practice_slides/slides_lab05.html#converting-predictions-into-classifications",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Converting predictions into classifications",
    "text": "Converting predictions into classifications\n\n# Convert predictions to classifications\nheart_train$heart_disease_pred_class &lt;- ifelse(heart_train$heart_disease_pred &gt; 0.5, 1, 0)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#evaluating-the-model",
    "href": "practice/practice_slides/slides_lab05.html#evaluating-the-model",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Evaluating the model]",
    "text": "Evaluating the model]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#roc-curve",
    "href": "practice/practice_slides/slides_lab05.html#roc-curve",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "ROC curve]",
    "text": "ROC curve]\n\n# Load the pROC package\nlibrary(pROC)\n\n# Create a ROC curve\nroc_curve &lt;- roc(heart_train$heart_disease, heart_train$heart_disease_pred)\n\n# Plot the ROC curve\nplot(roc_curve, col = \"blue\", main = \"ROC Curve\", legacy.axes = TRUE)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#confusion-matrix",
    "href": "practice/practice_slides/slides_lab05.html#confusion-matrix",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Confusion matrix]",
    "text": "Confusion matrix]\n\n# Confusion matrix\nconfusion_matrix &lt;- table(heart_train$heart_disease, heart_train$heart_disease_pred_class)\n\nconfusion_matrix\n\n        \n            0    1\n  No_HD  6790   30\n  Yes_HD  148   80"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#sensitivity-and-specificity",
    "href": "practice/practice_slides/slides_lab05.html#sensitivity-and-specificity",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Sensitivity and Specificity]",
    "text": "Sensitivity and Specificity]\n\n# Sensitivity\nsensitivity &lt;- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])\n\n# Specificity\nspecificity &lt;- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#dataset-on-breast-cancer-biopsy",
    "href": "practice/practice_slides/slides_lab05.html#dataset-on-breast-cancer-biopsy",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Dataset on Breast Cancer Biopsy]",
    "text": "Dataset on Breast Cancer Biopsy]\n\nName: Biopsy Data on Breast Cancer PatientsDocumentation: See reference on the data downloaded and conditioned for R here https://cran.r-project.org/web/packages/MASS/MASS.pdfSampling details: This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr.¬†William H. Wolberg. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992; each of nine attributes has been scored on a scale of 1 to 10, and the outcome is also known. The dataset contains the original Wisconsin breast cancer data with 699 observations on 11 variables."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#importing-dataset-biopsy",
    "href": "practice/practice_slides/slides_lab05.html#importing-dataset-biopsy",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Importing Dataset biopsy]",
    "text": "Importing Dataset biopsy]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe data can be interactively obtained form the MASS R package\n\n\n# (after loading pckg)\n# library(MASS)  \n\n# I can call \nutils::data(biopsy)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-variables-with-description",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-variables-with-description",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy variables with description]",
    "text": "biopsy variables with description]\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nid\ncharacter\nSample id\n\n\nV1\ninteger 1 - 10\nclump thickness\n\n\nV2\ninteger 1 - 10\nuniformity of cell size\n\n\nV3\ninteger 1 - 10\nuniformity of cell shape\n\n\nV4\ninteger 1 - 10\nmarginal adhesion\n\n\nV5\ninteger 1 - 10\nsingle epithelial cell size\n\n\nV6\ninteger 1 - 10\nbare nuclei (16 values are missing)\n\n\nV7\ninteger 1 - 10\nbland chromatin\n\n\nV8\ninteger 1 - 10\nnormal nucleoli\n\n\nV9\ninteger 1 - 10\nmitoses\n\n\nclass\nfactor\nbenign or malignant"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-variables-exploration",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-variables-exploration",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy variables exploration]",
    "text": "biopsy variables exploration]\n\nThe biopsy data contains 699 observations of 9 continuous variables, V1, V2, ‚Ä¶, V9.\nThe dataset also contains a character variable: id, and a factor variable: class, with two levels (‚Äúbenign‚Äù and ‚Äúmalignant‚Äù).\n\n# check variable types\nstr(biopsy)\n\n'data.frame':   699 obs. of  11 variables:\n $ ID   : chr  \"1000025\" \"1002945\" \"1015425\" \"1016277\" ...\n $ V1   : int  5 5 3 6 4 8 1 2 2 4 ...\n $ V2   : int  1 4 1 8 1 10 1 1 1 2 ...\n $ V3   : int  1 4 1 8 1 10 1 2 1 1 ...\n $ V4   : int  1 5 1 1 3 8 1 1 1 1 ...\n $ V5   : int  2 7 2 3 2 7 2 2 2 2 ...\n $ V6   : int  1 10 2 4 1 10 10 1 1 1 ...\n $ V7   : int  3 3 3 3 3 9 3 3 1 2 ...\n $ V8   : int  1 2 1 7 1 7 1 1 1 1 ...\n $ V9   : int  1 1 1 1 1 1 1 1 5 1 ...\n $ class: Factor w/ 2 levels \"benign\",\"malignant\": 1 1 1 1 1 2 1 1 1 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-missing-data",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-missing-data",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy missing data]",
    "text": "biopsy missing data]\n\nThere is one incomplete variable V6 = ‚Äúbare nuclei‚Äù with 16 missing values.\n\nremember the package skimr for exploring a dataframe?\n\n\n# check if vars have missing values\nbiopsy %&gt;% \n  # select only variables starting with \"V\"\n  skimr::skim(starts_with(\"V\")) %&gt;%\n  dplyr::select(skim_variable, \n                n_missing)\n\n# A tibble: 9 √ó 2\n  skim_variable n_missing\n  &lt;chr&gt;             &lt;int&gt;\n1 V1                    0\n2 V2                    0\n3 V3                    0\n4 V4                    0\n5 V5                    0\n6 V6                   16\n7 V7                    0\n8 V8                    0\n9 V9                    0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-missing-data-options",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-missing-data-options",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy missing data options]",
    "text": "biopsy missing data options]\n\nWe can decide what to do in these cases (informed by our knowledge of the dataset):\n\n\nOption 1) We drop the observation with incomplete data (i.e.¬†with missing values for V6 = ‚Äúbare nuclei‚Äù) with 16 missing values.\n\n\n# remove rows with missing values\nbiopsy_drop &lt;- biopsy %&gt;% \n  dplyr::filter(!is.na(V6))\n\nmean(biopsy_drop$V6)\n\n[1] 3.544656\n\n\n\n\nOption 2) We impute the missing values with the mean of the variable V6 = ‚Äúbare nuclei‚Äù.\n\n\n# impute missing values with the median of the variable\nbiopsy_impute &lt;- biopsy %&gt;% \n  dplyr::mutate(V6 = ifelse(is.na(V6), median(V6, na.rm = TRUE), V6))\n\nmean(biopsy_impute$V6)\n\n[1] 3.486409"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-dataset-exploration",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-dataset-exploration",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy dataset exploration]",
    "text": "biopsy dataset exploration]\n\n\nBiopsied cells of 700 breast cancer tumors, used to determine if the tumors were benign or malignant.\nThis determination was based on 9 characteristics of the cells, ranked from 1(benign) to 10(malignant):\n\n\n1) Clump Thickness ‚Äì How the cells aggregate. If monolayered they are benign and if clumped on top of each other they are malignant\n\n2) Uniform Size ‚Äì All cells of the same type should be the same size.\n\n3) Uniform Shape If cells vary in cell shape they could be malignant\n\n4) Marginal Adhesion ‚Äì Healthy cells have a strong ability to stick together whereas cancerous cells do not\n\n5) Single Epithelial Size ‚Äì If epithelial cells are not equal in size, it could be a sign of cancer\n\n6) Bare nuclei ‚Äì If the nucleus of the cell is not surrounded by cytoplasm, the cell could be malignant\n\n7) Bland Chromatin ‚Äì If the chromatin‚Äôs texture is coarse the cell could be malignant\n\n8) Normal Nucleoli ‚Äì In a healthy cell the nucleoli is small and hard detect via imagery. Enlarged nucleoli could be a sign of cancer\n\n9) Mitosis ‚Äì cells that multiply at an uncontrollable rate could be malignant"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-dataset-preparation",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-dataset-preparation",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy dataset preparation]",
    "text": "biopsy dataset preparation]\n\n\nThe explanatory variable(s) (clump_thickness, ‚Ä¶, mitosis) can be renamed for better readability\nThe observations with missing values (bare_nuclei) are removed for simplicity\n\nPatient ID (id) can be dropped as it is not used in this analysis\n\n\n\n# Create a clean version of the dataset\nbiopsy_clean &lt;- biopsy %&gt;%\n  # rename the columns (new = old)\n  rename(\n    id                = ID,\n    clump_thickness   =  V1,\n    uniform_size      =  V2,\n    uniform_shape     =  V3,\n    marginal_adhesion =  V4,\n    single_epith_size =  V5,\n    bare_nuclei       =  V6,\n    bland_chromatin   =  V7,\n    normal_nuclei     =  V8,\n    mitosis           =  V9,\n    class             =  class) %&gt;% \n  # remove rows with missing values\n  na.omit(bare_nuclei) %&gt;% \n  # remove the id column\n  select(-id)\n\n# check the structure of the dataset\npaint::paint(biopsy_clean)\n\n\ndata.frame [683, 10]\nclump_thickness   int 5 5 3 6 4 8\nuniform_size      int 1 4 1 8 1 10\nuniform_shape     int 1 4 1 8 1 10\nmarginal_adhesion int 1 5 1 1 3 8\nsingle_epith_size int 2 7 2 3 2 7\nbare_nuclei       int 1 10 2 4 1 10\nbland_chromatin   int 3 3 3 3 3 9\nnormal_nuclei     int 1 2 1 7 1 7\nmitosis           int 1 1 1 1 1 1\nclass             fct benign benign benign benign benign ma~"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-sample-splitting",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-sample-splitting",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy sample splitting]",
    "text": "biopsy sample splitting]\nIn Machine Learning, it is good practice to split the data into training and testing sets.\n\nWe will use the training set (80%) to fit the model and then the testing set (20%) to evaluate the model‚Äôs performance.\n\n\nset.seed(123)\n\n# Obtain 2 sub-samples from the dataset: training and testing\nsample  &lt;-  sample(c(TRUE, FALSE), nrow(biopsy_clean), replace = TRUE , prob = c(0.8, 0.2) )\nbiopsy_train  &lt;-  biopsy_clean[sample,]\nbiopsy_test  &lt;-  biopsy_clean[!sample,]\n\n\nWhich results in:\n\n\n# check the structure of the resulting datasets\ndim(biopsy_train)\n\n[1] 542  10\n\ndim(biopsy_test)\n\n[1] 141  10"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#indipendent-variables-visualization",
    "href": "practice/practice_slides/slides_lab05.html#indipendent-variables-visualization",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Indipendent variables‚Äô visualization]",
    "text": "Indipendent variables‚Äô visualization]\n\n\nWe create a new df biopsy_train2 (with only 3 columns)\nThen, in Figure¬†2, we visualize the distribution of the explanatory variables, where each is plotted between the two classes of the tumor.\n\n\n# New df for plotting\nbiopsy_train2 &lt;- data.frame(\n  \"level\" = c(biopsy_train$clump_thickness, biopsy_train$uniform_size,\n              biopsy_train$uniform_shape, biopsy_train$marginal_adhesion,\n              biopsy_train$single_epith_size, biopsy_train$bare_nuclei,\n              biopsy_train$bland_chromatin, biopsy_train$normal_nuclei,\n              biopsy_train$mitosis),\n  \"type\" = c(\"Clump Thickness\", \"Uniform Size\", \"Unifrom Shape\",\n             \"Marginal Adhesion\", \"Single Epithilial Size\", \"Bare Nuclei\",\n             \"Bland Chromatin\", \"Normal Nuclei\", \"Mitosis\"), \n  \"class\" = c(biopsy_train$class))\n\n# Plot\nggplot(biopsy_train2, aes(x = level, y = class , colour = class)) + \n  geom_boxplot(fill = NA) +\n  scale_color_manual(values = c(\"#005ca1\", \"#9b2339\")) + \n  geom_jitter(aes(fill = class), alpha = 0.25, shape = 21, width = 0.2) +  \n  scale_fill_manual(values = c(\"#57b7ff\", \"#e07689\")) +  \n  facet_wrap(~type, scales = \"free\") +  \n  theme(plot.title = element_text(size = 13,face=\"bold\", color = \"#873c4a\"),\n        axis.text.x = element_text(size=12,face=\"italic\"), \n        axis.text.y = element_text(size=12,face=\"italic\"),\n        legend.position = \"none\") + \n  labs(title = \"Distribution of each explanatory variable by tumor class (benign/malignant) in samples\") + \n  ylab(label = \"\") + xlab(label = \"\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#indipendent-variables-visualization-output",
    "href": "practice/practice_slides/slides_lab05.html#indipendent-variables-visualization-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Indipendent variables‚Äô visualization]",
    "text": "Indipendent variables‚Äô visualization]\n\n\n\nFigure¬†2: Boxplot of the independent variables  - values are consitently higher & more dispersed for malignant tumors  - values between 1 and 2 are classified as benign and values greater than 2 are classified as malignant"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-fitting",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-fitting",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: model fitting]",
    "text": "Logistic regr.: model fitting]\n\n\nWe fit a logistic regression model to the biopsy_train data using:\n\nthe glm function with argument family = binomial to specify the logistic regression model;\nand with Class ~ . to specify an initial model that uses all the variables as predictors (backward elimination approach).\n\n\n\n\n# Building initial model \nmodel = stats::glm(class ~ . , family = binomial, data=biopsy_train)\n\n\n\nTable¬†2 shows the model summary, with the coefficient estimate for each predictor.\n\nthe broom::tidy function converts the model summary into a data frame.\n\n\n\n\nbroom::tidy(model) %&gt;% \n  mutate('Sign.lev' = case_when(\n    `p.value` &lt; 0.001 ~ \"***\",\n    `p.value` &lt; 0.01 ~ \"**\",\n    `p.value` &lt; 0.05 ~ \"*\",\n    TRUE ~ \"\"))%&gt;%\n  mutate(across(where(is.numeric), ~ round(.x, 4))) %&gt;%\n  knitr::kable()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-coefficients",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-coefficients",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: model coefficients]",
    "text": "Logistic regr.: model coefficients]\n\n\n\nTable¬†2: Complete logistic regression model  + coefficients are in the form of natural logarithm of the odds of the event happening  + positive estimate indicates an increase in the odds of finding a malignant tumor\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nsignif. lev.\n\n\n\n(Intercept)\n-9.4169\n1.1637\n-8.0921\n0.0000\n***\n\n\nclump_thickness\n0.4984\n0.1434\n3.4758\n0.0005\n***\n\n\nuniform_size\n0.0992\n0.2356\n0.4211\n0.6737\n\n\n\nuniform_shape\n0.2809\n0.2655\n1.0580\n0.2901\n\n\n\nmarginal_adhesion\n0.2688\n0.1285\n2.0917\n0.0365\n*\n\n\nsingle_epith_size\n0.0800\n0.1679\n0.4765\n0.6337\n\n\n\nbare_nuclei\n0.3446\n0.0983\n3.5054\n0.0005\n***\n\n\nbland_chromatin\n0.4083\n0.1859\n2.1958\n0.0281\n*\n\n\nnormal_nuclei\n0.2196\n0.1283\n1.7119\n0.0869\n\n\n\nmitosis\n0.4356\n0.3513\n1.2397\n0.2151"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-coefficients-interpretation",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-coefficients-interpretation",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: coefficients‚Äô interpretation",
    "text": "Logistic regr.: coefficients‚Äô interpretation\n\nIn logistic regression, the coefficients are in the form of the natural logarithm of the odds of the response event happening (i.e.¬†\\(Y_i = 1\\)):\n\\[logit(p_i) = \\ln\\left( \\frac{p_i}{1-p_i} \\right) = -9.5063 + 0.3935 \\times Clump\\_Thickness + ... + 0.5065 \\times Mitosis\\]\nHowever, with some algebraic transformation, the logit function can be inverted to obtain the probability of the response event happening as a function of the predictors:\n\\[p_i = \\frac{1}{1 + e^{-(-9.5063 + 0.3935 \\times Clump\\_Thickness + ... + 0.5065 \\times Mitosis)}}\\]\nThis equation represents the logistic regression model‚Äôs best-fit line."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-multicollinearity",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-multicollinearity",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: multicollinearity]",
    "text": "Logistic regr.: multicollinearity]\nLet‚Äôs check for collinearity using the VIF function from the ‚Äòcar‚Äô package.\n\nA Variance Inflation Factor \\(VIF &gt; 5\\) indicates that there could be correlation between predictor variables.\nThe VIF values are all less than 5, which indicates that there is no severe correlation between predictor variables in the model. ‚úÖ\n\n\ncar::vif(model)\n\n  clump_thickness      uniform_size     uniform_shape marginal_adhesion \n         1.165502          2.775020          2.799658          1.258659 \nsingle_epith_size       bare_nuclei   bland_chromatin     normal_nuclei \n         1.456077          1.172923          1.266337          1.209717 \n          mitosis \n         1.060126"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-performance",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-model-performance",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: model performance]",
    "text": "Logistic regr.: model performance]\nHighlight key logistic model performance metrics using broom::glance() function:\n\n\nAIC: A measure of model quality; lower values indicate a better fit with fewer parameters.\n\nNull Deviance: A measure of model error; how well the response variable can be predicted by a model with only an intercept term.\n\nDeviance: A measure of model error; how well the response variable can be predicted by a model with predictor variables.\n\nlower values mean the model fits the data better!\n\n\n\n\nbroom::glance(model)[, c(\"AIC\", \"null.deviance\",\"deviance\")] %&gt;% \n  # show only performance  metrics\n  knitr::kable() \n\n\nTable¬†3: Key logistic model performance metrics\n\n\n\n\nAIC\nnull.deviance\ndeviance\n\n\n111.7472\n710.4404\n91.74724"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-improving-the-model",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-improving-the-model",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: improving the model]",
    "text": "Logistic regr.: improving the model]\n\n\n\nThe model includes all variables, but we could make it more parsimonious by removing variables that are not significant!\nWe use a statistic called the Akaike Information Criterion (AIC) to compare models.\n\nAIC‚Äôs calculation gives a penalty for including additional variables.\nThe model with the lowest AIC is considered the best.\n\n\n\n\n# For example let's fit a model without the variable `uniform_size`\nmodel2 = glm(class~ .-uniform_size, family = binomial, data=biopsy_train)\n\nAccording to the AIC values, the model2 seems better (AIC is lower).\n\n# Compare the AIC values of the 2 models\ntibble(Model = c(\"model\", \"model2\"), \n       AIC = c(AIC(model), AIC(model2) )) %&gt;% \n  kable()\n\n\n\nModel\nAIC\n\n\n\nmodel\n111.7472\n\n\nmodel2\n109.9322"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-systematic-model-selection",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-systematic-model-selection",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: systematic model selection]",
    "text": "Logistic regr.: systematic model selection]\n\n\nThe MASS package‚Äôs function stepAIC enables to perform a systematic model selection (by AIC):\n\nThe direction argument specifies the direction of the stepwise search.\nThe trace argument (if set to TRUE) prints out all the steps.\n\n\nThe best_model has removed these variables:\n\nuniform_shape\nsingle_epith_size\nnormal_nuclei\n\n\nThe best_model has the lowest AIC value (from 100 to 98.5), despite a higher Residual Deviance than the full model (from 80 to 80.6), albeit by a very slight amount.\n\n\n# Select the best model based on AIC\nbest_model &lt;- MASS::stepAIC(model, direction = \"both\", trace = FALSE)\n\n# Compare the AIC values of full and best model\ntibble(Model = c(\"model\", \"best_model\"), \n       AIC = c(AIC(model), AIC(model2)),\n       Deviance = c(deviance(model), deviance(best_model))) %&gt;% kable()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-systematic-model-selection-output",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-systematic-model-selection-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: systematic model selection]",
    "text": "Logistic regr.: systematic model selection]\n\n\n\nModel\nAIC\nDeviance\n\n\n\nmodel\n111.7472\n91.74724\n\n\nbest_model\n109.9322\n92.22712"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-predicting-on-test-data",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-predicting-on-test-data",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: predicting on test data]",
    "text": "Logistic regr.: predicting on test data]\n\nWe can use the predict function to predict the class of the biopsy_test using the best_model.\n\n\nbiopsy_test_pred contains the probability that each of observation (in test data) is malignant.\n\n\nThe classification of the PredictedValue... can be done using different probability thresholds (0.5, 0.4, 0.3, etc.). which will aÔ¨Äect the true and false positivity rates.:\n\n\nPredictedValue_05 is the standard threshold of 0.5.\n\nPredictedValue_04 is a more conservative threshold of 0.4.\n\nPredictedValue_07 is a more aggressive threshold of 0.7.\n\n\n\n\n# Fitted value for the test data 205 samples based on model\nbiopsy_test_pred &lt;- predict(best_model, newdata = biopsy_test, type = \"response\")\n\n# Convert the predicted probabilities into 2 predicted classes\nActualValue &lt;- biopsy_test$class\n\n# Different possible thresholds for the predicted probabilities\nPredictedValue_05 &lt;- if_else(biopsy_test_pred &gt; 0.5, \"pred_malignant\", \"pred_benign\")\nPredictedValue_04 &lt;- if_else(biopsy_test_pred &gt; 0.4, \"pred_malignant\", \"pred_benign\")\nPredictedValue_07 &lt;- if_else(biopsy_test_pred &gt; 0.7, \"pred_malignant\", \"pred_benign\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-predictions-confusion-matrix",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-predictions-confusion-matrix",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr. predictions: confusion matrix]",
    "text": "Logistic regr. predictions: confusion matrix]\n\nIn diagnosing malignant tumors, it is important to keep the false negative rate low as this would be telling someone who has a malignant tumor that it is benign.\n\n\nAt \\(p = 0.7\\), the model will predict more false positives than at \\(p = 0.4\\) (6, v. 4 FN) ‚Äì which we DON‚ÄôT WANT\n\nin this situation \\(p = 0.4\\) is preferable.\n\n\n\nThen, we can evaluate the model‚Äôs performance on the test data by building a confusion matrix\n\n# Build the confusion matrix with p = 0.4\ntable(ActualValue=biopsy_test$class, PredictedValue_04) %&gt;% \n  knitr::kable()\n\n\n\n\npred_benign\npred_malignant\n\n\n\nbenign\n97\n2\n\n\nmalignant\n1\n41\n\n\n\n\n\n\n# Build the confusion matrix with p = 0.7\ntable(ActualValue=biopsy_test$class, PredictedValue_07) %&gt;% \n  knitr::kable()\n\n\n\n\npred_benign\npred_malignant\n\n\n\nbenign\n98\n1\n\n\nmalignant\n2\n40"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-predictions-accuracy",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-predictions-accuracy",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr. predictions: accuracy]",
    "text": "Logistic regr. predictions: accuracy]\n\nWe found that a cutoÔ¨Ä of 0.4 gives a good balance of low false negatives while still maintaining a high true positive rate.\nWith the chosen threshold of \\(p = 0.4\\), we can calculate the model‚Äôs accuracy on the test data.\n\n\n# Build the confusion matrix with p = 0.4\nconf_matr_04 &lt;- table(ActualValue=biopsy_test$class, PredictedValue_04)  \n\n# Calculate the accuracy\naccuracy &lt;- sum(diag(conf_matr_04)) / sum(conf_matr_04)\naccuracy\n\n[1] 0.9787234"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-roc-curve",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-roc-curve",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: ROC curve]",
    "text": "Logistic regr.: ROC curve]\n\n\nbiopsy_test_pred"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-roc-curve-output",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-roc-curve-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: ROC curve]",
    "text": "Logistic regr.: ROC curve]\n\n          4           5           8          11          16          20 \n0.856141485 0.021801730 0.006638569 0.002740809 0.697791544 0.032716342 \n         21          25          32          33          52          61 \n0.997961706 0.002740809 0.004519927 0.998094980 0.381806237 0.890311717 \n         67          69          70          89          90          91 \n0.012240692 0.999981431 0.003471541 0.012240692 0.003929098 0.002740809 \n        106         108         109         113         116         120 \n0.941402362 0.992363246 0.002852352 0.999743776 0.004606417 0.010504861 \n        128         134         139         142         149         155 \n0.007445284 0.006121686 0.011678064 0.001901825 0.144563429 0.001152043 \n        179         185         187         195         196         199 \n0.012240692 0.988166650 0.989829799 0.007445284 0.012240692 0.001152043 \n        201         208         212         225         226         228 \n0.999880409 0.002740809 0.999653743 0.999855572 0.001777246 0.998393444 \n        237         245         247         256         257         268 \n0.999981069 0.002740809 0.999937031 0.933948013 0.003138053 0.859315512 \n        269         270         272         280         286         306 \n0.999916759 0.002740809 0.020062328 0.999271345 0.999995077 0.999301628 \n        308         309         330         331         334         335 \n0.002740809 0.998855592 0.998162104 0.993091237 0.971963147 0.991911245 \n        341         344         348         354         361         366 \n0.995690727 0.001152043 0.001849647 0.999461911 0.999999318 0.002932733 \n        370         374         377         387         390         394 \n0.003842243 0.017475517 0.001777246 0.988988418 0.023239762 0.001152043 \n        400         405         415         416         418         427 \n0.002492425 0.002622405 0.995754012 0.198484715 0.001777246 0.056025207 \n        432         440         445         446         449         460 \n0.044590613 0.008518553 0.054401619 0.001901825 0.001152043 0.018272953 \n        471         472         476         485         487         497 \n0.004835827 0.024892637 0.003138053 0.012487974 0.004835827 0.001152043 \n        500         505         506         511         524         528 \n0.007964004 0.001152043 0.003138053 0.001152043 0.997887796 0.012240692 \n        535         542         544         546         549         553 \n0.002932733 0.003138053 0.007964004 0.013089106 0.003138053 0.028155249 \n        556         558         561         563         564         569 \n0.091374216 0.015217068 0.020062328 0.002740809 0.004835827 0.946116385 \n        577         583         585         587         590         596 \n0.013089106 0.997256237 0.035930450 0.999994075 0.008518553 0.013089106 \n        597         598         600         604         608         611 \n0.011678064 0.042469039 0.026665424 0.987905231 0.001152043 0.999355762 \n        614         622         624         630         633         635 \n0.002932733 0.406899632 0.001152043 0.005173691 0.001152043 0.003138053 \n        637         638         644         648         653         655 \n0.999884288 0.061172200 0.001152043 0.002070039 0.016533076 0.007445284 \n        659         668         672         673         677         678 \n0.999488816 0.007445284 0.009959429 0.004519927 0.002613676 0.008518553 \n        683         693         699 \n0.025294048 0.003138053 0.990326447 \n\npredicted.data &lt;- data.frame(prob.of.malig=biopsy_test_pred, malig = biopsy_test$class)\n\npredicted.data &lt;- predicted.data[order(predicted.data$prob.of.malig, decreasing = F),]\n\npredicted.data$rank &lt;- 1:nrow(predicted.data)\n\nplot_ROC &lt;- ggplot(data=predicted.data, aes(x=rank, y=prob.of.malig)) +\n  geom_point(aes(color=malig), alpha=1, shape=4, stroke=2) +\n  xlab(\"Index\") + \n  ylab(\"Predicted Probability of Tumor Being Malignant\")  \n\nplot_ROC\n\n\nThis shows why lowering the cutoÔ¨Ä improves the accuracy of the model as some malignant tumors are being underestimated which would cause false negatives."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#logistic-regr.-conclusions",
    "href": "practice/practice_slides/slides_lab05.html#logistic-regr.-conclusions",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Logistic regr.: conclusions]",
    "text": "Logistic regr.: conclusions]\n\nUniform Size and Single Epithithial Size were not significant in predicting the malignancy of tumor cells so our model does not include these variables.\nOur fitted model reduces the null deviance and AIC without impacting the residual deviance by a significant amount and is able to predict the testing dataset with &gt;90% accuracy.\nFor further analysis, we could run the model multiple times because our original and revised model are similar.\nNew training and testing data would help confirm our results and help identify possible overfitting."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#section-1",
    "href": "practice/practice_slides/slides_lab05.html#section-1",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "‚Ä¶]",
    "text": "‚Ä¶]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-dataset-manipulation",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-dataset-manipulation",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy dataset manipulation]",
    "text": "biopsy dataset manipulation]\nWe will:\n\nexclude the non-numerical variables (id and class) before conducting the PCA.\nexclude the individuals with missing values using the na.omit() or filter(complete.cases() functions.\nWe can do both in 2 equivalent ways:\n\n\n\n\nwith base R (more compact)\n\n# new (manipulated) dataset \ndata_biopsy &lt;- na.omit(biopsy[,-c(1,11)])\n\n\nwith dplyr (more explicit)\n\n# new (manipulated) dataset \ndata_biopsy &lt;- biopsy %&gt;% \n  # drop incomplete & non-integer columns\n  dplyr::select(-ID, -class) %&gt;% \n  # drop incomplete observations (rows)\n  dplyr::filter(complete.cases(.))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biopsy-dataset-manipulation-1",
    "href": "practice/practice_slides/slides_lab05.html#biopsy-dataset-manipulation-1",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "\nbiopsy dataset manipulation]",
    "text": "biopsy dataset manipulation]\nWe obtained a new dataset with 9 variables and 683 observations (instead of the original 699).\n\n# check reduced dataset \nstr(data_biopsy)\n\n'data.frame':   683 obs. of  9 variables:\n $ V1: int  5 5 3 6 4 8 1 2 2 4 ...\n $ V2: int  1 4 1 8 1 10 1 1 1 2 ...\n $ V3: int  1 4 1 8 1 10 1 2 1 1 ...\n $ V4: int  1 5 1 1 3 8 1 1 1 1 ...\n $ V5: int  2 7 2 3 2 7 2 2 2 2 ...\n $ V6: int  1 10 2 4 1 10 10 1 1 1 ...\n $ V7: int  3 3 3 3 3 9 3 3 1 2 ...\n $ V8: int  1 2 1 7 1 7 1 1 1 1 ...\n $ V9: int  1 1 1 1 1 1 1 1 5 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#calculate-principal-components",
    "href": "practice/practice_slides/slides_lab05.html#calculate-principal-components",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Calculate Principal Components",
    "text": "Calculate Principal Components\nThe first step of PCA is to calculate the principal components. To accomplish this, we use the prcomp() function from the stats package.\n\nWith argument ‚Äúscale = TRUE‚Äù each variable in the biopsy data is scaled to have a mean of 0 and a standard deviation of 1 before calculating the principal components (just like option Autoscaling in MetaboAnalyst)\n\n\n# calculate principal component\nbiopsy_pca &lt;- prcomp(data_biopsy, \n                     # standardize variables\n                     scale = TRUE)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#analyze-principal-components",
    "href": "practice/practice_slides/slides_lab05.html#analyze-principal-components",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Analyze Principal Components",
    "text": "Analyze Principal Components\nLet‚Äôs check out the elements of our obtained biopsy_pca object\n\n(All accessible via the $ operator)\n\n\nnames(biopsy_pca)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\n\n‚Äúsdev‚Äù = the standard deviation of the principal components\n‚Äúsdev‚Äù^2 = the variance of the principal components (eigenvalues of the covariance/correlation matrix)\n‚Äúrotation‚Äù = the matrix of variable loadings (i.e., a matrix whose columns contain the eigenvectors).\n‚Äúcenter‚Äù and ‚Äúscale‚Äù = the means and standard deviations of the original variables before the transformation;\n‚Äúx‚Äù = the principal component scores (after PCA the observations are expressed in principal component scores)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#analyze-principal-components-cont.",
    "href": "practice/practice_slides/slides_lab05.html#analyze-principal-components-cont.",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Analyze Principal Components (cont.)",
    "text": "Analyze Principal Components (cont.)\n\nWe can see the summary of the analysis using the summary() function\n\nThe first row gives the Standard deviation of each component, which can also be retrieved via biopsy_pca$sdev.\nThe second row shows the Proportion of Variance, i.e.¬†the percentage of explained variance.\n\n\nsummary(biopsy_pca)\n\nImportance of components:\n                          PC1     PC2     PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.4289 0.88088 0.73434 0.67796 0.61667 0.54943 0.54259\nProportion of Variance 0.6555 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271\nCumulative Proportion  0.6555 0.74172 0.80163 0.85270 0.89496 0.92850 0.96121\n                           PC8     PC9\nStandard deviation     0.51062 0.29729\nProportion of Variance 0.02897 0.00982\nCumulative Proportion  0.99018 1.00000"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#proportion-of-variance-for-components",
    "href": "practice/practice_slides/slides_lab05.html#proportion-of-variance-for-components",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Proportion of Variance for components]",
    "text": "Proportion of Variance for components]\n\nThe row with Proportion of Variance can be either accessed from summary or calculated as follows:\n\n\n# a) Extracting Proportion of Variance from summary\nsummary(biopsy_pca)$importance[2,]\n\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9 \n0.65550 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271 0.02897 0.00982 \n\n# b) (same thing)\nround(biopsy_pca$sdev^2 / sum(biopsy_pca$sdev^2), digits = 5)\n\n[1] 0.65550 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271 0.02897 0.00982\n\n\n\n\nThe output suggests the 1st principal component explains around 65% of the total variance, the 2nd principal component explains about 9% of the variance, and this goes on with diminishing proportion for each component."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#cumulative-proportion-of-variance-for-components",
    "href": "practice/practice_slides/slides_lab05.html#cumulative-proportion-of-variance-for-components",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Cumulative Proportion of variance for components]",
    "text": "Cumulative Proportion of variance for components]\n\nThe last row from the summary(biopsy_pca), shows the Cumulative Proportion of variance, which calculates the cumulative sum of the Proportion of Variance.\n\n\n# Extracting Cumulative Proportion from summary\nsummary(biopsy_pca)$importance[3,]\n\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9 \n0.65550 0.74172 0.80163 0.85270 0.89496 0.92850 0.96121 0.99018 1.00000 \n\n\n\n\nOnce you computed the PCA in R you must decide the number of components to retain based on the obtained results."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#scree-plot",
    "href": "practice/practice_slides/slides_lab05.html#scree-plot",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Scree plot",
    "text": "Scree plot\nThere are several ways to decide on the number of components to retain.\n\nOne helpful option is visualizing the percentage of explained variance per principal component via a scree plot.\n\nPlotting with the fviz_eig() function from the factoextra package\n\n\n\n\n# Scree plot shows the variance of each principal component \nfactoextra::fviz_eig(biopsy_pca, \n                     addlabels = TRUE, \n                     ylim = c(0, 70))\n\n\n\n\nVisualization is essential in the interpretation of PCA results. Based on the number of retained principal components, which is usually the first few, the observations expressed in component scores can be plotted in several ways."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#scree-plot-output",
    "href": "practice/practice_slides/slides_lab05.html#scree-plot-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Scree plot",
    "text": "Scree plot\n\n\nThe obtained scree plot simply visualizes the output of summary(biopsy_pca)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores]",
    "text": "Principal Component Scores]\nAfter a PCA, the observations are expressed as principal component scores.\n\nWe can retrieve the principal component scores for each Variable by calling biopsy_pca$x, and store them in a new dataframe PC_scores.\nNext we draw a scatterplot of the observations ‚Äì expressed in terms of principal components\n\n\n# Create new object with PC_scores\nPC_scores &lt;- as.data.frame(biopsy_pca$x)\nhead(PC_scores)\n\n\nIt is also important to visualize the observations along the new axes (principal components) to interpret the relations in the dataset:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-output",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores]",
    "text": "Principal Component Scores]\n\n        PC1         PC2         PC3         PC4         PC5         PC6\n1  1.469095 -0.10419679  0.56527102  0.03193593 -0.15088743 -0.05997679\n2 -1.440990 -0.56972390 -0.23642767  0.47779958  1.64188188  0.48268150\n3  1.591311 -0.07606412 -0.04882192  0.09232038 -0.05969539  0.27916615\n4 -1.478728 -0.52806481  0.60260642 -1.40979365 -0.56032669 -0.06298211\n5  1.343877 -0.09065261 -0.02997533  0.33803588 -0.10874960 -0.43105416\n6 -5.010654 -1.53379305 -0.46067165 -0.29517264  0.39155544 -0.11527442\n         PC7        PC8          PC9\n1 -0.3491471 -0.4200360 -0.005687222\n2  1.1150819 -0.3792992  0.023409926\n3 -0.2325697 -0.2096465  0.013361828\n4  0.2109599  1.6059184  0.182642900\n5 -0.2596714 -0.4463277 -0.038791241\n6 -0.3842529  0.1489917 -0.042953075"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-adding-label-variable",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-adding-label-variable",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores plot (adding label variable)]",
    "text": "Principal Component Scores plot (adding label variable)]\n\nWhen data includes a factor variable, like in our case, it may be interesting to show the grouping on the plot as well.\n\n\nIn such cases, the label variable class can be added to the PC set as follows.\n\n\n# retrieve class variable\nbiopsy_no_na &lt;- na.omit(biopsy)\n# adding class grouping variable to PC_scores\nPC_scores$Label &lt;- biopsy_no_na$class\n\n The visualization of the observation points (point cloud) could be in 2D or 3D."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-2d",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-2d",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores plot (2D)]",
    "text": "Principal Component Scores plot (2D)]\nThe Scores Plot can be visualized via the ggplot2 package.\n\ngrouping is indicated by argument the color = Label;\n\ngeom_point() is used for the point cloud.\n\n\nggplot(PC_scores, \n       aes(x = PC1, \n           y = PC2, \n           color = Label)) +\n  geom_point() +\n  scale_color_manual(values=c(\"#245048\", \"#CC0066\")) +\n  ggtitle(\"Figure 1: Scores Plot\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-2d-output",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-2d-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores plot (2D)]",
    "text": "Principal Component Scores plot (2D)]\n\n\nFigure 1 shows the observations projected into the new data space made up of principal components"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-2d-ellipse-plot",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-2d-ellipse-plot",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores (2D Ellipse Plot)]",
    "text": "Principal Component Scores (2D Ellipse Plot)]\nConfidence ellipses can also be added to a grouped scatter plot visualized after a PCA. We use the ggplot2 package.\n\ngrouping is indicated by argument the color = Label;\n\ngeom_point() is used for the point cloud;\nthe stat_ellipse() function is called to add the ellipses per biopsy group.\n\n\nggplot(PC_scores, \n       aes(x = PC1, \n           y = PC2, \n           color = Label)) +\n  geom_point() +\n  scale_color_manual(values=c(\"#245048\", \"#CC0066\")) +\n  stat_ellipse() + \n  ggtitle(\"Figure 2: Ellipse Plot\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-2d-ellipse-plot-output",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-2d-ellipse-plot-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores (2D Ellipse Plot)]",
    "text": "Principal Component Scores (2D Ellipse Plot)]\n\n\nFigure 2 shows the observations projected into the new data space made up of principal components, with 95% confidence regions displayed."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-3d",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-3d",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores plot (3D)]",
    "text": "Principal Component Scores plot (3D)]\n\nA 3D scatterplot of observations shows the first 3 principal components‚Äô scores.\n\nFor this one, we need the scatterplot3d() function of the scatterplot3d package;\nThe color argument assigned to the Label variable;\nTo add a legend, we use the legend() function and specify its coordinates via the xyz.convert() function.\n\n\n# 3D scatterplot ...\nplot_3d &lt;- with(PC_scores, \n                scatterplot3d::scatterplot3d(PC_scores$PC1, \n                                             PC_scores$PC2, \n                                             PC_scores$PC3, \n                                             color = as.numeric(Label), \n                                             pch = 19, \n                                             main =\"Figure 3: 3D Scatter Plot\", \n                                             xlab=\"PC1\",\n                                             ylab=\"PC2\",\n                                             zlab=\"PC3\"))\n\n# ... + legend\nlegend(plot_3d$xyz.convert(0.5, 0.7, 0.5), \n       pch = 19, \n       yjust=-0.6,\n       xjust=-0.9,\n       legend = levels(PC_scores$Label), \n       col = seq_along(levels(PC_scores$Label)))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-3d-output",
    "href": "practice/practice_slides/slides_lab05.html#principal-component-scores-plot-3d-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Principal Component Scores plot (3D)]",
    "text": "Principal Component Scores plot (3D)]\n\n\nFigure 3 shows the observations projected into the new 3D data space made up of principal components."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biplot-principal-components-v.-original-variables",
    "href": "practice/practice_slides/slides_lab05.html#biplot-principal-components-v.-original-variables",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Biplot: principal components v. original variables]",
    "text": "Biplot: principal components v. original variables]\nNext, we create another special type of scatterplot (a biplot) to understand the relationship between the principal components and the original variables.\nIn the biplot each of the observations is projected onto a scatterplot that uses the first and second principal components as the axes.\n\nFor this plot, we use the fviz_pca_biplot() function from the factoextra package\n\nWe will specify the color for the variables, or rather, for the ‚Äúloading vectors‚Äù\nThe habillage argument allows to highlight with color the grouping by class\n\n\n\n\n\nfactoextra::fviz_pca_biplot(biopsy_pca, \n                repel = TRUE,\n                col.var = \"black\",\n                habillage = biopsy_no_na$class,\n                title = \"Figure 4: Biplot\", geom=\"point\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#biplot-principal-components-v.-original-variables-output",
    "href": "practice/practice_slides/slides_lab05.html#biplot-principal-components-v.-original-variables-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Biplot: principal components v. original variables]",
    "text": "Biplot: principal components v. original variables]\n\n\nThe axes show the principal component scores, and the vectors are the loading vectors"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#interpreting-biplot-output",
    "href": "practice/practice_slides/slides_lab05.html#interpreting-biplot-output",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Interpreting biplot output",
    "text": "Interpreting biplot output\n\nBiplots have two key elements: scores (the 2 axes) and loadings (the vectors). As in the scores plot, each point represents an observation projected in the space of principal components where:\n\nBiopsies of the same class are located closer to each other, which indicates that they have similar scores referred to the 2 main principal components;\nThe loading vectors show strength and direction of association of original variables with new PC variables.\n\n\nAs expected from PCA, the single PC1 accounts for variance in almost all original variables, while V9 has the major projection along PC2."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#interpreting-biplot-output-cont.",
    "href": "practice/practice_slides/slides_lab05.html#interpreting-biplot-output-cont.",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Interpreting biplot output (cont.)",
    "text": "Interpreting biplot output (cont.)\n\nscores &lt;- biopsy_pca$x\n\nloadings &lt;- biopsy_pca$rotation\n# excerpt of first 2 components\nloadings[ ,1:2] \n\n          PC1         PC2\nV1 -0.3020626 -0.14080053\nV2 -0.3807930 -0.04664031\nV3 -0.3775825 -0.08242247\nV4 -0.3327236 -0.05209438\nV5 -0.3362340  0.16440439\nV6 -0.3350675 -0.26126062\nV7 -0.3457474 -0.22807676\nV8 -0.3355914  0.03396582\nV9 -0.2302064  0.90555729"
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#recap-of-the-workshops-content",
    "href": "practice/practice_slides/slides_lab05.html#recap-of-the-workshops-content",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Recap of the workshop‚Äôs content]",
    "text": "Recap of the workshop‚Äôs content]\n\nTOPICS WE COVERED\n\nMotivated the choice of learning/using R for scientific quantitative analysis, and lay out some fundamental concepts in biostatistics with concrete R coding examples.\nConsolidated understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.\nDiscussed the relationship between any two variables, and introduce a widely used analytical tool: regression.\nPresented a popular ML technique for dimensionality reduction (PCA), performed both with MetaboAnalyst and R.\nIntroduction to power analysis to define the correct sample size for hypotheses testing and discussion of how ML approaches deal with available data."
  },
  {
    "objectID": "practice/practice_slides/slides_lab05.html#final-thoughts",
    "href": "practice/practice_slides/slides_lab05.html#final-thoughts",
    "title": "Lab 5: Intro to Machine Learning",
    "section": "Final thoughts",
    "text": "Final thoughts\n\n\n\n\nWhile the workshop only allowed for a synthetic overview of fundamental ideas, it hopefully provided a solid foundation on the most common statistical analysis you will likely run in your daily work:\n\nThorough understanding of the input data and the data collection process\nUnivariate and bivariate exploratory analysis (accompanied by visual intuition) to form hypothesis\nUpon verifying the assumptions, we fit data to hypothesized model(s)\n\nAssessment of the model performance (\\(R^2\\), \\(Adj. R^2\\), \\(F-Statistic\\), etc.)\n\n\nYou should now have a solid grasp on the R language to keep using and exploring the huge potential of this programming ecosystem\nWe only scratched the surface in terms of ML classification and prediction models, but we got a hang of the fundamental steps and some useful tools that might serve us also in more advanced analysis\n\n\n\n\n\n\n\nR 4 Statistics | 2025"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#topics-discussed-in-lecture-3",
    "href": "practice/practice_slides/slides_lab03.html#topics-discussed-in-lecture-3",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Topics discussed in Lecture # 3",
    "text": "Topics discussed in Lecture # 3\n\nLecture 3: topics\n\nTesting and summarizing relationship between 2 variables (correlation)\n\nPearson‚Äôs ùíì analysis (param)\n\nSpearman test (no param)\n\n\n\nMeasures of association\n\nChi-Square test of independence\n\nFisher‚Äôs Exact Test\n\nalternative to the Chi-Square Test of Independence\n\n\n\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\n\nWidely used analytical tools\n\nSimple linear regression models\nMultiple Linear Regression models\n\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised & Unsupervised algorithms"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab03.html#needed-r-packages",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n\n# Load pckgs for this R session\n\n# -- General \nlibrary(fs)      # file/directory interactions\nlibrary(here)    # tools find your project's files, based on working directory\nlibrary(paint) # paint data.frames summaries in colour\nlibrary(janitor) # tools for examining and cleaning data\nlibrary(dplyr)   # {tidyverse} tools for manipulating and summarizing tidy data \nlibrary(forcats) # {tidyverse} tool for handling factors\nlibrary(openxlsx) # Read, Write and Edit xlsx Files\nlibrary(flextable) # Functions for Tabular Reporting\n# -- Statistics\nlibrary(rstatix) # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(lmtest) # Testing Linear Regression Models \nlibrary(broom) # Convert Statistical Objects into Tidy Tibbles\n#library(tidymodels) # not installed on this machine\nlibrary(performance) # Assessment of Regression Models Performance \n# -- Plotting\nlibrary(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-1-nhanes",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-1-nhanes",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 1 (NHANES)",
    "text": "Importing Dataset 1 (NHANES)\n\nName: NHANES (National Health and Nutrition Examination Survey) combines interviews and physical examinations to assess the health and nutritional status of adults and children in the United States. Started in the 1960s, it became a continuous program in 1999.Documentation: dataset1Sampling details: Here we use a sample of 500 adults from NHANES 2009-2010 & 2011-2012 (nhanes.samp.adult.500 in the R oibiostat package, which has been adjusted so that it can be viewed as a random sample of the US population)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nnhanes_samp &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"nhanes.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n\nAdapting the function here to match your own folder structure"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#nhanes-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#nhanes-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "NHANES Variables and their description",
    "text": "NHANES Variables and their description\n\n[EXCERPT: see complete file in Input Data Folder]\n\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nX\nint\nxxxx\n\n\nID\nint\nxxxxx\n\n\nSurveyYr\nchr\nyyyy_mm. Ex. 2011_12\n\n\nGender\nchr\nGender (sex) of study participant coded as male or female\n\n\nAge\nint\n##\n\n\nAgeDecade\nchr\nyy-yy es 20-29\n\n\nEducation\nchr\n[&gt;= 20 yro]. Ex. 8thGrade, 9-11thGrade, HighSchool, SomeCollege, or CollegeGrad.\n\n\nWeight\ndbl\nWeight in kg\n\n\nHeight\ndbl\nStanding height in cm. Reported for participants aged 2 years or older.\n\n\nBMI\ndbl\nBody mass index (weight/height2 in kg/m2). Reported for participants aged 2 years or older\n\n\nPulse\nint\n60 second pulse rate\n\n\nBPDiaAve\nint\nCombined diastolic blood pressure reading, following the # procedure outlined for BPXDAR\n\n\nDirectChol\ndbl\nDirect HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nTotChol\ndbl\nTotal HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nDiabetes\nchr\nStudy participant told by a doctor or health professional that they have diabetes\n\n\nDiabetesAge\nint\nAge of study participant when first told they had diabetes\n\n\nHealthGen\nchr\nSelf-reported rating of health: Excellent, Vgood, Good, Fair, or Poor Fair\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-2-prevend",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-2-prevend",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 2 (PREVEND)",
    "text": "Importing Dataset 2 (PREVEND)\n\nName: PREVEND (Prevention of REnal and Vascular END-stage Disease) is a study which took place in the Netherlands starting in the 1990s, with subsequent follow-ups throughout the 2000s. This dataset is from the third survey, which participants completed in 2003-2006; data is provided for 4,095 individuals who completed cognitive testing.Documentation: dataset2 and sample dataset variables‚Äô codebookSampling details: Here we use a sample of 500 adults taken from 4,095 individuals who completed cognitive testing (i.e.¬†the prevend.samp dataset in the R oibiostat package)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nprevend_samp &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"prevend.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#prevend-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#prevend-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "PREVEND Variables and their description",
    "text": "PREVEND Variables and their description\n\n[EXCERPT: see complete file in Input Data Folder]\n\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nX\nint\nPatient ID\n\n\nAge\nint\nAge in years\n\n\nGender\nint\nExpressed as: 0 = males; 1 = females\n\n\nRFFT\nint\nPerformance on the Ruff Figural Fluency Test. Scores range from 0 (worst) to 175 (best)\n\n\nVAT\nint\nVisual Association Test score. Scores may range from 0 (worst) to 12 (best)\n\n\nChol\ndbl\nTotal cholesterol, in mmol/L.\n\n\nHDL\ndbl\nHDL cholesterol, in mmol/L.\n\n\nStatin\nint\nStatin use at enrollment. Numeric vector: 0 = No; 1 = Yes.\n\n\nCVD\nint\nHistory of cardiovascular event. Numeric vector: 0 = No; 1 = Yes\n\n\nDM\nint\nDiabetes mellitus status at enrollment. Numeric vector: 0 = No; 1 = Yes\n\n\nEducation\nint\nHighest level of education. Numeric: 0 primary school; 1 = lower secondary education; 3 = university\n\n\nSmoking\nint\nSmoking at enrollment. numeric vector: 0 = No; 1 = Yes\n\n\nHypertension\nint\nStatus of hypertension at enrollment. Numeric vector: 0 = No; 1 = Yes\n\n\nEthnicity\nint\nExpressed as: 0 = Western European; 1 = African; 2 = Asian; 3 = Other\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-3-famuss",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-3-famuss",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 3 (FAMuSS)",
    "text": "Importing Dataset 3 (FAMuSS)\n\nName: FAMuSS (Functional SNPs Associated with Muscle Size and Strength) examine the association of demographic, physiological and genetic characteristics with muscle strength ‚Äì including data on race and genotype at a specific locus on the ACTN3 gene (the ‚Äúsports gene‚Äù).Documentation: dataset3Sampling details: the DATASET includes 595 observations on 9 variables (famuss in the R oibiostat package)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nfamuss &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"famuss.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#famuss-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#famuss-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "FAMuSS Variables and their description",
    "text": "FAMuSS Variables and their description\n\n[See complete file in Input Data Folder]\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\nX\nid\n\n\nndrm.ch\nPercent change in strength in the non-dominant arm\n\n\ndrm.ch\nPercent change in strength in the dominant arm\n\n\nsex\nSex of the participant\n\n\nage\nAge in years\n\n\nrace\nRecorded as African Am (African American), Caucasian, Asian, Hispanic, Other\n\n\nheight\nHeight in inches\n\n\nweight\nWeight in pounds\n\n\nactn3.r577x\nGenotype at the location r577x in the ACTN3 gene.\n\n\nbmi\nBody Mass Index"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#explore-relationships-between-two-variables",
    "href": "practice/practice_slides/slides_lab03.html#explore-relationships-between-two-variables",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Explore relationships between two variables",
    "text": "Explore relationships between two variables\nApproaches for summarizing relationships between two variables vary depending on variable types‚Ä¶\n\nTwo numerical variables\nTwo categorical variables\nOne numerical variable and one categorical variable\n\nTwo variables \\(x\\) and \\(y\\) are\n\n\npositively associated if \\(y\\) increases as \\(x\\) increases.\n\nnegatively associated if \\(y\\) decreases as \\(x\\) increases."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables (plot)",
    "text": "Two numerical variables (plot)\nHeight and weight (taken from the nhanes_samp dataset) are positively associated.\n\nnotice we can also use the generic base R function plot for a quick scatter plot\n\n\n# rename for convenience\nnhanes &lt;- nhanes_samp %&gt;% \n  janitor::clean_names()\n\n# basis plot \nplot(nhanes$height, nhanes$weight,\n     xlab = \"Height (cm)\", ylab = \"Weight (kg)\", cex = 0.8)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot-output",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables (plot)",
    "text": "Two numerical variables (plot)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor)",
    "text": "Two numerical variables: correlation (with stats::cor)\n\nCorrelation is a numerical summary that measures the strength of a linear relationship between two variables.\n\n\nThe correlation coefficient \\(r\\) takes on values between \\(-1\\) and \\(1\\).\nThe closer \\(r\\) is to \\(\\pm 1\\), the stronger the linear association.\n\nHere we compute the Pearson rho (parametric), with base R function stats::cor\n\nthe use argument let us choose how to deal with missing values (in this case only using all complete pairs)\n\n\n\n\nis.numeric(nhanes$height) \n\n[1] TRUE\n\nis.numeric(nhanes$weight)\n\n[1] TRUE\n\n# using `stats` package\nstats::cor(x = nhanes$height, y =  nhanes$weight, \n    # argument for dealing with missing values\n    use = \"pairwise.complete.obs\",\n    method = \"pearson\")\n\n[1] 0.4102269"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor.test)",
    "text": "Two numerical variables: correlation (with stats::cor.test)\n\nHere we compute the Pearson rho (parametric), with the function cor.test (the same we used for testing paired samples)\n\nimplicitely takes care on NAs\n\n\n\n\n\n# using `stats` package \ncor_test_result &lt;- cor.test(x = nhanes$height, y =  nhanes$weight, \n                            method = \"pearson\")\n\n# looking at the cor estimate\ncor_test_result[[\"estimate\"]][[\"cor\"]]\n\n[1] 0.4102269\n\n\n\nThe function ggpubr::ggscatter gives us all in one (scatter plot + \\(r\\) (‚ÄúR‚Äù))! ü§Ø\n\n\nlibrary(\"ggpubr\") # 'ggplot2' Based Publication Ready Plots\nggpubr::ggscatter(nhanes, x = \"height\", y = \"weight\", \n                  cor.coef = TRUE, cor.method = \"pearson\", #cor.coef.coord = 2,\n                  xlab = \"Height (in)\", ylab = \"Weight (lb)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test-output",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor.test)",
    "text": "Two numerical variables: correlation (with stats::cor.test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation",
    "text": "Spearman rank-order correlation\nThe Spearman‚Äôs rank-order correlation is the nonparametric version of the Pearson correlation.\nSpearman‚Äôs correlation coefficient, (\\(œÅ\\), also signified by \\(rs\\)) measures the strength and direction of association between two ranked variables.\n\nused when 2 variables have a non-linear relationship\nexcellent for ordinal data (when Pearson‚Äôs is not appropriate), i.e.¬†Likert scale items\n\n\nTo compute it, we simply calculate Pearson‚Äôs correlation of the rankings of the raw data (instead of the data)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example)",
    "text": "Spearman rank-order correlation (example)\n\nLet‚Äôs say we want to get Spearman‚Äôs correlation with ordinal factors Education and HealthGen in the NHANES sample.\n\nWe have to convert them to their underlying numeric code, to compare rankings.\n\n\ntabyl(nhanes$education)\n\n nhanes$education   n percent valid_percent\n        8th Grade  32   0.064    0.06412826\n   9 - 11th Grade  68   0.136    0.13627255\n     College Grad 157   0.314    0.31462926\n      High School  94   0.188    0.18837675\n     Some College 148   0.296    0.29659319\n             &lt;NA&gt;   1   0.002            NA\n\ntabyl(nhanes$health_gen)\n\n nhanes$health_gen   n percent valid_percent\n         Excellent  47   0.094    0.10444444\n              Fair  53   0.106    0.11777778\n              Good 177   0.354    0.39333333\n              Poor  11   0.022    0.02444444\n             Vgood 162   0.324    0.36000000\n              &lt;NA&gt;  50   0.100            NA\n\nnhanes &lt;- nhanes %&gt;% \n  # reorder education\n  mutate (edu_ord = factor (education, \n                            levels = c(\"8th Grade\", \"9 - 11th Grade\",\n                                       \"High School\", \"Some College\",\n                                       \"College Grad\" , NA))) %&gt;%  \n  # create edu_rank \n  mutate (edu_rank = as.numeric(edu_ord)) %&gt;% \n  # reorder health education\n  mutate (health_ord = factor (health_gen, \n                            levels = c( NA, \"Poor\", \"Fair\",\n                                       \"Good\", \"Vgood\",\n                                       \"Excellent\"))) %&gt;%\n  # create health_rank \n  mutate (health_rank = as.numeric(health_ord))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example), cont.",
    "text": "Spearman rank-order correlation (example), cont.\n\n\nLet‚Äôs check out the ..._rank version of the 2 categorical variables of interest:\n\n\neducation from edu_ord to edu_rank\n\n\n\n\n\ntable(nhanes$edu_ord, useNA = \"ifany\" )\n\n\n     8th Grade 9 - 11th Grade    High School   Some College   College Grad \n            32             68             94            148            157 \n          &lt;NA&gt; \n             1 \n\ntable(nhanes$edu_rank, useNA = \"ifany\" )\n\n\n   1    2    3    4    5 &lt;NA&gt; \n  32   68   94  148  157    1 \n\n\n\n\ngeneral health from health_ord to health_rank\n\n\n\ntable(nhanes$health_ord, useNA = \"ifany\" )\n\n\n     Poor      Fair      Good     Vgood Excellent      &lt;NA&gt; \n       11        53       177       162        47        50 \n\ntable(nhanes$health_rank,  useNA = \"ifany\" )\n\n\n   1    2    3    4    5 &lt;NA&gt; \n  11   53  177  162   47   50"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.-1",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example cont.)",
    "text": "Spearman rank-order correlation (example cont.)\nAfter setting up the variables in the correct (numerical rank) format, now we can actually compute it: + same function call stats::cor.test + but specifying argument method = \"spearman\"\n\n# -- using `stats` package \ncor_test_result_sp &lt;- cor.test(x = nhanes$edu_rank,\n                               y = nhanes$health_rank, \n                               method = \"spearman\", \n                               exact = FALSE) # removes the Ties message warning \n# looking at the cor estimate\ncor_test_result_sp\n\n\n    Spearman's rank correlation rho\n\ndata:  nhanes$edu_rank and nhanes$health_rank\nS = 10641203, p-value = 1.915e-10\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2946493 \n\n# -- only print Spearman rho \n#cor_test_result_sp[[\"estimate\"]][[\"rho\"]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-plot",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-plot",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (plot)",
    "text": "Two categorical variables (plot)\n\nIn the famuss dataset, the variables race, and actn3.r577x are categorical variables.\n\nwe can use the generic base R function graphics::barplot\n\n\n\nmycolors_contrast &lt;- c(\"#9b2339\", \"#E7B800\",\"#239b85\", \"#85239b\", \"#9b8523\",\"#23399b\", \"#d8e600\", \"#0084e6\",\"#399B23\",  \"#e60066\" , \"#00d8e6\",  \"#005ca1\", \"#e68000\")\n\n## genotypes as columns\ngenotype.race = matrix(table(famuss$actn3.r577x, famuss$race), ncol=3, byrow=T)\ncolnames(genotype.race) = c(\"CC\", \"CT\", \"TT\")\nrownames(genotype.race) = c(\"African Am\", \"Asian\", \"Caucasian\", \"Hispanic\", \"Other\")\n\n# using generic base::barplot\ngraphics::barplot(genotype.race, col = mycolors_contrast[1:5], ylim=c(0,300), width=2)\nlegend(\"topright\", inset=c(.05, 0), fill=mycolors_contrast[1:5], \n       legend=rownames(genotype.race))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (contingency table)",
    "text": "Two categorical variables (contingency table)\n\nSpecifically, the variable actn3.r577x takes on three possible levels (CC, CT, or TT) which indicate the distribution of genotype at location r577x on the ACTN3 gene for the FAMuSS study participants.\nA contingency table summarizes data for two categorical variables.\n\nthe function stats::addmargins puts arbitrary Margins on multidimensional tables\n\nThe extra column & row \"Sum\" provide the marginal totals across each row and each column, respectively\n\n\n\n\n# levels of actn3.r577x\ntable(famuss$actn3.r577x)\n\n\n CC  CT  TT \n173 261 161 \n\n# contingency table to summarize race and actn3.r577x\naddmargins(table(famuss$race, famuss$actn3.r577x))\n\n            \n              CC  CT  TT Sum\n  African Am  16   6   5  27\n  Asian       21  18  16  55\n  Caucasian  125 216 126 467\n  Hispanic     4  10   9  23\n  Other        7  11   5  23\n  Sum        173 261 161 595"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table-prop",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table-prop",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (contingency table prop)",
    "text": "Two categorical variables (contingency table prop)\n\nContingency tables can also be converted to show proportions. Since there are 2 variables, it is necessary to specify whether the proportions are calculated according to the row variable or the column variable.\n\nusing the margin = argument in the base::prop.table function (1 indicates rows, 2 indicates columns)\n\n\n# adding row proportions\naddmargins(prop.table(table(famuss$race, famuss$actn3.r577x), margin =  1))\n\n            \n                    CC        CT        TT       Sum\n  African Am 0.5925926 0.2222222 0.1851852 1.0000000\n  Asian      0.3818182 0.3272727 0.2909091 1.0000000\n  Caucasian  0.2676660 0.4625268 0.2698073 1.0000000\n  Hispanic   0.1739130 0.4347826 0.3913043 1.0000000\n  Other      0.3043478 0.4782609 0.2173913 1.0000000\n  Sum        1.7203376 1.9250652 1.3545972 5.0000000\n\n# adding column proportions\naddmargins(prop.table(table(famuss$race, famuss$actn3.r577x),margin =  2))\n\n            \n                     CC         CT         TT        Sum\n  African Am 0.09248555 0.02298851 0.03105590 0.14652996\n  Asian      0.12138728 0.06896552 0.09937888 0.28973168\n  Caucasian  0.72254335 0.82758621 0.78260870 2.33273826\n  Hispanic   0.02312139 0.03831418 0.05590062 0.11733618\n  Other      0.04046243 0.04214559 0.03105590 0.11366392\n  Sum        1.00000000 1.00000000 1.00000000 3.00000000"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence",
    "text": "Chi Squared test of independence\nThe Chi-squared test is a hypothesis test used to determine whether there is a relationship between two categorical variables.\n\ncategorical vars. can have nominal or ordinal measurement scale\nthe observed frequencies are compared with the expected frequencies and their deviations are examined.\n\n\n# Chi-squared test\n# (Test of association to see if \n# H0: the 2 cat var (race  & actn3.r577x ) are independent\n# H1: the 2 cat var are correlated in __some way__\n\ntab &lt;- table(famuss$race, famuss$actn3.r577x)\ntest_chi &lt;- chisq.test(tab)\n\nthe obtained result (test_chi) is a list of objects‚Ä¶\n\n\n\n You try‚Ä¶\n\n\n‚Ä¶run View(test_chi) to check"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-cont",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-cont",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence (cont)",
    "text": "Chi Squared test of independence (cont)\nWithin test_chi results there are:\n\n\n\n\nObserved frequencies =\nhow often a combination occurs in our sample\n\n\n# Observed frequencies\ntest_chi$observed\n\n            \n              CC  CT  TT\n  African Am  16   6   5\n  Asian       21  18  16\n  Caucasian  125 216 126\n  Hispanic     4  10   9\n  Other        7  11   5\n\n\n\n\n\nExpected frequencies = what would it be if the 2 vars were PERFECTLY INDEPENDENT\n\n\n# Expected frequencies\nround(test_chi$expected  , digits = 1 )\n\n            \n                CC    CT    TT\n  African Am   7.9  11.8   7.3\n  Asian       16.0  24.1  14.9\n  Caucasian  135.8 204.9 126.4\n  Hispanic     6.7  10.1   6.2\n  Other        6.7  10.1   6.2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-results",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-results",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence (results)",
    "text": "Chi Squared test of independence (results)\n\nRecall that:\n\n\n\\(H_{0}\\): the 2 cat. var. are independent\n\n\n\\(H_{1}\\): the 2 cat. var. are correlated in some way\n\n\nThe result of Chi-Square test represents a comparison of the above two tables (observed v. expected):\n\np-value = 0.01286 smaller than Œ± = 0.05 so we REJECT the null hypothesis (i.e.¬†there‚Äôs likely an association between race and ACTN3 gene)\n\n\n\n\ntest_chi\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 19.4, df = 8, p-value = 0.01286"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence",
    "href": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Computing Cramer‚Äôs V after test of independence",
    "text": "Computing Cramer‚Äôs V after test of independence\n\nRecall that Crammer‚Äôs V allows to measure the effect size of the test of independence (i.e.¬†the strength of association between two nominal variables)\n\n\n\\(V\\) ranges from [0 1] (the smaller \\(V\\), the lower the correlation)\n\n\\[V=\\sqrt{\\frac{\\chi^2}{n(k-1)}} \\]\nwhere:\n\n\n\\(V\\) denotes Cram√©r‚Äôs V\n\n\\(\\chi^2\\) is the Pearson chi-square statistic from the prior test\n\n\\(n\\) is the sample size involved in the test\n\n\\(k\\) is the lesser number of categories of either variable"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence-2-ways",
    "href": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence-2-ways",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Computing Cramer‚Äôs V after test of independence (2 ways)",
    "text": "Computing Cramer‚Äôs V after test of independence (2 ways)\n\n\n‚úçüèª ‚ÄúBy hand‚Äù first to see the steps\n\n\n# Compute Creamer's V by hand\n \n# inputs \nchi_calc &lt;- test_chi$statistic\nn &lt;- nrow(famuss) # N of obd \nn_r &lt;- nrow(test_chi$observed) # number of rows in the contingency table\nn_c &lt;- ncol(test_chi$observed) # number of columns in the contingency table\n\n# Cramer‚Äôs V\nsqrt(chi_calc / (n*min(n_r -1, n_c -1)) )\n\nX-squared \n0.1276816 \n\n\n\nüë©üèª‚Äçüíª Using an R function rstatix::cramer_v\n\n\n\n# Cramer‚Äôs V with rstatix\nrstatix::cramer_v(test_chi$observed)\n\n[1] 0.1276816\n\n\nCramer‚Äôs V = 0.12, which indicates a relatively weak association between the two categorical variables. It suggests that while there may be some relationship between the variables, it is not particularly strong."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit",
    "text": "Chi Squared test of goodness of fit\nIn some cases the Chi-square test examines whether or not an observed frequency distribution matches an expected theoretical distribution.\nHere, we are conducting a type of Chi-square Goodness of Fit Test which:\n\nserves to test whether the observed distribution of a categorical variable differs from your expectations\ninterprets the statistic based on the discrepancies between observed and expected counts"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit (example)",
    "text": "Chi Squared test of goodness of fit (example)\n\nSince the participants of the FAMuSS study where volunteers at a university, they did not come from a ‚Äúrepresentative‚Äù sample of the US population, we can use the \\(\\chi^{2}\\) goodness of fit test to test against:\n\n\n\\(H_{0}\\): the study participants (1st row below) are racially representative of the general population (2nd row below)\n\n\n\n\n\n\n\nRace\nAfrican.American\nAsian\nCaucasian\nOther\nTotal\n\n\n\nFAMuSS (Observed) \n27\n55\n467\n46\n595\n\n\nUS Census (Expected) \n76.16\n5.95\n478.38\n34.51\n595\n\n\n\n\n\n\nWe use the formula \\[\\chi^{2} = \\sum_{k}\\frac{(Observed - Expected)^{2}}{Expected}\\]\nUnder \\(H_{0}\\), the sample proportions should equal the population proportions."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example-1",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit (example)",
    "text": "Chi Squared test of goodness of fit (example)\n\n\n# Subset the vectors of frequencies from the 2 rows  \nobserved &lt;- c(27,  55,  467, 46)\nexpected &lt;- c(76.2,  5.95, 478.38,  34.51)\n\n# Calculate Chi-Square statistic manually \nchi_sq_statistic &lt;- sum((observed - expected)^2 / expected) \ndf &lt;- length(observed) - 1 \np_value &lt;- 1 - pchisq(chi_sq_statistic, df) \n\n# Print results \nchi_sq_statistic\n\n[1] 440.2166\n\ndf\n\n[1] 3\n\np_value \n\n[1] 0\n\n\nThe calculated \\(\\chi^{2}\\) statistic is very large, and the p_value is close to 0. Hence, there is more than sufficient evidence to reject the null hypothesis that the sample is representative of the general population.\nComparing the observed and expected values (or the residuals), we find the largest discrepancy with the over-representation of Asian study participants."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: BMI and age",
    "text": "Visualize the data: BMI and age\nWe are mainly looking for a ‚Äúvaguely‚Äù linear shape here\n\n\nggplot2 gives us a visual confirmation with geom_point()\n\nEssentially, geom_smooth() adds a trend line over an existing plot\n\ninside the function, we have different options with the method argument (default is LOESS (locally estimated scatterplot smoothing))\nwith method = lm we get the linear best fit (the least squares regression line) & its 95% CI\n\n\n\n\nggplot(nhanes, aes (x = age, \n                          y = bmi)) + \n  geom_point() + \n  geom_smooth(method = lm,  \n              #se = FALSE\n              )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: BMI and age",
    "text": "Visualize the data: BMI and age"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-model",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nThe lm() function is used to fit linear models has the following generic structure:\n\nlm(y ~ x, data)\n\nwhere:\n\nthe 1st argument y ~ x specifies the variables used in the model (here the model regresses a response variable \\(y\\) against an explanatory variable \\(x\\).\nThe 2nd argument data is used only when the dataframe name is not already specified in the first argument."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models syntax",
    "text": "Linear regression models syntax\nThe following example shows fitting a linear model that predicts BMI from age (in years) using data from nhanes adult sample (individuals 21 years of age or older from the NHANES data).\n\n# fitting linear model\nlm(nhanes$bmi ~ nhanes$age)\n\n\n# or equivalently...\nlm(bmi ~ age, data = nhanes)\n\n\nCall:\nlm(formula = bmi ~ age, data = nhanes)\n\nCoefficients:\n(Intercept)          age  \n   28.40113      0.01982  \n\n\n\nRunning the function creates an object (of class lm) that contains several components (model coefficients, etc), either directly displayed or accessible with summary() notation or specific functions."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax-1",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models syntax",
    "text": "Linear regression models syntax\n\n\nWe can save the model and then extract individual output elements from it using the $ syntax\n\n# name the model object\nlr_model &lt;- lm(bmi ~ age, data = nhanes)\n\n# extract model output elements\nlr_model$coefficients\nlr_model$residuals\nlr_model$fitted.values\n\nThe command summary returns these elements\n\n\nCall: reminds the equation used for this regression model\n\nResiduals: a 5 number summary of the distribution of residuals from the regression model\n\nCoefficients:displays the estimated coefficients of the regression model and relative hypothesis testing, given for:\n\nintercept\nexplanatory variable(s) slope"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models interpretation: coefficients",
    "text": "Linear regression models interpretation: coefficients\n\nThe model tests the null hypothesis \\(H_{0}\\) that a coefficient is 0\n\ncoefficients outputs are: estimate, std. error, t-statistic, and p-value correspondent to the t-statistic for:\n\nintercept\n\nexplanatory variable(s) slope\n\n\nIn regression, the population parameter of interest is typically the slope parameter\n\nin this model, age doesn‚Äôt appear significantly ‚â† 0\n\n\n\n\nsummary(lr_model)$coefficients \n\n               Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 28.40112932 0.96172389 29.531480 2.851707e-111\nage          0.01981675 0.01824641  1.086063  2.779797e-01"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients-2",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients-2",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models interpretation: Coefficients 2",
    "text": "Linear regression models interpretation: Coefficients 2\nFor the the estimated coefficients of the regression model, we get:\n\n\nEstimate = the average increase in the response variable associated with a one unit increase in the predictor variable, (assuming all other predictor variables are held constant).\n\nStd. Error = a measure of the uncertainty in our estimate of the coefficient. \n\n\nt value = the t-statistic for the predictor variable, calculated as (Estimate) / (Std. Error).\n\nPr(&gt;|t|) = the p-value that corresponds to the t-statistic. If less than some alpha level (e.g.¬†0.05). the predictor variable is said to be statistically significant."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-fitted-values",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-fitted-values",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models outputs: fitted values",
    "text": "Linear regression models outputs: fitted values\nHere we see \\(\\hat{y}_i\\), i.e.¬†the fitted \\(y\\) value for the \\(i\\)-th individual\n\nfit_val &lt;- lr_model$fitted.values\n\n# print the first 6 elements\nhead(fit_val)\n\n       1        2        3        4        5        6 \n29.39197 29.33252 29.31270 28.95600 29.39197 29.17398"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-residuals",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-residuals",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models outputs: residuals",
    "text": "Linear regression models outputs: residuals\nHere we see \\(e_i = y_i - \\hat{y}_i\\), i.e.¬†the residual value for the \\(i\\)-th individual\n\nresid_val &lt;- lr_model$residuals \n\n# print the first 6 elements\nhead(resid_val)\n\n          1           2           3           4           5           6 \n-1.49196704  0.06748322 -3.96270002 -3.15599844 -2.49196704  3.75601726"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-residual-standard-error",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-residual-standard-error",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: Residual standard error",
    "text": "Linear regression model‚Äôs fit: Residual standard error\n\n\nThe Residual standard error (an estimate of the parameter \\(\\sigma\\)) tells the average distance that the observed values fall from the regression line (we are assuming constant variance).\n\nThe smaller it is, the better the model fits the dataset!\n\n\n\nWe can compute it manually as:\n\\({\\rm SE}_{resid}=\\ \\sqrt{\\frac{\\sum_{i=1}^{n}{(y_i-{\\hat{y}}_i)}^2}{{\\rm df}_{resid}}}\\)\n\n# Residual Standard error (Like Standard Deviation)\n\n# ---  inputs \n# sample size\nn =length(lr_model$residuals)\n# n of parameters in the model\nk = length(lr_model$coefficients)-1 #Subtract one to ignore intercept\n# degrees of freedom of the the residuals \ndf_resid = n-k-1\n# Squared Sum of Errors\nSSE =sum(lr_model$residuals^2) # 22991.19\n\n# --- Residual Standard Error\nResStdErr &lt;- sqrt(SSE/df_resid)  # 6.815192\nResStdErr\n\n[1] 6.815192"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-r2-and-adj.-r2",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-r2-and-adj.-r2",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: : \\(R^2\\) and \\(Adj. R^2\\)",
    "text": "Linear regression model‚Äôs fit: : \\(R^2\\) and \\(Adj. R^2\\)\n\nThe \\(R^2\\) tells us the proportion of the variance in the response variable that can be explained by the predictor variable(s).\n\nif \\(R^2\\) close to 0 -&gt; data more spread\nif \\(R^2\\) close to 1 -&gt; data more tight around the regression line\n\n\n# --- R^2\nsummary(lr_model)$r.squared\n\n[1] 0.00237723\n\n\nThe \\(Adj. R^2\\) is a modified version of \\(R^2\\) that has been adjusted for the number of predictors in the model.\n\nIt is always lower than the R-squared\nIt can be useful for comparing the fit of different regression models that use different numbers of predictor variables.\n\n\n# --- Adj. R^2\nsummary(lr_model)$adj.r.squared\n\n[1] 0.0003618303"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-f-statistic",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-f-statistic",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: : F statistic",
    "text": "Linear regression model‚Äôs fit: : F statistic\nThe F-statistic indicates whether the regression model provides a better fit to the data than a model that contains no independent variables. In essence, it tests if the regression model as a whole is useful.\n\n# extract only F statistic \nsummary(lr_model)$fstatistic \n\n     value      numdf      dendf \n  1.179533   1.000000 495.000000 \n\n# define function to extract overall p-value of model\noverall_p &lt;- function(my_model) {\n    f &lt;- summary(my_model)$fstatistic\n    p &lt;- pf(f[1],f[2],f[3],lower.tail=F)\n    attributes(p) &lt;- NULL\n    return(p)\n}\n\n# extract overall p-value of model\noverall_p(lr_model)\n\n[1] 0.2779797\n\n\nGiven the p-value is &gt; 0.05, this indicate that the predictor variable is not useful for predicting the value of the response variable."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: residuals 1/4",
    "text": "Linear regression diagnostic plots: residuals 1/4\n\nASSUMPTION 1: there exists a linear relationship between the independent variable, x, and the dependent variable, y\n\nFor an observation \\((x_i, y_i)\\), where \\(\\hat{y}_i\\) is the predicted value according to the line \\(\\hat{y} = b_0 + b_1x\\), the residual is the value \\(e_i = y_i - \\hat{y}_i\\)\n\nA linear (e.g.¬†lr_model) is a particularly good fit for the data when the residual plot shows random scatter above and below the horizontal line.\n\n(In this R plot, we look for a red line that is fairly straight)\n\n\n\n\n# residual plot\nplot(lr_model, which = 1 )\n\n\n\nWe use the argument which in the function plot so we see the plots one at a time."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: residuals 1/4",
    "text": "Linear regression diagnostic plots: residuals 1/4"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: normality of residuals 2/4",
    "text": "Linear regression diagnostic plots: normality of residuals 2/4\n\nASSUMPTION 2: The residuals of the model are normally distributed\n\nWith the quantile-quantile plot (Q-Q) we can checking normality of the residuals.\n\n# quantile-quantile plot\nplot(lr_model, which = 2 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: normality of residuals 2/4",
    "text": "Linear regression diagnostic plots: normality of residuals 2/4\n\n\nThe data appear roughly normal, but there are deviations from normality in the tails, particularly the upper tail."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: Homoscedasticity 3/4",
    "text": "Linear regression diagnostic plots: Homoscedasticity 3/4\n\nASSUMPTION 3: The residuals have constant variance at every level of x (‚Äúhomoscedasticity‚Äù)\n\nThis one is called a Spread-location plot: shows if residuals are spread equally along the ranges of predictors\n\n# Spread-location plot\nplot(lr_model, which = 3 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: Homoscedasticity 3/4",
    "text": "Linear regression diagnostic plots: Homoscedasticity 3/4"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#test-for-homoscedasticity",
    "href": "practice/practice_slides/slides_lab03.html#test-for-homoscedasticity",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Test for Homoscedasticity",
    "text": "Test for Homoscedasticity\n\nBesides visual check, we can perform the Breusch-Pagan test to verify the assumption of homoscedasticity. In this case:\n\n\\(H_{0}\\): residuals are distributed with equal variance\n\\(H_{1}\\): residuals are distributed with UNequal variance\nwe use bptest function from the lmtest package\n\n\n# Breusch-Pagan test against heteroskedasticity \nlmtest::bptest(lr_model)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lr_model\nBP = 2.7548, df = 1, p-value = 0.09696\n\n\nBecause the test statistic (BP) is small and the p-value is not significant (p-value &gt; 0.05): WE DO NOT REJECT THE NULL HYPOTHESIS (i.e.¬†we can assume equal variance)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: leverage 4/4",
    "text": "Linear regression diagnostic plots: leverage 4/4\nThis last diagnostic plot has to do with outliers:\n\nA residuals vs.¬†leverage plot allows us to identify influential observations in a regression model\n\nThe x-axis shows the ‚Äúleverage‚Äù of each point and the y-axis shows the ‚Äústandardized residual of each point‚Äù, i.e.¬†‚ÄúHow much would the coefficients in the regression model would change if a particular observation was removed from the dataset?‚Äù\n\n\nCook's distance lines (red dashed lines) ‚Äì not visible here ‚Äì should appear on the corners of the plot when there are influential cases\n\n\n\n\nplot(lr_model, which = 5 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: leverage 4/4",
    "text": "Linear regression diagnostic plots: leverage 4/4\n\n\nIn this particular case, there is no influential case, or cases"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#digression-on-the-broom-package",
    "href": "practice/practice_slides/slides_lab03.html#digression-on-the-broom-package",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "(Digression on the broom package)",
    "text": "(Digression on the broom package)\n\n\nThe broom package introduces the tidy approach to regression modeling code and outputs, allowing to convert/save them in the form of tibbles\n\nThe function tidy will turn an object into a tidy tibble\nThe function glance will construct a single row summary ‚Äúglance‚Äù of a model, fit, or other object\nThe function augment will show a lot of results for the model attached to each observation\n\nthis is very useful for further use of such objects, like ggplot2 etc.\n\n\n\n\n# render model as a dataframe \nbroom::tidy(lr_model)\n\n# see overal performance \nbroom::glance(lr_model)\n\n# save an object with all the model output elements \nmodel_aug &lt;- broom::augment(lr_model)\n\n\n\n\n You try‚Ä¶\n\n\nRun these functions and then run View(model_aug) to check out the output"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function",
    "text": "Visualize the data: Statin use and cognitive function\nStatins are a class of drugs widely used to lower cholesterol (recent guidelines would lead to statin use in almost half of Americans between 40 - 75 years of age and nearly all men over 60). But a few small studies have suggested that statins may be associated with lower cognitive ability.\n\nFrom this sample of the PREVEND study, we can observe the relationship between statin use (statin_use) and cognitive ability (rfft).\n\n\n# rename for convenience\nprevend &lt;- prevend_samp %&gt;% janitor::clean_names() %&gt;% \n  #create statin.use logical + factor\n  mutate(statin_use = as.logical(statin)) %&gt;% \n  mutate(statin_use_f = factor(statin, levels = c(0,1), labels = c(\"NonUser\", \"User\")))   \n \n# box plot \nggplot(prevend, \n       aes (x = statin_use_f, y = rfft, fill = statin_use_f)) + \n  geom_boxplot(alpha=0.5) +\n  scale_fill_manual(values=c(\"#005ca1\",\"#9b2339\" )) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function",
    "text": "Visualize the data: Statin use and cognitive function\n\n\nThe boxplot suggests that statin user (red) present lower cognitive ability score, on average"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#confirm-visual-intuition-with-independent-sample-t-test",
    "href": "practice/practice_slides/slides_lab03.html#confirm-visual-intuition-with-independent-sample-t-test",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Confirm visual intuition with independent sample t-test",
    "text": "Confirm visual intuition with independent sample t-test\nWe could use an independent t-test to confirm what the boxplot shows\n\nt_test_w &lt;- t.test(prevend$rfft[prevend$statin == 1], \n                   prevend$rfft[prevend$statin == 0],\n                   # here we specify the situation\n                   var.equal = TRUE,\n                   paired = FALSE, alternative = \"two.sided\") \n\nt_test_w\n\n\n    Two Sample t-test\n\ndata:  prevend$rfft[prevend$statin == 1] and prevend$rfft[prevend$statin == 0]\nt = -3.4917, df = 498, p-value = 0.0005226\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -15.710276  -4.396556\nsample estimates:\nmean of x mean of y \n 60.66087  70.71429 \n\n\n‚Ä¶statistically significant difference in means (Statin use: yes and no) do exist"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#consider-simple-linear-regression-statin-use-and-cognitive-function",
    "href": "practice/practice_slides/slides_lab03.html#consider-simple-linear-regression-statin-use-and-cognitive-function",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Consider Simple Linear regression: Statin use and cognitive function",
    "text": "Consider Simple Linear regression: Statin use and cognitive function\n\n‚Ä¶ and build a simple linear regression model like so:\n\\[E(RFFT) = b_0 + b_{statin} {(Statin\\ use)}\\]\n\n#fit the linear model\nmodel_1 &lt;- lm(rfft ~ statin, data=prevend)\nsummary(model_1)\n\n\nCall:\nlm(formula = rfft ~ statin, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.714 -22.714   0.286  18.299  73.339 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   70.714      1.381  51.212  &lt; 2e-16 ***\nstatin       -10.053      2.879  -3.492 0.000523 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.09 on 498 degrees of freedom\nMultiple R-squared:  0.0239,    Adjusted R-squared:  0.02194 \nF-statistic: 12.19 on 1 and 498 DF,  p-value: 0.0005226\n\n\n\nThis preliminary model shows that, on average, statin users score approximately 10 points lower on the RFFT cognitive test (and the statin coefficient is highly significant!)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function + age",
    "text": "Visualize the data: Statin use and cognitive function + age\nHowever, following the literature, this prelimary model might be misleading (biased) because it does not account for the underlying relationship between age and statin\n\nhence age could be a confounder within the statin -&gt; RFFT relationship\n\n\nggplot(prevend, \n       aes (x = age, y = rfft, group = statin_use)) + \n  geom_point (aes(color = statin_use , size=.01, alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" )) + \n  # decades line separators \n  geom_vline(xintercept = 40, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 50, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 60, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 70, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 80, color = \"#A6A6A6\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function + age",
    "text": "Visualize the data: Statin use and cognitive function + age\n\n\nStatin users are represented with red points; participants not using statins are shown as blue points"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#multiple-linear-regression-model",
    "href": "practice/practice_slides/slides_lab03.html#multiple-linear-regression-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Multiple linear regression model",
    "text": "Multiple linear regression model\nMultiple regression allows for a (richer) model that incorporates both statin use and age:\n\\[E(RFFT) = b_0 + b_{statin} {(Statin\\ use)}+ b_{age} {(Age)}\\]\n\nor (in statistical terms) the association between RFFT and Statin use is being estimated after adjusting for Age\n\n\nThe R syntax is very easy: simply use + to add covariates\n\n# fit the (multiple) linear model\nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#rfft-vs.-statin-use-age",
    "href": "practice/practice_slides/slides_lab03.html#rfft-vs.-statin-use-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "RFFT vs.¬†statin use & age‚Ä¶",
    "text": "RFFT vs.¬†statin use & age‚Ä¶\nAlthough the use of statins appeared to be associated with lower RFFT scores when no adjustment was made for possible confounders, statin use is not significantly associated with RFFT score in a regression model that adjusts for age.\n\nsummary(model_2)\n\n\nCall:\nlm(formula = rfft ~ statin + age, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-63.855 -16.860  -1.178  15.730  58.751 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 137.8822     5.1221  26.919   &lt;2e-16 ***\nstatin        0.8509     2.5957   0.328    0.743    \nage          -1.2710     0.0943 -13.478   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.21 on 497 degrees of freedom\nMultiple R-squared:  0.2852,    Adjusted R-squared:  0.2823 \nF-statistic: 99.13 on 2 and 497 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumptions-for-multiple-regression",
    "href": "practice/practice_slides/slides_lab03.html#assumptions-for-multiple-regression",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumptions for multiple regression",
    "text": "Assumptions for multiple regression\nSimilar to those of simple linear regression‚Ä¶\n\n\nLinearity: For each predictor variable \\(x_j\\), change in the predictor is linearly related to change in the response variable when the value of all other predictors is held constant.\n\nConstant variability: The residuals have approximately constant variance.\n\nNormality of residuals: The residuals are approximately normally distributed.\n\nIndependent observations: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nNo multicollinearity: i.e.¬†no situations when there is a strong linear correlation between the independent variables, conditional on the other variables in the model"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: age",
    "text": "Using residual plots to assess LINEARITY: age\n\nASSUMPTION 1: there exists a linear relationship between the independent variables, \\((x_1, x_2, \\dots, x_p)\\), and the dependent variable, y\n\nIt is not possible to make a scatterplot of a response against several simultaneous predictors. Instead, use a modified residual plot to assess linearity:\n\nFor each (numerical) predictor, plot the residuals on the \\(y\\)-axis and the predictor values on the \\(x\\)-axis.\nPatterns/curvature are indicative of non-linearity.\n\n\n# recall \nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)\n\n# assess linearity\nplot(residuals(model_2) ~ prevend$age,\n     main = \"Residuals vs Age in PREVEND (n = 500)\",\n     xlab = \"Age (years)\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: age",
    "text": "Using residual plots to assess LINEARITY: age\n\n\nThere are no apparent trends; the data scatter evenly above and below the horizontal line. There does not seem to be remaining nonlinearity with respect to age after the model is fit."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: statin use",
    "text": "Using residual plots to assess LINEARITY: statin use\nShould we be testing linearity of residuals also against a categorical variable (statin use)? (not really, because not meaningful)\n\n# recall \nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)\n\n#assess linearity\nplot(residuals(model_2) ~ prevend$statin,\n     main = \"Residuals vs Age in PREVEND (n = 500)\",\n     xlab = \"Age (years)\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: statin use",
    "text": "Using residual plots to assess LINEARITY: statin use\n\n\nIt is not necessary to assess linearity with respect to statin use since statin use is measured as a categorical variable. A line drawn through two points (that is, the mean of the two groups defined by a binary variable) is necessarily linear"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess CONSTANT VARIABILITY",
    "text": "Using residual plots to assess CONSTANT VARIABILITY\n\nASSUMPTION 2: The residuals have constant variance at every level of x (‚Äúhomoscedasticity‚Äù)\n\n\nConstant variability: plot the residual values on the \\(y\\)-axis and the predicted values on the \\(x\\)-axis\n\n\n#assess constant variance of residuals\nplot(residuals(model_2) ~ fitted(model_2),\n     main = \"Resid. vs Predicted RFFT in PREVEND (n = 500)\",\n     xlab = \"Predicted RFFT Score\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess CONSTANT VARIABILITY",
    "text": "Using residual plots to assess CONSTANT VARIABILITY\n\n\nThe variance of the residuals is somewhat smaller for lower predicted values of RFFT score, but this may simply be an artifact from observing few individuals with relatively low predicted scores. It seems reasonable to assume approximately constant variance."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess NORMALITY of residuals",
    "text": "Using residual plots to assess NORMALITY of residuals\n\nASSUMPTION 3: The residuals of the model are normally distributed - Normality of residuals: use Q-Q plots\n\n\n#assess normality of residuals\nqqnorm(resid(model_2),\n       pch = 21, col = \"cornflowerblue\", bg = \"slategray2\", cex = 0.75,\n       main = \"Q-Q Plot of Residuals\")\nqqline(resid(model_2), col = \"red\", lwd = 2)\n\n\nIn our example, we see that most data points are OK, except some observations at the tails. However, if all other plots indicate no violation of assumptions, some deviation of normality, particularly at the tails, can be less critical."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess NORMALITY of residuals",
    "text": "Using residual plots to assess NORMALITY of residuals\n\n\nThe residuals are reasonably normally distributed, with only slight departures from normality in the tails."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-independence-of-observations",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-independence-of-observations",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of INDEPENDENCE of observations",
    "text": "Assumption of INDEPENDENCE of observations\n\nASSUMPTION 4: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nIs it reasonable to assume that each set of observations is independent of the others?\n\nUsing the PREVEND data, it is reasonable to assume that the observations in this dataset are independent. The participants were recruited from a large city in the Netherlands for a study focusing on factors associated with renal and cardiovascular disease."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of NO MULTICOLLINEARITY",
    "text": "Assumption of NO MULTICOLLINEARITY\n\n\nASSUMPTION 5: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nThe R package performance actually provides a very helpful function check_model() which tests these assumptions all at the same time\n\n\nMulticollinearity is not an issue (based on a general threshold of 10 for VIF, all of them are below 10)\n\n\n# return and store a list of single plots\ndiagnostic_plots &lt;- plot(performance::check_model(model_2, panel = FALSE))\n\n# see multicollinearity plot \ndiagnostic_plots[[5]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity-output",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of NO MULTICOLLINEARITY",
    "text": "Assumption of NO MULTICOLLINEARITY"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#checking-out-the-performance-r-package",
    "href": "practice/practice_slides/slides_lab03.html#checking-out-the-performance-r-package",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Checking out the performance R package",
    "text": "Checking out the performance R package\n\nFind more info on the helpful performance R package here for verifying assumptions and model‚Äôs quality and goodness of fit.\n\n\n\n\n You try‚Ä¶\n\n\nRun also the following commands\n\nDiagnostic plot of linearity diagnostic_plots[[2]]\n\nDiagnostic plot of influential observations - outliers diagnostic_plots[[4]]\n\nDiagnostic plot of normally distributed residuals diagnostic_plots[[6]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#r2-with-multiple-regression",
    "href": "practice/practice_slides/slides_lab03.html#r2-with-multiple-regression",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "\\(R^2\\) with multiple regression",
    "text": "\\(R^2\\) with multiple regression\n\nAs in simple regression, \\(R^2\\) represents the proportion of variability in the response variable explained by the model.\n\nAs variables are added, \\(R^2\\) always increases.\n\nIn the summary(lm( )) output, Multiple R-squared is \\(R^2\\).\n\n#extract R^2 of a model\nsummary(model_2)$r.squared\n\n[1] 0.2851629\n\n\n\nThe \\(R^2\\) is 0.285; the model explains 28.5% of the observed variation in RFFT score. The moderately low \\(R^2\\) suggests that the model is missing other predictors of RFFT score."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#adjusted-r2-as-a-tool-for-model-assessment",
    "href": "practice/practice_slides/slides_lab03.html#adjusted-r2-as-a-tool-for-model-assessment",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Adjusted \\(R^2\\) as a tool for model assessment",
    "text": "Adjusted \\(R^2\\) as a tool for model assessment\nThe adjusted \\(R^2\\) is computed as:\\[R_{adj}^{2} = 1- \\left( \\frac{\\text{Var}(e_i)}{\\text{Var}(y_i)} \\times \\frac{n-1}{n-p-1} \\right)\\]\n\nwhere \\(n\\) is the number of cases and \\(p\\) is the number of predictor variables.\n\nAdjusted \\(R^2\\) incorporates a penalty for including predictors that do not contribute much towards explaining observed variation in the response variable.\n\nIt is often used to balance predictive ability with model complexity.\nUnlike \\(R^2\\), \\(R^2_{adj}\\) does not have an inherent interpretation.\n\n\n#extract adjusted R^2 of a model\nsummary(model_2)$adj.r.squared\n\n[1] 0.2822863"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - (example)",
    "text": "Categorical predictor in regression - (example)\n\nIs RFFT score associated with education? The variable Education in the PREVEND dataset indicates the highest level of education an individual completed in the Dutch educational system:\n\n0: primary school\n1: lower secondary school\n2: higher secondary education\n3: university education\n\n\n# convert Education to a factor\nprevend &lt;- prevend %&gt;% \n  mutate(educ_f = factor(education,\n                          levels = c(0, 1, 2, 3),\n                          labels = c(\"Primary\", \"LowerSecond\",\n                                     \"HigherSecond\", \"Univ\")))\n\n\n# load 4 color palette\npacificharbour_shades &lt;- c( \"#d4e6f3\",  \"#9cc6e3\", \"#5b8bac\", \"#39576c\",  \"#16222b\")\n\n# create plot\nplot(rfft ~ educ_f, data = prevend,\n     xlab = \"Educational Level\", ylab = \"RFFT Score\",\n     main = \"RFFT by Education in PREVEND (n = 500)\",\n     names = c(\"Primary\", \"LowSec\", \"HighSec\", \"Univ\"),\n     col = pacificharbour_shades[1:4])"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example-output",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - (example)",
    "text": "Categorical predictor in regression - (example)\n\n\nA very clear association seems to exist between education level and average RFFT score in the sample"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - model",
    "text": "Categorical predictor in regression - model\n\nCalculate the average RFFT score in the sample across education levels\n\n# calculate group means\nprevend %&gt;% \n  group_by(educ_f) %&gt;% \n  summarise(avg_RFFT_score = mean(rfft))\n\n# A tibble: 4 √ó 2\n  educ_f       avg_RFFT_score\n  &lt;fct&gt;                 &lt;dbl&gt;\n1 Primary                40.9\n2 LowerSecond            55.7\n3 HigherSecond           73.1\n4 Univ                   85.9\n\n\nFitting a model with education as a predictor\n\n# fit a model\nmodel_cat &lt;- lm(rfft ~ educ_f, data = prevend) \nmodel_cat$coefficients\n\n       (Intercept)  educ_fLowerSecond educ_fHigherSecond         educ_fUniv \n          40.94118           14.77857           32.13345           44.96389 \n\n\n\nNotice how Primary level of educ_f does NOT appear as a coefficient"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model-interpretation",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model-interpretation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - model interpretation",
    "text": "Categorical predictor in regression - model interpretation\n\n\n\n\nCall:\nlm(formula = rfft ~ educ_f, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-55.905 -15.975  -0.905  16.068  63.280 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          40.941      3.203  12.783  &lt; 2e-16 ***\neduc_fLowerSecond    14.779      3.686   4.009 7.04e-05 ***\neduc_fHigherSecond   32.133      3.763   8.539  &lt; 2e-16 ***\neduc_fUniv           44.964      3.684  12.207  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.87 on 496 degrees of freedom\nMultiple R-squared:  0.3072,    Adjusted R-squared:  0.303 \nF-statistic:  73.3 on 3 and 496 DF,  p-value: &lt; 2.2e-16\n\n\nThe baseline category represents individuals who at most completed primary school Education = 0. The coefficients represent the change in estimated average RFFT relative to the baseline category.\n\n\n(Intercept) is the sample mean RFFT score for these individuals, 40.94 points\nAn increase of 14.78 points is predicted for LowerSecond level, \\(40.94 + 14.78 = 55.72 \\ points\\)\n\nAn increase of 32.13 points is predicted for HigherSecond level, \\(40.94 + 32.13 = 73.07  \\ points\\)\n\nAn increase of 44.96 points is predicted for Univ level, \\(40.94 + 44.96 = 85.90 \\ points\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---example---nhanes",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---example---nhanes",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - (example) - NHANES",
    "text": "Interaction in regression - (example) - NHANES\nLet‚Äôs go back to the NHANES dataset and consider a linear model that predicts total cholesterol level (mmol/L) from age (yrs.) and diabetes status.\nThe multiple regression model:\n\\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_px_p + \\epsilon\\]\nassumes that when one of the predictors \\(x_j\\) is changed by 1 unit and the values of the other variables remain constant, the predicted response changes by \\(\\beta_j\\), regardless of the values of the other variables.\n\nWith statistical interaction, this assumption is not true, such that the effect of one explanatory variable \\(x_j\\) on the \\(y\\) depends on the particular value(s) of one or more other explanatory variables."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual",
    "text": "Interaction in regression - visual\nFitting a model with age and diabetes as independent predictors (i.e.¬†WITHOUT interaction terms)\n\n# fit a model\nmodel_NOinterac &lt;- lm(tot_chol ~ age + diabetes, data = nhanes) \nmodel_NOinterac$coefficients\n\n (Intercept)          age  diabetesYes \n 4.800011340  0.007491805 -0.317665963 \n\n\n\nUsing geom_smooth for a visual intuition of a linear relationship\n\n‚ö†Ô∏è here I consider sample DATA as a whole for plotting a smooth line\n\n\n\n\nggplot(nhanes, \n       aes (x = age, y = tot_chol)) + \n  # For POINTS I split by category (category)\n  geom_point (aes(color = diabetes, \n                  alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" )) + \n  # For SMOOTHED LINES I take ALL data\n  geom_smooth(colour=\"#BD8723\",  method = lm)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-output",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual",
    "text": "Interaction in regression - visual\n\n\nUsers in two categories are represented points; linear relationship is representated by ONE golden line for ALL SAMPLE"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual (RETHINKING)",
    "text": "Interaction in regression - visual (RETHINKING)\nSuppose two separate models were fit for the relationship between total cholesterol and age; one in diabetic individuals and one in non-diabetic individuals.\n\nUsing geom_smooth for a visual intuition of a linear relationship\n\n‚ö†Ô∏è here I consider sample DATA as 2 separate groups for plotting a smooth line\n\n\n\n\nggplot(nhanes, \n       # For *both POINTS & LINES* I split by category (category)\n       aes (x = age, y = tot_chol, color = diabetes)) + \n  geom_point (aes(alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  geom_smooth(method = lm)+ \n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" ))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking-output",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual (RETHINKING)",
    "text": "Interaction in regression - visual (RETHINKING)\n\n\nUsers in two categories are represented points; linear relationship is representated by 2 respective line according to diabetes status‚Ä¶ the association has DIFFERENT DIRECTION!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---adding-term-in-model",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---adding-term-in-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - adding term in model",
    "text": "Interaction in regression - adding term in model\nLet‚Äôs rethink the model and consider this new specification:\n\\[E(TotChol) = \\beta_0 + \\beta_1(Age) + \\beta_2(Diabetes) + \\beta_3(Diabetes \\times Age).\\]\nWhere: + the term \\((Diabetes \\times Age)\\) is the interaction term between diabetes status and age, and \\(\\beta_3\\) is the coefficient of such interaction term.\n\nnotice the use of ...*... in the model syntax\n\n\n#fit a model\nmodel_interac2 &lt;- lm(tot_chol ~ age*diabetes, data = nhanes) \nmodel_interac2$coefficients\n\n    (Intercept)             age     diabetesYes age:diabetesYes \n    4.695702513     0.009638183     1.718704342    -0.033451562"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---prediction-model",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---prediction-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - prediction model",
    "text": "Interaction in regression - prediction model\n\nWe obtained this predictive model: \\[\\widehat{TotChol} = 4.70 + 0.0096(Age) + 0.1.72(Diabetes) - 0.033(Age \\times Diabetes)\\]\n\nsummary(model_interac2)\n\n\nCall:\nlm(formula = tot_chol ~ age * diabetes, data = nhanes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3587 -0.7448 -0.0845  0.6307  4.2480 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      4.695703   0.159691  29.405  &lt; 2e-16 ***\nage              0.009638   0.003108   3.101  0.00205 ** \ndiabetesYes      1.718704   0.763905   2.250  0.02492 *  \nage:diabetesYes -0.033452   0.012272  -2.726  0.00665 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.061 on 469 degrees of freedom\n  (27 observations deleted due to missingness)\nMultiple R-squared:  0.03229,   Adjusted R-squared:  0.0261 \nF-statistic: 5.216 on 3 and 469 DF,  p-value: 0.001498"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---interactive-term-interpretation",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---interactive-term-interpretation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - interactive term interpretation",
    "text": "Interaction in regression - interactive term interpretation\n\nGiven:\n\\(\\widehat{TotChol} = 4.70 + 0.0096(Age) + 0.1.72(Diabetes) - 0.033(Age \\times Diabetes)\\) For diabetics ( DiabetesYes = 1 ), the model equation is:\n\\(TotChol_{diab} =  4.70 + 0.0096(Age) + 1.72(1) - 0.034(Age)(1)\\) i.e.\\(TotChol_{diab} =  6.42 - 0.024(Age)\\)\n\nFor non-diabetics ( DiabetesYes = 0 ), the model equation is:\n\\(TotChol_{NOdiab} =  4.70 + 0.0096(Age) + 1.72(0) - 0.034(Age)(0)\\) i.e.\\(TotChol_{NOdiab} =  4.70 + 0.0096(Age)\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab03.html#final-thoughtsrecommendations",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\n\n\nThe analyses proposed in this Lab are very similar to the process we go through in real life. The following steps are always included:\n\nThorough understanding of the input data and the data collection process\nBivariate analysis of correlation / association to form an intuition of which explanatory variable(s) may or may not affect the response variable\n\nDiagnostic plots to verify if the necessary assumptions are met for a linear model to be suitable\nUpon verifying the assumptions, we fit data to hypothesized (linear) model\n\nAssessment of the model performance (\\(R^2\\), \\(Adj. R^2\\), \\(F-Statistic\\), etc.)\n\n\nAs we saw with hypothesis testing, the assumptions we make (and require) for regression are of utter importance\n\nClearly, we only scratched the surface in terms of all the possible predictive models, but we got a hang of the fundamental steps and some useful tools that might serve us also in more advanced analysis\n\ne.g.¬†broom (within tidymodels), performace rstatix, lmtest\n\n\n\n\n\n\n\n\n\nR 4 Statistics | 2025"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#goal-of-todays-practice-session",
    "href": "practice/practice_slides/slides_lab01.html#goal-of-todays-practice-session",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "GOAL OF TODAY‚ÄôS PRACTICE SESSION",
    "text": "GOAL OF TODAY‚ÄôS PRACTICE SESSION\n\nMotivate the choice of learning/using R for scientific quantitative analysis, and lay out some fundamental concepts in biostatistics with concrete R coding examples.\n\n\nLecture 1: topics\n\n\nIntroduction to R and R-studio\n\nWhy R?\nPrinciples of reproducible analysis with R + RStudio\n\n\nR objects, functions, packages\n\nUnderstanding different types of variables\n\nPrinciples of ‚Äútidy data‚Äù\n\n\n\nDescriptive statistics\n\nMeasures of central tendency, measures of variability (or spread), and frequency distribution\n\n\n\nVisual data exploration\n\n{ggplot2}"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#r-version",
    "href": "practice/practice_slides/slides_lab01.html#r-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "R version",
    "text": "R version\nIf you have previously installed R on your machine, you can check which version you are running by executing this command in R:\n\n# check your R version\nR.Version()\n\n$platform\n[1] \"aarch64-apple-darwin20\"\n\n$arch\n[1] \"aarch64\"\n\n$os\n[1] \"darwin20\"\n\n$system\n[1] \"aarch64, darwin20\"\n\n$status\n[1] \"\"\n\n$major\n[1] \"4\"\n\n$minor\n[1] \"4.2\"\n\n$year\n[1] \"2024\"\n\n$month\n[1] \"10\"\n\n$day\n[1] \"31\"\n\n$`svn rev`\n[1] \"87279\"\n\n$language\n[1] \"R\"\n\n$version.string\n[1] \"R version 4.4.2 (2024-10-31)\"\n\n$nickname\n[1] \"Pile of Leaves\"\n\n# or just\n#R.version.string"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install",
    "href": "practice/practice_slides/slides_lab01.html#install",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install \n",
    "text": "Install \n\n\n\n\nR is available for free for Windows , GNU/Linux , and macOS .\n\nTo install R, go to this link https://cloud.r-project.org/. The latest available release is R 4.3.3 ‚ÄúAngel Food Cake‚Äù released on 2024-02/29, but any (fairly recent) version will do."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-rstudio-ide",
    "href": "practice/practice_slides/slides_lab01.html#install-rstudio-ide",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install RStudio IDE",
    "text": "Install RStudio IDE\nRStudio Desktop is an Integrated Development Editor (IDE), basically a graphical interface wrapping and interfacing R (which needs to be installed first).\nBesides RStudio, R (which is a command line driven program) can be executed:\n\nvia its native interface (R GUI)\nfrom many other code editors, like VS Code, Sublime Text, Jupyter Notebook\n\n\n\nTo install RStudio, go to this link https://posit.co/download/rstudio-desktop/. The free-version contains everything you need."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#use-rstudio-ide",
    "href": "practice/practice_slides/slides_lab01.html#use-rstudio-ide",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Use RStudio IDE",
    "text": "Use RStudio IDE\n\nRStudio Pane Layout Source: Posit‚Äôs RStudio User Guide"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio",
    "href": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Creating an R Project [in Rstudio]",
    "text": "Creating an R Project [in Rstudio]\nAn R Project will keep all the files associated with a project (including invisible ones!) organized together ‚Äì input data, R scripts, analytical results, figures. Besides being common practice, this has the advantage of implicitly setting the ‚Äúworking directory‚Äù, which is incredibly important when you need to load or output files, specifying their file path.\nIn Figure¬†1 you can see how easy it is just following RStudio prompts:\n\nCreate a new directory for each project\nSelect parent folder"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio-cont.",
    "href": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Creating an R Project [in Rstudio] (cont.)",
    "text": "Creating an R Project [in Rstudio] (cont.)\n\n\nFigure¬†1: Creating an R project\nNotice that, now, in the Files tab you see file with the extension .Rproj which is telling R that all folder‚Äôs files belong together."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-from-cran-stable-version",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-from-cran-stable-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages from CRAN (stable version)",
    "text": "Install R packages from CRAN (stable version)\nAn R package*  is a shareable bundle of functions. Besides the basic built-in functions already contained in the program (i.e.¬†the base, stats, utils packages), many useful R functions come in free libraries of code (or packages) written by R‚Äôs users. You can find them in different repositories:\nTo install a package use utils function install.packages(\"package_name)\n\n# Installing (ONLY the 1st time)\nutils::install.packages('here')\n\n# OR (same)\ninstall.packages('here')\n\n\n\nHere you are actually using a function (install.packages) of a pre-installed package (utils) using the syntax packagename::function_name. This prevents any ambiguity in case of duplicate function name‚Ä¶ also helps you see what you are using."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-rstudio-pane",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-rstudio-pane",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages RStudio pane",
    "text": "Install R packages RStudio pane\nIn alternative, you can install/update packages using the Packages tab on the lower right pane of RStudio.\n\nScreenshot Install/Update pckgs from RStudio"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-from-github-testing-version",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-from-github-testing-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages from GitHub (testing version)",
    "text": "Install R packages from GitHub (testing version)\nUse install_github from the package devtools.EXAMPLE: let‚Äôs install a little package paint (which colors the structure of dataset when printing).\n\n\n\nCode\n\n# Installing devtools (ONLY the 1st time)\nutils::install.packages('devtools')\n\n# Installing paint from GitHub \nlibrary(devtools)\ndevtools::install_github(\"MilesMcBain/paint\")\n\n# test paint out\nlibrary(paint)\n\n\nOutput {paint} function\n\n# Structure of a data.frame \npaint::paint(mtcars)\n\n\n\n\n\n[After devtools::install_github(\"MilesMcBain/paint\"), R asks me if I want to update related packages‚Ä¶]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#use-r-packages",
    "href": "practice/practice_slides/slides_lab01.html#use-r-packages",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Use R Packages",
    "text": "Use R Packages\n\nWe will be using {base} & {utils} (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\nlibrary(fs)        # file/directory interactions\nlibrary(here)      # tools find your project's files, based on working directory\nlibrary(janitor)   # tools for examining and cleaning data\nlibrary(skimr)     # tools for summary statistics \nlibrary(dplyr)     # {tidyverse} tools for manipulating and summarising tidy data \nlibrary(forcats)   # {tidyverse} tool for handling factors\nlibrary(ggplot2)   # {tidyverse} tools for plotting\nlibrary(ggridges)  # alternative to plot density functions"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#help-on-r-packagefunction",
    "href": "practice/practice_slides/slides_lab01.html#help-on-r-packagefunction",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Help on R package/function",
    "text": "Help on R package/function\nTo inquire about a package and/or its functions, you can again write in your console ?package_name or ??package_name and RStudio will open up the Help tab in the lower right pane.\n\n# Opening Help page on package/function\n?here\n\n??here"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#file-paths-logistics",
    "href": "practice/practice_slides/slides_lab01.html#file-paths-logistics",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "File paths logistics",
    "text": "File paths logistics\nIt is never good practice to ‚Äúhard code‚Äù the file‚Äôs absolute path: most likely it will break your code as soon as you (or someone else) need to run it on a different computer, let alone within a different OS.\n\nLet‚Äôs look at this example code using function readr::read_csv() (which reads a *.csv data file into the R workspace)\n\n# [NOT REPRODUCIBLE] hard coding your file path  -----------------------\n\n# File path on Mac:\ndataset &lt;- readr::read_csv(\"/Users/testuser/R4biostats/input_data/dataset.csv\")\n# Same file path on Windows:\ndataset &lt;- readr::read_csv(\"C:\\Users\\testuser\\R4biostats\\input_data\\dataset.csv\")\n\nüôÑ ‚Ä¶it won‚Äôt work on any other computer since it won‚Äôt have that same file structure!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#reproducible-file-paths-with-here-in-rstudio",
    "href": "practice/practice_slides/slides_lab01.html#reproducible-file-paths-with-here-in-rstudio",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(Reproducible) file paths with here (in Rstudio)",
    "text": "(Reproducible) file paths with here (in Rstudio)\n\nThe here package lets you reference file paths in a reproducible manner (anchored on the R Project‚Äôs folder as the root).\n\n\nWhere is my Working Directory?\n\nhere::here()\n\nYou should get: ‚Äú/Users/YourName/RProj_Dir‚Äù  Now, you can embed here(dir,subdir) specifications in other functions.\nFor example, create sub-directories (for saving input data and output data) with the fs package\n\n## --- [check the function documentation]\n?fs::dir_create\n# with `here` I simply add subfolder names relative to my wd \nfs::dir_create(here(\"practice\", \"data\",\"data_input\"))\n# ...and a subfolder to put output files at the end\nfs::dir_create(here(\"practice\", \"data\",\"data_output\"))\n\n## --- [if I need to remove it (I have them already)]\nfs::dir_delete(here(\"practice\", \"data\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#importing-data-into-r-workspace",
    "href": "practice/practice_slides/slides_lab01.html#importing-data-into-r-workspace",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Importing data into R workspace",
    "text": "Importing data into R workspace\nWe use utils::read.csv to load a csv file\n\n?read.csv # to learn about function and arguments"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-importing-from-a-url",
    "href": "practice/practice_slides/slides_lab01.html#option-1-importing-from-a-url",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1: Importing from a url",
    "text": "Option 1: Importing from a url\n\nautism_data_url &lt;- read.csv(\n  file = \"https://raw.githubusercontent.com/Sydney-Informatics-Hub/lessonbmc/gh-pages/_episodes_rmd/data/autism_data.csv\", \n  header = TRUE, # 1st line is the name of the variables\n  sep = \",\", # which is the field separator character.\n  na.strings = c(\"?\") # specific values R should interpret as NA\n)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-importing-from-my-folder-if-you-previously-downloaded-the-file",
    "href": "practice/practice_slides/slides_lab01.html#option-2-importing-from-my-folder-if-you-previously-downloaded-the-file",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2: Importing from my folder (if you previously downloaded the file)",
    "text": "Option 2: Importing from my folder (if you previously downloaded the file)\n\n\nhere lets me specify the complete path of the destination folder\n\n\n\n\n\n\n\n\nTip\n\n\nMake sure to match your own folder structure the file path here(...)!\n\n\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nautism_data_file &lt;- read.csv(\n  file = here(\"practice\", \"data_input\", \"01_datasets\", \"autism_data.csv\"), \n  header = TRUE, # 1st line is the name of the variables\n  sep = \",\", # which is the field separator character.\n  na.strings = c(\"?\"),# specific values R should interpret as NA\n  row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#viewing-the-dataset-and-variables",
    "href": "practice/practice_slides/slides_lab01.html#viewing-the-dataset-and-variables",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Viewing the dataset and variables",
    "text": "Viewing the dataset and variables\n\nView(autism_data_file)\n\n\nOr click on the object in Environment tab (upper right pane of RStudio)\n\n\n# What data type is this data?\nclass(autism_data_file)\n\n[1] \"data.frame\"\n\n# What variables are included in this dataset?\nbase::colnames(autism_data_file)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class.ASD\"      \n\n\n\nNotice the variable name formatting inconsistency: Class.ASD"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#manipulate-clean-the-dataframe",
    "href": "practice/practice_slides/slides_lab01.html#manipulate-clean-the-dataframe",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Manipulate / clean the dataframe",
    "text": "Manipulate / clean the dataframe\nI want consistent name formatting for variables: no ‚Äú.‚Äù, only ‚Äú_‚Äù separator. So, I use a very handy function clean_names from the janitor package\n\nautism_data &lt;- janitor::clean_names(autism_data_file, \n                                     case = \"none\") \n# check change\ncolnames(autism_data)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"      \n\ndim(autism_data)\n\n[1] 704  22\n\n\n\nBy default clean_names renames cols into ‚Äúsnake‚Äù format (i.e.¬†‚Äúabc_xyz‚Äù)\nThe option case is for capitalization preferences\n\n\ncase = \"none\" leaves the case as is, but only uses ‚Äú_‚Äù separator"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#isolate-a-variable-column",
    "href": "practice/practice_slides/slides_lab01.html#isolate-a-variable-column",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Isolate a variable (column)",
    "text": "Isolate a variable (column)\nYou can use the $ sign to extract a variable (column name)\n\nautism_data$id\nautism_data$A1_Score\nautism_data$gender\nautism_data$autism"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-a-new-column",
    "href": "practice/practice_slides/slides_lab01.html#add-a-new-column",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Add a new column",
    "text": "Add a new column\n(I prefer to rename the dataframe when I make changes)\n\n# rename dataframe \nautism_pids &lt;- autism_data\n\nCreate a new column, using paste (function to concatenate strings)\n\n# create a new column \nautism_pids$pids &lt;- paste(\"PatientID_\" , autism_data$id, sep = \"\")\n\nCheck results:\n\n# check change in df structure\nbase::colnames(autism_pids)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"       \"pids\"           \n\ndim(autism_data)\n\n[1] 704  22\n\ndim(autism_pids)\n\n[1] 704  23"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#optional-clean-up-workspace",
    "href": "practice/practice_slides/slides_lab01.html#optional-clean-up-workspace",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(optional) Clean up workspace",
    "text": "(optional) Clean up workspace\n\n# what do I have in the environment? \nls() \n\n[1] \"autism_data\"      \"autism_data_file\" \"autism_pids\"     \n\n# remove all EXCEPT for \"autism_pids\" \nrm(\"autism_data\", \"autism_data_file\", \"autism_data_url\" ) \n\n\n\n\n(Warning: mind that after rm(), you will not have these objects in your workspace anymore.)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-extract-cols-with",
    "href": "practice/practice_slides/slides_lab01.html#option-1-extract-cols-with",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 Extract cols with $",
    "text": "Option 1 Extract cols with $\n\n(head only specifies to take the first 6 observations of the dataset)\n\n\n# With the `$` sign I extract a variable (column name)\nhead(autism_pids$id) \n\n[1] 1 2 3 4 5 6\n\nhead(autism_pids$pids)\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" \"PatientID_5\"\n[6] \"PatientID_6\"\n\nhead(autism_pids$A1_Score)\n\n[1] 1 1 1 1 1 1\n\nhead(autism_pids$ethnicity)\n\n[1] \"White-European\" \"Latino\"         \"Latino\"         \"White-European\"\n[5] NA               \"Others\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2a-extract-cols-with-col",
    "href": "practice/practice_slides/slides_lab01.html#option-2a-extract-cols-with-col",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2a Extract cols with [,#col]",
    "text": "Option 2a Extract cols with [,#col]\n\nThis is called ‚Äúindexing‚Äù\n\n\n# Indexing to pick `[ , #col]`  \nhead(autism_pids[ ,1] )# empty rows means all \n\n[1] 1 2 3 4 5 6\n\nhead(autism_pids[ ,23])\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" \"PatientID_5\"\n[6] \"PatientID_6\"\n\nhead(autism_pids[ ,2])\n\n[1] 1 1 1 1 1 1\n\nhead(autism_pids[ ,14])\n\n[1] \"White-European\" \"Latino\"         \"Latino\"         \"White-European\"\n[5] NA               \"Others\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2b-extract-rows-with-row",
    "href": "practice/practice_slides/slides_lab01.html#option-2b-extract-rows-with-row",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2b Extract rows with [#row,]",
    "text": "Option 2b Extract rows with [#row,]\n\n# Indexing to pick `[#row, ]`  \nhead(autism_pids[1 , ] ) # empty cols means all \n\n  id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n1  1        1        1        1        1        0        0        1        1\n  A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n1        0         0  26      f White-European       no     no United States\n  used_app_before result    age_desc relation Class_ASD        pids\n1              no      6 18 and more     Self        NO PatientID_1\n\nhead(autism_pids[50,])\n\n   id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n50 50        1        1        0        0        0        1        1        1\n   A9_Score A10_Score age gender ethnicity jaundice autism contry_of_res\n50        0         1  30      f     Asian       no     no    Bangladesh\n   used_app_before result    age_desc relation Class_ASD         pids\n50              no      6 18 and more     Self        NO PatientID_50\n\nhead(autism_pids[25:26 ,])\n\n   id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n25 25        1        1        1        1        0        0        0        1\n26 26        0        1        1        0        0        0        0        1\n   A9_Score A10_Score age gender ethnicity jaundice autism contry_of_res\n25        0         0  43      m      &lt;NA&gt;       no     no       Lebanon\n26        0         0  24      f      &lt;NA&gt;      yes     no   Afghanistan\n   used_app_before result    age_desc relation Class_ASD         pids\n25              no      5 18 and more     &lt;NA&gt;        NO PatientID_25\n26              no      3 18 and more     &lt;NA&gt;        NO PatientID_26"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-3-extract-rows-cols-with-rowcol",
    "href": "practice/practice_slides/slides_lab01.html#option-3-extract-rows-cols-with-rowcol",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 3 Extract rows & cols with [#row,#col]",
    "text": "Option 3 Extract rows & cols with [#row,#col]\n\n# Indexing to pick `[#row, #col]`  \nautism_pids[1:3,1]\n\n[1] 1 2 3\n\nautism_pids[1:3,23]\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\"\n\nautism_pids[1:3,2]\n\n[1] 1 1 1\n\nautism_pids[1:3,14]\n\n[1] \"White-European\" \"Latino\"         \"Latino\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions",
    "href": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 using base functions",
    "text": "Option 1 using base functions\n\non the whole dataset\n\n\n# What are the data types of the variables? ---------------------------------\nstr(autism_pids) # integer and character\n\n'data.frame':   704 obs. of  23 variables:\n $ id             : int  1 2 3 4 5 6 7 8 9 10 ...\n $ A1_Score       : int  1 1 1 1 1 1 0 1 1 1 ...\n $ A2_Score       : int  1 1 1 1 0 1 1 1 1 1 ...\n $ A3_Score       : int  1 0 0 0 0 1 0 1 0 1 ...\n $ A4_Score       : int  1 1 1 1 0 1 0 1 0 1 ...\n $ A5_Score       : int  0 0 1 0 0 1 0 0 1 0 ...\n $ A6_Score       : int  0 0 0 0 0 0 0 0 0 1 ...\n $ A7_Score       : int  1 0 1 1 0 1 0 0 0 1 ...\n $ A8_Score       : int  1 1 1 1 1 1 1 0 1 1 ...\n $ A9_Score       : int  0 0 1 0 0 1 0 1 1 1 ...\n $ A10_Score      : int  0 1 1 1 0 1 0 0 1 0 ...\n $ age            : int  26 24 27 35 40 36 17 64 29 17 ...\n $ gender         : chr  \"f\" \"m\" \"m\" \"f\" ...\n $ ethnicity      : chr  \"White-European\" \"Latino\" \"Latino\" \"White-European\" ...\n $ jaundice       : chr  \"no\" \"no\" \"yes\" \"no\" ...\n $ autism         : chr  \"no\" \"yes\" \"yes\" \"yes\" ...\n $ contry_of_res  : chr  \"United States\" \"Brazil\" \"Spain\" \"United States\" ...\n $ used_app_before: chr  \"no\" \"no\" \"no\" \"no\" ...\n $ result         : int  6 5 8 6 2 9 2 5 6 8 ...\n $ age_desc       : chr  \"18 and more\" \"18 and more\" \"18 and more\" \"18 and more\" ...\n $ relation       : chr  \"Self\" \"Self\" \"Parent\" \"Self\" ...\n $ Class_ASD      : chr  \"NO\" \"NO\" \"YES\" \"NO\" ...\n $ pids           : chr  \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions-cont.",
    "href": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 using base functions (cont.)",
    "text": "Option 1 using base functions (cont.)\n\non specific columns\n\n\n# What values can the variables take? ---------------------------------\nsummary(autism_pids$pids)\n\n   Length     Class      Mode \n      704 character character \n\nlength(unique(autism_pids$pids)) # N unique values\n\n[1] 704\n\nsum(is.na(autism_pids$pids)) # N missing values\n\n[1] 0\n\nsummary(autism_pids$ethnicity)\n\n   Length     Class      Mode \n      704 character character \n\nlength(unique(autism_pids$ethnicity)) # N unique values\n\n[1] 12\n\nsum(is.na(autism_pids$ethnicity)) # N missing values\n\n[1] 95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim",
    "href": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2 using skimr function skim\n",
    "text": "Option 2 using skimr function skim\n\n\non specific columns\n\n\nautism_pids %&gt;% \n  skimr::skim(pids, ethnicity) %&gt;%\n  dplyr::select(#skim_variable, \n                skim_type, \n                complete_rate,\n                n_missing, \n                character.n_unique)\n\n\n\n# A tibble: 2 √ó 4\n  skim_type complete_rate n_missing character.n_unique\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;int&gt;              &lt;int&gt;\n1 character         1             0                704\n2 character         0.865        95                 11"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim-cont.",
    "href": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2 using skimr function skim (cont.)",
    "text": "Option 2 using skimr function skim (cont.)\n\non the whole dataset\n\n\nautism_pids %&gt;% \n  skimr::skim() \n\n\n\n\n‚îÄ‚îÄ Variable type: character ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   skim_variable   n_missing complete_rate min max empty n_unique whitespace\n 1 gender                  0         1       1   1     0        2          0\n 2 ethnicity              95         0.865   5  15     0       11          0\n 3 jaundice                0         1       2   3     0        2          0\n 4 autism                  0         1       2   3     0        2          0\n 5 contry_of_res           0         1       4  20     0       67          0\n 6 used_app_before         0         1       2   3     0        2          0\n 7 age_desc                0         1      11  11     0        1          0\n 8 relation               95         0.865   4  24     0        5          0\n 9 Class_ASD               0         1       2   3     0        2          0\n10 pids                    0         1      11  13     0      704          0\n\n‚îÄ‚îÄ Variable type: numeric ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   skim_variable n_missing complete_rate    mean      sd p0  p25  p50  p75 p100\n 1 id                    0         1     352.    203.     1 177. 352. 528.  704\n 2 A1_Score              0         1       0.722   0.449  0   0    1    1     1\n 3 A2_Score              0         1       0.453   0.498  0   0    0    1     1\n 4 A3_Score              0         1       0.457   0.499  0   0    0    1     1\n 5 A4_Score              0         1       0.496   0.500  0   0    0    1     1\n 6 A5_Score              0         1       0.499   0.500  0   0    0    1     1\n 7 A6_Score              0         1       0.284   0.451  0   0    0    1     1\n 8 A7_Score              0         1       0.418   0.494  0   0    0    1     1\n 9 A8_Score              0         1       0.649   0.478  0   0    1    1     1\n10 A9_Score              0         1       0.324   0.468  0   0    0    1     1\n11 A10_Score             0         1       0.574   0.495  0   0    1    1     1\n12 age                   2         0.997  29.2     9.71  17  21   27   35    64\n13 result                0         1       4.88    2.50   0   3    4    7    10"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to factor using base R",
    "text": "From character to factor using base R\n\n#### char 2 factor -------------------------------------------------------------\n# Say I want to treat some variables as factors\nautism_pids$gender &lt;- as.factor(autism_pids$gender)\nautism_pids$ethnicity &lt;- as.factor(autism_pids$ethnicity)\nautism_pids$contry_of_res &lt;- as.factor(autism_pids$contry_of_res)\nautism_pids$relation &lt;- as.factor(autism_pids$relation)\n\n# check \nclass(autism_pids$gender)\n\n[1] \"factor\"\n\nclass(autism_pids$ethnicity)\n\n[1] \"factor\"\n\nclass(autism_pids$contry_of_res)\n\n[1] \"factor\"\n\nclass(autism_pids$relation)\n\n[1] \"factor\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r-n-cols",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r-n-cols",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to factor using base R (n cols)",
    "text": "From character to factor using base R (n cols)\n\nautism_pids_temp &lt;- autism_pids # copy df for test \n\nto_factor &lt;- c(\"gender\", \"ethnicity\", \"contry_of_res\", \"relation\") # vector of col names \nautism_pids_temp[ ,to_factor] &lt;-  lapply(X =  autism_pids[ ,to_factor], FUN = as.factor)\n\n# check \nclass(autism_pids_temp$gender)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$ethnicity)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$contry_of_res)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$relation)\n\n[1] \"factor\"\n\n# now I have Variable type: factor"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways",
    "href": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Inspect factors levels (3 different ways)",
    "text": "Inspect factors levels (3 different ways)\n\nusing base::levels function\n\n\nlevels(autism_pids$ethnicity)\n\n [1] \"Asian\"           \"Black\"           \"Hispanic\"        \"Latino\"         \n [5] \"Middle Eastern \" \"others\"          \"Others\"          \"Pasifika\"       \n [9] \"South Asian\"     \"Turkish\"         \"White-European\" \n\n\n\nusing base::table function\n\n\ntable(autism_pids$ethnicity,useNA = \"ifany\")\n\n\n          Asian           Black        Hispanic          Latino Middle Eastern  \n            123              43              13              20              92 \n         others          Others        Pasifika     South Asian         Turkish \n              1              30              12              36               6 \n White-European            &lt;NA&gt; \n            233              95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways-cont.",
    "href": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Inspect factors levels ‚Äì 3 different ways (cont.)",
    "text": "Inspect factors levels ‚Äì 3 different ways (cont.)\n\nusing janitor function tabyl, which uses the ‚Äúpipe‚Äù operator %&gt;% which takes the output of a function as input of the next one\n\n\njanitor::tabyl(autism_pids$ethnicity) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_pct_formatting()\n\n autism_pids$ethnicity   n percent valid_percent\n                 Asian 123   17.5%         20.2%\n                 Black  43    6.1%          7.1%\n              Hispanic  13    1.8%          2.1%\n                Latino  20    2.8%          3.3%\n       Middle Eastern   92   13.1%         15.1%\n                others   1    0.1%          0.2%\n                Others  30    4.3%          4.9%\n              Pasifika  12    1.7%          2.0%\n           South Asian  36    5.1%          5.9%\n               Turkish   6    0.9%          1.0%\n        White-European 233   33.1%         38.3%\n                  &lt;NA&gt;  95   13.5%             -\n                 Total 704  100.0%        100.0%"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#identify-missing-values",
    "href": "practice/practice_slides/slides_lab01.html#identify-missing-values",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Identify missing values",
    "text": "Identify missing values\nUse is.na to check if the 95 missing obs are the same missing for ethnicity and relation\n\nwhich(is.na(autism_pids$ethnicity)) # indices of TRUE elements in vector\n\n [1]   5  13  14  15  20  21  25  26  63  80  81  82  92 217 222 239 258 271 277\n[20] 278 286 307 316 325 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n[39] 352 353 354 355 356 362 366 370 371 373 379 380 381 382 383 384 385 386 387\n[58] 388 389 391 396 400 401 402 404 424 428 429 430 433 439 454 486 506 519 528\n[77] 535 536 537 538 557 565 572 573 589 594 637 643 646 652 653 659 660 667 702\n\nwhich(is.na(autism_pids$relation))  # indices of TRUE elements in vector\n\n [1]   5  13  14  15  20  21  25  26  63  80  81  82  92 217 222 239 258 271 277\n[20] 278 286 307 316 325 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n[39] 352 353 354 355 356 362 366 370 371 373 379 380 381 382 383 384 385 386 387\n[58] 388 389 391 396 400 401 402 404 424 428 429 430 433 439 454 486 506 519 528\n[77] 535 536 537 538 557 565 572 573 589 594 637 643 646 652 653 659 660 667 702\n\n\n‚Ä¶indeed they are the same IDs!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-logical",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-logical",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to logical",
    "text": "From character to logical\nI may prefer to code a variable as logical. For example, age_desc may be more explicit if coded as logical.\n\nI create a new column age_desc_log\n\n\n\n# observe a subset of some columns \nautism_subset &lt;- autism_pids [1:5, c(\"gender\",\"jaundice\", \"autism\",\"age_desc\",\n                                     \"Class_ASD\",\"pids\")]\n# View(autism_subset)\n\n# recode \"age_desc\" as LOGICAL new var \"age_desc_log\"\nautism_pids$age_desc_log &lt;- ifelse(autism_pids$age_desc == \"18 and more\", TRUE, FALSE )\nclass(autism_pids$age_desc)\n\n[1] \"character\"\n\nclass(autism_pids$age_desc_log)\n\n[1] \"logical\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-dummy-01",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-dummy-01",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to dummy [0,1]",
    "text": "From character to dummy [0,1]\nI also may need binary variables expressed as [0,1] (e.g.¬†to incorporate nominal variables into regression analysis). Let‚Äôs recode autism.\n\nautism_pids$autism_dummy &lt;- ifelse(autism_pids$autism == 'yes', 1, 0)\nclass(autism_pids$autism)\n\n[1] \"character\"\n\nclass(autism_pids$autism_dummy)\n\n[1] \"numeric\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#subsetting-the-data-for-further-investigation",
    "href": "practice/practice_slides/slides_lab01.html#subsetting-the-data-for-further-investigation",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Subsetting the data for further investigation",
    "text": "Subsetting the data for further investigation\nRecall how to view the names of columns / variables\n\ncolnames(autism_pids)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"       \"pids\"            \"age_desc_log\"   \n[25] \"autism_dummy\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils",
    "href": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "using head or tail from utils\n",
    "text": "using head or tail from utils\n\n\n\nhead or tail return the first or last parts of an object\n\n\nhead(autism_pids)   #return fist 6 obs\ntail(autism_pids)   #return last 6 obs"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils-cont.",
    "href": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "using head or tail from utils (cont.)",
    "text": "using head or tail from utils (cont.)\n\nhead(autism_pids, n = 2) #return fist 2 obs\n\n  id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n1  1        1        1        1        1        0        0        1        1\n2  2        1        1        0        1        0        0        0        1\n  A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n1        0         0  26      f White-European       no     no United States\n2        0         1  24      m         Latino       no    yes        Brazil\n  used_app_before result    age_desc relation Class_ASD        pids\n1              no      6 18 and more     Self        NO PatientID_1\n2              no      5 18 and more     Self        NO PatientID_2\n  age_desc_log autism_dummy\n1         TRUE            0\n2         TRUE            1\n\ntail(autism_pids, n = 2) #return last 2 obs\n\n     id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n703 703        1        0        0        1        1        0        1        0\n704 704        1        0        1        1        1        0        1        1\n    A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n703        1         1  35      m    South Asian       no     no      Pakistan\n704        1         1  26      f White-European       no     no        Cyprus\n    used_app_before result    age_desc relation Class_ASD          pids\n703              no      6 18 and more     Self        NO PatientID_703\n704              no      8 18 and more     Self       YES PatientID_704\n    age_desc_log autism_dummy\n703         TRUE            0\n704         TRUE            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#investigating-a-subset-of-observations",
    "href": "practice/practice_slides/slides_lab01.html#investigating-a-subset-of-observations",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Investigating a subset of observations",
    "text": "Investigating a subset of observations\nE.g. I learned that some patients have missing age‚Ä¶ how many are they?\n\n# run...\nsum(is.na(autism_pids$age)) \n\n[1] 2\n\n# or \nskimr::n_missing(autism_pids$age)\n\n[1] 2\n\n\n So, next, I want to ID those patients with missing age."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 1) using [] from base\n\n\nmissing_age_subset &lt;- autism_pids[is.na(autism_pids$age), \n                                  c(\"pids\", \"age\", \"autism_dummy\") ]\nmissing_age_subset\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-1",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 2) using which from base\n\n\nmissing_age_subset2 &lt;- autism_pids[which(is.na(autism_pids$age)), \n                                   c(\"pids\", \"age\", \"autism_dummy\")] \nmissing_age_subset2\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-2",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-2",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 3) using subset from base\n\n\n# arguments allow me to specify rows and cols \nmissing_age_subset3 &lt;- subset(x = autism_pids, \n                              subset = is.na(autism_pids$age), # 1 logical condition\n                              select = c(\"pids\", \"age\", \"autism_dummy\") # which cols\n                              ) \nmissing_age_subset3\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df",
    "href": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (filtering on 2 conditions) as SUBSET of the given df",
    "text": "New df (filtering on 2 conditions) as SUBSET of the given df\nOption 1) using base::subset\n\n\n# Creates a SUBSET based on MORE conditions (`age` and `ethnicity`)\ntwocond_base_subset &lt;- subset(x = autism_pids, \n                       # 2 logical conditions      \n                       subset = age &lt; 25 & contry_of_res == \"Brazil\", \n                       # pick a few cols \n                       select = c(\"pids\", \"age\", \"contry_of_res\",\n                                  \"autism_dummy\")) \n\ntwocond_base_subset\n\n             pids age contry_of_res autism_dummy\n2     PatientID_2  24        Brazil            1\n54   PatientID_54  21        Brazil            1\n94   PatientID_94  19        Brazil            1\n429 PatientID_429  20        Brazil            0\n587 PatientID_587  21        Brazil            0\n588 PatientID_588  21        Brazil            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df-1",
    "href": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (filtering on 2 conditions) as SUBSET of the given df",
    "text": "New df (filtering on 2 conditions) as SUBSET of the given df\nOption 2) using dplyr (filter + select)\nSwitching to the package dplyr and embracing the ‚Äúpipe‚Äù (%&gt;%) operator logic, in which the filtering (rows) and selecting (columns) is done in sequence\n\n## here the filtering (rows) and selecting (columns) is done in sequence\ntwocond_dplyr_subset &lt;- autism_pids %&gt;% \n  dplyr::filter(age &lt; 25 & contry_of_res == \"Brazil\") %&gt;%  # which rows\n  dplyr::select (pids, age, contry_of_res, autism_dummy)   # which cols\n\ntwocond_dplyr_subset\n\n           pids age contry_of_res autism_dummy\n1   PatientID_2  24        Brazil            1\n2  PatientID_54  21        Brazil            1\n3  PatientID_94  19        Brazil            1\n4 PatientID_429  20        Brazil            0\n5 PatientID_587  21        Brazil            0\n6 PatientID_588  21        Brazil            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#input-values-where-missing",
    "href": "practice/practice_slides/slides_lab01.html#input-values-where-missing",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Input values where missing",
    "text": "Input values where missing\n\n‚ö†Ô∏è WARNINGÔ∏é: This is a very delicate & substantial step ‚ö†Ô∏è\n\nany modified/imputed data (beyond the original collection) can affect subsequent analysis and statistical modeling\nit will be necessary to document and justify whichever approach is used to deal with missing data.  Let‚Äôs assume we can get the missing data by cross-checking related clinical information\n\n\n# 1/2 create a new variable \nautism_pids$age_inputed &lt;- autism_pids$age\n# 2/2 replace value (presumably taken from other source) of `aged_inputed` \n  # CONDITIONAL on `pids`\nautism_pids$age_inputed[autism_pids$pids == \"PatientID_63\"] &lt;-  65\nautism_pids$age_inputed[autism_pids$pids == \"PatientID_92\"] &lt;-  45\n\n# check\nskimr::n_missing(autism_pids$age) \n\n[1] 2\n\nskimr::n_missing(autism_pids$age_inputed)  \n\n[1] 0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#summarizing-all-variables",
    "href": "practice/practice_slides/slides_lab01.html#summarizing-all-variables",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Summarizing all variables",
    "text": "Summarizing all variables\nTry these 2 options: \n\n\nbase::summary\n\nsummary(autism_pids)\n\n\nskimr::skim\n\nskimr::skim(autism_pids)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type",
    "href": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Notice summary different behavior according to the variable‚Äôs type",
    "text": "Notice summary different behavior according to the variable‚Äôs type\nThe function‚Äôs results depend on the class of the object\n\nlook at the output in case of integer (e.g.¬†A1_Score)\n\n\nsummary(autism_pids$A1_Score)     # min, max quartiles, mean, median\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.7216  1.0000  1.0000 \n\n\n\nlook at the output in case of factor (e.g.¬†ethnicity)\n\n\nsummary(autism_pids$ethnicity)    # counts of levels' frequency (included NA!)\n\n          Asian           Black        Hispanic          Latino Middle Eastern  \n            123              43              13              20              92 \n         others          Others        Pasifika     South Asian         Turkish \n              1              30              12              36               6 \n White-European            NA's \n            233              95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type-cont.",
    "href": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Notice summary different behavior according to the variable‚Äôs type (cont.)",
    "text": "Notice summary different behavior according to the variable‚Äôs type (cont.)\n\nlook at the output in case of logical (e.g.¬†age_desc_log)\n\n\nsummary(autism_pids$age_desc_log) # counts of TRUE \n\n   Mode    TRUE \nlogical     704"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#frequency-distributions-with-table",
    "href": "practice/practice_slides/slides_lab01.html#frequency-distributions-with-table",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Frequency distributions with table\n",
    "text": "Frequency distributions with table\n\n\nFrequency distributions can be used for nominal, ordinal, or interval/ration variables\n\n\ntable(autism_pids$gender)\n\n\n  f   m \n337 367 \n\ntable(autism_pids$age) # automatically drops missing...\n\n\n17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \n18 31 35 46 49 37 37 34 27 28 31 24 27 30 21 18 16 12 17 13 17 13  7 16  3 15 \n43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 59 60 61 64 \n11 10  4  6  8  4  3  5  1  5  6  2  6  2  2  1  1  2  1 \n\ntable(autism_pids$age, useNA = \"ifany\") #...unless specified\n\n\n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n  18   31   35   46   49   37   37   34   27   28   31   24   27   30   21   18 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n  16   12   17   13   17   13    7   16    3   15   11   10    4    6    8    4 \n  49   50   51   52   53   54   55   56   58   59   60   61   64 &lt;NA&gt; \n   3    5    1    5    6    2    6    2    2    1    1    2    1    2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#cross-tabulation-with-table-2-vars",
    "href": "practice/practice_slides/slides_lab01.html#cross-tabulation-with-table-2-vars",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Cross tabulation with table (2 vars)",
    "text": "Cross tabulation with table (2 vars)\n\nCross tabulation\n\n\ntable(autism_pids$gender, autism_pids$age_inputed)\n\n   \n    17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41\n  f  7 11 22 22 18 14 17 10 11 14 18 15 16 13  8 14  6  7 12  7 11  6  5  9  0\n  m 11 20 13 24 31 23 20 24 16 14 13  9 11 17 13  4 10  5  5  6  6  7  2  7  3\n   \n    42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 59 60 61 64 65\n  f  6  5  4  5  4  3  2  2  2  0  2  4  1  1  0  1  0  1  1  0  0\n  m  9  6  6  0  2  5  2  1  3  1  3  2  1  5  2  1  1  0  1  1  1\n\ntable(autism_pids$ethnicity, autism_pids$autism_dummy)\n\n                 \n                    0   1\n  Asian           118   5\n  Black            38   5\n  Hispanic         12   1\n  Latino           12   8\n  Middle Eastern   83   9\n  others            1   0\n  Others           28   2\n  Pasifika         10   2\n  South Asian      34   2\n  Turkish           5   1\n  White-European  183  50"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with base R",
    "text": "Grouping and summarizing with base R\nE.g. I want to know the average age of men and women sub-groups.\nOption 1) using by\n\n\n# by(data$column, data$grouping_column, mean)\nby(data = autism_pids$age_inputed, INDICES = autism_pids$gender, FUN = mean)\n\nautism_pids$gender: f\n[1] 29.60237\n------------------------------------------------------------ \nautism_pids$gender: m\n[1] 28.98365"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r-1",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with base R",
    "text": "Grouping and summarizing with base R\n\nUsing functions from the apply() family (sapply, lapply, tapply):\n\nAll of these functions allow us to iterate over a data structure, (a list, a matrix, an array, a DataFrame, etc.) and perform the same operation at each element.\n\nOption 2) using tapply\n\n(to apply a function to subsets of a vector where subsets are defined by some other vector, usually a factor)\n\n# i.e. apply a function to subsets of a vector or array, split by one or more factors.\ntapply(X = autism_pids$age_inputed, INDEX = autism_pids$gender, FUN = mean)\n\n       f        m \n29.60237 28.98365 \n\n\nOption 3) using split + sapply\n\n(it returns a vector)\n\n# sapply(split(data$column, data$grouping_column), mean)\nsapply(X = split(autism_pids$age_inputed, autism_pids$gender),FUN = mean) # returns a vector\n\n       f        m \n29.60237 28.98365"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-dplyr",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-dplyr",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with dplyr\n",
    "text": "Grouping and summarizing with dplyr\n\n\n\nUsing functions from the dplyr() package which ‚Äúconcatenates‚Äù each step\n\nautism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarise(mean(age_inputed))  # returns a dataframe!\n\n# A tibble: 2 √ó 2\n  gender `mean(age_inputed)`\n  &lt;fct&gt;                &lt;dbl&gt;\n1 f                     29.6\n2 m                     29.0\n\n\nI could add more statistics to the grouped summary‚Ä¶\n\nautism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarise(mean_age = mean(age_inputed),  \n                   N_obs = n(), \n                   N_with_autism = sum(autism_dummy == 1)\n  ) \n\n# A tibble: 2 √ó 4\n  gender mean_age N_obs N_with_autism\n  &lt;fct&gt;     &lt;dbl&gt; &lt;int&gt;         &lt;int&gt;\n1 f          29.6   337            54\n2 m          29.0   367            37"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#mean-and-median",
    "href": "practice/practice_slides/slides_lab01.html#mean-and-median",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Mean and median",
    "text": "Mean and median\nRecall that: \nPopulation MEAN \\(\\mu=\\frac{\\sum_{i=1}^n x_{i}}n\\)Sample MEAN \\(\\bar{x}=\\frac{\\sum_{i=1}^n x_{i}}n\\)\n\nSample MEDIAN\nFor uneven \\(n\\): \\(Mdn = \\frac{x_{(n+1)}}2\\)\nFor even \\(n\\): \\(Mdn = \\frac{x_{(n/2)} + x_{(n/2+1)}}2\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#meanmedian-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#meanmedian-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Mean/Median using base R",
    "text": "Mean/Median using base R\n\n\nUsing age (original variable)\n\nYou must specify the argument na.rm = TRUE or the functions won‚Äôt work!\n\n\n\n\n## Using `age` (original variable) \nmean(autism_pids$age)\n\n[1] NA\n\nmedian(autism_pids$age)\n\n[1] NA\n\n# specify to omit NA observations \nmean(autism_pids$age, na.rm = TRUE)\n\n[1] 29.20655\n\nmedian(autism_pids$age, na.rm = TRUE)\n\n[1] 27\n\n\n\nUsing age_inputed to see what inputed missing values did\n\n\n## Using `age_inputed` to see what inputed missing values did \nmean(autism_pids$age_inputed)\n\n[1] 29.27983\n\nmedian(autism_pids$age_inputed)\n\n[1] 27"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-12",
    "href": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-12",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Create custom function to calculate statistical mode 1/2",
    "text": "Create custom function to calculate statistical mode 1/2\nR doesn‚Äôt have a built-in function for the statistical mode, so we can create a custom one: f_calc_mode\nDefine the custom function\n\nf_calc_mode  &lt;- function(x) { \n  # `unique` returns a vector of unique values \n  uni_x &lt;- unique(x)  \n  # `match` returns the index positions of 1st vector against 2nd vector\n  match_x &lt;- match(x, uni_x)\n  # `tabulate` count the occurrences of integer values in a vector.\n  tab_x  &lt;-  tabulate(match_x) \n  # returns element of uni_x that corresponds to max occurrences\n  uni_x[tab_x == max(tab_x)]\n}"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-22",
    "href": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-22",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Create custom function to calculate statistical mode 2/2",
    "text": "Create custom function to calculate statistical mode 2/2\nCall the custom function\n\nf_calc_mode(autism_pids$age)\n\n[1] 21\n\nf_calc_mode(autism_pids$age_inputed)\n\n[1] 21\n\nf_calc_mode(autism_pids$ethnicity)\n\n[1] White-European\n11 Levels: Asian Black Hispanic Latino Middle Eastern  others ... White-European"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation",
    "href": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Variance and Standard deviation",
    "text": "Variance and Standard deviation\n\nPopulation Variance \\[\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}\\]Sample Variance \\[s^2 =\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}\\] Population Standard deviation \\[\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}}\\] Sample Standard deviation\\[s = \\sqrt\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}\\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Variance and Standard deviation using base R",
    "text": "Variance and Standard deviation using base R\n\nImportant to specify the argument na.rm = TRUE or the functions won‚Äôt work (or use the age_inputed variable)\n\n\nvar(autism_pids$age, na.rm = TRUE)\n\n[1] 94.28966\n\nvar(autism_pids$age_inputed)\n\n[1] 96.19328\n\nsd(autism_pids$age, na.rm = TRUE)\n\n[1] 9.710286\n\nsd(autism_pids$age_inputed)\n\n[1] 9.807817"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#introducing-r-package-ggplot2-for-graphics",
    "href": "practice/practice_slides/slides_lab01.html#introducing-r-package-ggplot2-for-graphics",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Introducing R package ggplot2 for graphics",
    "text": "Introducing R package ggplot2 for graphics\n\nggplot2 provides a set of tools to map data to visual elements on a plot, to specify the kind of plot you want, and then subsequently to control the fine details of how it will be displayed. It basically allows to build a plot layer by layer (Figure¬†2).\n\n\ndata -&gt; specify what the dataset is\n\naesthetic mappings (or just aesthetics) -&gt; specify which dataset‚Äôs variables will turn into the plot elements (e.g.¬†\\(x\\) and \\(y\\) values, or categorical variable into colors, points, and shapes).\n\ngeom -&gt; the overall type of plot, e.g.¬†geom_point() makes scatterplots, geom_bar() makes barplots, geom_boxplot() makes boxplots.\n\nAdditional (optional) pieces:\n\ninformation about the scales,\nthe labels of legends and axes\nother guides that help people to read the plot,"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#r-package-ggplot2-for-graphics-cont.",
    "href": "practice/practice_slides/slides_lab01.html#r-package-ggplot2-for-graphics-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "R package ggplot2 for graphics (cont.)",
    "text": "R package ggplot2 for graphics (cont.)\na layered approach!\n\n\nFigure¬†2: ggplot2 layers Source: Mine √áetinkaya-Rundel‚Äô Data Viz class"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#save-some-colors-for-customizing-plots",
    "href": "practice/practice_slides/slides_lab01.html#save-some-colors-for-customizing-plots",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Save some colors (for customizing plots)",
    "text": "Save some colors (for customizing plots)\n\nColors are defined in the form of Hexadecimal color values\n\n\n\ntwo_col_palette &lt;-  c(\"#9b2339\", \"#005ca1\")\n\ncontrast_cols_palette &lt;- c(\"#E7B800\",\"#239b85\", \"#85239b\", \"#9b8523\",\"#23399b\",\n                \"#d8e600\", \"#0084e6\", \"#399B23\", \"#e60066\",\n                \"#00d8e6\", \"#e68000\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms",
    "href": "practice/practice_slides/slides_lab01.html#histograms",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms",
    "text": "Histograms\nHistograms (and density plots) are often used to show the distribution of a continuous variable.\n\nOption 1) data inside the ggplot() function\n\n\nggplot(data = autism_pids, mapping = aes(x=age_inputed)) + \n  geom_histogram() + \n  theme_bw()\n\n\nOption 2) data before the pipe %&gt;%\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  geom_histogram() + \n  theme_bw()\n\n\n\n\nnotice that after calling ggplot(), subsequent layers are added with +"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-output",
    "href": "practice/practice_slides/slides_lab01.html#histograms-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms",
    "text": "Histograms"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#define-bin-width",
    "href": "practice/practice_slides/slides_lab01.html#define-bin-width",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ define bin width",
    "text": "‚Ä¶ define bin width\nHistograms split the data into ranges (bins) and show the number of observations in each. Hence, it‚Äôs important to pick widths that represents the data well.\n\nThe default value is 30\nWe can change it using the argument bins = #\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  # specify to avoid warning if we fail to specify the number of bins \n  geom_histogram(bins=40) + \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#define-bin-width-output",
    "href": "practice/practice_slides/slides_lab01.html#define-bin-width-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ define bin width",
    "text": "‚Ä¶ define bin width"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines",
    "href": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ add mean and std dev vertical lines",
    "text": "‚Ä¶ add mean and std dev vertical lines\n\nusing geom_vline() to add a vertical line for the mean, and the range between -1 and +1 sd from the mean.\nusing annotate() for adding small annotations (such as text labels)\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  geom_histogram(bins=40) + \n  # add mean vertical line\n  geom_vline(xintercept = mean(autism_pids$age_inputed),\n             na.rm = FALSE,\n             lwd=1,\n             color=\"#9b2339\") +\n  # add annotations with the mean value\n  annotate(\"text\",                        \n           x = mean(autism_pids$age_inputed) * 1.2, # coordinates for positioning\n           y = mean(autism_pids$age_inputed) * 2.5,\n           label = paste(\"Mean =\", round(mean(autism_pids$age_inputed), digits = 2)),\n           col = \"#9b2339\",\n           size = 4)+\n  # add also sd +1 and -1 \n  geom_vline(aes(xintercept = mean(autism_pids$age_inputed) + sd(autism_pids$age_inputed)), \n             color = \"#000000\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(autism_pids$age_inputed) - sd(autism_pids$age_inputed)), \n             color = \"#000000\", size = 1, linetype = \"dashed\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines-output",
    "href": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ add mean and std dev vertical lines",
    "text": "‚Ä¶ add mean and std dev vertical lines"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot",
    "href": "practice/practice_slides/slides_lab01.html#density-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot",
    "text": "Density plot\n\nspecifying x (the continuous variable)\nusing geom_density(), in which we\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed)) +\n  geom_density()+\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-output",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot",
    "text": "Density plot"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-cont.",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot (cont.)",
    "text": "Density plot (cont.)\n\nspecifying shape colors with the arguments inside geom_density(...)\n\n\ncolor for the line color\n\nfill for area color\n\n\nalpha to specify the degree of transparency in the density fill area\n\n\nautism_pids %&gt;% \n  ggplot(aes( x=age_inputed)) +\n  geom_density(fill=\"#85239b\", color=\"#4c4c4c\", alpha=0.5)+\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-cont.-output",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-cont.-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot (cont.)",
    "text": "Density plot (cont.)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks",
    "href": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ increase # of x-axis ticks",
    "text": "‚Ä¶ increase # of x-axis ticks\n\nspecifying the amount of breaks inside scale_x_continuous()\n\n\n\nautism_pids %&gt;% \n  ggplot(aes( x=age_inputed)) +\n  geom_density(fill=\"#85239b\", color=\"#4c4c4c\", alpha=0.5)+\n  theme_bw() + \n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,5 ), limits = c(16, 86))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks-output",
    "href": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ increase # of x-axis ticks",
    "text": "‚Ä¶ increase # of x-axis ticks"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category",
    "href": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms with fill = category\n",
    "text": "Histograms with fill = category\n\n\nindicate the categorical group as fill = in the aesthetic mapping\nspecify custom colors for each group:\n\n\nuse scale_color_manual() for changing line color\nuse scale_fill_manual() for changing area fill colors.\n\n\nautism_pids %&gt;% \n  # specifying `fill` = gender\n  ggplot(mapping = aes(x = age_inputed, fill = gender )) + \n  geom_histogram(bins=40) + \n  scale_fill_manual(values = c(\"#e07689\",\"#57b7ff\")) +\n  scale_color_manual(values = c(\"#9b2339\",\"#005ca1\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category-output",
    "href": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms with fill = category\n",
    "text": "Histograms with fill = category"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group",
    "href": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ shifting bars by group",
    "text": "‚Ä¶ shifting bars by group\n\nusing the specification position = 'dodge' inside geom_histogram()\n\n\n\n# trying to improve readability \nautism_pids %&gt;% \n  ggplot(mapping = aes(x = age_inputed, fill = gender )) + \n  # bars next to each other with `position = 'dodge'`\n  geom_histogram(bins=40, position = 'dodge')  + \n  scale_fill_manual(values = c(\"#e07689\",\"#57b7ff\")) +\n  scale_color_manual(values = c(\"#9b2339\",\"#005ca1\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group-output",
    "href": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ shifting bars by group",
    "text": "‚Ä¶ shifting bars by group"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender",
    "text": "‚Ä¶facet by gender\nThat‚Äôs still not very easy to digest. Instead of only filling, you can separate the data into multiple plots to improve readability\n\nadding facet_wrap() with the the specification of ~categ_var\n\nalso ncol = 1 requires the subplot to be in 1 column\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender )) + \n  geom_histogram(color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  theme_bw() + \n  # splitting the gender groups, specifying `ncol` to see one above the other\n  facet_wrap(~gender, ncol = 1)  + \n  scale_fill_cyclical(values = c(\"#9b2339\",\"#005ca1\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-output",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender",
    "text": "‚Ä¶facet by gender"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#adding-2-meanmedian-vert-lines-by-gender",
    "href": "practice/practice_slides/slides_lab01.html#adding-2-meanmedian-vert-lines-by-gender",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ adding 2 mean/median vert lines (by gender)",
    "text": "‚Ä¶ adding 2 mean/median vert lines (by gender)\nI want to see the mean vertical line for each of the subgroups, but in this case, I need to create a small dataframe of summary statistics (group_stats).\nI do so by using dplyr add a column mean_age with the group mean\n\ngroup_stats &lt;- autism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarize(mean_age = mean(age_inputed),\n                   median_age = median (age_inputed)) \n\ngroup_stats\n\n\n\n# A tibble: 2 √ó 3\n  gender mean_age median_age\n  &lt;fct&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 f          29.6         28\n2 m          29.0         26"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#small-digression-on-tidyrpivot_longer",
    "href": "practice/practice_slides/slides_lab01.html#small-digression-on-tidyrpivot_longer",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(Small digression on tidyr::pivot_longer)",
    "text": "(Small digression on tidyr::pivot_longer)\n\nThe new small dataframe group_stats offers an example of reshaping, i.e.¬†turning a table from a ‚Äúwide‚Äù form (with each variable in its own column) to a ‚Äúlong‚Äù form (one column for both the measures names and another for both the measures values).\n\nThis can be done using tidyr::pivot_longer function, where these arguments must be specified:\n\n\ncols: The names of the columns to pivot\n\nnames_to: The name for the new character column\n\nvalues_to: The name for the new values column\n\n\n\n\ngroup_stats_long &lt;- group_stats %&gt;% \n  tidyr::pivot_longer(cols = mean_age:median_age, \n                      names_to = \"Stat\", \n                      values_to = \"Value\") %&gt;% \n  dplyr::mutate(label = as.character(glue::glue(\"{gender}_{Stat}\")))\n\ngroup_stats_long \n\n# A tibble: 4 √ó 4\n  gender Stat       Value label       \n  &lt;fct&gt;  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n1 f      mean_age    29.6 f_mean_age  \n2 f      median_age  28   f_median_age\n3 m      mean_age    29.0 m_mean_age  \n4 m      median_age  26   m_median_age"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender + vert lines by group",
    "text": "‚Ä¶facet by gender + vert lines by group\nNotice that now the plot will have 2 data sources:\n\nautism_pids\ngroup_stats_long\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender)) + \n  # geom_histogram from dataframe 1\n  geom_histogram(bins=30,color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  facet_wrap(~gender, ncol = 1) + \n  scale_fill_manual(values = c(\"#9b2339\",\"#005ca1\"))  +\n  # geom_vline from dataframe 2\n  geom_vline(data = group_stats_long, \n             mapping = aes(xintercept = Value, color = Stat),\n             lwd=1,\n             linetype=1) + \n  scale_color_manual(values = c( \"#f0a441\" , \"#d8cf71\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group-output",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender + vert lines by group",
    "text": "‚Ä¶facet by gender + vert lines by group"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#finishing-touches",
    "href": "practice/practice_slides/slides_lab01.html#finishing-touches",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ finishing touches",
    "text": "‚Ä¶ finishing touches\n\nusing labs() and theme() layers\n\n\nhist_plot &lt;- autism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender)) + \n  # geom_histogram from dataframe 1\n  geom_histogram(bins=30,color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  facet_wrap(~gender, ncol = 1) + \n  scale_fill_manual(values = c(\"#9b2339\",\"#005ca1\"))  +\n  # geom_vline from dataframe 2\n  geom_vline(data = group_stats_long, \n             mapping = aes(xintercept = Value, color = Stat),\n             lwd=1.5,\n             linetype=6) + \n  scale_color_manual(values = c( \"#e68000\", \"#d8cf71\")) +\n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,10 ), limits = c(10,70)) +\n  # Additional theme details \n  labs(x = \"age brackets\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by gender\",\n       subtitle = \"\",\n       caption = \"Source: Thabtah,Fadi (2017) https://doi.org/10.24432/C5F019.\") +\n  theme(legend.position = \"right\",\n        plot.title = element_text(face = \"bold\")) \nhist_plot"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#finishing-touches-output",
    "href": "practice/practice_slides/slides_lab01.html#finishing-touches-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ finishing touches",
    "text": "‚Ä¶ finishing touches"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-ggridges-package",
    "href": "practice/practice_slides/slides_lab01.html#density-ggridges-package",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density ggridges package",
    "text": "Density ggridges package\nAs an alternative, you can use the ggridges package to make ridge plots. The geom geom_density_ridges calculates density estimates from the provided data and then plots those, using the ridgeline visualization. In this case plots include a vertical median line.\n\nautism_pids %&gt;% \n  # this takes also `y` = group\n  ggplot(aes(x=age_inputed, y = gender, fill = gender)) +\n  ggridges::geom_density_ridges() +\n  # I can add quantile lines (2 is the median)\n  stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.5), alpha = 0.75)+  \n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,10 ), limits = c(16, 86)) + \n  scale_fill_cyclical(values = c(\"#9b2339\",\"#005ca1\")) + \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-ggridges-package-output",
    "href": "practice/practice_slides/slides_lab01.html#density-ggridges-package-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density ggridges package",
    "text": "Density ggridges package"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#barchart",
    "href": "practice/practice_slides/slides_lab01.html#barchart",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Barchart",
    "text": "Barchart\nBar charts provide a visual presentation of categorical data, with geom_bar() (height of the bar proportional to the number of cases in each group)\n\n\nFigure¬†3: Difference barchart v. histogram Source: https://www.biorender.com/"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#barchart-cont.",
    "href": "practice/practice_slides/slides_lab01.html#barchart-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Barchart (cont.)",
    "text": "Barchart (cont.)\n\n# Let's take a variable that we recoded as `factor`\nclass(autism_pids$ethnicity)\n\n[1] \"factor\"\n\n#### ... no formatting ---------------------------------- \nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity )) + \n  geom_bar() +   \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-theme",
    "href": "practice/practice_slides/slides_lab01.html#improve-theme",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve theme",
    "text": "‚Ä¶improve theme\n\nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity )) + \n  geom_bar(fill = \"steelblue\") +\n  # reference line  \n  geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n  # labels, title, etc \n  labs(x = \"ethnicity\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by ethnicity\",\n       subtitle = \"\",\n       caption = \"Autism study\")  +\n  theme_bw() +\n  # specification son axis labels\n  theme(axis.text.x = element_text(angle=50, vjust=0.75), \n        axis.text.y = element_text(size=10,face=\"bold\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-theme-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-theme-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve theme",
    "text": "‚Ä¶improve theme"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (reorder bars)",
    "text": "‚Ä¶improve readability (reorder bars)\nReordering the bars by count using the package forcats and its function fct_infreq\n\n(which we can do because ethnicity was recoded as factor)\n\n\nautism_pids %&gt;% \n    # we modify our x like so \n    ggplot(aes(x = forcats::fct_infreq(ethnicity ))) + \n    geom_bar(fill = \"steelblue\") +\n    geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n    labs(x = \"ethnicity\", y = \"n of individuals\",\n         color = \"Stats\",\n         title = \"Distribution of observations by ethnicity\",\n         subtitle = \"\",\n         caption = \"Autism study\")  +\n    # --- wrap long x labels (flipped ) !!!\n    #  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 10)) +\n    theme_bw() +\n    theme(axis.text.x = element_text(angle=50, vjust=0.75), \n          axis.text.y = element_text(size=10,face=\"bold\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (reorder bars)",
    "text": "‚Ä¶improve readability (reorder bars)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA)",
    "text": "‚Ä¶improve readability (highlight NA)\nLet‚Äôs highlight the fact that the last column (NA) represents missing values.\n\nCreate the highlight variable\nMap color to a variable (fill = highlight)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA) code",
    "text": "‚Ä¶improve readability (highlight NA) code\n\nautism_pids %&gt;%\n  ## --- prep the dataframe \n  dplyr::mutate(# Add a factor variable with two levels\n    highlight = forcats::fct_other(ethnicity, \n                                   keep = \"NA\", \n                                   other_level = \"All Groups\")) %&gt;% \n  ## --- now plot \n  # In `aes mapping` we map color to a variable (`fill = highlight`)\n  ggplot(aes(x = forcats::fct_infreq(ethnicity), fill = highlight)) + \n  geom_bar()+\n  # Use custom color palettes\n  scale_fill_manual(values=c(\"#0084e6\")) +\n  # Add a line at a significant level \n  geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n  theme_bw() +\n  # make some more theme specifications  \n  labs(x = \"ethnicity\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by ethnicity\",\n       subtitle = \"\",\n       caption = \"Autism study\")  +\n  theme(axis.text.x = element_text(angle=50, vjust=0.75), \n        axis.text.y = element_text(size=10,face=\"bold\"))  +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA) code",
    "text": "‚Ä¶improve readability (highlight NA) code"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot",
    "href": "practice/practice_slides/slides_lab01.html#boxplot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot",
    "text": "Boxplot\nThe boxplot is one of the simplest ways of representing a distribution of a continuous variable and it is packed with information. It consists of two parts:\n\n\nBox ‚Äî Extending from the 1st to the 3rd quartile (Q1 to Q3) with a line in the middle that represents the median.\n\nWhiskers ‚Äî Lines extending from both ends of the box (minimum/maximum whisker values are calculated as Q1/Q3 -/+ 1.5 * IQR)\nEverything outside is represented as an outlier\n\n\n\n\nFigure¬†4: Boxplot Source: https://www.appsilon.com/post/ggplot2-boxplots"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-1",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 1",
    "text": "Boxplot example 1\nLet‚Äôs use a boxplot to explore how the continuous variable result is distributed in the autism dataset.\n\nin the aesthetic mapping we specify only x (continuous variable)\nswitch to vertical orientation with coord_flip()\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = result )) +\n  geom_boxplot(alpha=0.5)+\n  # switch to vertical orientation\n  coord_flip() +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-1-output",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-1-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 1",
    "text": "Boxplot example 1"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-2",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-2",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 2",
    "text": "Boxplot example 2\nLet‚Äôs also explore how the continuous variable result is distributed by the categorical variable (factor) ethnicity.\n\nin the aesthetic mapping we specify y (continuous variable), plus x and fill (categorical variable)\nmake x axis labels readable with theme(axis.text.x (...)) layer\nI specify colors that I had previously saved in a color palette contrast_cols_palette\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity,  y= result, fill = ethnicity)) +\n  geom_boxplot(alpha=0.5)+\n  scale_fill_manual(values =  contrast_cols_palette)   +\n  theme_bw()+\n  # make x axis labes readable\n  theme(axis.text.x = element_text(angle=50, vjust=0.75)) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-2-output",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-2-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 2",
    "text": "Boxplot example 2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot",
    "text": "Violin plot\nSimilarly, the violin plot is an interesting alternative to show the distribution of a continuous variable along one or more categorical variables. Here, the kernel density plot shows the smoothed curve of the probability density function (PDF) of the data. \nCompared to the box plot, a violin plot provides more information, as it shows not only the summary statistics but also the shape and variability of the data (i.e.¬†helping to identify any skewness or multimodality in the data)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot-example",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot-example",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot example",
    "text": "Violin plot example\n\nit requires the geom_violin function\nit can be enriched by adding with other geoms, such as points, lines, or box plots, to create more complex and informative plots\nlet‚Äôs add points with the geom_point layer\n\n\nautism_pids %&gt;% \n  ggplot(mapping = aes(y = age_inputed, x = ethnicity, fill = ethnicity)) +\n  geom_violin(alpha=0.5) +\n  geom_point(position = position_jitter(width = 0.1), size = 0.5)+ \n  scale_fill_manual(values =  contrast_cols_palette)  +\n  # make x axis labes readable\n  theme(axis.text.x = element_text(angle=50, vjust=0.75)) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot-example-output",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot-example-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot example",
    "text": "Violin plot example"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#saving-one-plot",
    "href": "practice/practice_slides/slides_lab01.html#saving-one-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Saving one plot",
    "text": "Saving one plot\nIf I want to use these output files later, I can easily save in the output folder created at the beginning.\n\nsave a plot with ggplot2::ggsave\n\nspecifying the output directory with here::here(...)\n\n\n\nggsave (hist_plot, \n        filename = here::here(\"practice\",  \"data_output\", \"hist_plot.png\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#saving-a-.rds-data-file.",
    "href": "practice/practice_slides/slides_lab01.html#saving-a-.rds-data-file.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Saving a .Rds data file.",
    "text": "Saving a .Rds data file.\n\nsave a dataframe with base::saveRDS\n\nspecifying the output directory with here::here(...)\n\n\n\nsaveRDS (object = autism_pids, \n         file =  here::here(\"practice\",  \"data_output\", \"autism_pids_v2.Rds\"))\n\n\n\n(later) load a saved dataframe with base::readRDS\n\n\n\n# to load it later I will use \nreadRDS(here::here(\"practice\",  \"data_output\", \"autism_pids_v2.Rds\")) \n\n\n\nnotice I renamed while saving: next time I load it it will be called ‚Äúautism_pids_v2‚Äù"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab01.html#final-thoughtsrecommendations",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\nAlways read the documentation (?package::function, especially the examples at the bottom)\nAlways inspect the data / variables before and after making changes\n\nIt is advisable to rename (i.e.¬†create a new R object) when you recode/manipulate a variable or a dataset\n\nthis promotes reproducibility, since you(or others) will be able to retrace your coding steps\n\n\nAlways plot distributions for visual data exploration\nMake changes in small increments (like we saw in building ggplot2 graph in subsequent layers)\n\n\n\n\n\nR 4 Statistics | 2025"
  },
  {
    "objectID": "modules/06_extra.html",
    "href": "modules/06_extra.html",
    "title": "Extra materials",
    "section": "",
    "text": "üî¥ ‚Ä¶ currently under review ‚Ä¶ üî¥"
  },
  {
    "objectID": "modules/06_extra.html#topics",
    "href": "modules/06_extra.html#topics",
    "title": "Extra materials",
    "section": "Topics",
    "text": "Topics\n\nIntroduction to MetaboAnalyst software\n\nA useful R-based resources for metabolomics\n\n\nElements of statistical Power Analysis"
  },
  {
    "objectID": "modules/06_extra.html#extra-lecture-slides",
    "href": "modules/06_extra.html#extra-lecture-slides",
    "title": "Extra materials",
    "section": "(Extra) lecture slides",
    "text": "(Extra) lecture slides\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/06_extra.html#extra-practice-slides",
    "href": "modules/06_extra.html#extra-practice-slides",
    "title": "Extra materials",
    "section": "(Extra) practice slides",
    "text": "(Extra) practice slides\n\nView practice slides in full screen ¬†\n\n\n\n\n\n\nPractice input data (as subfolder)\n\n\n\nPractice R code (as .R file)"
  },
  {
    "objectID": "modules/04_caus_pred.html",
    "href": "modules/04_caus_pred.html",
    "title": "Causal analysis essentials",
    "section": "",
    "text": "Recall the essential features of experimental study designs\n\nLearning the vocabulary of causal analysis\n\n\nGet a visual intuition of causal pathways, including challenging elements:\n\n\nCollider variables\n\nConfounder variables\n\nMediator variables\n\n\nDiscuss the correct causal model to capture the association among exposure, outcome and other covariates, (including challenging ones)\nDefine causal outcomes and choosing the appropriate ‚Äúestimands‚Äù:\n\n\nATE, ATT, or ATU?\n\n\nDevise statistical methods to estimate ATE, ATT, and ATU based on research question and (sub)population of interest"
  },
  {
    "objectID": "modules/04_caus_pred.html#outline",
    "href": "modules/04_caus_pred.html#outline",
    "title": "Causal analysis essentials",
    "section": "",
    "text": "Recall the essential features of experimental study designs\n\nLearning the vocabulary of causal analysis\n\n\nGet a visual intuition of causal pathways, including challenging elements:\n\n\nCollider variables\n\nConfounder variables\n\nMediator variables\n\n\nDiscuss the correct causal model to capture the association among exposure, outcome and other covariates, (including challenging ones)\nDefine causal outcomes and choosing the appropriate ‚Äúestimands‚Äù:\n\n\nATE, ATT, or ATU?\n\n\nDevise statistical methods to estimate ATE, ATT, and ATU based on research question and (sub)population of interest"
  },
  {
    "objectID": "modules/04_caus_pred.html#lecture-slides",
    "href": "modules/04_caus_pred.html#lecture-slides",
    "title": "Causal analysis essentials",
    "section": "Lecture slides",
    "text": "Lecture slides\n\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/04_caus_pred.html#practice-slides",
    "href": "modules/04_caus_pred.html#practice-slides",
    "title": "Causal analysis essentials",
    "section": "Practice slides",
    "text": "Practice slides\n\nView practice slides in full screen ¬†\n\n\n\n\n\n\nPractice input data (as subfolder)\n\n\n Download input data\n\n\nPractice R code (as .R file)\n\n\n Download R file"
  },
  {
    "objectID": "modules/02_inference.html",
    "href": "modules/02_inference.html",
    "title": "Statistical inference & hypothesis testing",
    "section": "",
    "text": "Purpose and foundations of inferential statistics\n\nProbability and random variables\nMeaningful probability distributions\nSampling distributions and Central Limit Theorem\n\n\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing\n\nThe null and alternative hypothesis\nThe probability of error? (Œ± or ‚Äúsignificance level‚Äù)\nThe p-value probability and tests interpretation\nConfidence Intervals\nTypes of errors (Type 1 and Type 2)\nEffective vs statistical significance\n\n\n\nHypothesis tests examples\n\nComparing sample mean to a hypothesized population mean (Z test & t test)\nComparing two independent sample means (t test)\nComparing sample means from 3 or more groups (ANOVA) \n\n\n\n\nA closer look at testing assumptions (with examples)\n\nTesting two groups that are not independent\nTesting if the data are not normally distributed: non-parametric tests\nTesting samples without homogeneous variance of observations"
  },
  {
    "objectID": "modules/02_inference.html#outline",
    "href": "modules/02_inference.html#outline",
    "title": "Statistical inference & hypothesis testing",
    "section": "",
    "text": "Purpose and foundations of inferential statistics\n\nProbability and random variables\nMeaningful probability distributions\nSampling distributions and Central Limit Theorem\n\n\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing\n\nThe null and alternative hypothesis\nThe probability of error? (Œ± or ‚Äúsignificance level‚Äù)\nThe p-value probability and tests interpretation\nConfidence Intervals\nTypes of errors (Type 1 and Type 2)\nEffective vs statistical significance\n\n\n\nHypothesis tests examples\n\nComparing sample mean to a hypothesized population mean (Z test & t test)\nComparing two independent sample means (t test)\nComparing sample means from 3 or more groups (ANOVA) \n\n\n\n\nA closer look at testing assumptions (with examples)\n\nTesting two groups that are not independent\nTesting if the data are not normally distributed: non-parametric tests\nTesting samples without homogeneous variance of observations"
  },
  {
    "objectID": "modules/02_inference.html#lecture-slides",
    "href": "modules/02_inference.html#lecture-slides",
    "title": "Statistical inference & hypothesis testing",
    "section": "Lecture slides",
    "text": "Lecture slides\n\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/02_inference.html#practice-slides",
    "href": "modules/02_inference.html#practice-slides",
    "title": "Statistical inference & hypothesis testing",
    "section": "Practice slides",
    "text": "Practice slides\n\nView practice slides in full screen ¬†\n\n\n\n\n\n\nPractice input data (as subfolder)\n\n\n Download input data\n\n\nPractice R code (as .R file)\n\n\n Download R file"
  },
  {
    "objectID": "me.html",
    "href": "me.html",
    "title": "About the Instructor",
    "section": "",
    "text": "Maria Chiara Mimmi, Ph.D., is a Research Fellow at University of Pavia - Dept. of Molecular Medicine, as well as NMR Expert at Fondazione IRCCS Policlinico San Matteo. She has twenty years of experience working in life science research, with a focus on NMR and Mass Spectrometry applied to metabolomics/lipidomics.\nIn 2020, she joined the University of Pavia, at the Molecular Medicine Dept., to work with the recently acquired 700 MHz NMR spectrometer. Since then she focused on NMR applied to either metabolomics and to structure/dynamics of amyloidogenic proteins.\n\n\nUniversit√† degli Studi di Pavia | Pavia, Italy Master of Biostatistics and Epidemiology | 2018-2019\nUniversit√† degli Studi di Milano | Milano, Italy Ph.D.¬†in Chemical Sciences | 2001 - 2003\nInstitut National de la Recherche Agronomique | Versailles-Grignon, France Visiting scholar | 2003 - 2003\nUniversit√† degli Studi di Pavia | Pavia, Italy BSc Degree in Chemistry | 1994 - 2000\nUniversiteit Leiden | Leiden, The Netherlands Erasmus exchange student (6 months) | 1999 - 1999\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n  \n      Google Scholar\n  \n  \n      Research Gate\n  \n  \n      Orcid"
  },
  {
    "objectID": "me.html#education",
    "href": "me.html#education",
    "title": "About the Instructor",
    "section": "",
    "text": "Universit√† degli Studi di Pavia | Pavia, Italy Master of Biostatistics and Epidemiology | 2018-2019\nUniversit√† degli Studi di Milano | Milano, Italy Ph.D.¬†in Chemical Sciences | 2001 - 2003\nInstitut National de la Recherche Agronomique | Versailles-Grignon, France Visiting scholar | 2003 - 2003\nUniversit√† degli Studi di Pavia | Pavia, Italy BSc Degree in Chemistry | 1994 - 2000\nUniversiteit Leiden | Leiden, The Netherlands Erasmus exchange student (6 months) | 1999 - 1999"
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation and setup",
    "section": "",
    "text": "This workshop showcases introductory bio statistics concepts using the open source (and free!) programming language . Each session of the workshop features exercises that will help you learn by doing.\nWe will quickly go over this at our first Practice session, but you are expected to have the required software installed on your machine before the workshop.\nBelow is a step by step process that should guide you through the needed installation steps."
  },
  {
    "objectID": "install.html#installing-packages-1st-time-you-use-an-r-package",
    "href": "install.html#installing-packages-1st-time-you-use-an-r-package",
    "title": "Installation and setup",
    "section": "Installing packages (1st time you use an R Package)",
    "text": "Installing packages (1st time you use an R Package)\nOption 1)\nYou could install one package at a time via the function install.packages()‚Ä¶\n\n# (**ONLY** the 1st time you use them)\n\n# Installing \ninstall.packages(\"name_of_package_here\" ) \n\n# [OPTIONAL ARGUMENT] Installing (with specification for dependencies)\ninstall.packages(\"name_of_package_here\" , dependencies = TRUE)\n\n‚Ä¶ or in bulk, like so (it might take a few moments more):\n\n# (**ONLY** the 1st time you use them)\n\n# ---- Installing R pckgs for 1st LAB \npkg_list_lab_1 &lt;- c(\"fs\",\"here\", \"janitor\", \"skimr\", \n                   \"dplyr\", \"forcats\", \n                   \"ggplot2\",  \"ggridges\")\n\ninstall.packages(pkg_list_lab_1)\n\n\n# ---- Installing (more) R pckgs for 2nd LAB  \npkg_list_lab_2 &lt;- c(\"tidyr\", \"patchwork\",\n                    \"ggthemes\", \"ggstatsplot\", \"ggpubr\",  \"viridis\",\n                    \"BSDA\", \"rstatix\", \"car\", \"multcomp\") \n\ninstall.packages(pkg_list_lab_2)\n\n\n# ----  Installing (more) R pckgs for 3rd LAB  \npkg_list_lab_3 &lt;- c(\"openxlsx\", \n                    \"lmtest\" , \n                    \"broom\", \n                    \"performance\")\n\ninstall.packages(pkg_list_lab_3)\n\n\n# ----  Installing (more) R pckgs for 4th LAB  \npkg_list_lab_4 &lt;- c(\"rsample\",\n                    \"MASS\",\n                    \"FactoMineR\",\n                    \"factoextra\",\n                    \"ggfortify\",\n                    \"scatterplot3d\",\n                    \"pwr\" )\n\ninstall.packages(pkg_list_lab_4)\n\nOption 2)\nIn alternative, you could install each package separately, using the RStudio GUI, from the Packages tab in the bottom right pane as indicated here:\n\n\nScreenshot Install/Update pckgs from RStudio"
  },
  {
    "objectID": "install.html#loading-a-package-at-the-beginning-of-every-r-session",
    "href": "install.html#loading-a-package-at-the-beginning-of-every-r-session",
    "title": "Installation and setup",
    "section": "Loading a package (at the beginning of every R session)",
    "text": "Loading a package (at the beginning of every R session)\nOnce packages have been installed, with the command library() loads the specific R packages that you are going to need in any given R session.\n\n# Loading a package (at the beginning of every R session) \n# --- General \nlibrary(here)       # tools find your project's files, based on working directory\nlibrary(fs)         # file/directory interactions\nlibrary(janitor)    # tools for examining and cleaning data\nlibrary(skimr)      # Compact and Flexible Summaries of Data     \nlibrary(openxlsx)   # Read, Write and Edit xlsx Files\n\n# --- Tidyverse \nlibrary(dplyr)      # {tidyverse} A Grammar of Data Manipulation     \nlibrary(tidyr)      # {tidyverse} Tools to create tidy data \nlibrary(forcats)    # {tidyverse} Tools for Categorical Var.(Factors)   \n\n# --- Plotting\nlibrary(ggplot2)    # {tidyverse} tools for plotting\nlibrary(ggstatsplot)# 'ggplot2' Based Plots with Statistical Details \nlibrary(ggpubr)     # 'ggplot2' Based Publication Ready Plots \nlibrary(patchwork)  # Functions for \"\"Grid\" Graphics\"composing\" plots \nlibrary(viridis)    # Colorblind-Friendly Color Maps for R \nlibrary(ggthemes)   # Extra Themes, Scales and Geoms for 'ggplot2'\nlibrary(ggridges)   # Ridgeline Plots in 'ggplot2' (density functions)\n\n# --- Statistics\nlibrary(BSDA)       # Basic Statistics and Data Analysis   \nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)        # Companion to Applied Regression\nlibrary(multcomp)   # Simultaneous Inference in General Parametric Models \nlibrary(lmtest)     # Testing Linear Regression Models  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles\nlibrary(performance)# Assessment of Regression Models Performance \nlibrary(pwr)        # Basic Functions for Power Analysis"
  },
  {
    "objectID": "install.html#learning-about-a-package-after-installation",
    "href": "install.html#learning-about-a-package-after-installation",
    "title": "Installation and setup",
    "section": "Learning about a package (after installation)",
    "text": "Learning about a package (after installation)\nOnce an R package is installed, you can also read the documentation about it directly inside the RStudio IDE. For example, try running in your Console:\n\n# - To ask about a package\n?here\n\n# -- To ask about a specific function\n?janitor::clean_names\n\n?dplyr::group_by\n\nCongrats! You are all done! üôåüèª"
  },
  {
    "objectID": "install.html#useful-keyboard-shortcuts-in-rstudio",
    "href": "install.html#useful-keyboard-shortcuts-in-rstudio",
    "title": "Installation and setup",
    "section": "Useful keyboard shortcuts in RStudio",
    "text": "Useful keyboard shortcuts in RStudio\n\n\n\n\n\n\nDescription\nWindows & Linux\nMac\n\n\n\nInsert code section\nCtrl+Shift+R\nShift+Command+R  or Ctrl+Shift+R\n\n\nInsert code chunk (Quarto/Rmarkdown)\nCtrl+Alt+I\nCommand+Option+I\n\n\nComment/uncomment line\nCtrl+Shift+C\nCommand+Shift+C\n\n\nReindent lines\nCtrl+I\nCommand+I\n\n\nInsert 'assign' operator &lt;-\nAlt+-\nOption+-\n\n\nInsert 'pipe' operator %&gt;% or |&gt;\nCtrl+Shift+M\nShift+Command+M\n\n\nCode completion (in source)\nTab\nTab\n\n\nFile path completion (in console)\n\"+Tab\n\"+Tab\n\n\nMultple cursor selection\nAlt+click\nAlt+click\n\n\nMultple cursor selection (next)\nAlt+Shift+click\nAlt+Shift+click\n\n\nSwitch cursor between source & console\nCtrl+1 and Ctrl+2\nCtrl+1 and Ctrl+2\n\n\nRun current line/selection\nCtrl+Enter\nCommand+Return\n\n\nRun current chunk\nCtrl+Alt+C\nCommand+Option+C\n\n\nRun entire file\nCtrl+Shift+Enter\nCommand+Shift+Return\n\n\nShow help for function at cursor\nF1\nF1\n\n\nSearch within file\nCtrl+F\nCommand+F\n\n\nSearch within project\nCtrl+Shift+F\nCommand+Shift+F\n\n\nRestart R session\nCtrl+Shift+F10\nCommand+Shift+F10\n\n\n\n\n\n\nHere you find the complete list of RStudio Keyboard Shortcuts"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Statistics & Machine Learning with ",
    "section": "",
    "text": "### Welcome!\nThis website hosts some teaching material on ‚ÄúIntroduction to Statistics & Machine Learning with R‚Äù ‚Äî an intensive workshop that offers a few lectures accompanied by matching practice sessions ‚Äì to reinforce the concepts learned using  programming.\nThe course was originally designed for a summer workshop offered to a group of PhD students from various EU universities specializing in life sciences (see https://R4biostats.com/).\nI (Luisa) co-created that workshop with my sister üòä (Chiara) and I am currently revising and expanding the materials presented here.\n\n\n\nGet in touch if you have questions and/or are interested in a similar workshop for your team!\n\n\n\n\n\n  ¬†¬†Email us"
  },
  {
    "objectID": "license_etc.html",
    "href": "license_etc.html",
    "title": "Acknowledgments and resources",
    "section": "",
    "text": "We are genuinely grateful to many people within the Statistics, Machine Learning, Epidemiology and R programming communities, who shared their valuable work, open source software, and training resources."
  },
  {
    "objectID": "license_etc.html#licensing-and-use-of-the-workshop-materials",
    "href": "license_etc.html#licensing-and-use-of-the-workshop-materials",
    "title": "Acknowledgments and resources",
    "section": "Licensing and use of the workshop materials",
    "text": "Licensing and use of the workshop materials\nThe workshop materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. All borrowed external materials (images, worked examples, etc.), are credited with proper ‚ÄúSource‚Äù statements and governed by their own licenses. To our knowledge, all the consulted materials were published under ‚Äúopen access‚Äù or ‚Äúcreative commons‚Äù frameworks. If this were not the case for any content piece displayed here, please let us know and it will be removed."
  },
  {
    "objectID": "license_etc.html#selected-resources-for-self-guided-learning",
    "href": "license_etc.html#selected-resources-for-self-guided-learning",
    "title": "Acknowledgments and resources",
    "section": "Selected resources for self-guided learning",
    "text": "Selected resources for self-guided learning\nBelow is a curated list of great resources (most of which free and openly accessible) you can peruse on your own.\n\n\nStatistics, Biostatistics, Epidemiology with R examples\n\n\n\n\nChoueiry, G. (2024, December 5). 8 Types of Treatment Effects Explained (with Examples) [Article]. https://quantifyinghealth.com/treatment-effects-explained/\n\n\nHeiss, A. (2024, March 21). Demystifying causal inference estimands: ATE, ATT, and ATU [Article]. Andrew Heiss‚Äôs blog. https://www.andrewheiss.com/blog/2024/03/21/demystifying-ate-att-atu\n\n\nGreifer, N., & Stuart, E. A. (2021). Choosing the Causal Estimand for Propensity Score Analysis of Observational Studies [Article]. https://doi.org/10.48550/ARXIV.2106.10577    \n\nApplied Epi Team (2024). Applied Epi - Elevating frontline epidemiology [Course]. Training, support, tools. https://www.appliedepi.org/\nApplied Epi Team (2024). R for applied epidemiology and public health The Epidemiologist R Handbook [Course]. https://epirhandbook.com/en/\nBobbitt, Z. (2024). Statology [Course]. Statology. https://www.statology.org/\n√áetinkaya-Rundel, M., & Hardim, J. (2023). Introduction to Modern Statistics (1st Ed) [Book]. https://openintro-ims.netlify.app/\nchilds_introductory_2022-1?\n\nSelby, D., & 2021 (2024). Analytical Epidemiology II [Course]. David Selby. https://personalpages.manchester.ac.uk/staff/david.selby/analysis/2021-03-30-inference/\n\nVu, J., & Harrington, D. (2021). Introductory Statistics for the Life and Biomedical Sciences [Book]. https://www.openintro.org/book/biostat/\nR packages & tools\n\nPOSIT (2024). POSIT resources [R]. https://posit.co/resources/.\nRStudio, & Posit (2024). Base-r-cheat-sheet.pdf [R]. https://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf\nVarious contributors (2024). Bioconductor - Open source software for Bioinformatics [R]. Bioconductor - Open source software for Bioinformatics. https://www.bioconductor.org/\nWickham, H., Fran√ßois, R., M√ºller, K., & Vaughan, D. (2023). Programming with dplyr [R]. dplyr. https://dplyr.tidyverse.org/articles/programming.html#tidy-selection\nWickham, H. (2014). Tidy Data [R]. Journal of Statistical Software, 59(10). https://doi.org/10.18637/jss.v059.i10\nSources of practice datasets\n\nVanderbilt Department of Biostatistics (2023, September 17). Vanderbilt Biostatistics Datasets [Dataset]. https://hbiostat.org/data/\nChicco, D., & Jurman, G. (2020). Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone [Dataset]. BMC Medical Informatics and Decision Making, 20(1), 16. https://doi.org/10.1186/s12911-020-1023-5\nAhmad, T., Munir, A., Bhatti, S. H., Aftab, M., & Raza, M. A. (2017). Survival analysis of heart failure patients: A case study [Dataset]. PLOS ONE, 12(7), e0181001. https://doi.org/10.1371/journal.pone.0181001\n\nJoosten, H., Van Eersel, M. E. A., Gansevoort, R. T., Bilo, H. J. G., Slaets, J. P. J., & Izaks, G. J. (2013). Cardiovascular Risk Profile and Cognitive Function in Young, Middle-Aged, and Elderly Subjects [Dataset]. Stroke, 44(6), 1543‚Äì1549. https://doi.org/10.1161/STROKEAHA.111.000496"
  },
  {
    "objectID": "modules/01_data_with_R.html",
    "href": "modules/01_data_with_R.html",
    "title": "Intro to R and data analysis",
    "section": "",
    "text": "Introduction to R and R-studio\n\nWhy R?\nPrinciples of reproducible analysis with R + RStudio\n\n\nR objects, functions, packages\nUnderstanding different types of variables\n\nPrinciples of ‚Äútidy data‚Äù\nData cleaning and manipulation\n\n\nDescriptive statistics\n\nMeasures of central tendency, measures of variability (or spread), and\n\n\nFrequency distribution\nVisual data exploration\n\n{ggplot2}"
  },
  {
    "objectID": "modules/01_data_with_R.html#outline",
    "href": "modules/01_data_with_R.html#outline",
    "title": "Intro to R and data analysis",
    "section": "",
    "text": "Introduction to R and R-studio\n\nWhy R?\nPrinciples of reproducible analysis with R + RStudio\n\n\nR objects, functions, packages\nUnderstanding different types of variables\n\nPrinciples of ‚Äútidy data‚Äù\nData cleaning and manipulation\n\n\nDescriptive statistics\n\nMeasures of central tendency, measures of variability (or spread), and\n\n\nFrequency distribution\nVisual data exploration\n\n{ggplot2}"
  },
  {
    "objectID": "modules/01_data_with_R.html#lecture-slides",
    "href": "modules/01_data_with_R.html#lecture-slides",
    "title": "Intro to R and data analysis",
    "section": "Lecture slides",
    "text": "Lecture slides\n\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/01_data_with_R.html#practice-slides",
    "href": "modules/01_data_with_R.html#practice-slides",
    "title": "Intro to R and data analysis",
    "section": "Practice slides",
    "text": "Practice slides\n\nView practice slides in full screen"
  },
  {
    "objectID": "modules/01_data_with_R.html#practice-input-data-as-subfolder",
    "href": "modules/01_data_with_R.html#practice-input-data-as-subfolder",
    "title": "Intro to R and data analysis",
    "section": "Practice input data (as subfolder)",
    "text": "Practice input data (as subfolder)\n\n\n Download input data"
  },
  {
    "objectID": "modules/01_data_with_R.html#practice-r-code-as-.r-file",
    "href": "modules/01_data_with_R.html#practice-r-code-as-.r-file",
    "title": "Intro to R and data analysis",
    "section": "Practice R code (as .R file)",
    "text": "Practice R code (as .R file)\n\n\n Download R file"
  },
  {
    "objectID": "modules/03_corr_regress.html",
    "href": "modules/03_corr_regress.html",
    "title": "Modeling correlation and regression",
    "section": "",
    "text": "Testing and summarizing relationship between 2 variables (correlation)\n\nPearson \\(r\\) analysis (param)\n\n(numerical variables)\n\n\nSpearman‚Äôs test (no param)\n\n\nMeasures of association\n\nChi-Square Test of Independence\n\n(categorical variables)\n\n\nFisher‚Äôs Exact Test\n\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\n\nWidely used analytical tools\n\nSimple linear regression models\nMultiple Linear Regression models\n\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised & Unsupervised algorithms"
  },
  {
    "objectID": "modules/03_corr_regress.html#outline",
    "href": "modules/03_corr_regress.html#outline",
    "title": "Modeling correlation and regression",
    "section": "",
    "text": "Testing and summarizing relationship between 2 variables (correlation)\n\nPearson \\(r\\) analysis (param)\n\n(numerical variables)\n\n\nSpearman‚Äôs test (no param)\n\n\nMeasures of association\n\nChi-Square Test of Independence\n\n(categorical variables)\n\n\nFisher‚Äôs Exact Test\n\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\n\nWidely used analytical tools\n\nSimple linear regression models\nMultiple Linear Regression models\n\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised & Unsupervised algorithms"
  },
  {
    "objectID": "modules/03_corr_regress.html#lecture-slides",
    "href": "modules/03_corr_regress.html#lecture-slides",
    "title": "Modeling correlation and regression",
    "section": "Lecture slides",
    "text": "Lecture slides\n\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/03_corr_regress.html#practice-slides",
    "href": "modules/03_corr_regress.html#practice-slides",
    "title": "Modeling correlation and regression",
    "section": "Practice slides",
    "text": "Practice slides\n\nView practice slides in full screen ¬†\n\n\n\n\nPractice input data (as subfolder)\n\n\n Download input data\n\n\nPractice R code (as .R file)\n\n\n Download R file"
  },
  {
    "objectID": "modules/05_intro_ML.html",
    "href": "modules/05_intro_ML.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "üü† ‚Ä¶ currently under review ‚Ä¶ üü†"
  },
  {
    "objectID": "modules/05_intro_ML.html#lecture-outline",
    "href": "modules/05_intro_ML.html#lecture-outline",
    "title": "Introduction to machine learning",
    "section": "Lecture Outline",
    "text": "Lecture Outline\n\nIntroduction to Machine Learning\n\nShifting the emphasis on empirical prediction\n\nDistinction between supervised & unsupervised algorithms\n\nSupervised ML Example\n\nLogistic regression\nüå≥ Random Forest / decision trees üå≤\n\n\nUnsupervised ML Example\n\nPCA for dimension reduction\nK-means Clustering"
  },
  {
    "objectID": "modules/05_intro_ML.html#lecture-slides",
    "href": "modules/05_intro_ML.html#lecture-slides",
    "title": "Introduction to machine learning",
    "section": "Lecture slides",
    "text": "Lecture slides\n\n\nView lecture slides in full screen"
  },
  {
    "objectID": "modules/05_intro_ML.html#practice-slides",
    "href": "modules/05_intro_ML.html#practice-slides",
    "title": "Introduction to machine learning",
    "section": "Practice slides",
    "text": "Practice slides\n\nView practice slides in full screen ¬†\n\n\n\n\n\n\nPractice input data (as subfolder)\n\n\n Download input data\n\n\nPractice R code (as .R file)\n\n\n Download R file"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#needed-r-packages",
    "href": "practice/practice_slides/slides_extra_01.html#needed-r-packages",
    "title": "Diving deeper into Causal Analysis",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\n\n# --- General \nlibrary(here)     # tools find your project's files, based on working directory\nlibrary(dplyr)    # A Grammar of Data Manipulation\nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(magrittr) # A Forward-Pipe Operator for R \nlibrary(readr)    # A Forward-Pipe Operator for R \n\n# Plotting & data visualization\nlibrary(ggplot2)      # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(scatterplot3d) # 3D Scatter Plot\n\n# --- Statistics\nlibrary(MASS)       # Support Functions and Datasets for Venables and Ripley's MASS\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\nlibrary(FactoMineR) # Multivariate Exploratory Data Analysis and Data Mining\nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\n\n# --- Tidymodels (meta package)\nlibrary(rsample)    # General Resampling Infrastructure  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#dataset-on-.",
    "href": "practice/practice_slides/slides_extra_01.html#dataset-on-.",
    "title": "Diving deeper into Causal Analysis",
    "section": "Dataset on ‚Ä¶.",
    "text": "Dataset on ‚Ä¶.\n\nName: ‚Ä¶. Documentation: ‚Ä¶. Sampling details: ‚Ä¶."
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#importing-dataset-....",
    "href": "practice/practice_slides/slides_extra_01.html#importing-dataset-....",
    "title": "Diving deeper into Causal Analysis",
    "section": "Importing Dataset ....",
    "text": "Importing Dataset ....\n.\n\nThe data can be interactively obtained form the MASS R package\n\n\n# (after loading pckg)\n# library(MASS)  \n\n# I can call \n# utils::data(biopsy)"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#section",
    "href": "practice/practice_slides/slides_extra_01.html#section",
    "title": "Diving deeper into Causal Analysis",
    "section": "",
    "text": "We define:\n\nthe individual treatment effect\n\nthe average treatment effect\n\nand the average treatment effect on the treated"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#final-thoughts",
    "href": "practice/practice_slides/slides_extra_01.html#final-thoughts",
    "title": "Diving deeper into Causal Analysis",
    "section": "Final thoughts",
    "text": "Final thoughts\n\n\n\n‚Ä¶..\n\n‚Ä¶\n\n\n‚Ä¶\n\n\n\n\n\n\nhttps://r4statistics.com | R 4 stats"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#goal-of-todays-practice-session",
    "href": "practice/practice_slides/slides_lab02.html#goal-of-todays-practice-session",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "GOAL OF TODAY‚ÄôS PRACTICE SESSION",
    "text": "GOAL OF TODAY‚ÄôS PRACTICE SESSION\nConsolidate understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.\n\n\nLecture 2: topics\n\n\nPurpose and foundations of inferential statistics    \n\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing     \n\n\nHypothesis testing\n\nreview examples\n\n\n\n\nA closer look at testing assumptions\n\nmore examples dealing with assumptions‚Äô violation"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab02.html#needed-r-packages",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n\n# Load pckgs for this R session\n\n# General \nlibrary(fs)           # file/directory interactions\nlibrary(here)         # tools find your project's files, based on working directory\nlibrary(janitor)      # tools for examining and cleaning data\nlibrary(dplyr)        # {tidyverse} tools for manipulating and summarising tidy data \nlibrary(forcats)      # {tidyverse} tool for handling factors\nlibrary(tidyr)        # Tidy Messy Data       \n\n# Statistics\nlibrary(BSDA)         # Basic Statistics and Data Analysis   \nlibrary(rstatix)      # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)          # Companion to Applied Regression\nlibrary(multcomp)     # Simultaneous Inference in General Parametric Models \n\n# Plotting\nlibrary(ggplot2)      # {tidyverse} tools for plotting\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details  \nlibrary(ggpubr)       # 'ggplot2' Based Publication Ready Plots \nlibrary(patchwork)    # Functions for \"\"Grid\" Graphics\"composing\" plots \nlibrary(viridis)      # Colorblind-Friendly Color Maps for R \nlibrary(ggthemes)     # Extra Themes, Scales and Geoms for 'ggplot2'"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#importing-from-project-folder-previously-downloaded-file",
    "href": "practice/practice_slides/slides_lab02.html#importing-from-project-folder-previously-downloaded-file",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Importing from project folder (previously downloaded file)",
    "text": "Importing from project folder (previously downloaded file)\nYou can access the dataset either:\n\nFrom the UC Irvine Machine Learning Repository Heart Failure Clinical Records\n\nFrom the workshop website: use function here to specify the complete path of the input data folder\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nheart_failure &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"02_datasets\",\n                                      \"heart_failure_clinical_records_dataset.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n\n\n\n\n\n\nTip\n\n\nMake sure to match your own folder structure!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#what-are-the-variables-and-their-levels-of-measurement",
    "href": "practice/practice_slides/slides_lab02.html#what-are-the-variables-and-their-levels-of-measurement",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "What are the variables and their levels of measurement?",
    "text": "What are the variables and their levels of measurement?\n\nThe data, with medical records of 299 heart failure patient, were collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad (Punjab, Pakistan), during April‚ÄìDecember 2015. See Table¬†1.\n\n\n\nTable¬†1"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#look-into-the-dataset-just-loaded-in-the-r-environment",
    "href": "practice/practice_slides/slides_lab02.html#look-into-the-dataset-just-loaded-in-the-r-environment",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Look into the dataset just loaded in the R environment",
    "text": "Look into the dataset just loaded in the R environment\nRecall some base R functions from Lab 1\n\n# What variables are included in this dataset?\ncolnames(heart_failure)\n\n [1] \"age\"                      \"anaemia\"                 \n [3] \"creatinine_phosphokinase\" \"diabetes\"                \n [5] \"ejection_fraction\"        \"high_blood_pressure\"     \n [7] \"platelets\"                \"serum_creatinine\"        \n [9] \"serum_sodium\"             \"sex\"                     \n[11] \"smoking\"                  \"time\"                    \n[13] \"DEATH_EVENT\"             \n\n# How many observations & variables?\nnrow(heart_failure)\n\n[1] 299\n\n# How many rows & columns?\ndim(heart_failure)\n\n[1] 299  13"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-base-r",
    "href": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-base-r",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Inspect the dataframe structure (base R)",
    "text": "Inspect the dataframe structure (base R)\n\n# What does the dataframe look like?\nstr(heart_failure)\n\n'data.frame':   299 obs. of  13 variables:\n $ age                     : num  75 55 65 50 65 90 75 60 65 80 ...\n $ anaemia                 : int  0 0 0 1 1 1 1 1 0 1 ...\n $ creatinine_phosphokinase: int  582 7861 146 111 160 47 246 315 157 123 ...\n $ diabetes                : int  0 0 0 0 1 0 0 1 0 0 ...\n $ ejection_fraction       : int  20 38 20 20 20 40 15 60 65 35 ...\n $ high_blood_pressure     : int  1 0 0 0 0 1 0 0 0 1 ...\n $ platelets               : num  265000 263358 162000 210000 327000 ...\n $ serum_creatinine        : num  1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ...\n $ serum_sodium            : int  130 136 129 137 116 132 137 131 138 133 ...\n $ sex                     : int  1 1 1 1 0 1 1 1 0 1 ...\n $ smoking                 : int  0 0 1 0 0 1 0 1 0 1 ...\n $ time                    : int  4 6 7 7 8 8 10 10 10 10 ...\n $ DEATH_EVENT             : int  1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-skimr",
    "href": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-skimr",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Inspect the dataframe structure (skimr)",
    "text": "Inspect the dataframe structure (skimr)\nRemember the skimr function skim?\n\n# some variables \nheart_failure %&gt;% skimr::skim( age, DEATH_EVENT ) \n\n# the whole dataframe\nheart_failure %&gt;% skimr::skim() \n\n\n\n\n\n You try‚Ä¶\n\n\nRun skimr::skim() on your own either on the whole dataset or on any specific variable\n\n\n\n\nnotice there are no (missing values) NAs in any of the variables"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#recode-some-variables-for-later-ease-of-analysis",
    "href": "practice/practice_slides/slides_lab02.html#recode-some-variables-for-later-ease-of-analysis",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Recode some variables for later ease of analysis",
    "text": "Recode some variables for later ease of analysis\n\nI may need some variables coded as factor (e.g.¬†categorical variables for plotting), and, while I am at it, I can add clearer labels for the variables‚Äô levels. Here, we are:\n\nusing tidyverse packages dplyr and forcats\n\nadding new (recoded) variables called ‚Äúoldname_f‚Äù\n\n\n\n\nheart_failure &lt;-heart_failure %&gt;% \n  dplyr::mutate(DEATH_EVENT_f = as.factor(DEATH_EVENT) %&gt;%\n                  forcats::fct_recode(\"died\" = \"1\", \"survived\" = \"0\")) %&gt;% \n  dplyr::mutate(sex_f = as.factor(sex) %&gt;%\n                  forcats::fct_recode(\"male\" = \"1\", \"female\" = \"0\"))\n\n# check \ntable(heart_failure$DEATH_EVENT_f)\n\n\nsurvived     died \n     203       96 \n\ntable(heart_failure$sex_f)\n\n\nfemale   male \n   105    194"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#some-more-dummy-variables-recoded-as-factor",
    "href": "practice/practice_slides/slides_lab02.html#some-more-dummy-variables-recoded-as-factor",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Some more dummy variables recoded as factor",
    "text": "Some more dummy variables recoded as factor\n\n[Mostly for illustration: it‚Äôs totally fine (if not preferable) to keep these as binary [0,1] variables]\n\nIt‚Äôs worth learning the useful function dplyr::across1, which allows to iteratively transform several columns at once!\n\n\n\n# Recode as factor with levels \"yes\" (= 1), \"no\" (= 0)\nfct_cols = c(\"anaemia\", \"diabetes\", \"high_blood_pressure\", \"smoking\" )\n\nheart_failure &lt;- heart_failure  %&gt;% \n  ## ---- 1st create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    # let's introduce `across` function \n    dplyr::across(\n      # Columns to transform\n      .cols = all_of(fct_cols), \n      # Functions to apply to each col  \n      .fns =  ~as.factor (.x),\n      # new name to apply where \"{.col}\" stands for the selected column\n      .names = \"{.col}_f\")) %&gt;% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      # Columns to transform 2 conditions \n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      # Functions to apply to each col(different syntax)\n      .fns = ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))\n\nThis is a bit more advanced, but it will save a lot of typing in some situations‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#small-digression-on-dplyracross",
    "href": "practice/practice_slides/slides_lab02.html#small-digression-on-dplyracross",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "(Small digression on dplyr::across)",
    "text": "(Small digression on dplyr::across)\n\nNotice how dplyr::across(.cols = ..., .fns = ..., .names = ...) has these arguments:\n\n\n.cols = to select the columns which we want to transform (i.e.¬†fct_cols)\n\nwith help from tidyselect functions: all_of, ends_with, and matches\n\n\n\n\n.fns = ~function(.x) to specify the function   \n\nwhere ~function(.x) uses the ‚Äúanonymous function‚Äù syntax of the tidyverse\n\nand .x inside the function is a ‚Äústand in‚Äù for each of the columns selected\n\n\n\n[optional] .names = to name the new cols created using {.col} in place of each of the transformed columns\n\n\n\n## ---- 1st create new cols as \"factor versions\" of old cols\nheart_failure &lt;- heart_failure  %&gt;% \n  dplyr::mutate(\n    dplyr::across(\n      .cols = all_of(fct_cols), \n      .fns = ~as.factor (.x), \n      # (optional)\n      .names = \"{.col}_f\")) %&gt;% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      .fns =  ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#why-is-visual-exploration-important",
    "href": "practice/practice_slides/slides_lab02.html#why-is-visual-exploration-important",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Why is visual exploration important?",
    "text": "Why is visual exploration important?\n\n\nGaining insight on the variables (range, outliers, missing data)\nPreliminary check of assumptions for parametric hypothesis testing:\n\nnormally distributed outcome variables?\nhomogeneity of variance across groups?\n\n\n\nLet‚Äôs explore the Heart failure dataset with some data visualization‚Ä¶\n\nFollowing the referenced articles (which were mostly interested in predict mortality based on patients‚Äô characteristics), we will take the categorical, binary variable DEATH_EVENT_f as our main criterion to split the sample (into survived and dead patients) to explore any significant difference between groups in terms of means of known quantitative features.\n\nWe will look at both:\n\n\ncontinuous variables in the dataset (with the Probability Density Function (PDF))\n\ndiscrete variables in the dataset (with the Probability Mass Function (PMF))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#age",
    "href": "practice/practice_slides/slides_lab02.html#age",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Age",
    "text": "Age\nIntroducing the handy R package patchwork which lets us compose different plots in a very simple and intuitive way\n\n(check it out with ??patchwork)\n\n\nage &lt;-ggplot(heart_failure,aes(x = age ))+\n  geom_histogram(binwidth = 5, color = \"white\", fill = \"grey\",alpha = 0.5)+\n  geom_vline(aes(xintercept = mean(age)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Age Distribution\" )+\n  scale_x_continuous(breaks = seq(40,100,5))  \n\nage2 &lt;-ggplot(heart_failure, aes(x = age, fill = DEATH_EVENT_f))+\n  geom_histogram(binwidth = 5, position = \"identity\",alpha = 0.5,color = \"white\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT == 0])), color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT==1])), color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  labs(title =  \"Age Distribution by group (Death Event)\")+\n  scale_x_continuous(breaks = seq(40,100,5))\n\n# patchwork\nlibrary(patchwork) # The Composer of Plots\nage + age2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#age-output",
    "href": "practice/practice_slides/slides_lab02.html#age-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Age",
    "text": "Age\n\n\nAs the age increases, the incidence of death event seems to increase"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk",
    "href": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Creatinine Phosphokinase (CPK)",
    "text": "Creatinine Phosphokinase (CPK)\n\ncpk &lt;- ggplot(heart_failure,aes(x = creatinine_phosphokinase))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title = \"Creatinine phosphokinase (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\ncpk2 &lt;- ggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\")\n\ncpk + cpk2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk-output",
    "href": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Creatinine Phosphokinase (CPK)",
    "text": "Creatinine Phosphokinase (CPK)\n\n\nThis definitely doesn‚Äôt look like a normal distribution!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#ejection-fraction",
    "href": "practice/practice_slides/slides_lab02.html#ejection-fraction",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Ejection Fraction",
    "text": "Ejection Fraction\n\nejf &lt;- ggplot(heart_failure,aes(x = ejection_fraction))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  geom_vline(aes(xintercept = mean(ejection_fraction)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Ejection Fraction (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nejf2 &lt;- ggplot(heart_failure,aes(x = ejection_fraction,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Ejection Fraction (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nejf + ejf2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#ejection-fraction-output",
    "href": "practice/practice_slides/slides_lab02.html#ejection-fraction-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Ejection Fraction",
    "text": "Ejection Fraction\n\n\nThis also doesn‚Äôt look like a normal distribution‚Ä¶ and there is a remarkable change in the probability density function (PDF) shape when we introduce the grouping variable"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#platelets",
    "href": "practice/practice_slides/slides_lab02.html#platelets",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Platelets",
    "text": "Platelets\n\n# normalize the var for readability \nheart_failure  &lt;-  heart_failure %&gt;%  dplyr::mutate(plat_norm = platelets/1000) \n\nplat &lt;- ggplot(heart_failure,aes(x = plat_norm))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  geom_vline(aes(xintercept = mean(plat_norm)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution)\",\n       y = \"Density\", x = \"Sample platelet count (in 10^3 ¬µL)\") \n\nplat2 &lt;- ggplot(heart_failure,aes(x = plat_norm,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution) by group (Death Event)\",\n       caption = \"(Sample platelet count in 10^3 ¬µL)\") \n \nplat + plat2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#platelets-output",
    "href": "practice/practice_slides/slides_lab02.html#platelets-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Platelets",
    "text": "Platelets\n\n\nHere the probability distributions resemble a Normal one and we observe more uniformity in the mean/variance across the 2 groups"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-creatinine",
    "href": "practice/practice_slides/slides_lab02.html#serum-creatinine",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Creatinine",
    "text": "Serum Creatinine\n\nser_cr &lt;- ggplot(heart_failure,aes(x = serum_creatinine))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  geom_vline(aes(xintercept = mean(serum_creatinine)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Creatinine (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nser_cr2 &lt;- ggplot(heart_failure,aes(x = serum_creatinine,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Serum Creatinine (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_cr + ser_cr2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-creatinine-output",
    "href": "practice/practice_slides/slides_lab02.html#serum-creatinine-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Creatinine",
    "text": "Serum Creatinine\n\n\nAnother continuous random variable with a non-normal distribution (long right tails) and a seemingly important difference in variance between the groups."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-sodium",
    "href": "practice/practice_slides/slides_lab02.html#serum-sodium",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Sodium",
    "text": "Serum Sodium\n\nser_sod &lt;- ggplot(heart_failure,aes(x = serum_sodium))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  geom_vline(aes(xintercept = mean(serum_sodium)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Sodium (density distribution)\" )\n\nser_sod2 &lt;- ggplot(heart_failure,aes(x = serum_sodium,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  labs(title =  \"Serum Sodium (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_sod + ser_sod2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-sodium-output",
    "href": "practice/practice_slides/slides_lab02.html#serum-sodium-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Sodium",
    "text": "Serum Sodium\n\n\nSame as above, except for the long left tails‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#anaemia",
    "href": "practice/practice_slides/slides_lab02.html#anaemia",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Anaemia",
    "text": "Anaemia\n\nanem &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = anaemia_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\") +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Anaemia\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Anemia\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nanem"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#anaemia-output",
    "href": "practice/practice_slides/slides_lab02.html#anaemia-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Anaemia",
    "text": "Anaemia\n\n\nThere seems to be a greater incidence of anaemia in group ‚Äòdied‚Äô"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#diabetes",
    "href": "practice/practice_slides/slides_lab02.html#diabetes",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Diabetes",
    "text": "Diabetes\n\ndiab &lt;- ggplot(heart_failure, \n               aes(x = forcats::fct_infreq(DEATH_EVENT_f ), fill = diabetes_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Diabetes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Diabetes\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\ndiab"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#diabetes-output",
    "href": "practice/practice_slides/slides_lab02.html#diabetes-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Diabetes",
    "text": "Diabetes"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#smoking",
    "href": "practice/practice_slides/slides_lab02.html#smoking",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Smoking",
    "text": "Smoking\n\nsmok &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = smoking_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Patient smokes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients who smoke\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nsmok"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#smoking-output",
    "href": "practice/practice_slides/slides_lab02.html#smoking-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Smoking",
    "text": "Smoking"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#high-blood-pressure",
    "href": "practice/practice_slides/slides_lab02.html#high-blood-pressure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "High blood pressure",
    "text": "High blood pressure\n\nhbp &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = high_blood_pressure_f ))+\n  geom_bar(position = \"dodge\")+\n    ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has high blood pressure\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with High blood pressure\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nhbp"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#high-blood-pressure-output",
    "href": "practice/practice_slides/slides_lab02.html#high-blood-pressure-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "High blood pressure",
    "text": "High blood pressure\n\n\nThere is also a greater incidence of high blood pressure in group ‚Äòdied‚Äô"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-z-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-z-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample mean to a hypothesized population mean (with Z test)",
    "text": "Comparing sample mean to a hypothesized population mean (with Z test)\n\nStating the above hypotheses more formally:\nWhat is the population Total Platelet Count (TPC) mean for all people who suffered of heart failure (\\(ùùÅ_{HF}\\))?\n\n\n\\(ùëØ_ùüé\\) : there is no difference in mean TPC between patients who suffered heart failure and the general population\n\n\n\\(ùùÅ_{HF}\\) = 236 -&gt; hypothesis of no effect or (‚Äúno difference‚Äù)\n\n\n\n\\(ùëØ_ùíÇ\\) : there is a difference in mean TPC between patients who have suffered heart failure and the general population (‚Äúsome effect‚Äù). This can be formalized as either:\n\n\n\\(ùùÅ_{HF}\\) &lt; 236 (one-sided test), or\n\n\n\\(ùùÅ_{HF}\\) &gt; 236 (one-sided test), or\n\n\\(ùùÅ_{HF}\\) ‚â† 236 (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n# compute mean & sd for plot\nmean_plat_p &lt;- round(mean(heart_failure$plat_norm), digits = 1)\nsd_plat_p &lt;- round(sd(heart_failure$plat_norm), digits = 1)\n \nheart_failure %&gt;% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.0085, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.0085, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/¬µL)\") \n\n\n\n\nGeneral population data taken from the literature (See Wongsaengsak, Dennis, Arevalo, Ball, & Nugent, 2019)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-output",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n\nFor a general population, the Total Platelet Count (TPL) has ùõç=236 (1000 /¬µL) and ùõî= 59 (1000 /¬µL). Below is the sample distribution:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.a Computation of the test statistic",
    "text": "2.a Computation of the test statistic\n\nIn this case, we have:\n\na large sample \\((n &gt; 100)\\)\n\na known \\(ùõî^ùüê\\) (of the reference population)\nthe observed sample mean \\(\\bar{x}\\) and sample sd \\(s\\).\n\nSo we can compute:\n\\(ùíÅ_{calc}=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\n‚úçüèª Let‚Äôs do it ‚Äúby hand‚Äù first to see the steps\n\n\n# General Population of reference \nmu &lt;- 236 \nsigma  &lt;- 59\n# Sample of HF patients\nn &lt;- 299\nx_HF &lt;- mean(heart_failure$plat_norm)         #    263.358\ns_HF &lt;- sd(heart_failure$plat_norm)           #    97.80424\n# IF large sample & KNOWN pop variance \nstd_err_HF &lt;- sigma /sqrt(n)                  # 3.412058\nz_calc_HF &lt;-  (x_HF - mu) / std_err_HF        # 8.018043"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.b Computation of the p-value associated to the test statistic",
    "text": "2.b Computation of the p-value associated to the test statistic\nTo find the p-value associated with a z-score in R, we can use the pnorm() function, which uses the following syntax:\n\n\nq: The z-score\n\nmean: The mean of the normal distribution. Default is 0.\n\nsd: The standard deviation of the normal distribution. Default is 1.\n\nlower.tail:\n\nIf TRUE, the probability to the left of q in the normal distribution is returned\nIf FALSE, the probability to the right is returned. Default is TRUE.\n\n\n\n\n# Left-tailed test\np_value_l &lt;- stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = TRUE) \n# Right-tailed test\np_value_r &lt;- stats::pnorm(z_calc_HF, mean = 0, sd = 1,lower.tail = FALSE) \n# Two-tailed test  (our case)\np_value_two &lt;- 2*stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = FALSE)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.c Computation of the p-value associated to the test statistic",
    "text": "2.c Computation of the p-value associated to the test statistic\n\nüë©üèª‚Äçüíª Let‚Äôs see how this could be done using an R function BSDA::z.test\n\n\n\nz_test_summary &lt;- BSDA::z.test(x = heart_failure$plat_norm,   \n             alternative='two.sided', \n             mu=236, \n             sigma.x=59, \n             conf.level=.95)\nz_test_summary\n\n\n    One-sample z-Test\n\ndata:  heart_failure$plat_norm\nz = 8.018, p-value = 1.074e-15\nalternative hypothesis: true mean is not equal to 236\n95 percent confidence interval:\n 256.6705 270.0455\nsample estimates:\nmean of x \n  263.358 \n\n\nSame results!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\n\nBased on the critical region, the calculated test statistic z_calc_HF = 8.0180 falls in the CRITICAL REGION (well beyond the critical point)\n\n\n# given \nz_critical  &lt;- c(-1.96, +1.96) # (Z score corresponding to ùõº  = 0.05)\n# Check \nz_calc_HF &gt; z_critical \n\n[1] TRUE TRUE\n\n\n\nBased on the p-value, p_value_two = 1.07443e-15 is much much smaller than \\(\\alpha\\)\n\n\n\n# Check\np_value_two &lt;  0.05\n\n[1] TRUE\n\n\nDECISION: we reject the Null Hypothesis (basically we conclude that it is extremely unlikely that the sample we drew could have occurred just by chance). So the test indicates that, indeed, there is a difference between heart failure patients and the general population in terms of average platelets count."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-t-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample mean to a hypothesized population mean (with t test)",
    "text": "Comparing sample mean to a hypothesized population mean (with t test)\n\nSame question, but with a smaller sample to work on (this varies, but generally it means \\(n &lt; 30\\)). Imagine the patients were only observed over a follow-up period of 21 days, and also let‚Äôs assume we don‚Äôt know the population‚Äôs variance\nStating the hypothesis more formally:\nWhat is the population Total Platelet Count (TPC) mean for all people who suffered of heart failure (\\(ùùÅ_{HF21d}\\)) in the past 21 days or less?\n\n\n\\(ùëØ_ùüé\\) : there is no difference in mean TPC between patients who suffered heart failure (visited in 21 days) and the general population\n\n\n\\(ùùÅ_{HF21d}\\) = 236 -&gt; hypothesis of no effect or (‚Äúno difference‚Äù)\n\n\n\n\\(ùëØ_ùíÇ\\) : there is a difference in mean TPC between patients who have suffered heart failure and the general population (‚Äúsome effect‚Äù). This can be formalized as:\n\n\n\\(ùùÅ_{HF21d}\\) ‚â† 236 (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n# normalize the var for readability \nheart_21d  &lt;-  heart_failure %&gt;%  dplyr::mutate(plat_norm = platelets/1000) %&gt;% \n  filter(time &lt;= 21)                                # 23 obs \n# compute mean & sd for plot\nmean_plat_p &lt;- round(mean(heart_21d$plat_norm), digits = 1)\nsd_plat_p &lt;- round(sd(heart_21d$plat_norm), digits = 1)\n \nheart_21d %&gt;% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.014, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.014, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/¬µL)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1-output",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n\nFor a general population, the Total Platelet Count (TPL) has ùõç=236 (1000 /¬µL) and ùõî= 59 (1000 /¬µL). Below is the smaller sample distribution:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-picking-the-suitable-test",
    "href": "practice/practice_slides/slides_lab02.html#a-picking-the-suitable-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.a Picking the suitable test",
    "text": "2.a Picking the suitable test\nIn this case, we have:\n\na ‚Äúsmall‚Äù sample \\(n = 23\\)\n\nan unknown \\(ùõî^ùüê\\) (of the reference population)\nWe obtained the sample mean \\(\\bar{x}\\) and sample sd \\(s\\).\n\nSo we can compute:\n\\(t_{calc} =\\frac{\\bar{x}-\\mu}{\\frac{s_\\bar{x}}{\\sqrt{n-1}}}\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.b Computation of the test statistic",
    "text": "2.b Computation of the test statistic\n\n\nOption 1: Let‚Äôs compute the t test ‚Äúby hand‚Äù ‚úçüèª\n\n\n# General Population of reference \nmu_pop &lt;- 236 \n\n# SAMPLE HF patients follow up less 21 days \nheart_21d &lt;- heart_failure %&gt;% filter(time &lt;= 21) \n\nn_21d &lt;- nrow(heart_21d)                            # 23\nx_HF_21d &lt;- mean(heart_21d$plat_norm)               # 251.5094\ns_HF_21d &lt;- sd(heart_21d$plat_norm)                 # 102.7341\ndf_HF_21d &lt;- n_21d-1                                # 22   \n\n# IF SMALL sample UNKNOWN sigma\nstd_err_HF_21d &lt;- s_HF_21d /sqrt(n_21d -1)        # 21.90298\nt_calc &lt;-  (x_HF_21d - mu_pop) / std_err_HF_21d   # 0.7080951\n\n\nOption 2: Let‚Äôs compute the t test with stats::t.test üë©üèª‚Äçüíª\n\n\nt_stat_HF_21d_v2 &lt;- stats::t.test(x = heart_21d$plat_norm,\n                                  mu = mu_pop,\n                                  alternative = \"two.sided\")\n# extract t_calc from results df\nt_calc_v2  &lt;- t_stat_HF_21d_v2[[\"statistic\"]][[\"t\"]] # 0.7240093\n\n\n\n\nThere is a small difference in the t_calc ‚â† t_calc_v2 due to the fact that I use the Bessel‚Äôs correction n-1 in the sample standard deviation formula denominator, while the R function uses n"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic-1",
    "href": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.c Computation of the p-value associated to the test statistic",
    "text": "2.c Computation of the p-value associated to the test statistic\n\n\nOption 1: ‚Äúby hand‚Äù ‚úçüèª\n\nTo find the p-value associated with a t-score in R, we can use the pt(q, df, lower.tail = TRUE) function, which uses the following syntax:\n\n\nq: The t-score\n\ndf: The degrees of freedom\n\nlower.tail:\n\nTRUE to calculate the probability to the left of q which is called as left-tailed test\nFALSE as right-tailed test.\n\n\n\n\n# ---- Option 1 \n# -- Left-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = TRUE)\n\n# -- Right-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = FALSE) \n\n# -- Two-tailed test  (our case)\np_value_t_test &lt;- 2*pt(t_calc, df_HF_21d, lower.tail = FALSE) # 0.4863214\n\n\nOption 2: from results of stats::t.test üë©üèª‚Äçüíª\n\n\n# ---- Option 2 \n# extract  p_value from results df\np_value_v2  &lt;- t_stat_HF_21d_v2[[\"p.value\"]] # 0.4766892"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-1",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\n\n\nBased on the critical region, t_calc ‚âÉ 0.71 is smaller than the t critical value, i.e.¬†it falls within the region of acceptance, so he null hypothesis is not rejected\n\n\n#find two-tailed t critical values\n\nt_crit_two &lt;- qt(p=.05/2, df=22, lower.tail=FALSE)    # 2.073873\n# Compare t score against t critical    \nt_calc &gt; t_crit_two  # FALSE \n\n[1] FALSE\n\n\n\nBased on the p-value, p_value ‚âÉ 0.48 is larger than \\(\\alpha\\), i.e.¬†the probability of observing a test statistic (assuming \\(H_0\\) is true) is quite large\n\n\n# Check \np_value_t_test &lt;  0.05  # FALSE \n\n[1] FALSE\n\n\nDECISION: we FAIL to reject \\(H_0\\). So the test indicates that there is not a statistically significant difference between heart failure patients visited within 21 days and the general population in terms of average platelets count.\n\n\n\n\n\n\nNote\n\n\nWhat changed testing a sample with smaller n, instead of a large one?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test)",
    "text": "Comparing two independent sample means (t test)\n\nThis time, we investigate if there might be an actual difference in the Platelet Count means between the patients who died and the patients who survived heart failure.\nStating the above hypotheses more formally:\nIs there a statistically significant difference between the mean values of two groups?\n\n\n\\(ùëØ_ùüé\\) : The two population means are equal\n\n\n\\(ùùÅ_ùüè = ùùÅ_ùüé ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé=ùüé\\)\n\n\n\n\n\\(ùëØ_ùíÇ\\) : There is a mean difference between the two groups in the population. Possible directional difference formulation (two-tailed, left-tailed, right-tailed)\n\n\n\\(ùùÅ_ùüè‚â†ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé‚â†ùüé\\) (the two population means are not equal)\n\n\\(ùùÅ_ùüè &lt; ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé&lt;ùüé\\) (population 1 mean is less than population 0 mean)\n\n\\(ùùÅ_ùüè &gt; ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé&gt;ùüé\\) (population 1 mean is greater than population 0 mean)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test) (cont.)",
    "text": "Comparing two independent sample means (t test) (cont.)\n1. Question: Is there a statistically significant difference between the Platelet Counts in the patients who died v. survived heart failure?\n\n# boxplot by group\nheart_failure %&gt;% \n  ggplot(mapping = aes(y = plat_norm, x = DEATH_EVENT_f, fill = DEATH_EVENT_f)) +\n  geom_boxplot(alpha=0.5)+ \n  #geom_violin(alpha=0.5) +\n  geom_point(position = position_jitter(width = 0.1), size = 0.5)+ \n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))  +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        legend.position = \"none\",\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\")) + \n  labs(title = \"Boxplot of Total Platelet Count (TPL), grouping by DEATH_EVENT [0,1]\",\n       x = \"\", y  = \"Platelet count (1000 /¬µL)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.-output",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test) (cont.)",
    "text": "Comparing two independent sample means (t test) (cont.)\n\n\nThere seems to be no major difference in the two groups"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-independent-t-test",
    "href": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-independent-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2. Verify the assumptions for independent t-test",
    "text": "2. Verify the assumptions for independent t-test\n\nThe 2 samples (‚Äúdied‚Äù and ‚Äúsurvived‚Äù) must be independent ‚úÖ\nThe dependent variable is scaled in intervals (Platelets Count in 10^3 ‚Äú/¬µL‚Äù) ‚úÖ\nThe dependent variable is normally distributed (Platelets Count in 10^3 ‚Äú/¬µL‚Äù) ‚úÖ\n\n\n(If not, use non parametric test)\n\n\n\nThe variance within the 2 groups should be similar ‚ùì\n\n\n(If not, perform Welch‚Äôs t-test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary Fisher‚Äôs F test to check for variance equality",
    "text": "Preliminary Fisher‚Äôs F test to check for variance equality\n\nWe can compute the Fisher test ‚Äúby hand‚Äù ‚úçüèª\n\n\n## -- data by group\nn_died &lt;- nrow(heart_failure[heart_failure$DEATH_EVENT == 1 ,])\nmean_died &lt;- mean(heart_failure [ heart_failure$DEATH_EVENT == 1,  \"plat_norm\"])\nsd_died &lt;- sd(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\nvar_died &lt;- var(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\n\nn_survived &lt;- nrow(heart_failure[heart_failure$DEATH_EVENT == 0, ])\nmean_survived &lt;- mean(heart_failure [ heart_failure$DEATH_EVENT == 0,  \"plat_norm\"])\nsd_survived &lt;- sd(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\nvar_survived &lt;- var(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\n\n## -- F TEST\nF_ratio &lt;- var_died / var_survived\nF_ratio  # 1.020497 \n\n[1] 1.020497"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality-.cont",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality-.cont",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary Fisher‚Äôs F test to check for variance equality (.cont)",
    "text": "Preliminary Fisher‚Äôs F test to check for variance equality (.cont)\n\n## -- Define the critical value of F distribution for a risk of alpha = 0.05\n# qf(p=.05, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # RIGHT-Tailed\n# qf(0.95, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # LEFT- Tailed \nqf(c(0.025, 0.975), df1 = n_died-1, df2 = n_survived-1) # TWO-Tailed \n\n[1] 0.6994659 1.3987233\n\n## --Compute the exact p-value (two-tailed )\np_value_f &lt;- 2 * (1 - pf(F_ratio, df1 = (n_died-1), df2 = (n_survived-1))) \np_value_f\n\n[1] 0.8914982\n\n\nA test statistic (F) of 1.02 is obtained, with degrees of freedom 95 and 202.\nThe p-value is 0.89, greater than the p-value threshold of 0.05. This suggests we can not reject the null hypothesis of equal variances.\nThe variance within the 2 groups should be similar ‚úÖ ‚Äì&gt; we can run a t-test."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-t-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-t-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.a Computation of t test statistic",
    "text": "3.a Computation of t test statistic\n\nSince we verified the required assumptions, the test method is the independent (two-sample) t-test. In this case, we have:\n\na large sample \\((ùêß_ùüè +ùêß_ùüê &gt; 100)\\)\n\nthe population variance(s) are unknown, but we can assume = variances in 2 groups\n\n\n\\(standard\\, error\\) of the means‚Äô difference is obtained as pooled estimate standard deviation of the sampling distribution of the difference\n\n\nSo we can compute: \\(t_{calc} = \\frac{Difference\\,Between\\,Sample\\,means}{Std.\\,Err.\\,of\\,the\\,difference} = \\frac{\\bar{x_1} -\\bar{x_2}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}}+\\frac{s_{2}^{2}}{n_{2}}}}\\)\n\n\n# Step 1 - compute difference of sample means\nmean_diff &lt;- (mean_died - mean_survived) # -10.27645 \n\n# Step 2 - Compute associated t-statistics\n# pooled std error \npooled_stderror &lt;- sqrt(sd_died^2/(n_died ) + sd_survived^2/(n_survived )) \n# pooled std error corrected\npooled_stderror_corr &lt;- sqrt(sd_died^2/(n_died-1) + sd_survived^2/(n_survived-1)) \n\n###  t statistic  \nt_calc &lt;- (mean_died - mean_survived) / pooled_stderror_corr"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-t-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-t-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.b Computation of the p-value associated to the t statistic",
    "text": "3.b Computation of the p-value associated to the t statistic\n\n# Step 3 - degrees of freedom\n# n1 + n2 - number of estimated parameters (2 means)\nd_f &lt;- n_died + n_survived - 1 - 1 # 297\n\n# Step 4 - Deduced p-value\np_value &lt;- 2 * pt(t_calc, df = d_f) # 0.4009635\np_value\n\n[1] 0.4009635"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-2",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-2",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\n\n\nLooking at the confidence interval of the difference, the sample mean_diff is well inside the 95% CI of = population mean\n\n\nmean_diff\n\n[1] -10.27645\n\n# CI of the means difference \nCI_lower &lt;- mean_diff + qt(.025, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_lower\n\n[1] -34.32074\n\nCI_upper &lt;- mean_diff + qt(.975, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_upper\n\n[1] 13.76785\n\n\n\nAs for the p-value, p_value = 0.40 is bigger than threshold probability \\(\\alpha\\)\n\n\n\n# Check \np_value\n\n[1] 0.4009635\n\np_value &lt;  0.05  # FALSE \n\n[1] FALSE\n\n\nDECISION: So, we fail to reject the null hypothesis of equal populations means of TPC. So the test indicates that we do not have sufficient evidence to say that the mean counts of platelets in between these two populations is different."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-means-from-3-or-more-groups-anova",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-means-from-3-or-more-groups-anova",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample means from 3 or more groups (ANOVA)",
    "text": "Comparing sample means from 3 or more groups (ANOVA)\nIn this example, we adopt the ANOVA (‚ÄúAnalysis Of Variance‚Äù) test, i.e.¬†an extension of the previous test, but examined how means of a variable differ across 3 or more groups. We will use ‚Äòone- way‚Äô ANOVA, which serves when there is only one explanatory variable (‚Äútreatment‚Äù) with 3 or more levels, and only one level of treatment is applied for a given subject.\nFor this particular case, we use another realistic dataset showing the survival times of 33 laboratory mice with thymic leukemia who were randomly divided into 3 groups:\n\n1st group received Treatment 1\n2nd group received Treatment 2\n3rd group as Control\n\n\n# load new dataset\nmice &lt;- readxl::read_excel(here::here(\"practice\",\"data_input\",\n                                      \"02_datasets\",\"mice_exe_ANOVA.xlsx\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between the mean values of the k populations?",
    "text": "1. Question: Is there a statistically significant difference between the mean values of the k populations?\nDefining the question formally:\n\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_ùüè = ùùÅ_ùüê =  ùùÅ_3\\) all 3 population means are equal\n\n\\(ùëØ_ùíÇ\\) : at least one of \\((ùùÅ_ùüè,ùùÅ_ùüê,ùùÅ_3)\\) is not equal to the other means\n\n\n# boxplot by group\nmice %&gt;% \nggplot(., aes(x = group, y = surv_days, fill = group)) +\n  geom_boxplot() + \n  scale_fill_viridis(discrete = TRUE, alpha=0.6, option=\"A\") +\n  geom_jitter(color=\"black\", size=0.4, alpha=0.9) +\n  # theme_minimal() +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\"),\n        legend.position = \"none\",\n        ) + \n  labs(title = \"Visually check mean and variance in populations' samples\" ) + \n  ylab(label = \"Survival (# days\") + xlab(label = \"\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations-output",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between the mean values of the k populations?",
    "text": "1. Question: Is there a statistically significant difference between the mean values of the k populations?\n\n\nThe boxplot suggests that the 3 groups might have some fairly different distributions"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-one-way-anova",
    "href": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-one-way-anova",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2. Verify the assumptions for one-way ANOVA",
    "text": "2. Verify the assumptions for one-way ANOVA\nThe dependent variable is on a metric scale. In the case of the analysis of variance, the independent variable (factor) has at least three levels.\nAssumptions for the results of a one-way ANOVA to be valid:\n\n\nIndependence of observations ‚Äì The observations in each group are independent of each other and the observations within groups were obtained by a random sample. ‚úÖ\n\nNormally-distributed response variable ‚Äì The values of the dependent variable follow a normal distribution. ‚ùì\n\nHomogeneity of variance ‚Äì The variances of the populations that the samples come from are equal. ‚ùì"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nNormally-distributed response variable ‚úÖ\n\n\n(confirmed by visual inspection )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-statsshapiro.test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-statsshapiro.test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with stats::shapiro.test",
    "text": "Preliminary check for normality (test) with stats::shapiro.test\n\n# Shapiro-Wilk Normality Test to verify normality  \n# option 1 \nstats::shapiro.test(mice[mice$group == \"Control\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Control\", \"surv_days\", drop = TRUE]\nW = 0.99374, p-value = 0.9989\n\nstats::shapiro.test(mice[mice$group == \"Treatment 1\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 1\", \"surv_days\", drop = TRUE]\nW = 0.95716, p-value = 0.6106\n\nstats::shapiro.test(mice[mice$group == \"Treatment 2\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 2\", \"surv_days\", drop = TRUE]\nW = 0.97921, p-value = 0.9601"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with rstatix::shapiro_test",
    "text": "Preliminary check for normality (test) with rstatix::shapiro_test\n(same thing, but using a different R function)\n\n\nNormally-distributed response variable ‚Äì ‚úÖ\n\n\n(confirmed by Shapiro-Wilk normality test)\n\n[The null hypothesis of this test is \\(H_0\\) = ‚Äúsample distribution is normal‚Äù ]\n\n# Shapiro-Wilk Normality Test to verify normality  \n# option 2 (all 3 groups at once)\nmice %&gt;%\n  dplyr::group_by(group) %&gt;%\n  rstatix::shapiro_test(surv_days)\n\n# A tibble: 3 √ó 4\n  group       variable  statistic     p\n  &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 Control     surv_days     0.994 0.999\n2 Treatment 1 surv_days     0.957 0.611\n3 Treatment 2 surv_days     0.979 0.960"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-variance-equality",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-variance-equality",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check variance equality",
    "text": "Preliminary check variance equality\n\n\n\nHomogeneity of variance ‚Äì ‚úÖ\n\n\n(Besides visual inspection, confirmed by Levene test for variance equality)\n\n[The null hypothesis \\(H_0\\) = several groups have the same variance (possible variance differences occur only by chance, since there are small differences in each sampling)]\n\n# Levene test for variance equality\nlevene &lt;- mice %&gt;%                               # name of the data\n  car::leveneTest(surv_days ~ as.factor(group),   # continuous DV ~  group IV\n                  data = .,            # pipe the data from above\n                  center = mean)       # default is median \nlevene\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df F value Pr(&gt;F)\ngroup  2  0.1721 0.8427\n      30               \n\n\nNo evidence of violations of HOV were found, since the p-value for the Levene test (= 0.8427157) is greater than .05, then the variances are not significantly different from each other (i.e., the homogeneity assumption of the variance is met)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-anova-f-ratio",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-anova-f-ratio",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3 Computation of ANOVA F-ratio",
    "text": "3 Computation of ANOVA F-ratio\nANOVA in R can be done in several ways.\nSince it‚Äôs quite straightforward, let‚Äôs do all the steps by hand first. We need to obtain the needed ‚Äúingredients‚Äù to calculate the F-ratio:\n\\[ùë≠_{calc}=\\frac{Mean\\, Square\\, Between}{Mean, Square\\, Within}=  \\frac{MSB}{MSW} = \\frac{\\frac{SSB}{df1}}{\\frac{SSW}{df2}} \\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-anova-f-ratio-by-hand",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-anova-f-ratio-by-hand",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.a Computation of ANOVA F-ratio (‚Äúby hand‚Äù)",
    "text": "3.a Computation of ANOVA F-ratio (‚Äúby hand‚Äù)\n\n\nOption 1: Let‚Äôs compute the ANOVA test ‚Äúby hand‚Äù ‚úçüèª\n\n\n# Summary statistics\nmice_calc &lt;- mice %&gt;% \n  dplyr::mutate(mean_all = mean(surv_days),\n         sd_all = sd (surv_days),\n         dfw = 33-3, # df1 = n-k\n         dfb = 3-1, # df2 = K‚àí1 \n         group_f = as.factor(group)\n         ) %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::mutate(n_group = n(),\n         mean_group = mean(surv_days),\n         sd_group = sd (surv_days)) %&gt;% \n  ungroup() %&gt;% \n  mutate (ST = (surv_days - mean_all)^2,\n          SW = (surv_days - mean_group)^2,\n          SB = (mean_group - mean_all)^2)\n\n# Sum of Squares \nSST &lt;- sum(mice_calc$ST)\nSSB &lt;- sum(mice_calc$SB)\nSSW &lt;- sum(mice_calc$SW)\ndfw &lt;- 33-3  # df2\ndfb &lt;- 3-1 # df1\n\n# calculated F statistic \nF_calc &lt;- (SSB/dfb)/(SSW/dfw) # 5.65\n# F critical value\nF_crit &lt;- qf(p = 0.01, df1 = 2, df2 = 30, lower.tail = FALSE) # 5.390346"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-anova-f-ratio-with-r-functions",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-anova-f-ratio-with-r-functions",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.b Computation of ANOVA F-ratio (with R functions)",
    "text": "3.b Computation of ANOVA F-ratio (with R functions)\n\nThat was just to show how to build it step-by-step (ü§ì), but we don‚Äôt have to! We have alternative R functions that can do ANOVA for us:\n\nOption 2: With the stats::aov followed by the command summary üë©üèª‚Äçüíª\n\n\naov_1 &lt;- stats::aov(surv_days ~ group_f,\n                 data = mice_calc)\nsummary(aov_1) \n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ngroup_f      2  434.6  217.32   5.652 0.00826 **\nResiduals   30 1153.4   38.45                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nOption 3: With the stats::oneway.test() function üë©üèª‚Äçüíª\n\n\naov_2 &lt;- stats::oneway.test(surv_days ~ group_f,\n            data = mice_calc,\n            # assuming equal variances\n            var.equal = TRUE)\naov_2\n\n\n    One-way analysis of means\n\ndata:  surv_days and group_f\nF = 5.6522, num df = 2, denom df = 30, p-value = 0.008258"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-3",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-3",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\nAll 3 options have given the same results, i.e., F-ratio = 5.652 and a p-value = 0.00826\nDECISION: Given that the p-value is smaller than 0.05, we reject the null hypothesis, so we reject the hypothesis that all means are equal. Therefore, we can conclude that at least one group is different than the others in mean number of survival days.\n\n\n\n\n\n\nNote\n\n\nHave you seen the kind of notation Pr(&gt;F) 0.00826 ** before (as in the output of the stats::aov function)?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-two-groups-that-are-not-independent",
    "href": "practice/practice_slides/slides_lab02.html#testing-two-groups-that-are-not-independent",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing two groups that are not independent",
    "text": "Testing two groups that are not independent\nLet‚Äôs introduce another toy dataset just for demonstration purposes: imagine a statistics test is administered to the same group of 12 students before and after attending a workshop üòâ.\n\n# toy dataset for paired groups\ngrades &lt;- data.frame(\n  before = c(16, 5, 15, 2, 14, 15, 4, 7, 15, 6, 7, 14),\n  after = c(19, 18, 9, 17, 8, 7, 16, 19, 20, 9, 11, 18)\n)\n\nWe may reshape the dataframe into the long form using tidyr::pivot_longer (for plotting)\n\n# reshape into long form\ngrades_long &lt;- grades %&gt;% \n  dplyr::mutate(id = row_number()) %&gt;%\n  tidyr::pivot_longer(cols = before:after, \n                      names_to = \"time\", \n                      values_to = \"grade\") %&gt;% \n  dplyr::group_by(id) %&gt;% \n  # recode time as factor \n  dplyr::mutate(time_f = as_factor(time ))  %&gt;% \n  # reorder time_ levels  \n  dplyr::mutate(time_f =  fct_relevel(time_f, \"after\", after =  1))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-the-difference-between-two-paired-samples-statistically-significant",
    "href": "practice/practice_slides/slides_lab02.html#question-is-the-difference-between-two-paired-samples-statistically-significant",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is the difference between two PAIRED samples statistically significant?",
    "text": "1. Question: Is the difference between two PAIRED samples statistically significant?\n\nWhat a successful workshop! üòÅ"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#hypotehsis-for-the-paired-t-test-for-dependent-samples",
    "href": "practice/practice_slides/slides_lab02.html#hypotehsis-for-the-paired-t-test-for-dependent-samples",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Hypotehsis for the PAIRED t-test for dependent samples",
    "text": "2 Hypotehsis for the PAIRED t-test for dependent samples\n\nIn this example, it is clear that the two samples are not independent since the same 12 students took the test before and after the workshop.\nGiven that the normality assumption is NOT violated (and given the small sample size), we use the paired t-test, with the following hypotheses:\n\n\n\\(ùëØ_ùüé\\) : mean grades before and after the workshop are equal\n\n\\(ùëØ_ùíÇ\\) : mean grades before and after the workshop are different"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-paired-t-test-for-dependent-samples",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-paired-t-test-for-dependent-samples",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Computation of the PAIRED t-test for dependent samples",
    "text": "2 Computation of the PAIRED t-test for dependent samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt_stat_paired &lt;- stats::t.test(x = grades$before,\n                               y = grades$after, \n                               mu = 0, \n                               alternative = \"two.sided\",\n                               paired = TRUE\n)\nt_stat_paired\n\n\n    Paired t-test\n\ndata:  grades$before and grades$after\nt = -1.8777, df = 11, p-value = 0.08718\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -9.2317713  0.7317713\nsample estimates:\nmean difference \n          -4.25 \n\n# extract t_calc from results df\nt_calc_pair   &lt;- t_stat_paired[[\"statistic\"]][[\"t\"]] # -1.877683\np_value_pair   &lt;- t_stat_paired[[\"p.value\"]] # 0.08717703"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-4",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-4",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\nWe obtain the test statistic, the p-value and a reminder of the hypothesis tested.\nThe calculated t value is -1.8776829 The p-value is 0.087177. Therefore, at the 5% significance level, we do not reject the null hypothesis that the statistics‚Äô grades are similar before and after the workshop (üò≠)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#bonus-function",
    "href": "practice/practice_slides/slides_lab02.html#bonus-function",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Bonus function!",
    "text": "Bonus function!\nIt is worth mentioning the ggstatsplot package, which combines plots representing the distribution for each group‚Äîand the results of the statistical test displayed in the subtitle of the plot.\nBelow we check out the ggwithinstats() function for paired samples.\n\n# load package\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details\n\n# plot with statistical results\ngrades_long %&gt;% \n  # must ungroup the dataframe or it will give an error\n  ungroup () %&gt;% \n  ggstatsplot::ggwithinstats(.,\n                             x = time_f ,\n                             y = grade ,\n                             type = \"parametric\", # for t test \n                             centrality.plotting = FALSE # remove median\n  )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#bonus-function-output",
    "href": "practice/practice_slides/slides_lab02.html#bonus-function-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Bonus function!",
    "text": "Bonus function!\n\n\nThe test results are rendered with the plot!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-samples-without-normality-assumption",
    "href": "practice/practice_slides/slides_lab02.html#testing-samples-without-normality-assumption",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing samples without normality assumption",
    "text": "Testing samples without normality assumption\nLet‚Äôs go back to the HEART FAILURE dataset but looking at the levels of Creatinine Phosphokinase (CPK) in the blood, an enzyme that might indicate a heart failure or injury"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?\nDefining the question formally:\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_{CPK-died} = ùùÅ_{CPK-surv}\\) there is no difference in mean CPK between patients who suffered heart failure and died versus patients who survived after heart failure\n\\(ùëØ_ùíÇ\\) : \\(ùùÅ_{CPK-died} ‚â† ùùÅ_{CPK-surv}\\) there is a difference in mean CPK between patients who suffered heart failure and died versus patients who survived after heart failure (two-sided test)\n\n\nggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  guides(fill = \"none\") +\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\") + \n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure-output",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?\n\n\nThe density plot suggests non normality of the variable distribution"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nNormally-distributed response variable - ‚ùå\n\nQQ plot (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. A 45-degree reference line is also plotted. In a QQ plot, each observation is plotted as a single dot.\n\nIf the data are normal, the dots should form a straight line.\n\n\n# visual verification with QQ plot \nggpubr::ggqqplot( \n  heart_failure$creatinine_phosphokinase, \n  title = \"QQ plot for CPK levels in blood\",\n  xlab =\"Theoretical\", ylab = \"Sample (CPK)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1-output",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nIn a QQ plot, if the data are normal, the dots should follow a straight line."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test-1",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with rstatix::shapiro_test",
    "text": "Preliminary check for normality (test) with rstatix::shapiro_test\n(same thing, but using a different R function)\n\n\nNormally-distributed response variable - ‚ùå\n\n(NOT normality confirmed by Shapiro-Wilk normality test)\n\n\n\n[The null hypothesis of this test is \\(H_0\\) = ‚Äúsample distribution(s) is/are normal‚Äù ]\nGiven the p-value we reject the null hypothesis\n\n# Shapiro-Wilk Normality Test to verify normality  \nheart_failure %&gt;%\n  dplyr::group_by(DEATH_EVENT_f) %&gt;%\n  rstatix::shapiro_test(creatinine_phosphokinase)\n\n# A tibble: 2 √ó 4\n  DEATH_EVENT_f variable                 statistic        p\n  &lt;fct&gt;         &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;\n1 survived      creatinine_phosphokinase     0.628 8.51e-21\n2 died          creatinine_phosphokinase     0.439 1.99e-17"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-wilcoxon-rank-sum-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-wilcoxon-rank-sum-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Computation of the Wilcoxon Rank Sum test statistic",
    "text": "3. Computation of the Wilcoxon Rank Sum test statistic\nThe Wilcoxon Rank Sum test is considered to be the nonparametric equivalent to the two-sample independent t-test\nIts ASSUMPTIONS are:\n\nOrdinal or Continuous dependent variable: e.g.¬†CPK levels ‚úÖ\nIndependence: All of the observations from both groups are independent of each other ‚úÖ\nShape: The shapes of the distributions for the two groups are roughly the same ‚úÖ\n\n\nwrs_res &lt;- wilcox.test(creatinine_phosphokinase ~ DEATH_EVENT, # immagino 0, 1\n                   data = heart_failure ,\n                   exact = FALSE, \n                   alternative = \"two.sided\" )\nwrs_res\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  creatinine_phosphokinase by DEATH_EVENT\nW = 9460, p-value = 0.684\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nThe Wilcoxon Rank Sum test is equivalent to the Mann-Whitney U test to compare two independent samples. Different software use one or the other."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-5",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-5",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\nRESULTS: since the test statistic is W = 9460 and the corresponding p-value is 0.684 &gt; 0.05, we fail to reject the null hypothesis.\nINTERPRETATION: We do not have sufficient evidence to say that CPK levels for dead patients is different than that of survived patients \\(ùùÅ_{CPK-died} ‚â† ùùÅ_{CPK-surv}\\) at some statistically significant level)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-samples-without-homogeneous-variance-of-observations-assumption",
    "href": "practice/practice_slides/slides_lab02.html#testing-samples-without-homogeneous-variance-of-observations-assumption",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing samples without homogeneous variance of observations assumption",
    "text": "Testing samples without homogeneous variance of observations assumption"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-serum-sodium-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-serum-sodium-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between serum sodium levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between serum sodium levels in the blood of the survivors v. those who died after heart failure?\nDefining the question formally:\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_{sersod-died} = ùùÅ_{sersod-surv}\\) there is no difference in mean serum sodium between patients who suffered heart failure and died versus patients who survived after heart failure\n\\(ùëØ_ùíÇ\\) : \\(ùùÅ_{sersod-died} ‚â† ùùÅ_{sersod-surv}\\) there is a difference in mean serum sodium between patients who suffered heart failure and died versus patients who survived after heart failure (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)\n\n\n\nHomogeneity of Variance assumption - ‚ùå Plotting the data offers some graphical intuition that the variance of observations in the two groups seem not homogenous\n\n\n#Compute means and 95% confidence intervals\nswstats &lt;- heart_failure %&gt;%\n  group_by(DEATH_EVENT_f) %&gt;%\n  summarise(count = n(),\n    mean = mean(serum_sodium,na.rm=TRUE),\n    stddev = sd(serum_sodium, na.rm=TRUE),\n    meansd_l = mean - stddev,\n    meansd_u = mean + stddev)\n\n#The complete script with some styling added\nggplot(swstats, aes(x=DEATH_EVENT_f, y=mean)) + \n  geom_point(colour = \"black\" , size = 2) +\n  #Now plotting the individual data points before the mean values\n  geom_point(data=heart_failure, aes(x=DEATH_EVENT_f, y=serum_sodium, colour = DEATH_EVENT_f), \n             position = position_jitter() ) +\n  scale_colour_manual(values = c(\"#999999\",\"#d8717b\") ) +\n  #Add the error bars\n  geom_errorbar(aes(ymin = meansd_l, ymax = meansd_u), width=0.2, color = \"black\") +\n  labs(title = \"Mean (-/+SD) serum sodium (mEq/L) by group\", x = \"\", y = \"Serum Sodium\") +\n  guides(fill = \"none\")  +\n  coord_flip() +\n  labs(title =  \"Serum Sodium means and 95% confidence intervals by group (Death Event)\") + \n  theme(legend.position=\"none\",plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual-output",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (test)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (test)\nIt is always best to use an actual test, so we use also the Fisher‚Äôs F test to verify equal variances of Serum Sodium concentration in the two groups. [In this test \\(H_0\\) = ‚Äúthe ratio of variances is equal to 1‚Äù]\n\nf_test_res &lt;- stats::var.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] ,\n                              heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0])\nf_test_res\n\n\n    F test to compare two variances\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nF = 1.5769, num df = 95, denom df = 202, p-value = 0.007646\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.127401 2.254466\nsample estimates:\nratio of variances \n          1.576922 \n\n\nGiven the p-value = 0.007646 (smaller than \\(\\alpha\\)) we reject the null hypothesis, hence the HOV assumption for the t test does not hold."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-t-test-with-the-welch-correction",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-t-test-with-the-welch-correction",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Computation of the t test with the Welch correction",
    "text": "2 Computation of the t test with the Welch correction\n\nWe can still run the t test but with Welch correction, i.e.¬†the unequal variance condition is compensated by lowering the df. In fact the documentation (?t.test), reads:\n\nIf var.equal = TRUE, then the pooled variance is used to estimate the variance\nOtherwise (var.equal = FALSE), the Welch approximation to the degrees of freedom is used.\n\n\n# With Welch correction (on by default) Unequal variance is compensated by lowering df\nt_test_w &lt;- t.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1], \n                   heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0],\n                   # here we specify the situation\n                   var.equal = FALSE,\n                   paired = FALSE, alternative = \"two.sided\") \n\nt_test_w\n\n\n    Welch Two Sample t-test\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nt = -3.1645, df = 154.01, p-value = 0.001872\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.9914879 -0.6920096\nsample estimates:\nmean of x mean of y \n 135.3750  137.2167"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-6",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-6",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\nRESULTS: since the test statistic is t = -3.1645 (with df = 154.01) and the corresponding p-value is 0.001872 &lt; 0.05, we reject the null hypothesis.\nINTERPRETATION: We therefore have sufficient evidence to say that the level of serum sodium levels for dead patients is significantly different than that of survived patients \\(ùùÅ_{sersod-died} ‚â† ùùÅ_{sersod-surv}\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab02.html#final-thoughtsrecommendations",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\n\n\nThere are often many ways to do the same thing in R (which is both a blessing and a curse in open source software). Which should you choose? It depends on the situation, but you may want to consider:\n\nhow recent/popular/well maintained is a {package} (this affects its stability)\nthe more a function abstracts away complexity, the easier it is to use interactively, but the harder it gets to handle inside your own custom functions\ndifferent function outputs may be more/less suitable for your analysis/publication requirements (check out your peers‚Äô choices!)\n(Always read the documentation to assess all of the above)\n\n\nWith easy equations, breaking them down ‚Äúby hand‚Äù (at least once!) can really help you understand them\nIt may seem a lot of work to write R code the first time ü•µ (e.g.¬†for a publication-ready plot), but the good news is once you wrote a script, you will be able to easily re-use it in many more instances üôåüèª üòÉ\nSample size n has a very powerful impact on classical hypothesis testing results! More on this later‚Ä¶\n\n\n\n\n\n\n\n\nR 4 Statistics | 2025"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab04.html#needed-r-packages",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\n\n# --- General \nlibrary(here) # A Simpler Way to Find Your Files   \nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(paint)   # Fancy structure for data frames \nlibrary(janitor)  # Simple Tools for Examining and Cleaning Dirty Data\nlibrary(tidyverse) # Easily Install and Load the 'Tidyverse'\nlibrary(gt) # Easily Create Presentation-Ready Display Tables\nlibrary(marginaleffects) # Marginal Effects for Model Objects\nlibrary(WeightIt) # Weighting for Covariate Balance in Observational Studies\n# --- Plotting & data visualization\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(ggpubr)        # 'ggplot2' Based Publication Ready Plots\nlibrary(patchwork) # The Composer of Plots\n# --- Descriptive statistics and regressions\nlibrary(broom) # Convert Statistical Objects into Tidy Tibbles\nlibrary(Hmisc) # Harrell Miscellaneous\nlibrary(estimatr) # Fast Estimators for Design-Based Inference\nlibrary(modelsummary) # Summary Tables and Plots for Statistical Models and Data:\nlibrary(kableExtra) # Construct Complex Table with 'kable' and Pipe Syntax\nlibrary(sandwich) #for robust variance estimation\nlibrary(survey) # Analysis of Complex Survey Samples\nlibrary(haven) # Import and Export 'SPSS', 'Stata' and 'SAS' Files\nlibrary(simstudy) # Simulation of Study Data\nlibrary(NHANES) # Data from the US National Health and Nutrition Examination Study  \nlibrary(mediation) # Causal Mediation Analysis"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#importing-dataset-1-nhanes",
    "href": "practice/practice_slides/slides_lab04.html#importing-dataset-1-nhanes",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Importing Dataset 1 (NHANES)",
    "text": "Importing Dataset 1 (NHANES)\n\nName: NHANES, accessible from package NHANESDocumentation: See reference on the data downloaded with ?NHANESSampling details: We‚Äôll use a subset of the NHANES dataset, focusing on variables related to smoking status (SmokeNow), systolic blood pressure (BPSysAve), Body Mass Index (BMI) and age (Age).\n\nset.seed(123) # Set seed for reproducibility\ndata(NHANES)\n# Select relevant columns and drop rows with missing values\nnhanes_data &lt;- NHANES %&gt;%\n  dplyr::select(ID, Gender, Age, Race1, Height, Weight, BMI, SmokeNow, PhysActive, PhysActiveDays,\n         BPSysAve, BPDiaAve, TotChol, DirectChol, Diabetes, HealthGen,\n         Education, HHIncomeMid, Poverty) %&gt;%\n  drop_na() %&gt;% \n  # make it smaller \n  slice_sample(n = 1000) # Randomly select 1000 rows using\n\n# Take a quick look at the data\n#paint(nhanes_data)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dataset-1-nhanes-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab04.html#dataset-1-nhanes-variables-and-their-description",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Dataset 1 (NHANES) Variables and their description",
    "text": "Dataset 1 (NHANES) Variables and their description\n\nEXCERPT: see complete file in Input Data Folder\n\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nID\nint\nxxxxx\n\n\nGender\nchr\nGender (sex) of study participant coded as male or female\n\n\nAge\nint\n##\n\n\nAgeDecade\nchr\nyy-yy es 20-29\n\n\nRace1\nchr\nReported race of study participant: Mexican, Hispanic, White, #Black, or Other\n\n\nEducation\nchr\n[&gt;= 20 yro]. Ex. 8thGrade, 9-11thGrade, HighSchool, SomeCollege, or CollegeGrad.\n\n\nHHIncome\nchr\nTotal annual gross income for the household in US dollars\n\n\nHHIncomeMid\nint\nNumerical version of HHIncome derived from the middle income # in each category. Ex. 12500 40000\n\n\nPoverty\ndbl\nA ratio of family income to poverty guidelines. Smaller # numbers indicate more poverty Ex.. 0.95 1.74 4.99\n\n\nWeight\ndbl\nWeight in kg\n\n\nHeight\ndbl\nStanding height in cm. Reported for participants aged 2 years or older.\n\n\nBMI\ndbl\nBody mass index (weight/height2 in kg/m2). Reported for participants aged 2 years or older\n\n\nPulse\nint\n60 second pulse rate\n\n\nBPSysAve\nint\nCombined systolic blood pressure reading, following the # procedure outlined for BPXSAR\n\n\nBPDiaAve\nint\nCombined diastolic blood pressure reading, following the # procedure outlined for BPXDAR\n\n\nDirectChol\ndbl\nDirect HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nTotChol\ndbl\nTotal HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nDiabetes\nchr\nStudy participant told by a doctor or health professional that they have diabetes\n\n\nHealthGen\nchr\nSelf-reported rating of health: Excellent, Vgood, Good, Fair, or Poor Fair\n\n\nPhysActive\nchr\nParticipant does moderate or vigorous-intensity sports, fitness or recreational activities (Yes or No).\n\n\nSmokeNow\nchr\nStudy participant currently smokes cigarettes regularly. (Yes or No)\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-collider",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-collider",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with collider\n",
    "text": "DAG with collider\n\n\n\n# df DAG \ndag_collid &lt;- ggdag::dagify( Y ~ X + e, Z ~ X + Y, \n                      exposure = \"X\",outcome = \"Y\", #latent = \"e\",\n                      # labels\n                      labels = c(\"Z\" = \"Collider\",  \"X\" = \"Exposure\",\n                                 \"Y\" = \"Outcome\", \"e\" = \"Unobserved \\nerror\"),\n                      # positions\n                      coords = list(\n                        x = c(X = 0, Y= 4, Z = 2 , e = 5),\n                        y = c(X = 0, Y = 0, Z = 2, e = 1) \n                      )) %&gt;% \n  ggdag::tidy_dagitty() \n\n# Plot DAG \ndag_col_p &lt;-  dag_collid %&gt;% \n  ggdag::ggdag(., layout = \"circle\") +  # decided in dagify\n  theme_dag_blank(plot.caption = element_text(hjust = 1)) +\n  # Nodes \n   ggdag::geom_dag_node(aes(color = name)) +  \n  # Labels dodged to avoid overlap\n   ggdag::geom_dag_label(aes(label = label), color = \"#4c4c4c\", nudge_x = 0.7, nudge_y = 0.2) +  \n  \n   ggdag::geom_dag_text(color=\"white\") +\n   ggplot2::labs(title = \"Causal map with COLLIDER (Z)\" , \n       #subtitle = \"X = exposure, Y = outcome, Z = collider, e = random error\", \n       caption = ) +\n  # Map colors to specific nodes\n   ggplot2::scale_color_manual(values = c(\"X\" = \"#9b6723\", \"Y\" = \"#72aed8\", \"Z\" = \"#d02e4c\",\n                                \"e\" = \"#A6A6A6\"), \n                     guide = \"none\")    # Remove legend\n\ndag_col_p"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-collider-output",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-collider-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with collider\n",
    "text": "DAG with collider"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-confounder",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-confounder",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with confounder\n",
    "text": "DAG with confounder\n\n\n\n# df DAG \ndag_confounder &lt;- ggdag::dagify(Y ~ X + Z + e, X ~  Z, \n                                exposure = \"X\", outcome = \"Y\", #latent = \"e\",\n                                # labels\n                                labels = c(\n                                  \"Z\" = \"Confounder\",\n                                  \"X\" = \"Exposure\",\n                                  \"Y\" = \"Outcome\",\n                                  \"e\" = \"Unobserved \\nerror\"),\n                                # positions\n                                coords = list(\n                                  x = c(X = 0, Y= 4, Z = 2 , e = 5),\n                                  y = c(X = 0, Y = 0, Z = 2, e = 1) \n                                )) %&gt;% \n  ggdag::tidy_dagitty()     # Add edge_type within pipe\n\n# Plot DAG \ndag_conf_p &lt;- dag_confounder %&gt;% \n  ggdag::ggdag(., layout = \"circle\") + \n  ggdag::theme_dag_blank(plot.caption = element_text(hjust = 1)) +\n  # Nodes \n  ggdag::geom_dag_node(aes(color = name)) +  \n  # Labels dodged to avoid overlap\n  ggdag::geom_dag_label(aes(label = label), color = \"#4c4c4c\", nudge_x = 0.7, nudge_y = 0.2) +  \n  ggdag::geom_dag_text(color=\"white\") +\n  ggplot2::labs(title = \"Causal map with CONFOUNDER (Z)\" , #subtitle = \" \",\n        caption = ) +\n  # Map colors to specific nodes\n  ggplot2::scale_color_manual(values = c(\"X\" = \"#9b6723\", \"Y\" = \"#72aed8\", \"Z\" = \"#d02e4c\",\n                                \"e\" = \"#A6A6A6\"), \n                     guide = \"none\")   \ndag_conf_p"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-confounder-output",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-confounder-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with confounder\n",
    "text": "DAG with confounder"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-mediator",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-mediator",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with mediator\n",
    "text": "DAG with mediator\n\n\n\n# df DAG \ndag_med &lt;- ggdag::dagify( Y ~ Z + e,  Z ~ X, exposure = \"X\", outcome = \"Y\",  #latent = \"e\",\n                   # labels\n                   labels = c(\n                     \"Z\" = \"Mediator\",\n                     \"X\" = \"Exposure\",\n                     \"Y\" = \"Outcome\",\n                     \"e\" = \"Unobserved \\nerror\"),\n                   # positions\n                   coords = list(\n                     x = c(X = 0, Y= 4, Z = 2 , e = 5),\n                     y = c(X = 0, Y = 0, Z = 2, e = 1) \n                   )) %&gt;% \n  ggdag::tidy_dagitty()     # Add edge_type within pipe\n\n# Plot DAG \ndag_med_p &lt;-  dag_med %&gt;% \n  ggdag::ggdag(., layout = \"circle\") +  # decided in dagify\n  ggdag::theme_dag_blank(plot.caption = element_text(hjust = 1)) +\n  # Nodes \n  ggdag::geom_dag_node(aes(color = name)) +  \n  # Labels dodged to avoid overlap\n  ggdag::geom_dag_label(aes(label = label), color = \"#4c4c4c\", nudge_x = 0.7, nudge_y = 0.2) +  \n  \n  ggdag::geom_dag_text(color=\"white\") +\n  ggplot2::labs(title = \"Causal map with MEDIATOR (Z)\" , \n       #subtitle = \"X = exposure, Y = outcome, Z = collider, e = random error\", \n       caption = ) +\n  # Map colors to specific nodes\n  ggplot2::scale_color_manual(values = c(\"X\" = \"#9b6723\", \"Y\" = \"#72aed8\", \"Z\" = \"#d02e4c\",\n                                \"e\" = \"#A6A6A6\"), guide = \"none\")    # Remove legend\ndag_med_p"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-mediator-output",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-mediator-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with mediator\n",
    "text": "DAG with mediator"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-confounder-1",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-confounder-1",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with confounder\n",
    "text": "DAG with confounder\n\n\n\nZ = Age = confounder\nX = SmokeNow\nY = BPSysAve (blood pressure)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#example-of-confounder",
    "href": "practice/practice_slides/slides_lab04.html#example-of-confounder",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Example of CONFOUNDER",
    "text": "Example of CONFOUNDER\n\nZ = Age = confounder for the relationship between X = SmokeNow and Y = BPSysAve (blood pressure)\n\n\ndata(NHANES)\n# Select relevant columns and drop rows with missing values\nnhanes_conf &lt;- NHANES %&gt;%\n  dplyr::select(ID, Age, SmokeNow, BPSysAve) %&gt;%\n  tidyr::drop_na()\n  \n# Take a quick look at the data\npaint::paint(nhanes_conf)\n\ntibble [3108, 4]\nID       int 51624 51624 51624 51630 51654 51666\nAge      int 34 34 34 49 66 58\nSmokeNow fct No No No Yes No Yes\nBPSysAve int 113 113 113 112 111 127\n\n\nIn this context:\n\n\nAge influences both smoking (SmokeNow) and blood pressure (BPSysAve), making it a confounder.\n\n\nSmokeNow directly affects BPSysAve."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#visualisation-of-confounder",
    "href": "practice/practice_slides/slides_lab04.html#visualisation-of-confounder",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Visualisation of CONFOUNDER",
    "text": "Visualisation of CONFOUNDER\n\n# Scatterplot of Age and Blood Pressure by Smoking Status\nggplot2::ggplot(nhanes_conf, aes(x = Age, y = BPSysAve, color = SmokeNow)) +\n  geom_point(alpha = 0.6) +\n  # linear rel \n  geom_smooth(method = \"lm\", se = FALSE,  size = 1.5,  linetype = \"dashed\", color = \"black\") +\n  scale_color_manual(\n    values = c(\"No\" = \"#1b9e77\", \"Yes\" = \"#d95f02\")) +\n  facet_wrap(~ SmokeNow) + \n  labs(\n    title = \"Scatterplot of Age and Blood Pressure by Smoking Status\",\n    x = \"Age\",\n    y = \"Blood Pressure (mmHg)\",\n    color = \"Smokers\"\n  )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#visualisation-of-confounder-output",
    "href": "practice/practice_slides/slides_lab04.html#visualisation-of-confounder-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Visualisation of CONFOUNDER",
    "text": "Visualisation of CONFOUNDER"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#regression-analysis-controlling-for-the-confounder",
    "href": "practice/practice_slides/slides_lab04.html#regression-analysis-controlling-for-the-confounder",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Regression analysis: controlling for the confounder",
    "text": "Regression analysis: controlling for the confounder\nUnadjusted model:\n\n# Unadjusted linear model \nmodel_unadjusted &lt;- lm(BPSysAve ~ SmokeNow, data = nhanes_conf)\nsummary(model_unadjusted)$coefficients\n\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   124.38      0.432  287.97  0.0e+00\nSmokeNowYes    -4.26      0.643   -6.64  3.8e-11\n\n\nAdjusted model:\n\nincludes the confounder Age in the model\n\n\n# Adjusted model\nmodel_adjusted &lt;- lm(BPSysAve ~ SmokeNow + Age, data = nhanes_conf)\nsummary(model_adjusted)$coefficients\n\n            Estimate Std. Error t value  Pr(&gt;|t|)\n(Intercept)  100.997     1.0886   92.78  0.00e+00\nSmokeNowYes    0.684     0.6313    1.08  2.79e-01\nAge            0.432     0.0187   23.09 5.19e-109"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#compare-models-without-and-with-confounder",
    "href": "practice/practice_slides/slides_lab04.html#compare-models-without-and-with-confounder",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Compare models (without and with confounder)",
    "text": "Compare models (without and with confounder)\n\n\nIn the Unadjusted Model any observed relationship between smoking and blood pressure might be confounded.\nIn the Adjusted Model (which ‚Äòcontrols for‚Äô Age) a more accurate estimate of the causal effect of smoking (SmokeNowYes) on blood pressure (BPSysAve) accounts for the confounding influence of Age.\n\n\n\n# Create the table with a custom statistic formatter\nconf_sum &lt;- modelsummary::msummary(\n  list(\n    \"NO Confounder\" = model_unadjusted, \n    \"Confounder\" = model_adjusted\n  ),\n  output = \"gt\",\n  statistic = c(\n    \"conf.int\",\n    \"s.e. = {std.error}\"\n  ), \n  fmt = \"%.3f\", \n  gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC|RMSE',\n  stars = c('*' = .05, '**' = .01)\n)\n\n# Render the table directly\nconf_sum  %&gt;%    # text and background color\n  tab_style(\n    style = cell_text(weight = \"bold\", color = \"#005ca1\"),\n    locations = cells_column_labels(\n      columns = c(\"NO Confounder\", \"Confounder\"))) %&gt;% \n  tab_style(style = cell_text(weight = \"bold\"),\n            locations = cells_body(rows = c(1,4,7))) %&gt;% \n  tab_style(style = cell_fill(color = 'lightblue'),\n            locations = cells_body(rows = 4:5)) %&gt;% \n  # Make 'Age' font color red\n  tab_style(style = cell_text(color = \"#d02e4c\"),\n    locations = cells_body(rows = c(7,8,9))\n  )\n\n\n\n\n\n\n\n\nNO Confounder\nConfounder\n\n\n\n(Intercept)\n124.384**\n100.997**\n\n\n\n[123.537, 125.231]\n[98.863, 103.131]\n\n\n\ns.e. = 0.432\ns.e. = 1.089\n\n\nSmokeNowYes\n-4.264**\n0.684\n\n\n\n[-5.524, -3.004]\n[-0.554, 1.922]\n\n\n\ns.e. = 0.643\ns.e. = 0.631\n\n\nAge\n\n0.432**\n\n\n\n\n[0.395, 0.468]\n\n\n\n\ns.e. = 0.019\n\n\nNum.Obs.\n3108\n3108\n\n\nR2\n0.014\n0.158\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#compare-predicted-values-from-2-models",
    "href": "practice/practice_slides/slides_lab04.html#compare-predicted-values-from-2-models",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Compare predicted values from 2 models",
    "text": "Compare predicted values from 2 models\n\n\nWith tidyr::pivot_longer() we reshape the dataset so we can plot the predicted values from both models in a faceted plot.\n\n\n# Add predicted values from the unadjusted and adjusted models\nnhanes_conf &lt;- nhanes_conf %&gt;%\n  dplyr::mutate(\n    pred_unadjusted = predict(model_unadjusted),  # Predicted BPSysAve from unadjusted model\n    pred_adjusted = predict(model_adjusted)       # Predicted BPSysAve from adjusted model\n  )\n\n# Reshape the data into long format using pivot_longer()\nnhanes_long &lt;- nhanes_conf %&gt;%\n  tidyr::pivot_longer(cols = c(pred_unadjusted, pred_adjusted), \n               names_to = \"model\", values_to = \"predicted\") %&gt;%\n  dplyr::mutate(model = recode(model, \n                        pred_unadjusted = \"Unadjusted: SmokeNow on BPSysAve\", \n                        pred_adjusted = \"Adjusted: SmokeNow + Age on BPSysAve\")) %&gt;% \n  #Reorder the 'model' factor to change the order of the facets\n  dplyr::mutate(model = factor(\n   model,   levels = c(\"Unadjusted: SmokeNow on BPSysAve\", \"Adjusted: SmokeNow + Age on BPSysAve\")\n))\n\n\ncheck the df new size\n\n\ndim(nhanes_conf)\n\n[1] 3108    6\n\ndim(nhanes_long)\n\n[1] 6216    6"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#plot-predicted-values-from-2-models",
    "href": "practice/practice_slides/slides_lab04.html#plot-predicted-values-from-2-models",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Plot predicted values from 2 models",
    "text": "Plot predicted values from 2 models\n\n\n\nUsing nhanes_long df in ‚Äúlong shape‚Äù\n\n\n# Violin plot with dashed line connecting the two conditions\nggplot(nhanes_long, aes(x = factor(SmokeNow), y = BPSysAve, fill = model)) +\n  # Create the violin plot to show the distribution of blood pressure\n  geom_point(color = \"grey\", alpha = 0.4, position = position_dodge(width = 0.3) ) +\n  # Overlay the predicted dashed line between the two smoking conditions\n  geom_line(aes(y = predicted, group = model, color = model), \n            size = 0.8, linetype = \"dashed\", position = position_dodge(width = 0.3)) +\n  # Facet vertically for unadjusted and adjusted models\n  facet_wrap(model ~ ., scales = \"free_y\",ncol = 2) +\n  # Add labels and title\n  labs(title = \"Confounder Analysis: Predicted values in Unadjusted vs Adjusted Regression models\",\n       subtitle = \"Age = Confounder\",\n       x = \"Smoking Status\",\n       y = \"Systolic Blood Pressure (BPSysAve)\",\n       color = \"Model\",\n       fill = \"Model\"\n       ) +\n  # Customize colors for better contrast\n  scale_fill_manual(values = c(\"Unadjusted: SmokeNow on BPSysAve\" =\"lightcoral\" , \n                               \"Adjusted: SmokeNow + Age on BPSysAve\" = \"lightblue\")) +\n  scale_color_manual(values = c(\"Unadjusted: SmokeNow on BPSysAve\" = \"red\", \n                                \"Adjusted: SmokeNow + Age on BPSysAve\" = \"blue\")) +\n  # Minimal theme for clarity\n  theme_minimal()+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#plot-predicted-values-from-2-models-output",
    "href": "practice/practice_slides/slides_lab04.html#plot-predicted-values-from-2-models-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Plot predicted values from 2 models",
    "text": "Plot predicted values from 2 models\n\n\n\n\n\n\nFigure¬†1: As age causes high blood pressure, but also determines smoking status, the Adjusted model (right) gives us a more credible relationship between smoking and blood pressure."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dag-with-mediator-1",
    "href": "practice/practice_slides/slides_lab04.html#dag-with-mediator-1",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "DAG with mediator\n",
    "text": "DAG with mediator\n\n\n\nM = BMI is a mediator\nX = PhysActiveDays\nY = BPSysAve (blood pressure)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#fitting-unadjusted-total-model",
    "href": "practice/practice_slides/slides_lab04.html#fitting-unadjusted-total-model",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Fitting unadjusted (total) model",
    "text": "Fitting unadjusted (total) model\n\nBefore adjusting for any mediator, we fit a simple linear model to estimate the total effect of PhysActiveDays on Systolic Blood Pressure (disregarding any possible mediation of BMI).\n\n\nTotal Effect Model (Unadjusted)\n\nThis model gives the total effect of of PhysActiveDays on Systolic Blood Pressure (including any indirect effects through M = BMI or other variables that haven‚Äôt been included.)\n\n\n\n\n# Unadjusted model: total effect of smoking on blood pressure\ntotal_effect_model &lt;- lm(BPSysAve ~ PhysActiveDays, data = nhanes_med)\nsummary(total_effect_model)$coefficients\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)      120.12      1.055  113.88   0.0000\nPhysActiveDays     0.59      0.262    2.25   0.0246"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#set-up-the-mediation-models-12",
    "href": "practice/practice_slides/slides_lab04.html#set-up-the-mediation-models-12",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Set up the mediation models 1/2",
    "text": "Set up the mediation models 1/2\n\nThen, we fit the model to estimate the effect of X = PhysActiveDays on M = BMI:\n\n\nMediator model\n\nThis model allows us to see whether more physically active days are associated with (lower) BMI values (which could then affect blood pressure).\n\n\n\n\n# Mediator model: SmokeNow affects BMI\nmediator_model &lt;- lm(BMI ~ PhysActiveDays, data = nhanes_med)\nsummary(mediator_model)$coefficients\n\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     28.2176     0.3444  81.934    0.000\nPhysActiveDays  -0.0821     0.0856  -0.959    0.338"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#set-up-the-mediation-models-22",
    "href": "practice/practice_slides/slides_lab04.html#set-up-the-mediation-models-22",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Set up the mediation models 2/2",
    "text": "Set up the mediation models 2/2\n\nLastly, we fit the model to estimate the effect of X = PhysActiveDays on Y = BPSysAve while adjusting for M = BMI:\n\n\nOutcome Model (Adjusted for BMI)\n\nThis model estimates the effect of PhysActiveDays and BMI on Systolic Blood Pressure (BPSysAve). This is the adjusted model.\n\n\n\n\n# Outcome model: PhysActiveDays and BMI affect BPSysAve\noutcome_model &lt;- lm(BPSysAve ~  PhysActiveDays + BMI, data = nhanes_med)\nsummary(outcome_model)$coefficients\n\n               Estimate Std. Error t value  Pr(&gt;|t|)\n(Intercept)     109.353     2.4763   44.16 3.15e-271\nPhysActiveDays    0.621     0.2603    2.39  1.71e-02\nBMI               0.382     0.0795    4.80  1.77e-06"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#compare-3-models",
    "href": "practice/practice_slides/slides_lab04.html#compare-3-models",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Compare 3 models",
    "text": "Compare 3 models\n\n\nThe Total (unadjusted) effect model estimates the effect of PhysActiveDays on BPSysAve.\nThe Mediator model estimates the effect of PhysActiveDays on BMI (M).\nThe Outcome model estimates the effect of (PhysActiveDays + BMI) on BPSysAve.\n\n\nmed_sum &lt;- modelsummary::msummary(\n  list(\"BPSysAve ~ Total Effect\" = total_effect_model,\n       \"BMI ~ Mediator Effect\" = mediator_model,\n       \"BPSysAve ~ Outcome\" = outcome_model), \n  output = \"gt\",\n  statistic = c(\n    \"conf.int\",\n    \"s.e. ={std.error}\"),\n  fmt = \"%.3f\", # format\n  gof_omit = 'DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC|RMSE',\n  stars = c('*' = .05, '**' = .01))\n\n# Render the table\nmed_sum %&gt;% \n  tab_spanner(label = \"Tot (unadj) Mod.\",columns = 2) %&gt;%\n  tab_spanner(label = \"Med Mod.\", columns = 3) %&gt;%\n  tab_spanner(label = \"Outcome Mod.\",columns = 4) %&gt;%\n   tab_style(\n    style = cell_text(weight = \"bold\", color = \"#7f173d\"),\n    locations = cells_column_labels(columns = 3)) %&gt;% \n  tab_style(\n    style = cell_text(weight = \"bold\", color = \"#005ca1\"),\n    locations = cells_column_labels(columns = c(2,4))) %&gt;% \n  tab_style(style = cell_text(weight = \"bold\"),\n            locations = cells_body(rows = c(1,4,7))) %&gt;% \n  # Highlight X \n   tab_style(style = cell_fill(color = 'lightblue'),\n            locations = cells_body(rows = 4:6)) %&gt;% \n  # Make 'MEdiator' font color red\n  tab_style(style = cell_text(color = \"#d02e4c\"),\n    locations = cells_body(rows = 7:9))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#compare-3-models-output",
    "href": "practice/practice_slides/slides_lab04.html#compare-3-models-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Compare 3 models",
    "text": "Compare 3 models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTot (unadj) Mod.\n\n\nMed Mod.\n\n\nOutcome Mod.\n\n\n\nBPSysAve ~ Total Effect\nBMI ~ Mediator Effect\nBPSysAve ~ Outcome\n\n\n\n\n(Intercept)\n120.120**\n28.218**\n109.353**\n\n\n\n[118.051, 122.189]\n[27.542, 28.893]\n[104.495, 114.210]\n\n\n\ns.e. =1.055\ns.e. =0.344\ns.e. =2.476\n\n\nPhysActiveDays\n0.590*\n-0.082\n0.621*\n\n\n\n[0.076, 1.104]\n[-0.250, 0.086]\n[0.111, 1.132]\n\n\n\ns.e. =0.262\ns.e. =0.086\ns.e. =0.260\n\n\nBMI\n\n\n0.382**\n\n\n\n\n\n[0.226, 0.538]\n\n\n\n\n\ns.e. =0.080\n\n\nNum.Obs.\n1463\n1463\n1463\n\n\nR2\n0.003\n0.001\n0.019\n\n\n\n* p &lt; 0.05, ** p &lt; 0.01"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#calculate-the-indirect-direct-and-total-effects-12",
    "href": "practice/practice_slides/slides_lab04.html#calculate-the-indirect-direct-and-total-effects-12",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Calculate the Indirect, Direct, and Total Effects (1/2)",
    "text": "Calculate the Indirect, Direct, and Total Effects (1/2)\nUsing the coefficients from the models, we can calculate the mediation effects manually.\n\n\nDirect Effect: This is the coefficient of PhysActiveDays in the outcome model, which gives the direct effect of exercise on blood pressure (controlling for BMI = M)\n\nIndirect Effect: This is the product of the coefficient from the mediator model (PhysActiveDays ‚Üí BMI) and the coefficient from the outcome model (BMI ‚Üí BPSysAve).\n\nTotal Effect: This is the coefficient of PhysActiveDays in the unadjusted model (NOT controlling for BMI = M)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#calculate-the-indirect-direct-and-total-effects-22",
    "href": "practice/practice_slides/slides_lab04.html#calculate-the-indirect-direct-and-total-effects-22",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Calculate the Indirect, Direct, and Total Effects (2/2)",
    "text": "Calculate the Indirect, Direct, and Total Effects (2/2)\n\nBreakdown of the estimated effects:\n\n# TOTAL effect: The effect of PhysActiveDays on BPSysAve without adjusting for BMI\ntotal_effect &lt;- coef(total_effect_model)[\"PhysActiveDays\"]# 0.59\ntotal_effect\n\nPhysActiveDays \n          0.59 \n\n# DIRECT effect: The effect of PhysActiveDays on BPSysAve after adjusting for BMI.\ndirect_effect &lt;- coef(outcome_model)[\"PhysActiveDays\"]# 0.621 \ndirect_effect\n\nPhysActiveDays \n         0.621 \n\n# Indirect effect: The portion of the effect on BPSysAve that is mediated through BMI\nindirect_effect &lt;- coef(mediator_model)[\"PhysActiveDays\"] * coef(outcome_model)[\"BMI\"] # [-0.0821 X 0.382]  \nindirect_effect\n\nPhysActiveDays \n       -0.0313 \n\n# Proportion mediated: The proportion of the total effect that is mediated through BMI\nproportion_mediated &lt;- glue::glue(\"{round(indirect_effect / total_effect *100, 2)}%\")\nproportion_mediated #  -0.0531\n\n-5.31%"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#visualise-the-indirect-direct-and-total-effects",
    "href": "practice/practice_slides/slides_lab04.html#visualise-the-indirect-direct-and-total-effects",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Visualise the Indirect, Direct, and Total Effects",
    "text": "Visualise the Indirect, Direct, and Total Effects\n\n\n\n# Create a data frame for the effects\neffects_df &lt;- data.frame(\n  Effect = c(\"Total Effect\", \"Direct Effect\", \n             \"Indirect Effect\"),\n  Value = c(total_effect, direct_effect, \n            indirect_effect)\n)\n\n# Create the bar plot\nggplot(effects_df, aes(x = Effect, y = Value,\n                       fill = Effect)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Mediation Analysis: Total, Direct, and Indirect Effects\", \n       subtitle = \"Effect (coefficient) of Physical Activity on Systolic Blood Pressure\",\n       y = \"\", x = \"\") +\n  theme_minimal()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#visualise-the-indirect-direct-and-total-effects-output",
    "href": "practice/practice_slides/slides_lab04.html#visualise-the-indirect-direct-and-total-effects-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Visualise the Indirect, Direct, and Total Effects",
    "text": "Visualise the Indirect, Direct, and Total Effects"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#interpreting-the-results",
    "href": "practice/practice_slides/slides_lab04.html#interpreting-the-results",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Interpreting the results",
    "text": "Interpreting the results\n\nThe total effect tells us the overall relationship between PhysActiveDays and BPSysAve.\nThe direct effect represents the relationship between PhysActiveDays and BPSysAve, controlling for BMI.\nThe indirect effect (mediated effect) shows how much of the relationship between PhysActiveDays and BPSysAve is explained through BMI (AKA the coef of PhysActiveDays in the mediator model times the coef of BMI in the outcome model)\nThe proportion mediated indicates how much of the total effect is due to the mediation by BMI."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#using-mediation-package",
    "href": "practice/practice_slides/slides_lab04.html#using-mediation-package",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Using mediation package",
    "text": "Using mediation package\n\nThe mediation package can be used to estimate various quantities for causal mediation analysis\n\nThe function mediate() needs two regression models: 1) \\((X ‚Üí M)\\), and 2) \\((X + M ‚Üí Y)\\)\n\nIt returns\n\nthe average causal mediation effect (ACME),\naverage direct effect (ADE),\nand total effect.\n\n\n\n\n# recall\n#mediator_model[[\"call\"]][[\"formula\"]]\n#outcome_model[[\"call\"]][[\"formula\"]]\n\n# Calculate the mediation effect\nmediation_model &lt;- mediate(mediator_model, outcome_model, \n                           treat = \"PhysActiveDays\", \n                           mediator = \"BMI\", \n                           boot=TRUE, sims=500)\n\nsummary(mediation_model)$d1  # Direct effect\n\n[1] -0.0313\n\nsummary(mediation_model)$z1  # Indirect effect\n\n[1] 0.621\n\nsummary(mediation_model)$tau.coef  # Total effect\n\n[1] 0.59"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#using-mediation-pckg---results",
    "href": "practice/practice_slides/slides_lab04.html#using-mediation-pckg---results",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Using mediation pckg - results",
    "text": "Using mediation pckg - results\n\nsummary(mediation_model)\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value  \nACME            -0.0313      -0.1067         0.03   0.256  \nADE              0.6213       0.1246         1.16   0.016 *\nTotal Effect     0.5899       0.0576         1.10   0.020 *\nProp. Mediated  -0.0531      -0.5263         0.06   0.276  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 1463 \n\n\nSimulations: 500"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#using-mediation-pckg---prediction",
    "href": "practice/practice_slides/slides_lab04.html#using-mediation-pckg---prediction",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Using mediation pckg - prediction",
    "text": "Using mediation pckg - prediction\n\n\n# Add predicted values for BMI, BPSysAve (adjusted), and BPSysAve (total effect)\nnhanes_med_pred &lt;- nhanes_med %&gt;%\n  mutate(\n    pred_bmi = predict(mediator_model),         # Predicted BMI (mediator model)\n    pred_bps_adj = predict(outcome_model),      # Predicted BPSysAve (adjusted for Age)\n    pred_bps_total = predict(total_effect_model) # Predicted BPSysAve (total effect)\n  )\n\nnhanes_med_pred[1:3, c(1:2, 8:10)]\n\n# A tibble: 3 √ó 5\n  Gender   Age pred_bmi pred_bps_adj pred_bps_total\n  &lt;fct&gt;  &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n1 male      66     27.6         123.           124.\n2 female    58     28.1         121.           121.\n3 female    57     28.0         119.           122."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#plot-prediction-results-12",
    "href": "practice/practice_slides/slides_lab04.html#plot-prediction-results-12",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Plot prediction results 1/2",
    "text": "Plot prediction results 1/2\nNow, let‚Äôs create a plot that includes:\n\nThe total effect of BMI on blood pressure (without adjusting for Age).\nThe adjusted effect of BMI on blood pressure (controlling for Age).\nThe mediator effect (BMI‚Äôs effect on Age).\n\n\n# Check column names\ncolnames(nhanes_med_pred)\n\n [1] \"Gender\"         \"Age\"            \"BPSysAve\"       \"BMI\"           \n [5] \"PhysActiveDays\" \"Diabetes\"       \"SmokeNow\"       \"pred_bmi\"      \n [9] \"pred_bps_adj\"   \"pred_bps_total\"\n\n# Reshape the data into long format for faceting\nnhanes_long &lt;- nhanes_med_pred %&gt;%\n  gather(key = \"model\", value = \"predicted\",  pred_bps_adj, pred_bps_total) %&gt;%\n  mutate(model = recode(model, \n                        #pred_bmi = \"Mediator Effect: BPSysAve on BMI\", \n                        pred_bps_adj = \"Adj. Effect: PhysActiveDays + BMI on BPSysAve\", \n                        pred_bps_total = \"Total Effect: PhysActiveDays on BPSysAve\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#plot-prediction-results-22",
    "href": "practice/practice_slides/slides_lab04.html#plot-prediction-results-22",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Plot prediction results 2/2",
    "text": "Plot prediction results 2/2\n\n# Plot with vertically aligned facets\nggplot(nhanes_long, aes(x = BMI)) +\n  # Actual data points for BPSysAve\n  geom_point(aes(y = BPSysAve), color = \"black\", shape = 16, alpha = 0.5) +  \n  # Predicted values from different models\n  geom_line(aes(y = predicted, color = model), size = 1) +  \n  # Facet vertically\n  facet_grid(model ~ ., scales = \"free_y\") +  \n  labs(title = \"Mediation Analysis: Total, Adjusted, and Mediator Effects\",\n       x = \"BMI\",\n       y = \"Blood Pressure | Age\",\n       color = \"Effect Type\") +\n  theme_minimal()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#plot-prediction-results-22-output",
    "href": "practice/practice_slides/slides_lab04.html#plot-prediction-results-22-output",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Plot prediction results 2/2",
    "text": "Plot prediction results 2/2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#establishing-some-common-symbols",
    "href": "practice/practice_slides/slides_lab04.html#establishing-some-common-symbols",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Establishing some common symbols",
    "text": "Establishing some common symbols\n\n\n\\(X\\) = treatment or intervention\n\n\\(Y^1\\) = potential outcome if treated\n\n\\(Y^0\\) = potential outcome if not treated\n\n\\(\\delta\\) = difference \\((Y^1 - Y^0)\\), or the individual-level causal effect."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#example-with-toy-case",
    "href": "practice/practice_slides/slides_lab04.html#example-with-toy-case",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "EXAMPLE with toy case",
    "text": "EXAMPLE with toy case\nAssuming we could observe the potential outcomes for each individual:\n\nbasic_po &lt;- tribble(\n  ~id, ~age,    ~treated, ~outcome_1, ~outcome_0,\n  1,   \"Old\",   1,        80,         60,\n  2,   \"Old\",   1,        75,         70,\n  3,   \"Old\",   1,        85,         80,\n  4,   \"Old\",   0,        70,         60,\n  5,   \"Young\", 1,        75,         70,\n  6,   \"Young\", 0,        80,         80,\n  7,   \"Young\", 0,        90,         100,\n  8,   \"Young\", 0,        85,         80\n) |&gt; \n  dplyr::mutate(\n    ice = outcome_1 - outcome_0,\n    outcome = ifelse(treated == 1, outcome_1, outcome_0)\n  )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#ite-in-toy-example-example-all-outcomes",
    "href": "practice/practice_slides/slides_lab04.html#ite-in-toy-example-example-all-outcomes",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "ITE in toy example example (all outcomes!)",
    "text": "ITE in toy example example (all outcomes!)\n\n\nEach person (ID) has two potential outcomes and an individual causal effect (\\(ITE_i= Y_{i}^1  ‚àí Y_{i}^0\\) = \\(\\delta_i\\)).\n\n\\(\\delta_i\\) would in fact be measurable only with 2 parallel universes!\n\n\n\n\n\nTable¬†1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfounder\n\n\nTreatment\n\n\nUnobservable\n\n\nRealized\n\n\n\nID\n\nAge\n\n\nTreated\n\n\nPotential outcomes\n\n\nITE or \\(\\delta_i\\)\n\n\nOutcome\n\n\n\n\\[Z_i\\]\n\\[X_i\\]\n\\[Y^1_i\\]\n\\[Y^0_i\\]\n\\[Y^1_i - Y^0_i\\]\n\\[Y_i\\]\n\n\n\n\n1\nOld\n1\n80\n60\n20\n80\n\n\n2\nOld\n1\n75\n70\n5\n75\n\n\n3\nOld\n1\n85\n80\n5\n85\n\n\n4\nOld\n0\n70\n60\n10\n60\n\n\n5\nYoung\n1\n75\n70\n5\n75\n\n\n6\nYoung\n0\n80\n80\n0\n80\n\n\n7\nYoung\n0\n90\n100\n‚àí10\n100\n\n\n8\nYoung\n0\n85\n80\n5\n80"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#ate-average-treatment-effect",
    "href": "practice/practice_slides/slides_lab04.html#ate-average-treatment-effect",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "ATE = Average Treatment Effect",
    "text": "ATE = Average Treatment Effect\nIf we could compare all the same people in different universes and measure their ITE, we could calculate the Average Treatment Effect (ATE), or the effect of the intervention across the whole population.\n\n\\[\n\\begin{aligned}\n\\text{ATE} &= E[\\delta_i] & \\text{ or} \\\\\n\\text{ATE} &= E[Y^1_i - Y^0_i]\n\\end{aligned}\n\\]\nGiven the data of the \\(\\delta\\) column in Table¬†1, the ATE is 5.\n\\[\n\\text{ATE} = \\frac{20 + 5 + 5 + 5 + 10 + 0 + -10 + 5}{8} = 5\n\\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#att-average-treatment-effect-on-treated",
    "href": "practice/practice_slides/slides_lab04.html#att-average-treatment-effect-on-treated",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "ATT = Average Treatment Effect on Treated",
    "text": "ATT = Average Treatment Effect on Treated\nWe might want to know how big the effect is just for those who received the treatment.\nThis is called the Average Treatment effect on the Treated (ATT), and is the average of the individual causal effects just among those who were treated.\n\\[\n\\begin{aligned}\n\\text{ATT} &= E[\\delta_i \\mid X_i = 1] & \\text{or} \\\\\n\\text{ATT} &= E[Y^1_i - Y^0_i \\mid X_i = 1]\n\\end{aligned}\n\\]\nIn this case, that means we‚Äôre only looking at the average \\(\\delta\\) for rows 1, 2, 3, and 5 in Table¬†1:\n\\[\n\\text{ATT} = \\frac{20 + 5 + 5 + 5}{4} = 8.75\n\\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#atu-average-treatment-effect-on-untreated",
    "href": "practice/practice_slides/slides_lab04.html#atu-average-treatment-effect-on-untreated",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "ATU = Average Treatment Effect on Untreated",
    "text": "ATU = Average Treatment Effect on Untreated\nWe can also calculate the Average Treatment effect on the Untreated (ATU; sometimes called the ATC (for effect on the control group)) by finding the average of the individual causal effects among those who were not treated.\n\\[\n\\begin{aligned}\n\\text{ATU} &= E[\\delta_i \\mid X_i = 0] & \\text{or} \\\\\n\\text{ATU} &= E[Y^1_i - Y^0_i \\mid X_i = 0]\n\\end{aligned}\n\\]\nHere, we‚Äôre only looking at the average \\(\\delta\\) for rows 4, 6, 7, and 8 in Table¬†1:\n\\[\n\\text{ATU} = \\frac{10 + 0 - 10 + 5}{4} = 1.25\n\\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu",
    "href": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Relation among ATE, ATT and ATU",
    "text": "Relation among ATE, ATT and ATU\nIn fact, the ATE is technically a weighted average of the ATT and the ATU (here \\(\\pi\\) indicates ‚Äúproportion‚Äù):\n\\[\n\\text{ATE} = (\\pi_\\text{Treated} \\times \\text{ATT}) + (\\pi_\\text{Untreated} \\times \\text{ATU})\n\\]\nIn our example, Table¬†1, we can get the same ATE:\n\\[\n\\begin{aligned}\n\\text{ATE} &= (\\frac{4}{8} \\times 8.75) + (\\frac{4}{8} \\times 1.25) \\\\\n&= 4.375 + 0.625 \\\\\n&= 5\n\\end{aligned}\n\\]\n\nDecomposing the ATE into these two parts like this shows that there‚Äôs some systematic difference between the treated and untreated people. This difference is called selection bias."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu-1",
    "href": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu-1",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Relation among ATE, ATT and ATU",
    "text": "Relation among ATE, ATT and ATU\nWe can see the selection bias in an alternative decomposition of the ATE:\n\\[\n\\text{ATE} = \\text{ATT} + \\text{Selection bias}\n\\]\n\nThe fact that the ATT (8.75) is bigger than the ATE (5) here is a sign the two groups are different. This intervention, whatever it is, has a big effect on the treated people who signed up for it, likely because they somehow knew that the intervention would be helpful for them.\n\n\nThose who were untreated have a really low ATU (1.25)‚Äîthey likely didn‚Äôt sign up for the intervention because they knew that it wouldn‚Äôt do much for them."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu-r",
    "href": "practice/practice_slides/slides_lab04.html#relation-among-ate-att-and-atu-r",
    "title": "Lab 4:Mapping causal & predictive approaches",
    "section": "Relation among ATE, ATT and ATU (R)",
    "text": "Relation among ATE, ATT and ATU (R)\n\n# OBTAIN ATT, ATU\neffect_types &lt;- basic_po |&gt; \n  dplyr::group_by(treated) |&gt; \n  dplyr::summarize(effect = mean(ice), n = n() ) |&gt; \n  dplyr::mutate(prop = n / sum(n),\n    weighted_effect = effect * prop) |&gt; \n  dplyr::mutate(estimand = case_match(treated, 0 ~ \"ATU\", 1 ~ \"ATT\"), .before = 1)\n\neffect_types\n\n# A tibble: 2 √ó 6\n  estimand treated effect     n  prop weighted_effect\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;           &lt;dbl&gt;\n1 ATU            0   1.25     4   0.5           0.625\n2 ATT            1   8.75     4   0.5           4.38 \n\n# OBTAIN ATE\neffect_types |&gt; dplyr::summarize(ATE = sum(weighted_effect))\n\n# A tibble: 1 √ó 1\n    ATE\n  &lt;dbl&gt;\n1     5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR 4 Statistics | 2025"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#topics-discussed-in-lecture-6",
    "href": "practice/practice_slides/slides_lab06.html#topics-discussed-in-lecture-6",
    "title": "Lab 6: Bonus practice materials",
    "section": "Topics discussed in Lecture # 6",
    "text": "Topics discussed in Lecture # 6\n\n\n\n\n\n\n\nIntroduction to MetaboAnalyst software\n\nA useful R-based resources for metabolomics\n\n\nElements of statistical Power Analysis"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab06.html#needed-r-packages",
    "title": "Lab 6: Bonus practice materials",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\n\n# --- General \nlibrary(here)     # tools find your project's files, based on working directory\nlibrary(dplyr)    # A Grammar of Data Manipulation\nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(magrittr) # A Forward-Pipe Operator for R \nlibrary(readr)    # A Forward-Pipe Operator for R \n\n# Plotting & data visualization\nlibrary(ggplot2)      # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(scatterplot3d) # 3D Scatter Plot\n\n# --- Statistics\nlibrary(MASS)       # Support Functions and Datasets for Venables and Ripley's MASS\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\nlibrary(FactoMineR) # Multivariate Exploratory Data Analysis and Data Mining\nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\n\n# --- Tidymodels (meta package)\nlibrary(rsample)    # General Resampling Infrastructure  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#sample-size-determination-in-inferential-statistics",
    "href": "practice/practice_slides/slides_lab06.html#sample-size-determination-in-inferential-statistics",
    "title": "Lab 6: Bonus practice materials",
    "section": "Sample Size determination in Inferential statistics",
    "text": "Sample Size determination in Inferential statistics\n\n\n\n\n‚ÄúOK, so how big of a sample do I need?‚Äù  ‚Ä¶the 1,000,000 $ question‚Äù! üôÄ"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#purpose-and-challenges-of-power-analysis",
    "href": "practice/practice_slides/slides_lab06.html#purpose-and-challenges-of-power-analysis",
    "title": "Lab 6: Bonus practice materials",
    "section": "Purpose and challenges of Power Analysis",
    "text": "Purpose and challenges of Power Analysis\n\n\n\nPower analysis helps with the key question How many observations/subjects do I need for my experiment? (= \\(n\\))\n\n\nToo small of a sample size can under detect the effect of interest in your experiment\n\nToo large of a sample size may lead to unnecessary wasting of resources\nWe strive to have just the sufficient number of observations needed to have a good chance of detecting the effect researched. (Even more so in a very time-consuming or expensive experiment.)\n\n\n\nWhen should we do power analysis?\n\n(Ideally), before the experiment: a priori power analysis allows to determine the necessary sample size \\(n\\) of a test, given a desired \\(\\alpha\\) level, a desired power level (\\(1- \\beta\\)), and the size of the effect to be detected (a measure of difference between \\(H_o\\) and \\(H_1\\))\nIn reality, sometimes you can only do post-hoc power analysis after the experiment, so the sample size \\(n\\) is already given.\n\nIn this case, given \\(n\\), \\(\\alpha\\), and a specified effect size, the analysis will return the power (\\(1- \\beta\\)) of the test, or \\(\\beta\\) (i.e.¬†the probability of Type II error = incorrectly retaining \\(H_o\\))."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#required-inputs-to-define-the-sample-size-n",
    "href": "practice/practice_slides/slides_lab06.html#required-inputs-to-define-the-sample-size-n",
    "title": "Lab 6: Bonus practice materials",
    "section": "Required inputs to define the sample size n",
    "text": "Required inputs to define the sample size n\n\n\nA specified effect size (i.e.¬†the minimum deviation from \\(H_o\\) that you hope to detect for a meaningful result)\n\nThe larger the effect size, the easier it is to detect an effect and require fewer obs\n\n\n\nAs \\(standard deviation\\) gets bigger, it is harder to detect a significant difference, so you‚Äôll need a bigger sample size.\n\n\n\n\n\\(\\alpha\\) is the significance level of the test (i.e.¬†the probability of incorrectly rejecting the null hypothesis (a false positive).\n\nUnderstanding if the test is one-tailed (difference has a direction) or two-tailed\n\n\n\n\\(\\beta\\) is the probability of accepting the null hypothesis, even though it is false (a false negative), when the real difference is equal to the minimum effect size.\n\n\n\\(1- \\beta\\) is the power of a test is the probability of correctly rejecting the null hypothesis (getting a significant result) when the real difference is equal to the minimum effect size.\n\na power of 80% (equivalent to a beta of 20%) is probably the most common, while some people use 50% or 90%"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#specifying-effect-size",
    "href": "practice/practice_slides/slides_lab06.html#specifying-effect-size",
    "title": "Lab 6: Bonus practice materials",
    "section": "Specifying effect size",
    "text": "Specifying effect size\n\nSo (since \\(\\alpha\\) and \\(1-\\beta\\) are normally set) the key piece of information we need is the effect size, which is essentially a function of the difference between the means of the null and alternative hypotheses over the variation (standard deviation) in the data.\n\nThe tricky part is that effect size is related to biological/practical significance rather than statistical significance\n\nHow should you estimate a meaningful Effect Size?\n\nUse preliminary information in the form of pilot study\nUse background information in the form of similar studies in the literature\n(With no prior information), make an estimated guess on the effect size expected (see guidelines next)\n\n\nMost R functions for sample size only allow you to enter effect size as input"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#specifying-effect-size-general-guidelines",
    "href": "practice/practice_slides/slides_lab06.html#specifying-effect-size-general-guidelines",
    "title": "Lab 6: Bonus practice materials",
    "section": "Specifying effect size: general guidelines",
    "text": "Specifying effect size: general guidelines\nAs a general indicative reference, below are the ‚ÄúCohen‚Äôs Standard Effect Sizes‚Äù (from statistician Jacob Cohen who came up with a rough set of numerical measures for ‚Äúsmall‚Äù, ‚Äúmedium‚Äù and ‚Äúlarge‚Äù effect sizes that are still in use today)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#the-pwr-package",
    "href": "practice/practice_slides/slides_lab06.html#the-pwr-package",
    "title": "Lab 6: Bonus practice materials",
    "section": "The pwr package",
    "text": "The pwr package\n\nThe pwr package (develped by St√©phane Champely), implements power analysis as outlined by Cohen (1988). The key arguments of the function pwr.t.test are 4 quantities, plus 2 for the test description:\n\n\nn = sample size\n\nd = effect size (based on Cohen‚Äôs)\n\nsig.level = the desired significance level\n\n\nThe significance level (\\(\\alpha\\)) defaults to 0.05. Therefore, to calculate the significance level, given an effect size, sample size, and power (\\(1- \\beta\\)), use the option \"sig.level=NULL\".\n\n\n\npower = the desired power\n\ntype = the type of t-test you will eventually be carrying out (one of two.sample, one.sample or paired)\n\nalternative = the type of alternative hypothesis you want to test (one of two.sided, less or greater)\n\n\nThe core idea behind its functions is that you enter 3 of the 4 quantities (effect size, sample size, significance level, power) and the 4th is calculated."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-sample-mean-exe-data",
    "href": "practice/practice_slides/slides_lab06.html#one-sample-mean-exe-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "One Sample Mean: EXE data",
    "text": "One Sample Mean: EXE data\n\n\nGOAL: Imagine this is a pilot study, in which we tested fish is (on average) different form 20 cm in length.\nThe guanapo_data dataset contains information on fish lengths from the Guanapo river pilot\n\n# Load data on river fish length \nfishlength_data &lt;- readr::read_csv(here::here(\"practice\", \"data_input\", \"05_datasets\", \n                                              \"fishlength.csv\"),\n                              show_col_types = FALSE)\n\n# Select a portion of the data (i.e. out \"pilot\" experiment) \nguanapo_data &lt;- fishlength_data %&gt;% \n  dplyr::filter(river == \"Guanapo\")\n\n# Pilot experiment data \nnames(guanapo_data)\n\n[1] \"id\"     \"river\"  \"length\"\n\nmean_H1 &lt;-  mean(guanapo_data$length) # 18.29655\nmean_H1\n\n[1] 18.29655\n\nsd_sample &lt;- sd(guanapo_data$length)  # 2.584636\nsd_sample\n\n[1] 2.584636"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-example-cont.",
    "href": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-example-cont.",
    "title": "Lab 6: Bonus practice materials",
    "section": "One Sample Mean t-test: EXAMPLE cont.",
    "text": "One Sample Mean t-test: EXAMPLE cont.\n\nLet‚Äôs compute the one sample t-test with stats::t.test against a hypothetical average fish length (\\(mean\\_H_o = 20\\) )\n\n# Hypothetical fish population length mean (H0)\nmean_H0 &lt;- 20\n# one-sample mean t-test \nt_stat &lt;- stats::t.test(x = guanapo_data$length,\n                        mu = mean_H0,\n                        alternative = \"two.sided\")\n# one-sample t-test results\nt_stat\n\n\n    One Sample t-test\n\ndata:  guanapo_data$length\nt = -3.5492, df = 28, p-value = 0.001387\nalternative hypothesis: true mean is not equal to 20\n95 percent confidence interval:\n 17.31341 19.27969\nsample estimates:\nmean of x \n 18.29655 \n\n\n\nThere appear to be a statistically significant result here: the mean length of the fish appears to be different from 20 cm.\n\nQUESTION: In a new study of the same fish, what sample size n would you need to get a comparable result?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-power-analysis-n",
    "href": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-power-analysis-n",
    "title": "Lab 6: Bonus practice materials",
    "section": "One Sample Mean t-test: POWER ANALYSIS (n)",
    "text": "One Sample Mean t-test: POWER ANALYSIS (n)\n\n\nWe input Cohen‚Äôs d (after calculating it manually) following: \\(effect\\ size\\ \\approx \\frac{{Mean}_{H_1}\\ -{\\ Mean}_{H_0}}{Std\\ Dev}\\)\nWe use pwr::pwr.t.test to calculate the minimum sample size n required: \n\n\n# Cohen's d formula \neff_size &lt;- (mean_H1 - mean_H0) / sd_sample # -0.6590669\n\n# power analysis to actually calculate the minimum sample size required:\npwr::pwr.t.test(d = eff_size, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 20.07483\n              d = 0.6590669\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\n\nWe would need n = 21 (rounding up) observations for an experiment (e.g.¬†in different river) to detect an effect size as the pilot study at a 5% significance level and 80% power."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-power-analysis-stricter-conditions",
    "href": "practice/practice_slides/slides_lab06.html#one-sample-mean-t-test-power-analysis-stricter-conditions",
    "title": "Lab 6: Bonus practice materials",
    "section": "One Sample Mean t-test: POWER ANALYSIS, stricter conditions",
    "text": "One Sample Mean t-test: POWER ANALYSIS, stricter conditions\nWhat if we wanted the results to be even more stringent?\n\ne.g.¬†require higher significance level (0.01) and power (0.90) with the same effect?\n\n\n# power analysis to actually calculate the minimum sample size required:\npwr::pwr.t.test(d = eff_size, \n                sig.level = 0.01, \n                power = 0.9,\n                type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 37.62974\n              d = 0.6590669\n      sig.level = 0.01\n          power = 0.9\n    alternative = two.sided\n\n\n\nThis time, we would need n = 38 observations for an experiment to detect the same effect size at the stricter level of significance and power."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-independent-samples-exe-data",
    "href": "practice/practice_slides/slides_lab06.html#two-independent-samples-exe-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Independent Samples: EXE data",
    "text": "Two Independent Samples: EXE data\n\n\nLet‚Äôs look at the entire fishlength_data with the lengths of fish from 2 separate rivers.\n\n# Explore complete data \nfishlength_data %&gt;% \n  dplyr::group_by (river) %&gt;% \n  dplyr::summarise (N = n(), \n                    mean_len = mean(length),\n                    sd_len = sd(length)) \n\n# A tibble: 2 √ó 4\n  river       N mean_len sd_len\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Aripo      39     20.3   1.78\n2 Guanapo    29     18.3   2.58\n\n\nVisualize quickly the 2 samples (rivers) with a boxplot\n\n# visualize the data\nfishlength_data %&gt;% \n  ggplot(aes(x = river, y = length)) +\n  geom_boxplot()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-independent-samples-exe-data-output",
    "href": "practice/practice_slides/slides_lab06.html#two-independent-samples-exe-data-output",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Independent Samples: EXE data",
    "text": "Two Independent Samples: EXE data\n\n\nThe fish in the 2 samples appear to have different mean length"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-independent-samples-t-test",
    "href": "practice/practice_slides/slides_lab06.html#two-independent-samples-t-test",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Independent Samples: t-test",
    "text": "Two Independent Samples: t-test\nLet‚Äôs confirm it with a two sample t-test against \\(ùëØ_ùüé\\): The two population means are equal\n\n# Perform two-samples unpaired test\nfishlength_data %&gt;% \n  rstatix::t_test(length ~ river,\n                  paired = FALSE\n                    )\n\n# A tibble: 1 √ó 8\n  .y.    group1 group2     n1    n2 statistic    df       p\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 length Aripo  Guanapo    39    29      3.64  46.9 0.00067\n\n\n\nThe t-test analysis confirms that the difference is significant.\n\n QUESTION: Can we use this information to design a more efficient experiment? I.e. run an experiment powerful enough to pick up the same observed difference in means but with fewer observations?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-independent-samples-power-analysis-12",
    "href": "practice/practice_slides/slides_lab06.html#two-independent-samples-power-analysis-12",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Independent Samples: POWER ANALYSIS 1/2",
    "text": "Two Independent Samples: POWER ANALYSIS 1/2\n\nLet‚Äôs work out exactly the effect size of this study by estimating Cohen‚Äôs d using this data.\n\n\n(We use a function from the package rstatix::cohens_d to estimate Cohen‚Äôs d)\n\n\n# Estimate cohen's d \nfishlength_data %&gt;%\n  rstatix::cohens_d(length ~ river, var.equal = TRUE)\n\n# A tibble: 1 √ó 7\n  .y.    group1 group2  effsize    n1    n2 magnitude\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 length Aripo  Guanapo   0.942    39    29 large    \n\n\n\nThe effsize column contains the information that we want, in this case 0.94"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-independent-samples-power-analysis-22-n",
    "href": "practice/practice_slides/slides_lab06.html#two-independent-samples-power-analysis-22-n",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Independent Samples: POWER ANALYSIS 2/2 (n)",
    "text": "Two Independent Samples: POWER ANALYSIS 2/2 (n)\n\nActually answer the question about how many fish we really need to catch in the future\n\n\n# run power analysis \npwr::pwr.t.test(d = 0.94, power = 0.8, sig.level = 0.05,\n           type = \"two.sample\", alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 18.77618\n              d = 0.94\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\nThe n output ( = 19 observations per group) -as opposed to 39 + 29- would be sufficient if we wanted to confidently detect the difference observed in the previous study"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-paired-samples-exe-data",
    "href": "practice/practice_slides/slides_lab06.html#two-paired-samples-exe-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Paired Samples: EXE data",
    "text": "Two Paired Samples: EXE data\n\nThe cortisol_data dataset contains information about cortisol levels measured on 20 participants in the morning and evening\n\n# Load data \ncortisol_data &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"05_datasets\", \n                                        \"cortisol.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n# Explore data \nnames(cortisol_data)\n\n[1] \"patient_id\" \"time\"       \"cortisol\"  \n\ncortisol_data %&gt;% \n  dplyr::group_by (time) %&gt;% \n  dplyr::summarise (\n    N = n(), \n    mean_cort = mean(cortisol),\n    sd_cort = sd(cortisol)) \n\n# A tibble: 2 √ó 4\n  time        N mean_cort sd_cort\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 evening    20      197.    87.5\n2 morning    20      313.    73.8\n\n\n\nNotice the difference in the paired sample means is quite large"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-visualization",
    "href": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-visualization",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Paired Samples t-test: visualization",
    "text": "Two Paired Samples t-test: visualization\nVisualize quickly the 2 paired samples (morning and evening) with a boxplot\n\n# visualize the data\ncortisol_data %&gt;% \n  ggplot(aes(x = time, y = cortisol)) +\n  geom_boxplot()\n\n\nThe cortisol levels in the 2 paired amples appear quite different"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-paired-samples-power-analysis-d",
    "href": "practice/practice_slides/slides_lab06.html#two-paired-samples-power-analysis-d",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Paired Samples: POWER ANALYSIS (d)",
    "text": "Two Paired Samples: POWER ANALYSIS (d)\n\nGOAL: Flipping the question, if we know the given n (20 patients observed twice): How big should the effect size be to be detected at power of 0.8 and significance level 0.05?\n\nWe use pwr::pwr.t.test, with the argument specification type = \"paired\", but this time to estimate the effect size \n\n\n\n# power analysis to actually calculate the effect size at the desired conditions:\npwr::pwr.t.test(n = 20, \n                #d =  eff_size, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 20\n              d = 0.6604413\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\n\nThe functions returns the effect size (Cohen‚Äôs metric): d = 0.6604413. So, with this experimental design we would be able to detect a medium-large effect size."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-power-analysis-on-given-n",
    "href": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-power-analysis-on-given-n",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Paired Samples t-test: POWER ANALYSIS on given n",
    "text": "Two Paired Samples t-test: POWER ANALYSIS on given n\nLooking instead at the actual sample data, what would be the observed effect size?\n\nTo compute ‚Äúobserved d‚Äù we can use the function rstatix::cohens_d\n\n\n\nd &lt;- cortisol_data %&gt;% \n  # estimate cohen's d\n  rstatix::cohens_d(cortisol ~ time, paired = TRUE)\n\nd\n\n# A tibble: 1 √ó 7\n  .y.      group1  group2  effsize    n1    n2 magnitude\n* &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 cortisol evening morning   -1.16    20    20 large    \n\n\nThe obtained d (-1.16) is extremely large, so we likely have more participants in this study than actually needed given such a large effect."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-power-analysis-gives-sufficient-n",
    "href": "practice/practice_slides/slides_lab06.html#two-paired-samples-t-test-power-analysis-gives-sufficient-n",
    "title": "Lab 6: Bonus practice materials",
    "section": "Two Paired Samples t-test: POWER ANALYSIS gives sufficient n",
    "text": "Two Paired Samples t-test: POWER ANALYSIS gives sufficient n\nLet‚Äôs re-compute the power analysis, but leave n as the unknown quantity, given the effect size (d) we have observed\n\n# power analysis to calculate minimunm n given the observed effect size in the sample \npwr::pwr.t.test(# n = 20, \n                d =  -1.16, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 7.960846\n              d = 1.16\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\n\nAs a matter of fact, n = 8 pairs of observations would have sufficed in this study, given the size of effect we were trying to detect."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-exe-data",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-exe-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: EXE data",
    "text": "One-way ANOVA test: EXE data\n\nThe mussels_data dataset contains information about the length of the anterior adductor muscle scar in the mussel Mytilus trossulus across five locations around the world!\n\n# Load data \nmussels_data &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"05_datasets\", \n                                        \"mussels.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n# Explore data \nnames(mussels_data)\n\n[1] \"length\"   \"location\"\n\nstats &lt;- mussels_data %&gt;% \n  dplyr::group_by (location) %&gt;% \n  dplyr::summarise (\n    N = n(), \n    mean_len = mean(length),\n    sd_len = sd(length)) \n\nstats\n\n# A tibble: 5 √ó 4\n  location       N mean_len  sd_len\n  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Magadan        8   0.0780 0.0129 \n2 Newport        8   0.0748 0.00860\n3 Petersburg     7   0.103  0.0162 \n4 Tillamook     10   0.0802 0.0120 \n5 Tvarminne      6   0.0957 0.0130"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-visualization",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-visualization",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: visualization",
    "text": "One-way ANOVA test: visualization\n\n\nThere appears to be a noticeable difference in lenght at average measurements at least between some of the locations\n\n\n\n\n\n\n\n\n\n\n\n# Visualize the data with a boxplot\nmussels_data %&gt;% \n  ggplot(aes(x = location, y = length)) +\n  geom_boxplot()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-visualization-output",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-visualization-output",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: visualization",
    "text": "One-way ANOVA test: visualization"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-example-cont.",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-example-cont.",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: EXAMPLE cont.",
    "text": "One-way ANOVA test: EXAMPLE cont.\n\nAssuming we verified the required assumptions, let‚Äôs run the ANOVA test to confirm the visual intuition\n\nWith the stats::aov followed by the command summary\n\n\n\n# Summary of test outputs: \nsummary_ANOVA &lt;- summary(stats::aov(length ~ location,\n                   data = mussels_data))\n\n# From which we extract all the output elements \n# F value \nsummary_ANOVA[[1]][[\"F value\"]] # 7.121019\n\n[1] 7.121019       NA\n\n# p value \nsummary_ANOVA[[1]][[\"Pr(&gt;F)\"]]  # 0.0002812242\n\n[1] 0.0002812242           NA\n\n# df of numerator and denominator\nsummary_ANOVA[[1]][[\"Df\"]]      # 4, 34 \n\n[1]  4 34\n\n# Sum of Square BETWEEN groups\nSSB &lt;- summary_ANOVA[[1]][[\"Sum Sq\"]][1]  # 0.004519674\n# Sum of Square WITHIN groups\nSSW &lt;- summary_ANOVA[[1]][[\"Sum Sq\"]][2]  # 0.005394906\n\n\nA one-way ANOVA test confirms that the mean lengths of muscle scar differed significantly between locations ( F = 7.121, with df = [4, 34], and p = 0.000281)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-power-analysis-effect",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-power-analysis-effect",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: POWER ANALYSIS (effect)",
    "text": "One-way ANOVA test: POWER ANALYSIS (effect)\n\nIn ANOVA it may be tricky to decide what kind of effect size we are looking for:\n\nif we care about an overall significance test, the sample size needed is a function of the standard deviation of the group means\nif we‚Äôre interested in the comparisons of means, there are other ways of expressing the effect size (e.g.¬†a difference between the smallest and largest means)\n\nHere let‚Äôs consider an overall test in which we could reasonably collect the same n.¬†of observations in each group\n\nn_loc &lt;- nrow(stats)\n\nmeans_by_loc &lt;- c(0.0780, 0.0748, 0.103, 0.0802, 0.0957)\noverall_mean &lt;-  mean(means_by_loc)\nsd_by_loc &lt;- c(0.0129, 0.00860, 0.0162, 0.0120, 0.0130)\noverall_sd &lt;-  mean(sd_by_loc)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#one-way-anova-test-power-analysis-effect-1",
    "href": "practice/practice_slides/slides_lab06.html#one-way-anova-test-power-analysis-effect-1",
    "title": "Lab 6: Bonus practice materials",
    "section": "One-way ANOVA test: POWER ANALYSIS (effect)",
    "text": "One-way ANOVA test: POWER ANALYSIS (effect)\n\n\n# Effect Size f formula\nCohen_f = sqrt( sum( (1/n_loc) * (means_by_loc - overall_mean)^2) ) /overall_sd\nCohen_f # EXTREMELY BIG \n\n[1] 0.877622\n\n# Power analysis with given f \npwr::pwr.anova.test(k = n_loc,\n                    n = NULL,\n                    f = Cohen_f,\n                    sig.level = 0.05,\n                    power = 0.80)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 5\n              n = 4.166759\n              f = 0.877622\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\n\nThe n output ( = 5 observations per group) -as opposed to &gt;6 per group- would be sufficient if we wanted to confidently detect the difference observed in the previous study"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-exe-data",
    "href": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-exe-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "Linear Regression with grouped data: EXE data",
    "text": "Linear Regression with grouped data: EXE data\n\nThe ideas covered before apply also to linear models, although here:\n\nwe use pwr.f2.test() to do the power calculation\nthe effect sizes (\\(f^2\\)) is based on \\(R^2\\)\n\n\n\\[ f^2=\\ \\frac{R^2}{1-\\ R^2}\\]\n\n# define the linear model\nlm_mussels &lt;- lm(length ~ location, \n                 data = mussels_data)\n\n\n# summarise the model\nsummary(lm_mussels)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-exe-data-output",
    "href": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-exe-data-output",
    "title": "Lab 6: Bonus practice materials",
    "section": "Linear Regression with grouped data: EXE data",
    "text": "Linear Regression with grouped data: EXE data\n\n\nCall:\nlm(formula = length ~ location, data = mussels_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.025400 -0.007956  0.000100  0.007000  0.031757 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.078012   0.004454  17.517  &lt; 2e-16 ***\nlocationNewport    -0.003213   0.006298  -0.510  0.61331    \nlocationPetersburg  0.025430   0.006519   3.901  0.00043 ***\nlocationTillamook   0.002187   0.005975   0.366  0.71656    \nlocationTvarminne   0.017687   0.006803   2.600  0.01370 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0126 on 34 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3918 \nF-statistic: 7.121 on 4 and 34 DF,  p-value: 0.0002812"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-power-analysis",
    "href": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-power-analysis",
    "title": "Lab 6: Bonus practice materials",
    "section": "Linear Regression with grouped data: POWER ANALYSIS",
    "text": "Linear Regression with grouped data: POWER ANALYSIS\n\nFrom the linear model we get that the \\(R^2\\) value is 0.4559 and we can use this to calculate Cohen‚Äôs \\(f^2\\) value using the formula\n\n# Extract R squared\nR_2 &lt;- summary(lm_mussels)$r.squared\n# compute f squared\nf_2 &lt;- R_2 / (1 - R_2)\nf_2\n\n[1] 0.837767\n\n\nOur model has 5 parameters (because we have 5 groups) and so the numerator degrees of freedom \\(u\\) will be 4 (5‚àí1=4).\nHence, we carry out the power analysis with the function pwr.f2.test:\n\n# power analysis for overall linear model \npwr::pwr.f2.test(u = 4, v = NULL, \n                 f2 = 0.8378974,\n                 sig.level = 0.05 , power = 0.8)\n\n\n     Multiple regression power calculation \n\n              u = 4\n              v = 14.62182\n             f2 = 0.8378974\n      sig.level = 0.05\n          power = 0.8"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-power-analysis-interpret.",
    "href": "practice/practice_slides/slides_lab06.html#linear-regression-with-grouped-data-power-analysis-interpret.",
    "title": "Lab 6: Bonus practice materials",
    "section": "Linear Regression with grouped data: POWER ANALYSIS interpret.",
    "text": "Linear Regression with grouped data: POWER ANALYSIS interpret.\n\nRecall that, in the F statistic evaluating the model,\n\n\nu the df for the numerator: \\(df_{between} =k‚àí1 = 5-1 = 4\\)\n\n\nv the df for the denominator: \\(df_{within} = n-k = ?\\)\n\nso \\(n = v+5\\)\n\n\n\n\n\npwr::pwr.f2.test(u = 4, f2 = 0.8378974,\n            sig.level = 0.05 , power = 0.8)\n\n\n     Multiple regression power calculation \n\n              u = 4\n              v = 14.62182\n             f2 = 0.8378974\n      sig.level = 0.05\n          power = 0.8\n\n\n\nThis tells us that the denominator degrees of freedom v should be 15 (14.62 rounded up), and this means that we would only need 20 observations n = v+5 in total across all 5 groups to detect this effect size"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#different-approaches-with-different-takes-on-empirical-data",
    "href": "practice/practice_slides/slides_lab06.html#different-approaches-with-different-takes-on-empirical-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "2 different approaches with different takes on empirical data",
    "text": "2 different approaches with different takes on empirical data\n\n(Simplifying a little)\n\n\nInferential statistics\n\nGOAL: Convincingly explain\nAPPROACH: Strong emphasis on defining assumptions (about variables distributions) and/or hypotheses on the relationship between them\n\nDATA:\n\nThe collection strategy is designed ex-ante , according to the experiment goal\nUsually, ALL AVAILABLE DATA are used to estimate effect of interest (as sampling was designed to be representative of a population).\n\n\n\n\nMachine Learning\n\nGOAL: Accurately predict\nAPPROACH: Focus on labeling observations or uncovering (‚Äúlearn‚Äù) a pattern, without worrying about explaining them\n\nDATA:\n\nData drives the search for patterns, but there is a huge risk of ‚Äúoverfitting‚Äù models (too specific to initial data!)\nIt is critical to SPLIT THE DATA (usually 75% for training and 25% for testing the algorithms) leaving aside a sub-sample to test the model with unseen new data"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#data-splitting-in-ml-approaches",
    "href": "practice/practice_slides/slides_lab06.html#data-splitting-in-ml-approaches",
    "title": "Lab 6: Bonus practice materials",
    "section": "Data Splitting in ML approaches",
    "text": "Data Splitting in ML approaches\n\nConsistent with the ML approach (learning from (data) examples), it is critical to split the available data to obtain:\n\n60-80% ‚ûú training sample for fitting a model and making prediction on the training data itself\n20-40% ‚ûú testing sample for evaluating the performance of the selected model(s) and test it works on new data too\n\n\nSince in ML we don‚Äôt claim to know what works in advance, it is essential to ‚Äútest‚Äù a candidate predictive model on fresh new data and see if it holds"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#introducing-r-metapackage-tidymodels-for-modeling-and-ml",
    "href": "practice/practice_slides/slides_lab06.html#introducing-r-metapackage-tidymodels-for-modeling-and-ml",
    "title": "Lab 6: Bonus practice materials",
    "section": "Introducing R (metapackage) tidymodels for modeling and ML",
    "text": "Introducing R (metapackage) tidymodels for modeling and ML\n\n\nThe package tidymodels (much like the tidyverse) is an ecosystem of packages meant to enable a wide variety of approaches for modeling and statistical analysis.\n\nOne package in this system is rsample is one of its building blocks for resampling data"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#revisiting-nhanes-for-a-quick-demonstration-of-predictive-modeling",
    "href": "practice/practice_slides/slides_lab06.html#revisiting-nhanes-for-a-quick-demonstration-of-predictive-modeling",
    "title": "Lab 6: Bonus practice materials",
    "section": "Revisiting NHANES for a quick demonstration of predictive modeling",
    "text": "Revisiting NHANES for a quick demonstration of predictive modeling\n\nLet‚Äôs re-load a dataset from Lab # 3 (the NHANES dataset) for a quick demonstration of data splitting in an ML predictive modeling scenario\n\nWe can try predicting BMI from age (in years), PhysActive, and gender, using linear regression model (which is a Supervised ML algorithm)\n(we already saved this dataset)\n\n\n# (we already saved this dataset in our project folders)\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nnhanes &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"nhanes.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#splitting-the-dataset-into-training-and-testing-samples",
    "href": "practice/practice_slides/slides_lab06.html#splitting-the-dataset-into-training-and-testing-samples",
    "title": "Lab 6: Bonus practice materials",
    "section": "Splitting the dataset into training and testing samples",
    "text": "Splitting the dataset into training and testing samples\n\n\nWith this approach, it is best practice to ‚Äúhold back‚Äù some data for testing to get a better estimate of how models will perform on new data\n\nWe can easily specify training and testing sets using rsample‚Äôs function initial_split\n\n\n\n\n# ensure we always get the same result when sampling (for convenience )\nset.seed(12345)\n\nnhanes_split &lt;- nhanes %&gt;%\n  # define the training proportion as 75%\n  rsample::initial_split(prop = 0.75,\n  # ensuring both sets are balanced in gender\n                         strata = Gender)\n\n# resulting datasets\nnhanes_train &lt;- rsample::training(nhanes_split)\ndim(nhanes_train)\n\n[1] 374  77\n\nnhanes_test &lt;- rsample::testing(nhanes_split)\ndim(nhanes_test)\n\n[1] 126  77"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#fitting-a-linear-model-on-the-training-data",
    "href": "practice/practice_slides/slides_lab06.html#fitting-a-linear-model-on-the-training-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "Fitting a linear model on the training data",
    "text": "Fitting a linear model on the training data\n\nIn this case the regression models serves for predicting numeric, continuous quantities\n\n# fitting  linear regression model specification\nlin_mod &lt;- lm(BMI ~ Age + Gender + PhysActive, data = nhanes_train)\n\nsummary(lin_mod)\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + PhysActive, data = nhanes_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.685  -4.674  -1.419   4.257  38.016 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   30.14217    1.30426  23.110  &lt; 2e-16 ***\nAge            0.01429    0.02198   0.650  0.51596    \nGendermale    -0.72960    0.72176  -1.011  0.31275    \nPhysActiveYes -2.26539    0.73620  -3.077  0.00225 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.903 on 367 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.03416,   Adjusted R-squared:  0.02626 \nF-statistic: 4.327 on 3 and 367 DF,  p-value: 0.005155"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#predicting-bmi-estimates-for-new-data-set",
    "href": "practice/practice_slides/slides_lab06.html#predicting-bmi-estimates-for-new-data-set",
    "title": "Lab 6: Bonus practice materials",
    "section": "Predicting BMI estimates for new data set",
    "text": "Predicting BMI estimates for new data set\n\nUsing the above model, we can predict the BMI for different individuals (those left in the testing data)\n\nwith the function predict, where we specify the argument newdata = nhanes_test)\nadding the prediction interval (the 95% CI), which gives uncertainty around a single value of the prediction\n\n\n# Obtain predictions from the results of a model fitting function\npred_bmi &lt;- stats::predict(lin_mod, \n               newdata = nhanes_test,\n               interval = \"confidence\" )\nhead(pred_bmi)\n\n       fit      lwr      upr\n1 28.59148 27.33499 29.84797\n2 27.70464 26.45051 28.95878\n3 30.88546 29.72888 32.04203\n4 28.01911 26.64955 29.38867\n5 29.78421 28.04027 31.52815\n6 27.60459 26.24230 28.96688"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#evaluating-the-predictive-performance-in-testing-data",
    "href": "practice/practice_slides/slides_lab06.html#evaluating-the-predictive-performance-in-testing-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "Evaluating the predictive performance in testing data",
    "text": "Evaluating the predictive performance in testing data\n\nThe ultimate goal of holding data back from the model training process was to evaluate its predictive performance on new data. \n\nA common measure used is the RMSE (Root Mean Square Error) = a measure of the distance between observed values and predicted values in the testing dataset\n\n# Computing the Root Mean Square Error\nRMSE_test &lt;- sqrt(mean((nhanes_test$BMI - predict(lin_mod, nhanes_test))^2, na.rm = T))\nRMSE_test # 6.170518\n\n[1] 6.170518\n\n\n\nThe RMSE (= 6.170518) tells us, (roughly speaking) by how much, on average, the new observed BMI values differ from those predicted by our model"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#and-what-about-rmse-in-training-data",
    "href": "practice/practice_slides/slides_lab06.html#and-what-about-rmse-in-training-data",
    "title": "Lab 6: Bonus practice materials",
    "section": "‚Ä¶ and what about RMSE in training data?",
    "text": "‚Ä¶ and what about RMSE in training data?\nLet‚Äôs see the RMSE in the training dataset (for comparison)\n\nRMSE_train &lt;- sqrt(mean((nhanes_train$BMI - predict(lin_mod, nhanes_train))^2, na.rm = T))\nRMSE_train # 6.866044\n\n[1] 6.866044\n\n# R squared is also quite low \nsummary(lin_mod)$r.squared     # R^2 0.0341589\n\n[1] 0.0341589\n\n\n\nThis is not what expected ü§î, since RMSE on the training data is sliglthly bigger that in the testing data!\n\nA possible explanation is that out model is underfitting in the first place (model‚Äôs \\({R}^2\\) was quite low too), so we should definitely try different models‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#recap-of-the-workshops-content",
    "href": "practice/practice_slides/slides_lab06.html#recap-of-the-workshops-content",
    "title": "Lab 6: Bonus practice materials",
    "section": "Recap of the workshop‚Äôs content",
    "text": "Recap of the workshop‚Äôs content\n\nTOPICS WE COVERED\n\nMotivated the choice of learning/using R for scientific quantitative analysis, and lay out some fundamental concepts in biostatistics with concrete R coding examples.\nConsolidated understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.\nDiscussed the relationship between any two variables, and introduce a widely used analytical tool: regression.\nPresented a popular ML technique for dimensionality reduction (PCA), performed both with MetaboAnalyst and R.\nIntroduction to power analysis to define the correct sample size for hypotheses testing and discussion of how ML approaches deal with available data."
  },
  {
    "objectID": "practice/practice_slides/slides_lab06.html#final-thoughts",
    "href": "practice/practice_slides/slides_lab06.html#final-thoughts",
    "title": "Lab 6: Bonus practice materials",
    "section": "Final thoughts",
    "text": "Final thoughts\n\n\n\n\nWhile the workshop only allowed for a synthetic overview of fundamental ideas, it hopefully provided a solid foundation on the most common statistical analysis you will likely run in your daily work:\n\nThorough understanding of the input data and the data collection process\nUnivariate and bivariate exploratory analysis (accompanied by visual intuition) to form hypothesis\nUpon verifying the assumptions, we fit data to hypothesized model(s)\n\nAssessment of the model performance (\\(R^2\\), \\(Adj. R^2\\), \\(F-Statistic\\), etc.)\n\n\nYou should now have a solid grasp on the R language to keep using and exploring the huge potential of this programming ecosystem\nWe only scratched the surface in terms of ML classification and prediction models, but we got a hang of the fundamental steps and some useful tools that might serve us also in more advanced analysis\n\n\n\n\n\n\n\nR 4 Statistics | 2025"
  }
]