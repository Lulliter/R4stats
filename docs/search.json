[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course Description & Objectives",
    "section": "",
    "text": "Course Description\n\n\nThis is an intensive course originally designed for PhD students and researchers dealing with biological datasets to help them consolidate their practical understanding of frequently implemented data analysis and statistical modeling for academic research purposes. This course focuses on empowering participants to conduct end-to-end data analyses, guiding them through reproducible data storage, cleaning, exploration, analysis, and interpretation cycle.\nBeyond the conceptual foundations, participants engage in hands-on coding sessions in the R software with real-world datasets and solved questions, validating in practice the skills needed to confidently acquire and communicate insights throughout the analytical process.\nParticular emphasis is placed on developing an understanding of the statistical methods used, when to apply them, and how to interpret them, in close connection to ‚Äúreal life‚Äù situations for a research scientists. \n\n\n\n\n\n\n\n\n\nTarget Audience\nThe target audience for this course is graduate students, post-doctoral fellows, and researchers in industry or academia already familiar with basic statistics (ideally in R) and looking to learn more about conducting an analysis from start to finish with more intermediate or advanced statistical techniques.\n\n\nPrerequisites\n\n\n\n\n\n\n\n\n\n\n\n\nWhile there are no specific prerequisites, because of the intensive nature of this course, participants will make the most of it if they have prior exposure to quantitative work in the biology/life science field. Similarly, some prior exposure to R programming will make the lab sessions more engaging.\nDetailed instructions are provided to complete the required installation of R and RStudio ahead of the workshop, so that participants can follow along the lab sessions.\n\n\nCourse Outline\n\nModule 1: Introduction to R and data analysis\n\nIntroduction to reproducible end-to-end analysis using R\n\nWhy use R?\nPrinciples of reproducible analysis with R + RStudio\nR objects, functions, packages\n\nDiscussion of different variable types (qualitative, quantitative) and levels of measurement (nominal, ordinal, interval, ratio)\n\nPrinciples of ‚Äútidy data‚Äù\nIntroduction to data cleaning and manipulation methods\n\nDescriptive statistics\n\nUnivariate analysis\nMeasures of central tendency, measures of variability (or spread), and frequency distributions\n\nVisual data exploration\n\nIntroduction to ggplot2 package for making graphs in R\n\n\n\n\n\n\n\nModule 2: Statistical inference and classical hypothesis testing\n\nPurpose and foundations of inferential statistics\n\nProbability and random variables\nMeaningful probability distributions\nSampling distributions and Central Limit Theorem\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing\n\nThe null and alternative hypothesis\nThe probability of error? (Œ± or ‚Äúsignificance level‚Äù)\nThe p-value probability and tests interpretation\nConfidence Intervals\nTypes of errors (Type 1 and Type 2)\nEffective vs statistical significance\n\nHypothesis tests examples\n\nComparing sample mean to a hypothesized population mean (Z test & t test)\nComparing two independent sample means (t test)\nComparing sample means from 3 or more groups (ANOVA)\n\nA closer look at testing assumptions (with examples)\n\nTesting two groups that are not independent\nTesting if the data are not normally distributed: non-parametric tests\nTesting samples without homogeneous variance of observations\n\n\n\n\nModule 3: Modeling correlation and regression\n\nTesting and summarizing relationship between 2 variables (correlation)\n\nPearson \\(r\\) analysis (parametric)\n\n(numerical variables)\n\nSpearman‚Äôs test (not parametric)\n\nMeasures of association\n\nChi-Square Test of Independence\n\n(categorical variables)\n\nFisher‚Äôs Exact Test\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\nIntroduction of regression based statistical methods\n\nSimple linear regression models\nMultiple Linear Regression models\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised and Unsupervised algorithms\n\n\n\n\nModule 4: Introduction to machine learning\n\nExamples of Machine Learning algorithms\n\nPCA ‚Äì ‚Äúunsupervised‚Äù ML algorithm for dimensionality reduction\nPLS-Discriminant Analysis ‚Äì ‚Äúsupervised‚Äù alternative to PCA performing simultaneous dimensionality reduction and classification    \n\nIntroduction to MetaboAnalyst software\n\nOverview of a useful, R-based resources for metabolomics\nIllustrative workflow with MetaboAnalyst\n\nElements of statistical Power Analysis\n\nBrief review of hypothesis testing framework (from Module 2)\nReview of type I and type II decision errors, contextualizing them in experimental settings\nUnderstanding the test‚Äôs statistical power in connection to the effect size of an experiment\n\n\n\n\n programming labs\nEach of the above module is accompanied by a matching practical session intended to consolidate the theoretical concepts via hands-on R coding sessions.\n\nThe illustrative examples used are based on real biology/clinical research data.\nIn each example, the student is guided through the entire process: acquiring and reading data into R, identifying the appropriate analytical method, running the analysis and, finally, interpreting the obtained outcomes.\nFor every exercise, the participant is provided with input datasets (complete with documentation) and R code source files (*.R) with solved examples for future reference.\nThe instructor will also use the lab sessions as an opportunity to discuss common questions and challenges that are normally encountered in the day-to-day life of research scientists."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#topics-discussed-in-lecture-3",
    "href": "practice/practice_slides/slides_lab03.html#topics-discussed-in-lecture-3",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Topics discussed in Lecture # 3",
    "text": "Topics discussed in Lecture # 3\n\nLecture 3: topics\n\nTesting and summarizing relationship between 2 variables (correlation)\n\nPearson‚Äôs ùíì analysis (param)\n\nSpearman test (no param)\n\n\n\nMeasures of association\n\nChi-Square test of independence\n\nFisher‚Äôs Exact Test\n\nalternative to the Chi-Square Test of Independence\n\n\n\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\n\nWidely used analytical tools\n\nSimple linear regression models\nMultiple Linear Regression models\n\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised & Unsupervised algorithms"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab03.html#needed-r-packages",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n\n# Load pckgs for this R session\n\n# -- General \nlibrary(fs)      # file/directory interactions\nlibrary(here)    # tools find your project's files, based on working directory\nlibrary(paint) # paint data.frames summaries in colour\nlibrary(janitor) # tools for examining and cleaning data\nlibrary(dplyr)   # {tidyverse} tools for manipulating and summarizing tidy data \nlibrary(forcats) # {tidyverse} tool for handling factors\nlibrary(openxlsx) # Read, Write and Edit xlsx Files\nlibrary(flextable) # Functions for Tabular Reporting\n# -- Statistics\nlibrary(rstatix) # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(lmtest) # Testing Linear Regression Models \nlibrary(broom) # Convert Statistical Objects into Tidy Tibbles\n#library(tidymodels) # not installed on this machine\nlibrary(performance) # Assessment of Regression Models Performance \n# -- Plotting\nlibrary(ggplot2) # Create Elegant Data Visualisations Using the Grammar of Graphics"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-1-nhanes",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-1-nhanes",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 1 (NHANES)",
    "text": "Importing Dataset 1 (NHANES)\n\nName: NHANES (National Health and Nutrition Examination Survey) combines interviews and physical examinations to assess the health and nutritional status of adults and children in the United States. Sterted in the 1960s, it became a continuous program in 1999.Documentation: dataset1Sampling details: Here we use a sample of 500 adults from NHANES 2009-2010 & 2011-2012 (nhanes.samp.adult.500 in the R oibiostat package, which has been adjusted so that it can be viewed as a random sample of the US population)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nnhanes_samp &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"nhanes.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n\nAdapting the function here to match your own folder structure"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#nhanes-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#nhanes-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "NHANES Variables and their description",
    "text": "NHANES Variables and their description\n\n[EXCERPT: see complete file in Input Data Folder]\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nX\nint\nxxxx\n\n\nID\nint\nxxxxx\n\n\nSurveyYr\nchr\nyyyy_mm. Ex. 2011_12\n\n\nGender\nchr\nGender (sex) of study participant coded as male or female\n\n\nAge\nint\n##\n\n\nAgeDecade\nchr\nyy-yy es 20-29\n\n\nEducation\nchr\n[&gt;= 20 yro]. Ex. 8thGrade, 9-11thGrade, HighSchool, SomeCollege, or CollegeGrad.\n\n\nWeight\ndbl\nWeight in kg\n\n\nHeight\ndbl\nStanding height in cm. Reported for participants aged 2 years or older.\n\n\nBMI\ndbl\nBody mass index (weight/height2 in kg/m2). Reported for participants aged 2 years or older\n\n\nPulse\nint\n60 second pulse rate\n\n\nDirectChol\ndbl\nDirect HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nTotChol\ndbl\nTotal HDL cholesterol in mmol/L. Reported for participants aged 6 years or older\n\n\nDiabetes\nchr\nStudy participant told by a doctor or health professional that they have diabetes\n\n\nDiabetesAge\nint\nAge of study participant when first told they had diabetes\n\n\nHealthGen\nchr\nSelf-reported rating of health: Excellent, Vgood, Good, Fair, or Poor Fair\n\n\nAlcohol12PlusYr\nchr\nParticipant has consumed at least 12 drinks of any type of alcoholic beverage in any one year\n\n\n...\n...\n..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-2-prevend",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-2-prevend",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 2 (PREVEND)",
    "text": "Importing Dataset 2 (PREVEND)\n\nName: PREVEND (Prevention of REnal and Vascular END-stage Disease) is a study which took place in the Netherlands starting in the 1990s, with subsequent follow-ups throughout the 2000s. This dataset is from the third survey, which participants completed in 2003-2006; data is provided for 4,095 individuals who completed cognitive testing.Documentation: dataset2 and sample dataset variables‚Äô codebookSampling details: Here we use a sample of 500 adults taken from 4,095 individuals who completed cognitive testing (i.e.¬†the prevend.samp dataset in the R oibiostat package)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nprevend_samp &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"prevend.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#prevend-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#prevend-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "PREVEND Variables and their description",
    "text": "PREVEND Variables and their description\n\n[EXCERPT: see complete file in Input Data Folder]\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nX\nint\nPatient ID\n\n\nAge\nint\nAge in years\n\n\nGender\nint\nExpressed as: 0 = males; 1 = females\n\n\nRFFT\nint\nPerformance on the Ruff Figural Fluency Test. Scores range from 0 (worst) to 175 (best)\n\n\nVAT\nint\nVisual Association Test score. Scores may range from 0 (worst) to 12 (best)\n\n\nChol\ndbl\nTotal cholesterol, in mmol/L.\n\n\nHDL\ndbl\nHDL cholesterol, in mmol/L.\n\n\nStatin\nint\nStatin use at enrollment. Numeric vector: 0 = No; 1 = Yes.\n\n\nCVD\nint\nHistory of cardiovascular event. Numeric vector: 0 = No; 1 = Yes\n\n\nDM\nint\nDiabetes mellitus status at enrollment. Numeric vector: 0 = No; 1 = Yes\n\n\nEducation\nint\nHighest level of education. Numeric: 0 primary school; 1 = lower secondary education; 3 = university\n\n\nSmoking\nint\nSmoking at enrollment. numeric vector: 0 = No; 1 = Yes\n\n\nHypertension\nint\nStatus of hypertension at enrollment. Numeric vector: 0 = No; 1 = Yes\n\n\nEthnicity\nint\nExpressed as: 0 = Western European; 1 = African; 2 = Asian; 3 = Other\n\n\n...\n...\n..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#importing-dataset-3-famuss",
    "href": "practice/practice_slides/slides_lab03.html#importing-dataset-3-famuss",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Importing Dataset 3 (FAMuSS)",
    "text": "Importing Dataset 3 (FAMuSS)\n\nName: FAMuSS (Functional SNPs Associated with Muscle Size and Strength) examine the association of demographic, physiological and genetic characteristics with muscle strength ‚Äì including data on race and genotype at a specific locus on the ACTN3 gene (the ‚Äúsports gene‚Äù).Documentation: dataset3Sampling details: the DATASET includes 595 observations on 9 variables (famuss in the R oibiostat package)\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nfamuss &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"famuss.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#famuss-variables-and-their-description",
    "href": "practice/practice_slides/slides_lab03.html#famuss-variables-and-their-description",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "FAMuSS Variables and their description",
    "text": "FAMuSS Variables and their description\n\n[See complete file in Input Data Folder]\n\n\n\n\n\nVariable\nDescription\n\n\n\nX\nid\n\n\nndrm.ch\nPercent change in strength in the non-dominant arm\n\n\ndrm.ch\nPercent change in strength in the dominant arm\n\n\nsex\nSex of the participant\n\n\nage\nAge in years\n\n\nrace\nRecorded as African Am (African American), Caucasian, Asian, Hispanic, Other\n\n\nheight\nHeight in inches\n\n\nweight\nWeight in pounds\n\n\nactn3.r577x\nGenotype at the location r577x in the ACTN3 gene.\n\n\nbmi\nBody Mass Index"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#explore-relationships-between-two-variables",
    "href": "practice/practice_slides/slides_lab03.html#explore-relationships-between-two-variables",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Explore relationships between two variables",
    "text": "Explore relationships between two variables\nApproaches for summarizing relationships between two variables vary depending on variable types‚Ä¶\n\nTwo numerical variables\nTwo categorical variables\nOne numerical variable and one categorical variable\n\nTwo variables \\(x\\) and \\(y\\) are\n\n\npositively associated if \\(y\\) increases as \\(x\\) increases.\n\nnegatively associated if \\(y\\) decreases as \\(x\\) increases."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables (plot)",
    "text": "Two numerical variables (plot)\nHeight and weight (taken from the nhanes_samp dataset) are positively associated.\n\nnotice we can also use the generic base R function plot for a quick scatter plot\n\n\n# rename for convenience\nnhanes &lt;- nhanes_samp %&gt;% \n  janitor::clean_names()\n\n# basis plot \nplot(nhanes$height, nhanes$weight,\n     xlab = \"Height (cm)\", ylab = \"Weight (kg)\", cex = 0.8)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot-output",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-plot-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables (plot)",
    "text": "Two numerical variables (plot)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor)",
    "text": "Two numerical variables: correlation (with stats::cor)\n\nCorrelation is a numerical summary that measures the strength of a linear relationship between two variables.\n\n\nThe correlation coefficient \\(r\\) takes on values between \\(-1\\) and \\(1\\).\nThe closer \\(r\\) is to \\(\\pm 1\\), the stronger the linear association.\n\nHere we compute the Pearson rho (parametric), with base R function stats::cor\n\nthe use argument let us choose how to deal with missing values (in this case only using all complete pairs)\n\n\n\n\nis.numeric(nhanes$height) \n\n[1] TRUE\n\nis.numeric(nhanes$weight)\n\n[1] TRUE\n\n# using `stats` package\nstats::cor(x = nhanes$height, y =  nhanes$weight, \n    # argument for dealing with missing values\n    use = \"pairwise.complete.obs\",\n    method = \"pearson\")\n\n[1] 0.4102269"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor.test)",
    "text": "Two numerical variables: correlation (with stats::cor.test)\n\nHere we compute the Pearson rho (parametric), with the function cor.test (the same we used for testing paired samples)\n\nimplicitely takes care on NAs\n\n\n\n\n\n# using `stats` package \ncor_test_result &lt;- cor.test(x = nhanes$height, y =  nhanes$weight, \n                            method = \"pearson\")\n\n# looking at the cor estimate\ncor_test_result[[\"estimate\"]][[\"cor\"]]\n\n[1] 0.4102269\n\n\n\nThe function ggpubr::ggscatter gives us all in one (scatter plot + \\(r\\) (‚ÄúR‚Äù))! ü§Ø\n\n\nlibrary(\"ggpubr\") # 'ggplot2' Based Publication Ready Plots\nggpubr::ggscatter(nhanes, x = \"height\", y = \"weight\", \n                  cor.coef = TRUE, cor.method = \"pearson\", #cor.coef.coord = 2,\n                  xlab = \"Height (in)\", ylab = \"Weight (lb)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test-output",
    "href": "practice/practice_slides/slides_lab03.html#two-numerical-variables-correlation-with-statscor.test-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two numerical variables: correlation (with stats::cor.test)",
    "text": "Two numerical variables: correlation (with stats::cor.test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation",
    "text": "Spearman rank-order correlation\nThe Spearman‚Äôs rank-order correlation is the nonparametric version of the Pearson correlation.\nSpearman‚Äôs correlation coefficient, (\\(œÅ\\), also signified by \\(rs\\)) measures the strength and direction of association between two ranked variables.\n\nused when 2 variables have a non-linear relationship\nexcellent for ordinal data (when Pearson‚Äôs is not appropriate), i.e.¬†Likert scale items\n\n\nTo compute it, we simply calculate Pearson‚Äôs correlation of the rankings of the raw data (instead of the data)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example)",
    "text": "Spearman rank-order correlation (example)\n\nLet‚Äôs say we want to get Spearman‚Äôs correlation with ordinal factors Education and HealthGen in the NHANES sample.\n\nWe have to convert them to their underlying numeric code, to compare rankings.\n\n\ntabyl(nhanes$education)\n\n nhanes$education   n percent valid_percent\n        8th Grade  32   0.064    0.06412826\n   9 - 11th Grade  68   0.136    0.13627255\n     College Grad 157   0.314    0.31462926\n      High School  94   0.188    0.18837675\n     Some College 148   0.296    0.29659319\n             &lt;NA&gt;   1   0.002            NA\n\ntabyl(nhanes$health_gen)\n\n nhanes$health_gen   n percent valid_percent\n         Excellent  47   0.094    0.10444444\n              Fair  53   0.106    0.11777778\n              Good 177   0.354    0.39333333\n              Poor  11   0.022    0.02444444\n             Vgood 162   0.324    0.36000000\n              &lt;NA&gt;  50   0.100            NA\n\nnhanes &lt;- nhanes %&gt;% \n  # reorder education\n  mutate (edu_ord = factor (education, \n                            levels = c(\"8th Grade\", \"9 - 11th Grade\",\n                                       \"High School\", \"Some College\",\n                                       \"College Grad\" , NA))) %&gt;%  \n  # create edu_rank \n  mutate (edu_rank = as.numeric(edu_ord)) %&gt;% \n  # reorder health education\n  mutate (health_ord = factor (health_gen, \n                            levels = c( NA, \"Poor\", \"Fair\",\n                                       \"Good\", \"Vgood\",\n                                       \"Excellent\"))) %&gt;%\n  # create health_rank \n  mutate (health_rank = as.numeric(health_ord))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example), cont.",
    "text": "Spearman rank-order correlation (example), cont.\n\n\nLet‚Äôs check out the ..._rank version of the 2 categorical variables of interest:\n\n\neducation from edu_ord to edu_rank\n\n\n\n\n\ntable(nhanes$edu_ord, useNA = \"ifany\" )\n\n\n     8th Grade 9 - 11th Grade    High School   Some College   College Grad \n            32             68             94            148            157 \n          &lt;NA&gt; \n             1 \n\ntable(nhanes$edu_rank, useNA = \"ifany\" )\n\n\n   1    2    3    4    5 &lt;NA&gt; \n  32   68   94  148  157    1 \n\n\n\n\ngeneral health from health_ord to health_rank\n\n\n\ntable(nhanes$health_ord, useNA = \"ifany\" )\n\n\n     Poor      Fair      Good     Vgood Excellent      &lt;NA&gt; \n       11        53       177       162        47        50 \n\ntable(nhanes$health_rank,  useNA = \"ifany\" )\n\n\n   1    2    3    4    5 &lt;NA&gt; \n  11   53  177  162   47   50"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.-1",
    "href": "practice/practice_slides/slides_lab03.html#spearman-rank-order-correlation-example-cont.-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Spearman rank-order correlation (example cont.)",
    "text": "Spearman rank-order correlation (example cont.)\nAfter setting up the variables in the correct (numerical rank) format, now we can actually compute it: + same function call stats::cor.test + but specifying argument method = \"spearman\"\n\n# -- using `stats` package \ncor_test_result_sp &lt;- cor.test(x = nhanes$edu_rank,\n                               y = nhanes$health_rank, \n                               method = \"spearman\", \n                               exact = FALSE) # removes the Ties message warning \n# looking at the cor estimate\ncor_test_result_sp\n\n\n    Spearman's rank correlation rho\n\ndata:  nhanes$edu_rank and nhanes$health_rank\nS = 10641203, p-value = 1.915e-10\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2946493 \n\n# -- only print Spearman rho \n#cor_test_result_sp[[\"estimate\"]][[\"rho\"]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-plot",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-plot",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (plot)",
    "text": "Two categorical variables (plot)\n\nIn the famuss dataset, the variables race, and actn3.r577x are categorical variables.\n\nwe can use the generic base R function graphics::barplot\n\n\n\nmycolors_contrast &lt;- c(\"#9b2339\", \"#E7B800\",\"#239b85\", \"#85239b\", \"#9b8523\",\"#23399b\", \"#d8e600\", \"#0084e6\",\"#399B23\",  \"#e60066\" , \"#00d8e6\",  \"#005ca1\", \"#e68000\")\n\n## genotypes as columns\ngenotype.race = matrix(table(famuss$actn3.r577x, famuss$race), ncol=3, byrow=T)\ncolnames(genotype.race) = c(\"CC\", \"CT\", \"TT\")\nrownames(genotype.race) = c(\"African Am\", \"Asian\", \"Caucasian\", \"Hispanic\", \"Other\")\n\n# using generic base::barplot\ngraphics::barplot(genotype.race, col = mycolors_contrast[1:5], ylim=c(0,300), width=2)\nlegend(\"topright\", inset=c(.05, 0), fill=mycolors_contrast[1:5], \n       legend=rownames(genotype.race))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (contingency table)",
    "text": "Two categorical variables (contingency table)\n\nSpecifically, the variable actn3.r577x takes on three possible levels (CC, CT, or TT) which indicate the distribution of genotype at location r577x on the ACTN3 gene for the FAMuSS study participants.\nA contingency table summarizes data for two categorical variables.\n\nthe function stats::addmargins puts arbitrary Margins on multidimensional tables\n\nThe extra column & row \"Sum\" provide the marginal totals across each row and each column, respectively\n\n\n\n\n# levels of actn3.r577x\ntable(famuss$actn3.r577x)\n\n\n CC  CT  TT \n173 261 161 \n\n# contingency table to summarize race and actn3.r577x\naddmargins(table(famuss$race, famuss$actn3.r577x))\n\n            \n              CC  CT  TT Sum\n  African Am  16   6   5  27\n  Asian       21  18  16  55\n  Caucasian  125 216 126 467\n  Hispanic     4  10   9  23\n  Other        7  11   5  23\n  Sum        173 261 161 595"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table-prop",
    "href": "practice/practice_slides/slides_lab03.html#two-categorical-variables-contingency-table-prop",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Two categorical variables (contingency table prop)",
    "text": "Two categorical variables (contingency table prop)\n\nContingency tables can also be converted to show proportions. Since there are 2 variables, it is necessary to specify whether the proportions are calculated according to the row variable or the column variable.\n\nusing the margin = argument in the base::prop.table function (1 indicates rows, 2 indicates columns)\n\n\n# adding row proportions\naddmargins(prop.table(table(famuss$race, famuss$actn3.r577x), margin =  1))\n\n            \n                    CC        CT        TT       Sum\n  African Am 0.5925926 0.2222222 0.1851852 1.0000000\n  Asian      0.3818182 0.3272727 0.2909091 1.0000000\n  Caucasian  0.2676660 0.4625268 0.2698073 1.0000000\n  Hispanic   0.1739130 0.4347826 0.3913043 1.0000000\n  Other      0.3043478 0.4782609 0.2173913 1.0000000\n  Sum        1.7203376 1.9250652 1.3545972 5.0000000\n\n# adding column proportions\naddmargins(prop.table(table(famuss$race, famuss$actn3.r577x),margin =  2))\n\n            \n                     CC         CT         TT        Sum\n  African Am 0.09248555 0.02298851 0.03105590 0.14652996\n  Asian      0.12138728 0.06896552 0.09937888 0.28973168\n  Caucasian  0.72254335 0.82758621 0.78260870 2.33273826\n  Hispanic   0.02312139 0.03831418 0.05590062 0.11733618\n  Other      0.04046243 0.04214559 0.03105590 0.11366392\n  Sum        1.00000000 1.00000000 1.00000000 3.00000000"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence",
    "text": "Chi Squared test of independence\nThe Chi-squared test is a hypothesis test used to determine whether there is a relationship between two categorical variables.\n\ncategorical vars. can have nominal or ordinal measurement scale\nthe observed frequencies are compared with the expected frequencies and their deviations are examined.\n\n\n# Chi-squared test\n# (Test of association to see if \n# H0: the 2 cat var (race  & actn3.r577x ) are independent\n# H1: the 2 cat var are correlated in __some way__\n\ntab &lt;- table(famuss$race, famuss$actn3.r577x)\ntest_chi &lt;- chisq.test(tab)\n\nthe obtained result (test_chi) is a list of objects‚Ä¶\n\n\n\n You try‚Ä¶\n\n\n‚Ä¶run View(test_chi) to check"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-cont",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-cont",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence (cont)",
    "text": "Chi Squared test of independence (cont)\nWithin test_chi results there are:\n\n\n\n\nObserved frequencies =\nhow often a combination occurs in our sample\n\n\n# Observed frequencies\ntest_chi$observed\n\n            \n              CC  CT  TT\n  African Am  16   6   5\n  Asian       21  18  16\n  Caucasian  125 216 126\n  Hispanic     4  10   9\n  Other        7  11   5\n\n\n\n\n\nExpected frequencies = what would it be if the 2 vars were PERFECTLY INDEPENDENT\n\n\n# Expected frequencies\nround(test_chi$expected  , digits = 1 )\n\n            \n                CC    CT    TT\n  African Am   7.9  11.8   7.3\n  Asian       16.0  24.1  14.9\n  Caucasian  135.8 204.9 126.4\n  Hispanic     6.7  10.1   6.2\n  Other        6.7  10.1   6.2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-results",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-independence-results",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of independence (results)",
    "text": "Chi Squared test of independence (results)\n\nRecall that:\n\n\n\\(H_{0}\\): the 2 cat. var. are independent\n\n\n\\(H_{1}\\): the 2 cat. var. are correlated in some way\n\n\nThe result of Chi-Square test represents a comparison of the above two tables (observed v. expected):\n\np-value = 0.01286 smaller than Œ± = 0.05 so we REJECT the null hypothesis (i.e.¬†there‚Äôs likely an association between race and ACTN3 gene)\n\n\n\n\ntest_chi\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 19.4, df = 8, p-value = 0.01286"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence",
    "href": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Computing Cramer‚Äôs V after test of independence",
    "text": "Computing Cramer‚Äôs V after test of independence\n\nRecall that Crammer‚Äôs V allows to measure the effect size of the test of independence (i.e.¬†the strength of association between two nominal variables)\n\n\n\\(V\\) ranges from [0 1] (the smaller \\(V\\), the lower the correlation)\n\n\\[V=\\sqrt{\\frac{\\chi^2}{n(k-1)}} \\]\nwhere:\n\n\n\\(V\\) denotes Cram√©r‚Äôs V\n\n\\(\\chi^2\\) is the Pearson chi-square statistic from the prior test\n\n\\(n\\) is the sample size involved in the test\n\n\\(k\\) is the lesser number of categories of either variable"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence-2-ways",
    "href": "practice/practice_slides/slides_lab03.html#computing-cramers-v-after-test-of-independence-2-ways",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Computing Cramer‚Äôs V after test of independence (2 ways)",
    "text": "Computing Cramer‚Äôs V after test of independence (2 ways)\n\n\n‚úçüèª ‚ÄúBy hand‚Äù first to see the steps\n\n\n# Compute Creamer's V by hand\n \n# inputs \nchi_calc &lt;- test_chi$statistic\nn &lt;- nrow(famuss) # N of obd \nn_r &lt;- nrow(test_chi$observed) # number of rows in the contingency table\nn_c &lt;- ncol(test_chi$observed) # number of columns in the contingency table\n\n# Cramer‚Äôs V\nsqrt(chi_calc / (n*min(n_r -1, n_c -1)) )\n\nX-squared \n0.1276816 \n\n\n\nüë©üèª‚Äçüíª Using an R function rstatix::cramer_v\n\n\n\n# Cramer‚Äôs V with rstatix\nrstatix::cramer_v(test_chi$observed)\n\n[1] 0.1276816\n\n\nCramer‚Äôs V = 0.12, which indicates a relatively weak association between the two categorical variables. It suggests that while there may be some relationship between the variables, it is not particularly strong."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit",
    "text": "Chi Squared test of goodness of fit\nIn some cases the Chi-square test examines whether or not an observed frequency distribution matches an expected theoretical distribution.\nHere, we are conducting a type of Chi-square Goodness of Fit Test which:\n\nserves to test whether the observed distribution of a categorical variable differs from your expectations\ninterprets the statistic based on the discrepancies between observed and expected counts"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit (example)",
    "text": "Chi Squared test of goodness of fit (example)\n\nSince the participants of the FAMuSS study where volunteers at a university, they did not come from a ‚Äúrepresentative‚Äù sample of the US population, we can use the \\(\\chi^{2}\\) goodness of fit test to test against:\n\n\n\\(H_{0}\\): the study participants (1st row below) are racially representative of the general population (2nd row below)\n\n\n\n\n\n\n\nRace\nAfrican.American\nAsian\nCaucasian\nOther\nTotal\n\n\n\nFAMuSS (Observed) \n27\n55\n467\n46\n595\n\n\nUS Census (Expected) \n76.16\n5.95\n478.38\n34.51\n595\n\n\n\n\n\n\nWe use the formula \\[\\chi^{2} = \\sum_{k}\\frac{(Observed - Expected)^{2}}{Expected}\\]\nUnder \\(H_{0}\\), the sample proportions should equal the population proportions."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example-1",
    "href": "practice/practice_slides/slides_lab03.html#chi-squared-test-of-goodness-of-fit-example-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Chi Squared test of goodness of fit (example)",
    "text": "Chi Squared test of goodness of fit (example)\n\n\n# Subset the vectors of frequencies from the 2 rows  \nobserved &lt;- c(27,  55,  467, 46)\nexpected &lt;- c(76.2,  5.95, 478.38,  34.51)\n\n# Calculate Chi-Square statistic manually \nchi_sq_statistic &lt;- sum((observed - expected)^2 / expected) \ndf &lt;- length(observed) - 1 \np_value &lt;- 1 - pchisq(chi_sq_statistic, df) \n\n# Print results \nchi_sq_statistic\n\n[1] 440.2166\n\ndf\n\n[1] 3\n\np_value \n\n[1] 0\n\n\nThe calculated \\(\\chi^{2}\\) statistic is very large, and the p_value is close to 0. Hence, there is more than sufficient evidence to reject the null hypothesis that the sample is representative of the general population.\nComparing the observed and expected values (or the residuals), we find the largest discrepancy with the over-representation of Asian study participants."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: BMI and age",
    "text": "Visualize the data: BMI and age\nWe are mainly looking for a ‚Äúvaguely‚Äù linear shape here\n\n\nggplot2 gives us a visual confirmation with geom_point()\n\nEssentially, geom_smooth() adds a trend line over an existing plot\n\ninside the function, we have different options with the method argument (default is LOESS (locally estimated scatterplot smoothing))\nwith method = lm we get the linear best fit (the least squares regression line) & its 95% CI\n\n\n\n\nggplot(nhanes, aes (x = age, \n                          y = bmi)) + \n  geom_point() + \n  geom_smooth(method = lm,  \n              #se = FALSE\n              )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-bmi-and-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: BMI and age",
    "text": "Visualize the data: BMI and age"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-model",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model",
    "text": "Linear regression model\nThe lm() function is used to fit linear models has the following generic structure:\n\nlm(y ~ x, data)\n\nwhere:\n\nthe 1st argument y ~ x specifies the variables used in the model (here the model regresses a response variable \\(y\\) against an explanatory variable \\(x\\).\nThe 2nd argument data is used only when the dataframe name is not already specified in the first argument."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models syntax",
    "text": "Linear regression models syntax\nThe following example shows fitting a linear model that predicts BMI from age (in years) using data from nhanes adult sample (individuals 21 years of age or older from the NHANES data).\n\n# fitting linear model\nlm(nhanes$bmi ~ nhanes$age)\n\n\n# or equivalently...\nlm(bmi ~ age, data = nhanes)\n\n\nCall:\nlm(formula = bmi ~ age, data = nhanes)\n\nCoefficients:\n(Intercept)          age  \n   28.40113      0.01982  \n\n\n\nRunning the function creates an object (of class lm) that contains several components (model coefficients, etc), either directly displayed or accessible with summary() notation or specific functions."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax-1",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-syntax-1",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models syntax",
    "text": "Linear regression models syntax\n\n\nWe can save the model and then extract individual output elements from it using the $ syntax\n\n# name the model object\nlr_model &lt;- lm(bmi ~ age, data = nhanes)\n\n# extract model output elements\nlr_model$coefficients\nlr_model$residuals\nlr_model$fitted.values\n\nThe command summary returns these elements\n\n\nCall: reminds the equation used for this regression model\n\nResiduals: a 5 number summary of the distribution of residuals from the regression model\n\nCoefficients:displays the estimated coefficients of the regression model and relative hypothesis testing, given for:\n\nintercept\nexplanatory variable(s) slope"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models interpretation: coefficients",
    "text": "Linear regression models interpretation: coefficients\n\nThe model tests the null hypothesis \\(H_{0}\\) that a coefficient is 0\n\ncoefficients outputs are: estimate, std. error, t-statistic, and p-value correspondent to the t-statistic for:\n\nintercept\n\nexplanatory variable(s) slope\n\n\nIn regression, the population parameter of interest is typically the slope parameter\n\nin this model, age doesn‚Äôt appear significantly ‚â† 0\n\n\n\n\nsummary(lr_model)$coefficients \n\n               Estimate Std. Error   t value      Pr(&gt;|t|)\n(Intercept) 28.40112932 0.96172389 29.531480 2.851707e-111\nage          0.01981675 0.01824641  1.086063  2.779797e-01"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients-2",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-interpretation-coefficients-2",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models interpretation: Coefficients 2",
    "text": "Linear regression models interpretation: Coefficients 2\nFor the the estimated coefficients of the regression model, we get:\n\n\nEstimate = the average increase in the response variable associated with a one unit increase in the predictor variable, (assuming all other predictor variables are held constant).\n\nStd. Error = a measure of the uncertainty in our estimate of the coefficient. \n\n\nt value = the t-statistic for the predictor variable, calculated as (Estimate) / (Std. Error).\n\nPr(&gt;|t|) = the p-value that corresponds to the t-statistic. If less than some alpha level (e.g.¬†0.05). the predictor variable is said to be statistically significant."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-fitted-values",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-fitted-values",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models outputs: fitted values",
    "text": "Linear regression models outputs: fitted values\nHere we see \\(\\hat{y}_i\\), i.e.¬†the fitted \\(y\\) value for the \\(i\\)-th individual\n\nfit_val &lt;- lr_model$fitted.values\n\n# print the first 6 elements\nhead(fit_val)\n\n       1        2        3        4        5        6 \n29.39197 29.33252 29.31270 28.95600 29.39197 29.17398"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-residuals",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-outputs-residuals",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression models outputs: residuals",
    "text": "Linear regression models outputs: residuals\nHere we see \\(e_i = y_i - \\hat{y}_i\\), i.e.¬†the residual value for the \\(i\\)-th individual\n\nresid_val &lt;- lr_model$residuals \n\n# print the first 6 elements\nhead(resid_val)\n\n          1           2           3           4           5           6 \n-1.49196704  0.06748322 -3.96270002 -3.15599844 -2.49196704  3.75601726"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-residual-standard-error",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-residual-standard-error",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: Residual standard error",
    "text": "Linear regression model‚Äôs fit: Residual standard error\n\n\nThe Residual standard error (an estimate of the parameter \\(\\sigma\\)) tells the average distance that the observed values fall from the regression line (we are assuming constant variance).\n\nThe smaller it is, the better the model fits the dataset!\n\n\n\nWe can compute it manually as:\n\\({\\rm SE}_{resid}=\\ \\sqrt{\\frac{\\sum_{i=1}^{n}{(y_i-{\\hat{y}}_i)}^2}{{\\rm df}_{resid}}}\\)\n\n# Residual Standard error (Like Standard Deviation)\n\n# ---  inputs \n# sample size\nn =length(lr_model$residuals)\n# n of parameters in the model\nk = length(lr_model$coefficients)-1 #Subtract one to ignore intercept\n# degrees of freedom of the the residuals \ndf_resid = n-k-1\n# Squared Sum of Errors\nSSE =sum(lr_model$residuals^2) # 22991.19\n\n# --- Residual Standard Error\nResStdErr &lt;- sqrt(SSE/df_resid)  # 6.815192\nResStdErr\n\n[1] 6.815192"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-r2-and-adj.-r2",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-r2-and-adj.-r2",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: : \\(R^2\\) and \\(Adj. R^2\\)",
    "text": "Linear regression model‚Äôs fit: : \\(R^2\\) and \\(Adj. R^2\\)\n\nThe \\(R^2\\) tells us the proportion of the variance in the response variable that can be explained by the predictor variable(s).\n\nif \\(R^2\\) close to 0 -&gt; data more spread\nif \\(R^2\\) close to 1 -&gt; data more tight around the regression line\n\n\n# --- R^2\nsummary(lr_model)$r.squared\n\n[1] 0.00237723\n\n\nThe \\(Adj. R^2\\) is a modified version of \\(R^2\\) that has been adjusted for the number of predictors in the model.\n\nIt is always lower than the R-squared\nIt can be useful for comparing the fit of different regression models that use different numbers of predictor variables.\n\n\n# --- Adj. R^2\nsummary(lr_model)$adj.r.squared\n\n[1] 0.0003618303"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-f-statistic",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-models-fit-f-statistic",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression model‚Äôs fit: : F statistic",
    "text": "Linear regression model‚Äôs fit: : F statistic\nThe F-statistic indicates whether the regression model provides a better fit to the data than a model that contains no independent variables. In essence, it tests if the regression model as a whole is useful.\n\n# extract only F statistic \nsummary(lr_model)$fstatistic \n\n     value      numdf      dendf \n  1.179533   1.000000 495.000000 \n\n# define function to extract overall p-value of model\noverall_p &lt;- function(my_model) {\n    f &lt;- summary(my_model)$fstatistic\n    p &lt;- pf(f[1],f[2],f[3],lower.tail=F)\n    attributes(p) &lt;- NULL\n    return(p)\n}\n\n# extract overall p-value of model\noverall_p(lr_model)\n\n[1] 0.2779797\n\n\nGiven the p-value is &gt; 0.05, this indicate that the predictor variable is not useful for predicting the value of the response variable."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: residuals 1/4",
    "text": "Linear regression diagnostic plots: residuals 1/4\n\nASSUMPTION 1: there exists a linear relationship between the independent variable, x, and the dependent variable, y\n\nFor an observation \\((x_i, y_i)\\), where \\(\\hat{y}_i\\) is the predicted value according to the line \\(\\hat{y} = b_0 + b_1x\\), the residual is the value \\(e_i = y_i - \\hat{y}_i\\)\n\nA linear (e.g.¬†lr_model) is a particularly good fit for the data when the residual plot shows random scatter above and below the horizontal line.\n\n(In this R plot, we look for a red line that is fairly straight)\n\n\n\n\n# residual plot\nplot(lr_model, which = 1 )\n\n\n\nWe use the argument which in the function plot so we see the plots one at a time."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-residuals-14-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: residuals 1/4",
    "text": "Linear regression diagnostic plots: residuals 1/4"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: normality of residuals 2/4",
    "text": "Linear regression diagnostic plots: normality of residuals 2/4\n\nASSUMPTION 2: The residuals of the model are normally distributed\n\nWith the quantile-quantile plot (Q-Q) we can checking normality of the residuals.\n\n# quantile-quantile plot\nplot(lr_model, which = 2 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-normality-of-residuals-24-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: normality of residuals 2/4",
    "text": "Linear regression diagnostic plots: normality of residuals 2/4\n\n\nThe data appear roughly normal, but there are deviations from normality in the tails, particularly the upper tail."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: Homoscedasticity 3/4",
    "text": "Linear regression diagnostic plots: Homoscedasticity 3/4\n\nASSUMPTION 3: The residuals have constant variance at every level of x (‚Äúhomoscedasticity‚Äù)\n\nThis one is called a Spread-location plot: shows if residuals are spread equally along the ranges of predictors\n\n# Spread-location plot\nplot(lr_model, which = 3 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-homoscedasticity-34-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: Homoscedasticity 3/4",
    "text": "Linear regression diagnostic plots: Homoscedasticity 3/4"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#test-for-homoscedasticity",
    "href": "practice/practice_slides/slides_lab03.html#test-for-homoscedasticity",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Test for Homoscedasticity",
    "text": "Test for Homoscedasticity\n\nBesides visual check, we can perform the Breusch-Pagan test to verify the assumption of homoscedasticity. In this case:\n\n\\(H_{0}\\): residuals are distributed with equal variance\n\\(H_{1}\\): residuals are distributed with UNequal variance\nwe use bptest function from the lmtest package\n\n\n# Breusch-Pagan test against heteroskedasticity \nlmtest::bptest(lr_model)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lr_model\nBP = 2.7548, df = 1, p-value = 0.09696\n\n\nBecause the test statistic (BP) is small and the p-value is not significant (p-value &gt; 0.05): WE DO NOT REJECT THE NULL HYPOTHESIS (i.e.¬†we can assume equal variance)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: leverage 4/4",
    "text": "Linear regression diagnostic plots: leverage 4/4\nThis last diagnostic plot has to do with outliers:\n\nA residuals vs.¬†leverage plot allows us to identify influential observations in a regression model\n\nThe x-axis shows the ‚Äúleverage‚Äù of each point and the y-axis shows the ‚Äústandardized residual of each point‚Äù, i.e.¬†‚ÄúHow much would the coefficients in the regression model would change if a particular observation was removed from the dataset?‚Äù\n\n\nCook's distance lines (red dashed lines) ‚Äì not visible here ‚Äì should appear on the corners of the plot when there are influential cases\n\n\n\n\nplot(lr_model, which = 5 )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44-output",
    "href": "practice/practice_slides/slides_lab03.html#linear-regression-diagnostic-plots-leverage-44-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Linear regression diagnostic plots: leverage 4/4",
    "text": "Linear regression diagnostic plots: leverage 4/4\n\n\nIn this particular case, there is no influential case, or cases"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#digression-on-the-broom-package",
    "href": "practice/practice_slides/slides_lab03.html#digression-on-the-broom-package",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "(Digression on the broom package)",
    "text": "(Digression on the broom package)\n\n\nThe broom package introduces the tidy approach to regression modeling code and outputs, allowing to convert/save them in the form of tibbles\n\nThe function tidy will turn an object into a tidy tibble\nThe function glance will construct a single row summary ‚Äúglance‚Äù of a model, fit, or other object\nThe function augment will show a lot of results for the model attached to each observation\n\nthis is very useful for further use of such objects, like ggplot2 etc.\n\n\n\n\n# render model as a dataframe \nbroom::tidy(lr_model)\n\n# see overal performance \nbroom::glance(lr_model)\n\n# save an object with all the model output elements \nmodel_aug &lt;- broom::augment(lr_model)\n\n\n\n\n You try‚Ä¶\n\n\nRun these functions and then run View(model_aug) to check out the output"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function",
    "text": "Visualize the data: Statin use and cognitive function\nStatins are a class of drugs widely used to lower cholesterol (recent guidelines would lead to statin use in almost half of Americans between 40 - 75 years of age and nearly all men over 60). But a few small studies have suggested that statins may be associated with lower cognitive ability.\n\nFrom this sample of the PREVEND study, we can observe the relationship between statin use (statin_use) and cognitive ability (rfft).\n\n\n# rename for convenience\nprevend &lt;- prevend_samp %&gt;% janitor::clean_names() %&gt;% \n  #create statin.use logical + factor\n  mutate(statin_use = as.logical(statin)) %&gt;% \n  mutate(statin_use_f = factor(statin, levels = c(0,1), labels = c(\"NonUser\", \"User\")))   \n \n# box plot \nggplot(prevend, \n       aes (x = statin_use_f, y = rfft, fill = statin_use_f)) + \n  geom_boxplot(alpha=0.5) +\n  scale_fill_manual(values=c(\"#005ca1\",\"#9b2339\" )) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function",
    "text": "Visualize the data: Statin use and cognitive function\n\n\nThe boxplot suggests that statin user (red) present lower cognitive ability score, on average"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#confirm-visual-intuition-with-independent-sample-t-test",
    "href": "practice/practice_slides/slides_lab03.html#confirm-visual-intuition-with-independent-sample-t-test",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Confirm visual intuition with independent sample t-test",
    "text": "Confirm visual intuition with independent sample t-test\nWe could use an independent t-test to confirm what the boxplot shows\n\nt_test_w &lt;- t.test(prevend$rfft[prevend$statin == 1], \n                   prevend$rfft[prevend$statin == 0],\n                   # here we specify the situation\n                   var.equal = TRUE,\n                   paired = FALSE, alternative = \"two.sided\") \n\nt_test_w\n\n\n    Two Sample t-test\n\ndata:  prevend$rfft[prevend$statin == 1] and prevend$rfft[prevend$statin == 0]\nt = -3.4917, df = 498, p-value = 0.0005226\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -15.710276  -4.396556\nsample estimates:\nmean of x mean of y \n 60.66087  70.71429 \n\n\n‚Ä¶statistically significant difference in means (Statin use: yes and no) do exist"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#consider-simple-linear-regression-statin-use-and-cognitive-function",
    "href": "practice/practice_slides/slides_lab03.html#consider-simple-linear-regression-statin-use-and-cognitive-function",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Consider Simple Linear regression: Statin use and cognitive function",
    "text": "Consider Simple Linear regression: Statin use and cognitive function\n\n‚Ä¶ and build a simple linear regression model like so:\n\\[E(RFFT) = b_0 + b_{statin} {(Statin\\ use)}\\]\n\n#fit the linear model\nmodel_1 &lt;- lm(rfft ~ statin, data=prevend)\nsummary(model_1)\n\n\nCall:\nlm(formula = rfft ~ statin, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.714 -22.714   0.286  18.299  73.339 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   70.714      1.381  51.212  &lt; 2e-16 ***\nstatin       -10.053      2.879  -3.492 0.000523 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.09 on 498 degrees of freedom\nMultiple R-squared:  0.0239,    Adjusted R-squared:  0.02194 \nF-statistic: 12.19 on 1 and 498 DF,  p-value: 0.0005226\n\n\n\nThis preliminary model shows that, on average, statin users score approximately 10 points lower on the RFFT cognitive test (and the statin coefficient is highly significant!)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function + age",
    "text": "Visualize the data: Statin use and cognitive function + age\nHowever, following the literature, this prelimary model might be misleading (biased) because it does not account for the underlying relationship between age and statin\n\nhence age could be a confounder within the statin -&gt; RFFT relationship\n\n\nggplot(prevend, \n       aes (x = age, y = rfft, group = statin_use)) + \n  geom_point (aes(color = statin_use , size=.01, alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" )) + \n  # decades line separators \n  geom_vline(xintercept = 40, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 50, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 60, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 70, color = \"#A6A6A6\")+\n  geom_vline(xintercept = 80, color = \"#A6A6A6\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age-output",
    "href": "practice/practice_slides/slides_lab03.html#visualize-the-data-statin-use-and-cognitive-function-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Visualize the data: Statin use and cognitive function + age",
    "text": "Visualize the data: Statin use and cognitive function + age\n\n\nStatin users are represented with red points; participants not using statins are shown as blue points"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#multiple-linear-regression-model",
    "href": "practice/practice_slides/slides_lab03.html#multiple-linear-regression-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Multiple linear regression model",
    "text": "Multiple linear regression model\nMultiple regression allows for a (richer) model that incorporates both statin use and age:\n\\[E(RFFT) = b_0 + b_{statin} {(Statin\\ use)}+ b_{age} {(Age)}\\]\n\nor (in statistical terms) the association between RFFT and Statin use is being estimated after adjusting for Age\n\n\nThe R syntax is very easy: simply use + to add covariates\n\n# fit the (multiple) linear model\nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#rfft-vs.-statin-use-age",
    "href": "practice/practice_slides/slides_lab03.html#rfft-vs.-statin-use-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "RFFT vs.¬†statin use & age‚Ä¶",
    "text": "RFFT vs.¬†statin use & age‚Ä¶\nAlthough the use of statins appeared to be associated with lower RFFT scores when no adjustment was made for possible confounders, statin use is not significantly associated with RFFT score in a regression model that adjusts for age.\n\nsummary(model_2)\n\n\nCall:\nlm(formula = rfft ~ statin + age, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-63.855 -16.860  -1.178  15.730  58.751 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 137.8822     5.1221  26.919   &lt;2e-16 ***\nstatin        0.8509     2.5957   0.328    0.743    \nage          -1.2710     0.0943 -13.478   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.21 on 497 degrees of freedom\nMultiple R-squared:  0.2852,    Adjusted R-squared:  0.2823 \nF-statistic: 99.13 on 2 and 497 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumptions-for-multiple-regression",
    "href": "practice/practice_slides/slides_lab03.html#assumptions-for-multiple-regression",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumptions for multiple regression",
    "text": "Assumptions for multiple regression\nSimilar to those of simple linear regression‚Ä¶\n\n\nLinearity: For each predictor variable \\(x_j\\), change in the predictor is linearly related to change in the response variable when the value of all other predictors is held constant.\n\nConstant variability: The residuals have approximately constant variance.\n\nNormality of residuals: The residuals are approximately normally distributed.\n\nIndependent observations: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nNo multicollinearity: i.e.¬†no situations when there is a strong linear correlation between the independent variables, conditional on the other variables in the model"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: age",
    "text": "Using residual plots to assess LINEARITY: age\n\nASSUMPTION 1: there exists a linear relationship between the independent variables, \\((x_1, x_2, \\dots, x_p)\\), and the dependent variable, y\n\nIt is not possible to make a scatterplot of a response against several simultaneous predictors. Instead, use a modified residual plot to assess linearity:\n\nFor each (numerical) predictor, plot the residuals on the \\(y\\)-axis and the predictor values on the \\(x\\)-axis.\nPatterns/curvature are indicative of non-linearity.\n\n\n# recall \nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)\n\n# assess linearity\nplot(residuals(model_2) ~ prevend$age,\n     main = \"Residuals vs Age in PREVEND (n = 500)\",\n     xlab = \"Age (years)\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-age-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: age",
    "text": "Using residual plots to assess LINEARITY: age\n\n\nThere are no apparent trends; the data scatter evenly above and below the horizontal line. There does not seem to be remaining nonlinearity with respect to age after the model is fit."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: statin use",
    "text": "Using residual plots to assess LINEARITY: statin use\nShould we be testing linearity of residuals also against a categorical variable (statin use)? (not really, because not meaningful)\n\n# recall \nmodel_2 &lt;- lm(rfft ~ statin + age , data=prevend)\n\n#assess linearity\nplot(residuals(model_2) ~ prevend$statin,\n     main = \"Residuals vs Age in PREVEND (n = 500)\",\n     xlab = \"Age (years)\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-linearity-statin-use-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess LINEARITY: statin use",
    "text": "Using residual plots to assess LINEARITY: statin use\n\n\nIt is not necessary to assess linearity with respect to statin use since statin use is measured as a categorical variable. A line drawn through two points (that is, the mean of the two groups defined by a binary variable) is necessarily linear"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess CONSTANT VARIABILITY",
    "text": "Using residual plots to assess CONSTANT VARIABILITY\n\nASSUMPTION 2: The residuals have constant variance at every level of x (‚Äúhomoscedasticity‚Äù)\n\n\nConstant variability: plot the residual values on the \\(y\\)-axis and the predicted values on the \\(x\\)-axis\n\n\n#assess constant variance of residuals\nplot(residuals(model_2) ~ fitted(model_2),\n     main = \"Resid. vs Predicted RFFT in PREVEND (n = 500)\",\n     xlab = \"Predicted RFFT Score\", ylab = \"Residual\",\n     pch = 21, col = \"cornflowerblue\", bg = \"slategray2\",\n     cex = 0.60)\nabline(h = 0, col = \"red\", lty = 2)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-constant-variability-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess CONSTANT VARIABILITY",
    "text": "Using residual plots to assess CONSTANT VARIABILITY\n\n\nThe variance of the residuals is somewhat smaller for lower predicted values of RFFT score, but this may simply be an artifact from observing few individuals with relatively low predicted scores. It seems reasonable to assume approximately constant variance."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess NORMALITY of residuals",
    "text": "Using residual plots to assess NORMALITY of residuals\n\nASSUMPTION 3: The residuals of the model are normally distributed - Normality of residuals: use Q-Q plots\n\n\n#assess normality of residuals\nqqnorm(resid(model_2),\n       pch = 21, col = \"cornflowerblue\", bg = \"slategray2\", cex = 0.75,\n       main = \"Q-Q Plot of Residuals\")\nqqline(resid(model_2), col = \"red\", lwd = 2)\n\n\nIn our example, we see that most data points are OK, except some observations at the tails. However, if all other plots indicate no violation of assumptions, some deviation of normality, particularly at the tails, can be less critical."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals-output",
    "href": "practice/practice_slides/slides_lab03.html#using-residual-plots-to-assess-normality-of-residuals-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Using residual plots to assess NORMALITY of residuals",
    "text": "Using residual plots to assess NORMALITY of residuals\n\n\nThe residuals are reasonably normally distributed, with only slight departures from normality in the tails."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-independence-of-observations",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-independence-of-observations",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of INDEPENDENCE of observations",
    "text": "Assumption of INDEPENDENCE of observations\n\nASSUMPTION 4: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nIs it reasonable to assume that each set of observations is independent of the others?\n\nUsing the PREVEND data, it is reasonable to assume that the observations in this dataset are independent. The participants were recruited from a large city in the Netherlands for a study focusing on factors associated with renal and cardiovascular disease."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of NO MULTICOLLINEARITY",
    "text": "Assumption of NO MULTICOLLINEARITY\n\n\nASSUMPTION 5: Each set of observations \\((y, x_1, x_2, \\dots, x_p)\\) is independent.\n\nThe R package performance actually provides a very helpful function check_model() which tests these assumptions all at the same time\n\n\nMulticollinearity is not an issue (based on a general threshold of 10 for VIF, all of them are below 10)\n\n\n# return and store a list of single plots\ndiagnostic_plots &lt;- plot(performance::check_model(model_2, panel = FALSE))\n\n# see multicollinearity plot \ndiagnostic_plots[[5]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity-output",
    "href": "practice/practice_slides/slides_lab03.html#assumption-of-no-multicollinearity-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Assumption of NO MULTICOLLINEARITY",
    "text": "Assumption of NO MULTICOLLINEARITY"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#checking-out-the-performance-r-package",
    "href": "practice/practice_slides/slides_lab03.html#checking-out-the-performance-r-package",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Checking out the performance R package",
    "text": "Checking out the performance R package\n\nFind more info on the helpful performance R package here for verifying assumptions and model‚Äôs quality and goodness of fit.\n\n\n\n\n You try‚Ä¶\n\n\nRun also the following commands\n\nDiagnostic plot of linearity diagnostic_plots[[2]]\n\nDiagnostic plot of influential observations - outliers diagnostic_plots[[4]]\n\nDiagnostic plot of normally distributed residuals diagnostic_plots[[6]]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#r2-with-multiple-regression",
    "href": "practice/practice_slides/slides_lab03.html#r2-with-multiple-regression",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "\\(R^2\\) with multiple regression",
    "text": "\\(R^2\\) with multiple regression\n\nAs in simple regression, \\(R^2\\) represents the proportion of variability in the response variable explained by the model.\n\nAs variables are added, \\(R^2\\) always increases.\n\nIn the summary(lm( )) output, Multiple R-squared is \\(R^2\\).\n\n#extract R^2 of a model\nsummary(model_2)$r.squared\n\n[1] 0.2851629\n\n\n\nThe \\(R^2\\) is 0.285; the model explains 28.5% of the observed variation in RFFT score. The moderately low \\(R^2\\) suggests that the model is missing other predictors of RFFT score."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#adjusted-r2-as-a-tool-for-model-assessment",
    "href": "practice/practice_slides/slides_lab03.html#adjusted-r2-as-a-tool-for-model-assessment",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Adjusted \\(R^2\\) as a tool for model assessment",
    "text": "Adjusted \\(R^2\\) as a tool for model assessment\nThe adjusted \\(R^2\\) is computed as:\\[R_{adj}^{2} = 1- \\left( \\frac{\\text{Var}(e_i)}{\\text{Var}(y_i)} \\times \\frac{n-1}{n-p-1} \\right)\\]\n\nwhere \\(n\\) is the number of cases and \\(p\\) is the number of predictor variables.\n\nAdjusted \\(R^2\\) incorporates a penalty for including predictors that do not contribute much towards explaining observed variation in the response variable.\n\nIt is often used to balance predictive ability with model complexity.\nUnlike \\(R^2\\), \\(R^2_{adj}\\) does not have an inherent interpretation.\n\n\n#extract adjusted R^2 of a model\nsummary(model_2)$adj.r.squared\n\n[1] 0.2822863"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - (example)",
    "text": "Categorical predictor in regression - (example)\n\nIs RFFT score associated with education? The variable Education in the PREVEND dataset indicates the highest level of education an individual completed in the Dutch educational system:\n\n0: primary school\n1: lower secondary school\n2: higher secondary education\n3: university education\n\n\n# convert Education to a factor\nprevend &lt;- prevend %&gt;% \n  mutate(educ_f = factor(education,\n                          levels = c(0, 1, 2, 3),\n                          labels = c(\"Primary\", \"LowerSecond\",\n                                     \"HigherSecond\", \"Univ\")))\n\n\n# load 4 color palette\npacificharbour_shades &lt;- c( \"#d4e6f3\",  \"#9cc6e3\", \"#5b8bac\", \"#39576c\",  \"#16222b\")\n\n# create plot\nplot(rfft ~ educ_f, data = prevend,\n     xlab = \"Educational Level\", ylab = \"RFFT Score\",\n     main = \"RFFT by Education in PREVEND (n = 500)\",\n     names = c(\"Primary\", \"LowSec\", \"HighSec\", \"Univ\"),\n     col = pacificharbour_shades[1:4])"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example-output",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---example-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - (example)",
    "text": "Categorical predictor in regression - (example)\n\n\nA very clear association seems to exist between education level and average RFFT score in the sample"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - model",
    "text": "Categorical predictor in regression - model\n\nCalculate the average RFFT score in the sample across education levels\n\n# calculate group means\nprevend %&gt;% \n  group_by(educ_f) %&gt;% \n  summarise(avg_RFFT_score = mean(rfft))\n\n# A tibble: 4 √ó 2\n  educ_f       avg_RFFT_score\n  &lt;fct&gt;                 &lt;dbl&gt;\n1 Primary                40.9\n2 LowerSecond            55.7\n3 HigherSecond           73.1\n4 Univ                   85.9\n\n\nFitting a model with education as a predictor\n\n# fit a model\nmodel_cat &lt;- lm(rfft ~ educ_f, data = prevend) \nmodel_cat$coefficients\n\n       (Intercept)  educ_fLowerSecond educ_fHigherSecond         educ_fUniv \n          40.94118           14.77857           32.13345           44.96389 \n\n\n\nNotice how Primary level of educ_f does NOT appear as a coefficient"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model-interpretation",
    "href": "practice/practice_slides/slides_lab03.html#categorical-predictor-in-regression---model-interpretation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Categorical predictor in regression - model interpretation",
    "text": "Categorical predictor in regression - model interpretation\n\n\n\n\nCall:\nlm(formula = rfft ~ educ_f, data = prevend)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-55.905 -15.975  -0.905  16.068  63.280 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          40.941      3.203  12.783  &lt; 2e-16 ***\neduc_fLowerSecond    14.779      3.686   4.009 7.04e-05 ***\neduc_fHigherSecond   32.133      3.763   8.539  &lt; 2e-16 ***\neduc_fUniv           44.964      3.684  12.207  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.87 on 496 degrees of freedom\nMultiple R-squared:  0.3072,    Adjusted R-squared:  0.303 \nF-statistic:  73.3 on 3 and 496 DF,  p-value: &lt; 2.2e-16\n\n\nThe baseline category represents individuals who at most completed primary school Education = 0. The coefficients represent the change in estimated average RFFT relative to the baseline category.\n\n\n(Intercept) is the sample mean RFFT score for these individuals, 40.94 points\nAn increase of 14.78 points is predicted for LowerSecond level, \\(40.94 + 14.78 = 55.72 \\ points\\)\n\nAn increase of 32.13 points is predicted for HigherSecond level, \\(40.94 + 32.13 = 73.07  \\ points\\)\n\nAn increase of 44.96 points is predicted for Univ level, \\(40.94 + 44.96 = 85.90 \\ points\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---example---nhanes",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---example---nhanes",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - (example) - NHANES",
    "text": "Interaction in regression - (example) - NHANES\nLet‚Äôs go back to the NHANES dataset and consider a linear model that predicts total cholesterol level (mmol/L) from age (yrs.) and diabetes status.\nThe multiple regression model:\n\\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_px_p + \\epsilon\\]\nassumes that when one of the predictors \\(x_j\\) is changed by 1 unit and the values of the other variables remain constant, the predicted response changes by \\(\\beta_j\\), regardless of the values of the other variables.\n\nWith statistical interaction, this assumption is not true, such that the effect of one explanatory variable \\(x_j\\) on the \\(y\\) depends on the particular value(s) of one or more other explanatory variables."
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual",
    "text": "Interaction in regression - visual\nFitting a model with age and diabetes as independent predictors (i.e.¬†WITHOUT interaction terms)\n\n# fit a model\nmodel_NOinterac &lt;- lm(tot_chol ~ age + diabetes, data = nhanes) \nmodel_NOinterac$coefficients\n\n (Intercept)          age  diabetesYes \n 4.800011340  0.007491805 -0.317665963 \n\n\n\nUsing geom_smooth for a visual intuition of a linear relationship\n\n‚ö†Ô∏è here I consider sample DATA as a whole for plotting a smooth line\n\n\n\n\nggplot(nhanes, \n       aes (x = age, y = tot_chol)) + \n  # For POINTS I split by category (category)\n  geom_point (aes(color = diabetes, \n                  alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" )) + \n  # For SMOOTHED LINES I take ALL data\n  geom_smooth(colour=\"#BD8723\",  method = lm)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-output",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual",
    "text": "Interaction in regression - visual\n\n\nUsers in two categories are represented points; linear relationship is representated by ONE golden line for ALL SAMPLE"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual (RETHINKING)",
    "text": "Interaction in regression - visual (RETHINKING)\nSuppose two separate models were fit for the relationship between total cholesterol and age; one in diabetic individuals and one in non-diabetic individuals.\n\nUsing geom_smooth for a visual intuition of a linear relationship\n\n‚ö†Ô∏è here I consider sample DATA as 2 separate groups for plotting a smooth line\n\n\n\n\nggplot(nhanes, \n       # For *both POINTS & LINES* I split by category (category)\n       aes (x = age, y = tot_chol, color = diabetes)) + \n  geom_point (aes(alpha = 0.75),\n              show.legend = c(size = F, alpha = F) )+\n  geom_smooth(method = lm)+ \n  scale_color_manual(values=c(\"#005ca1\",\"#9b2339\" ))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking-output",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---visual-rethinking-output",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - visual (RETHINKING)",
    "text": "Interaction in regression - visual (RETHINKING)\n\n\nUsers in two categories are represented points; linear relationship is representated by 2 respective line according to diabetes status‚Ä¶ the association has DIFFERENT DIRECTION!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---adding-term-in-model",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---adding-term-in-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - adding term in model",
    "text": "Interaction in regression - adding term in model\nLet‚Äôs rethink the model and consider this new specification:\n\\[E(TotChol) = \\beta_0 + \\beta_1(Age) + \\beta_2(Diabetes) + \\beta_3(Diabetes \\times Age).\\]\nWhere: + the term \\((Diabetes \\times Age)\\) is the interaction term between diabetes status and age, and \\(\\beta_3\\) is the coefficient of such interaction term.\n\nnotice the use of ...*... in the model syntax\n\n\n#fit a model\nmodel_interac2 &lt;- lm(tot_chol ~ age*diabetes, data = nhanes) \nmodel_interac2$coefficients\n\n    (Intercept)             age     diabetesYes age:diabetesYes \n    4.695702513     0.009638183     1.718704342    -0.033451562"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---prediction-model",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---prediction-model",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - prediction model",
    "text": "Interaction in regression - prediction model\n\nWe obtained this predictive model: \\[\\widehat{TotChol} = 4.70 + 0.0096(Age) + 0.1.72(Diabetes) - 0.033(Age \\times Diabetes)\\]\n\nsummary(model_interac2)\n\n\nCall:\nlm(formula = tot_chol ~ age * diabetes, data = nhanes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3587 -0.7448 -0.0845  0.6307  4.2480 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      4.695703   0.159691  29.405  &lt; 2e-16 ***\nage              0.009638   0.003108   3.101  0.00205 ** \ndiabetesYes      1.718704   0.763905   2.250  0.02492 *  \nage:diabetesYes -0.033452   0.012272  -2.726  0.00665 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.061 on 469 degrees of freedom\n  (27 observations deleted due to missingness)\nMultiple R-squared:  0.03229,   Adjusted R-squared:  0.0261 \nF-statistic: 5.216 on 3 and 469 DF,  p-value: 0.001498"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#interaction-in-regression---interactive-term-interpretation",
    "href": "practice/practice_slides/slides_lab03.html#interaction-in-regression---interactive-term-interpretation",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Interaction in regression - interactive term interpretation",
    "text": "Interaction in regression - interactive term interpretation\n\nGiven:\n\\(\\widehat{TotChol} = 4.70 + 0.0096(Age) + 0.1.72(Diabetes) - 0.033(Age \\times Diabetes)\\) For diabetics ( DiabetesYes = 1 ), the model equation is:\n\\(TotChol_{diab} =  4.70 + 0.0096(Age) + 1.72(1) - 0.034(Age)(1)\\) i.e.\\(TotChol_{diab} =  6.42 - 0.024(Age)\\)\n\nFor non-diabetics ( DiabetesYes = 0 ), the model equation is:\n\\(TotChol_{NOdiab} =  4.70 + 0.0096(Age) + 1.72(0) - 0.034(Age)(0)\\) i.e.\\(TotChol_{NOdiab} =  4.70 + 0.0096(Age)\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab03.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab03.html#final-thoughtsrecommendations",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\n\n\nThe analyses proposed in this Lab are very similar to the process we go through in real life. The following steps are always included:\n\nThorough understanding of the input data and the data collection process\nBivariate analysis of correlation / association to form an intuition of which explanatory variable(s) may or may not affect the response variable\n\nDiagnostic plots to verify if the necessary assumptions are met for a linear model to be suitable\nUpon verifying the assumptions, we fit data to hypothesized (linear) model\n\nAssessment of the model performance (\\(R^2\\), \\(Adj. R^2\\), \\(F-Statistic\\), etc.)\n\n\nAs we saw with hypothesis testing, the assumptions we make (and require) for regression are of utter importance\n\nClearly, we only scratched the surface in terms of all the possible predictive models, but we got a hang of the fundamental steps and some useful tools that might serve us also in more advanced analysis\n\ne.g.¬†broom (within tidymodels), performace rstatix, lmtest\n\n\n\n\n\n\n\n\nR 4 Biostatistics | MITGEST::training(2024)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#goal-of-todays-practice-session",
    "href": "practice/practice_slides/slides_lab01.html#goal-of-todays-practice-session",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "GOAL OF TODAY‚ÄôS PRACTICE SESSION",
    "text": "GOAL OF TODAY‚ÄôS PRACTICE SESSION\n\nMotivate the choice of learning/using R for scientific quantitative analysis, and lay out some fundamental concepts in biostatistics with concrete R coding examples.\n\n\nLecture 1: topics\n\n\nIntroduction to R and R-studio\n\nWhy R?\nPrinciples of reproducible analysis with R + RStudio\n\n\nR objects, functions, packages\n\nUnderstanding different types of variables\n\nPrinciples of ‚Äútidy data‚Äù\n\n\n\nDescriptive statistics\n\nMeasures of central tendency, measures of variability (or spread), and frequency distribution\n\n\n\nVisual data exploration\n\n{ggplot2}"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#r-version",
    "href": "practice/practice_slides/slides_lab01.html#r-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "R version",
    "text": "R version\nIf you have previously installed R on your machine, you can check which version you are running by executing this command in R:\n\n# check your R version\nR.Version()\n\n$platform\n[1] \"x86_64-apple-darwin17.0\"\n\n$arch\n[1] \"x86_64\"\n\n$os\n[1] \"darwin17.0\"\n\n$system\n[1] \"x86_64, darwin17.0\"\n\n$status\n[1] \"\"\n\n$major\n[1] \"4\"\n\n$minor\n[1] \"2.2\"\n\n$year\n[1] \"2022\"\n\n$month\n[1] \"10\"\n\n$day\n[1] \"31\"\n\n$`svn rev`\n[1] \"83211\"\n\n$language\n[1] \"R\"\n\n$version.string\n[1] \"R version 4.2.2 (2022-10-31)\"\n\n$nickname\n[1] \"Innocent and Trusting\"\n\n# or just\n#R.version.string"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install",
    "href": "practice/practice_slides/slides_lab01.html#install",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install \n",
    "text": "Install \n\n\n\n\nR is available for free for Windows , GNU/Linux , and macOS .\n\nTo install R, go to this link https://cloud.r-project.org/. The latest available release is R 4.3.3 ‚ÄúAngel Food Cake‚Äù released on 2024-02/29, but any (fairly recent) version will do."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-rstudio-ide",
    "href": "practice/practice_slides/slides_lab01.html#install-rstudio-ide",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install RStudio IDE",
    "text": "Install RStudio IDE\nRStudio Desktop is an Integrated Development Editor (IDE), basically a graphical interface wrapping and interfacing R (which needs to be installed first).\nBesides RStudio, R (which is a command line driven program) can be executed:\n\nvia its native interface (R GUI)\nfrom many other code editors, like VS Code, Sublime Text, Jupyter Notebook\n\n\n\nTo install RStudio, go to this link https://posit.co/download/rstudio-desktop/. The free-version contains everything you need."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#use-rstudio-ide",
    "href": "practice/practice_slides/slides_lab01.html#use-rstudio-ide",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Use RStudio IDE",
    "text": "Use RStudio IDE\n\nRStudio Pane Layout Source: Posit‚Äôs RStudio User Guide"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio",
    "href": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Creating an R Project [in Rstudio]",
    "text": "Creating an R Project [in Rstudio]\nAn R Project will keep all the files associated with a project (including invisible ones!) organized together ‚Äì input data, R scripts, analytical results, figures. Besides being common practice, this has the advantage of implicitly setting the ‚Äúworking directory‚Äù, which is incredibly important when you need to load or output files, specifying their file path.\nIn Figure¬†1 you can see how easy it is just following RStudio prompts:\n\nCreate a new directory for each project\nSelect parent folder"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio-cont.",
    "href": "practice/practice_slides/slides_lab01.html#creating-an-r-project-in-rstudio-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Creating an R Project [in Rstudio] (cont.)",
    "text": "Creating an R Project [in Rstudio] (cont.)\n\n\nFigure¬†1: Creating an R project\nNotice that, now, in the Files tab you see file with the extension .Rproj which is telling R that all folder‚Äôs files belong together."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-from-cran-stable-version",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-from-cran-stable-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages from CRAN (stable version)",
    "text": "Install R packages from CRAN (stable version)\nAn R package*  is a shareable bundle of functions. Besides the basic built-in functions already contained in the program (i.e.¬†the base, stats, utils packages), many useful R functions come in free libraries of code (or packages) written by R‚Äôs users. You can find them in different repositories:\nTo install a package use utils function install.packages(\"package_name)\n\n# Installing (ONLY the 1st time)\nutils::install.packages('here')\n\n# OR (same)\ninstall.packages('here')\n\n\n\nHere you are actually using a function (install.packages) of a pre-installed package (utils) using the syntax packagename::function_name. This prevents any ambiguity in case of duplicate function name‚Ä¶ also helps you see what you are using."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-rstudio-pane",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-rstudio-pane",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages RStudio pane",
    "text": "Install R packages RStudio pane\nIn alternative, you can install/update packages using the Packages tab on the lower right pane of RStudio.\n\nScreenshot Install/Update pckgs from RStudio"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#install-r-packages-from-github-testing-version",
    "href": "practice/practice_slides/slides_lab01.html#install-r-packages-from-github-testing-version",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Install R packages from GitHub (testing version)",
    "text": "Install R packages from GitHub (testing version)\nUse install_github from the package devtools.EXAMPLE: let‚Äôs install a little package paint (which colors the structure of dataset when printing).\n\n\n\nCode\n\n# Installing devtools (ONLY the 1st time)\nutils::install.packages('devtools')\n\n# Installing paint from GitHub \nlibrary(devtools)\ndevtools::install_github(\"MilesMcBain/paint\")\n\n# test paint out\nlibrary(paint)\n\n\nOutput {paint} function\n\n# Structure of a data.frame \npaint::paint(mtcars)\n\n\n\n\n\n[After devtools::install_github(\"MilesMcBain/paint\"), R asks me if I want to update related packages‚Ä¶]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#use-r-packages",
    "href": "practice/practice_slides/slides_lab01.html#use-r-packages",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Use R Packages",
    "text": "Use R Packages\n\nWe will be using {base} & {utils} (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\nlibrary(fs)        # file/directory interactions\nlibrary(here)      # tools find your project's files, based on working directory\nlibrary(janitor)   # tools for examining and cleaning data\nlibrary(skimr)     # tools for summary statistics \nlibrary(dplyr)     # {tidyverse} tools for manipulating and summarising tidy data \nlibrary(forcats)   # {tidyverse} tool for handling factors\nlibrary(ggplot2)   # {tidyverse} tools for plotting\nlibrary(ggridges)  # alternative to plot density functions"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#help-on-r-packagefunction",
    "href": "practice/practice_slides/slides_lab01.html#help-on-r-packagefunction",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Help on R package/function",
    "text": "Help on R package/function\nTo inquire about a package and/or its functions, you can again write in your console ?package_name or ??package_name and RStudio will open up the Help tab in the lower right pane.\n\n# Opening Help page on package/function\n?here\n\n??here"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#file-paths-logistics",
    "href": "practice/practice_slides/slides_lab01.html#file-paths-logistics",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "File paths logistics",
    "text": "File paths logistics\nIt is never good practice to ‚Äúhard code‚Äù the file‚Äôs absolute path: most likely it will break your code as soon as you (or someone else) need to run it on a different computer, let alone within a different OS.\n\nLet‚Äôs look at this example code using function readr::read_csv() (which reads a *.csv data file into the R workspace)\n\n# [NOT REPRODUCIBLE] hard coding your file path  -----------------------\n\n# File path on Mac:\ndataset &lt;- readr::read_csv(\"/Users/testuser/R4biostats/input_data/dataset.csv\")\n# Same file path on Windows:\ndataset &lt;- readr::read_csv(\"C:\\Users\\testuser\\R4biostats\\input_data\\dataset.csv\")\n\nüôÑ ‚Ä¶it won‚Äôt work on any other computer since it won‚Äôt have that same file structure!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#reproducible-file-paths-with-here-in-rstudio",
    "href": "practice/practice_slides/slides_lab01.html#reproducible-file-paths-with-here-in-rstudio",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(Reproducible) file paths with here (in Rstudio)",
    "text": "(Reproducible) file paths with here (in Rstudio)\n\nThe here package lets you reference file paths in a reproducible manner (anchored on the R Project‚Äôs folder as the root).\n\n\nWhere is my Working Directory?\n\nhere::here()\n\nYou should get: ‚Äú/Users/YourName/RProj_Dir‚Äù  Now, you can embed here(dir,subdir) specifications in other functions.\nFor example, create sub-directories (for saving input data and output data) with the fs package\n\n## --- [check the function documentation]\n?fs::dir_create\n# with `here` I simply add subfolder names relative to my wd \nfs::dir_create(here(\"practice\", \"data\",\"data_input\"))\n# ...and a subfolder to put output files at the end\nfs::dir_create(here(\"practice\", \"data\",\"data_output\"))\n\n## --- [if I need to remove it (I have them already)]\nfs::dir_delete(here(\"practice\", \"data\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#importing-data-into-r-workspace",
    "href": "practice/practice_slides/slides_lab01.html#importing-data-into-r-workspace",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Importing data into R workspace",
    "text": "Importing data into R workspace\nWe use utils::read.csv to load a csv file\n\n?read.csv # to learn about function and arguments"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-importing-from-a-url",
    "href": "practice/practice_slides/slides_lab01.html#option-1-importing-from-a-url",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1: Importing from a url",
    "text": "Option 1: Importing from a url\n\nautism_data_url &lt;- read.csv(\n  file = \"https://raw.githubusercontent.com/Sydney-Informatics-Hub/lessonbmc/gh-pages/_episodes_rmd/data/autism_data.csv\", \n  header = TRUE, # 1st line is the name of the variables\n  sep = \",\", # which is the field separator character.\n  na.strings = c(\"?\") # specific values R should interpret as NA\n)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-importing-from-my-folder-if-you-previously-downloaded-the-file",
    "href": "practice/practice_slides/slides_lab01.html#option-2-importing-from-my-folder-if-you-previously-downloaded-the-file",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2: Importing from my folder (if you previously downloaded the file)",
    "text": "Option 2: Importing from my folder (if you previously downloaded the file)\n\n\nhere lets me specify the complete path of the destination folder\n\n\n\n\n\n\n\n\nTip\n\n\nMake sure to match your own folder structure the file path here(...)!\n\n\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nautism_data_file &lt;- read.csv(\n  file = here(\"practice\", \"data_input\", \"01_datasets\", \"autism_data.csv\"), \n  header = TRUE, # 1st line is the name of the variables\n  sep = \",\", # which is the field separator character.\n  na.strings = c(\"?\"),# specific values R should interpret as NA\n  row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#viewing-the-dataset-and-variables",
    "href": "practice/practice_slides/slides_lab01.html#viewing-the-dataset-and-variables",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Viewing the dataset and variables",
    "text": "Viewing the dataset and variables\n\nView(autism_data_file)\n\n\nOr click on the object in Environment tab (upper right pane of RStudio)\n\n\n# What data type is this data?\nclass(autism_data_file)\n\n[1] \"data.frame\"\n\n# What variables are included in this dataset?\nbase::colnames(autism_data_file)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class.ASD\"      \n\n\n\nNotice the variable name formatting inconsistency: Class.ASD"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#manipulate-clean-the-dataframe",
    "href": "practice/practice_slides/slides_lab01.html#manipulate-clean-the-dataframe",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Manipulate / clean the dataframe",
    "text": "Manipulate / clean the dataframe\nI want consistent name formatting for variables: no ‚Äú.‚Äù, only ‚Äú_‚Äù separator. So, I use a very handy function clean_names from the janitor package\n\nautism_data &lt;- janitor::clean_names(autism_data_file, \n                                     case = \"none\") \n# check change\ncolnames(autism_data)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"      \n\ndim(autism_data)\n\n[1] 704  22\n\n\n\nBy default clean_names renames cols into ‚Äúsnake‚Äù format (i.e.¬†‚Äúabc_xyz‚Äù)\nThe option case is for capitalization preferences\n\n\ncase = \"none\" leaves the case as is, but only uses ‚Äú_‚Äù separator"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#isolate-a-variable-column",
    "href": "practice/practice_slides/slides_lab01.html#isolate-a-variable-column",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Isolate a variable (column)",
    "text": "Isolate a variable (column)\nYou can use the $ sign to extract a variable (column name)\n\nautism_data$id\nautism_data$A1_Score\nautism_data$gender\nautism_data$autism"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-a-new-column",
    "href": "practice/practice_slides/slides_lab01.html#add-a-new-column",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Add a new column",
    "text": "Add a new column\n(I prefer to rename the dataframe when I make changes)\n\n# rename dataframe \nautism_pids &lt;- autism_data\n\nCreate a new column, using paste (function to concatenate strings)\n\n# create a new column \nautism_pids$pids &lt;- paste(\"PatientID_\" , autism_data$id, sep = \"\")\n\nCheck results:\n\n# check change in df structure\nbase::colnames(autism_pids)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"       \"pids\"           \n\ndim(autism_data)\n\n[1] 704  22\n\ndim(autism_pids)\n\n[1] 704  23"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#optional-clean-up-workspace",
    "href": "practice/practice_slides/slides_lab01.html#optional-clean-up-workspace",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(optional) Clean up workspace",
    "text": "(optional) Clean up workspace\n\n# what do I have in the environment? \nls() \n\n[1] \"autism_data\"      \"autism_data_file\" \"autism_pids\"     \n\n# remove all EXCEPT for \"autism_pids\" \nrm(\"autism_data\", \"autism_data_file\", \"autism_data_url\" ) \n\n\n\n\n(Warning: mind that after rm(), you will not have these objects in your workspace anymore.)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-extract-cols-with",
    "href": "practice/practice_slides/slides_lab01.html#option-1-extract-cols-with",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 Extract cols with $",
    "text": "Option 1 Extract cols with $\n\n(head only specifies to take the first 6 observations of the dataset)\n\n\n# With the `$` sign I extract a variable (column name)\nhead(autism_pids$id) \n\n[1] 1 2 3 4 5 6\n\nhead(autism_pids$pids)\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" \"PatientID_5\"\n[6] \"PatientID_6\"\n\nhead(autism_pids$A1_Score)\n\n[1] 1 1 1 1 1 1\n\nhead(autism_pids$ethnicity)\n\n[1] \"White-European\" \"Latino\"         \"Latino\"         \"White-European\"\n[5] NA               \"Others\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2a-extract-cols-with-col",
    "href": "practice/practice_slides/slides_lab01.html#option-2a-extract-cols-with-col",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2a Extract cols with [,#col]",
    "text": "Option 2a Extract cols with [,#col]\n\nThis is called ‚Äúindexing‚Äù\n\n\n# Indexing to pick `[ , #col]`  \nhead(autism_pids[ ,1] )# empty rows means all \n\n[1] 1 2 3 4 5 6\n\nhead(autism_pids[ ,23])\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" \"PatientID_5\"\n[6] \"PatientID_6\"\n\nhead(autism_pids[ ,2])\n\n[1] 1 1 1 1 1 1\n\nhead(autism_pids[ ,14])\n\n[1] \"White-European\" \"Latino\"         \"Latino\"         \"White-European\"\n[5] NA               \"Others\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2b-extract-rows-with-row",
    "href": "practice/practice_slides/slides_lab01.html#option-2b-extract-rows-with-row",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2b Extract rows with [#row,]",
    "text": "Option 2b Extract rows with [#row,]\n\n# Indexing to pick `[#row, ]`  \nhead(autism_pids[1 , ] ) # empty cols means all \n\n  id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n1  1        1        1        1        1        0        0        1        1\n  A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n1        0         0  26      f White-European       no     no United States\n  used_app_before result    age_desc relation Class_ASD        pids\n1              no      6 18 and more     Self        NO PatientID_1\n\nhead(autism_pids[50,])\n\n   id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n50 50        1        1        0        0        0        1        1        1\n   A9_Score A10_Score age gender ethnicity jaundice autism contry_of_res\n50        0         1  30      f     Asian       no     no    Bangladesh\n   used_app_before result    age_desc relation Class_ASD         pids\n50              no      6 18 and more     Self        NO PatientID_50\n\nhead(autism_pids[25:26 ,])\n\n   id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n25 25        1        1        1        1        0        0        0        1\n26 26        0        1        1        0        0        0        0        1\n   A9_Score A10_Score age gender ethnicity jaundice autism contry_of_res\n25        0         0  43      m      &lt;NA&gt;       no     no       Lebanon\n26        0         0  24      f      &lt;NA&gt;      yes     no   Afghanistan\n   used_app_before result    age_desc relation Class_ASD         pids\n25              no      5 18 and more     &lt;NA&gt;        NO PatientID_25\n26              no      3 18 and more     &lt;NA&gt;        NO PatientID_26"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-3-extract-rows-cols-with-rowcol",
    "href": "practice/practice_slides/slides_lab01.html#option-3-extract-rows-cols-with-rowcol",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 3 Extract rows & cols with [#row,#col]",
    "text": "Option 3 Extract rows & cols with [#row,#col]\n\n# Indexing to pick `[#row, #col]`  \nautism_pids[1:3,1]\n\n[1] 1 2 3\n\nautism_pids[1:3,23]\n\n[1] \"PatientID_1\" \"PatientID_2\" \"PatientID_3\"\n\nautism_pids[1:3,2]\n\n[1] 1 1 1\n\nautism_pids[1:3,14]\n\n[1] \"White-European\" \"Latino\"         \"Latino\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions",
    "href": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 using base functions",
    "text": "Option 1 using base functions\n\non the whole dataset\n\n\n# What are the data types of the variables? ---------------------------------\nstr(autism_pids) # integer and character\n\n'data.frame':   704 obs. of  23 variables:\n $ id             : int  1 2 3 4 5 6 7 8 9 10 ...\n $ A1_Score       : int  1 1 1 1 1 1 0 1 1 1 ...\n $ A2_Score       : int  1 1 1 1 0 1 1 1 1 1 ...\n $ A3_Score       : int  1 0 0 0 0 1 0 1 0 1 ...\n $ A4_Score       : int  1 1 1 1 0 1 0 1 0 1 ...\n $ A5_Score       : int  0 0 1 0 0 1 0 0 1 0 ...\n $ A6_Score       : int  0 0 0 0 0 0 0 0 0 1 ...\n $ A7_Score       : int  1 0 1 1 0 1 0 0 0 1 ...\n $ A8_Score       : int  1 1 1 1 1 1 1 0 1 1 ...\n $ A9_Score       : int  0 0 1 0 0 1 0 1 1 1 ...\n $ A10_Score      : int  0 1 1 1 0 1 0 0 1 0 ...\n $ age            : int  26 24 27 35 40 36 17 64 29 17 ...\n $ gender         : chr  \"f\" \"m\" \"m\" \"f\" ...\n $ ethnicity      : chr  \"White-European\" \"Latino\" \"Latino\" \"White-European\" ...\n $ jaundice       : chr  \"no\" \"no\" \"yes\" \"no\" ...\n $ autism         : chr  \"no\" \"yes\" \"yes\" \"yes\" ...\n $ contry_of_res  : chr  \"United States\" \"Brazil\" \"Spain\" \"United States\" ...\n $ used_app_before: chr  \"no\" \"no\" \"no\" \"no\" ...\n $ result         : int  6 5 8 6 2 9 2 5 6 8 ...\n $ age_desc       : chr  \"18 and more\" \"18 and more\" \"18 and more\" \"18 and more\" ...\n $ relation       : chr  \"Self\" \"Self\" \"Parent\" \"Self\" ...\n $ Class_ASD      : chr  \"NO\" \"NO\" \"YES\" \"NO\" ...\n $ pids           : chr  \"PatientID_1\" \"PatientID_2\" \"PatientID_3\" \"PatientID_4\" ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions-cont.",
    "href": "practice/practice_slides/slides_lab01.html#option-1-using-base-functions-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 1 using base functions (cont.)",
    "text": "Option 1 using base functions (cont.)\n\non specific columns\n\n\n# What values can the variables take? ---------------------------------\nsummary(autism_pids$pids)\n\n   Length     Class      Mode \n      704 character character \n\nlength(unique(autism_pids$pids)) # N unique values\n\n[1] 704\n\nsum(is.na(autism_pids$pids)) # N missing values\n\n[1] 0\n\nsummary(autism_pids$ethnicity)\n\n   Length     Class      Mode \n      704 character character \n\nlength(unique(autism_pids$ethnicity)) # N unique values\n\n[1] 12\n\nsum(is.na(autism_pids$ethnicity)) # N missing values\n\n[1] 95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim",
    "href": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2 using skimr function skim\n",
    "text": "Option 2 using skimr function skim\n\n\non specific columns\n\n\nautism_pids %&gt;% \n  skimr::skim(pids, ethnicity) %&gt;%\n  dplyr::select(#skim_variable, \n                skim_type, \n                complete_rate,\n                n_missing, \n                character.n_unique)\n\n\n\n# A tibble: 2 √ó 4\n  skim_type complete_rate n_missing character.n_unique\n  &lt;chr&gt;             &lt;dbl&gt;     &lt;int&gt;              &lt;int&gt;\n1 character         1             0                704\n2 character         0.865        95                 11"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim-cont.",
    "href": "practice/practice_slides/slides_lab01.html#option-2-using-skimr-function-skim-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Option 2 using skimr function skim (cont.)",
    "text": "Option 2 using skimr function skim (cont.)\n\non the whole dataset\n\n\nautism_pids %&gt;% \n  skimr::skim() \n\n\n\n\n‚îÄ‚îÄ Variable type: character ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   skim_variable   n_missing complete_rate min max empty n_unique whitespace\n 1 gender                  0         1       1   1     0        2          0\n 2 ethnicity              95         0.865   5  15     0       11          0\n 3 jaundice                0         1       2   3     0        2          0\n 4 autism                  0         1       2   3     0        2          0\n 5 contry_of_res           0         1       4  20     0       67          0\n 6 used_app_before         0         1       2   3     0        2          0\n 7 age_desc                0         1      11  11     0        1          0\n 8 relation               95         0.865   4  24     0        5          0\n 9 Class_ASD               0         1       2   3     0        2          0\n10 pids                    0         1      11  13     0      704          0\n\n‚îÄ‚îÄ Variable type: numeric ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   skim_variable n_missing complete_rate    mean      sd p0  p25  p50  p75 p100\n 1 id                    0         1     352.    203.     1 177. 352. 528.  704\n 2 A1_Score              0         1       0.722   0.449  0   0    1    1     1\n 3 A2_Score              0         1       0.453   0.498  0   0    0    1     1\n 4 A3_Score              0         1       0.457   0.499  0   0    0    1     1\n 5 A4_Score              0         1       0.496   0.500  0   0    0    1     1\n 6 A5_Score              0         1       0.499   0.500  0   0    0    1     1\n 7 A6_Score              0         1       0.284   0.451  0   0    0    1     1\n 8 A7_Score              0         1       0.418   0.494  0   0    0    1     1\n 9 A8_Score              0         1       0.649   0.478  0   0    1    1     1\n10 A9_Score              0         1       0.324   0.468  0   0    0    1     1\n11 A10_Score             0         1       0.574   0.495  0   0    1    1     1\n12 age                   2         0.997  29.2     9.71  17  21   27   35    64\n13 result                0         1       4.88    2.50   0   3    4    7    10"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to factor using base R",
    "text": "From character to factor using base R\n\n#### char 2 factor -------------------------------------------------------------\n# Say I want to treat some variables as factors\nautism_pids$gender &lt;- as.factor(autism_pids$gender)\nautism_pids$ethnicity &lt;- as.factor(autism_pids$ethnicity)\nautism_pids$contry_of_res &lt;- as.factor(autism_pids$contry_of_res)\nautism_pids$relation &lt;- as.factor(autism_pids$relation)\n\n# check \nclass(autism_pids$gender)\n\n[1] \"factor\"\n\nclass(autism_pids$ethnicity)\n\n[1] \"factor\"\n\nclass(autism_pids$contry_of_res)\n\n[1] \"factor\"\n\nclass(autism_pids$relation)\n\n[1] \"factor\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r-n-cols",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-factor-using-base-r-n-cols",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to factor using base R (n cols)",
    "text": "From character to factor using base R (n cols)\n\nautism_pids_temp &lt;- autism_pids # copy df for test \n\nto_factor &lt;- c(\"gender\", \"ethnicity\", \"contry_of_res\", \"relation\") # vector of col names \nautism_pids_temp[ ,to_factor] &lt;-  lapply(X =  autism_pids[ ,to_factor], FUN = as.factor)\n\n# check \nclass(autism_pids_temp$gender)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$ethnicity)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$contry_of_res)\n\n[1] \"factor\"\n\nclass(autism_pids_temp$relation)\n\n[1] \"factor\"\n\n# now I have Variable type: factor"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways",
    "href": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Inspect factors levels (3 different ways)",
    "text": "Inspect factors levels (3 different ways)\n\nusing base::levels function\n\n\nlevels(autism_pids$ethnicity)\n\n [1] \"Asian\"           \"Black\"           \"Hispanic\"        \"Latino\"         \n [5] \"Middle Eastern \" \"others\"          \"Others\"          \"Pasifika\"       \n [9] \"South Asian\"     \"Turkish\"         \"White-European\" \n\n\n\nusing base::table function\n\n\ntable(autism_pids$ethnicity,useNA = \"ifany\")\n\n\n          Asian           Black        Hispanic          Latino Middle Eastern  \n            123              43              13              20              92 \n         others          Others        Pasifika     South Asian         Turkish \n              1              30              12              36               6 \n White-European            &lt;NA&gt; \n            233              95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways-cont.",
    "href": "practice/practice_slides/slides_lab01.html#inspect-factors-levels-3-different-ways-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Inspect factors levels ‚Äì 3 different ways (cont.)",
    "text": "Inspect factors levels ‚Äì 3 different ways (cont.)\n\nusing janitor function tabyl, which uses the ‚Äúpipe‚Äù operator %&gt;% which takes the output of a function as input of the next one\n\n\njanitor::tabyl(autism_pids$ethnicity) %&gt;% \n  adorn_totals() %&gt;% \n  adorn_pct_formatting()\n\n autism_pids$ethnicity   n percent valid_percent\n                 Asian 123   17.5%         20.2%\n                 Black  43    6.1%          7.1%\n              Hispanic  13    1.8%          2.1%\n                Latino  20    2.8%          3.3%\n       Middle Eastern   92   13.1%         15.1%\n                others   1    0.1%          0.2%\n                Others  30    4.3%          4.9%\n              Pasifika  12    1.7%          2.0%\n           South Asian  36    5.1%          5.9%\n               Turkish   6    0.9%          1.0%\n        White-European 233   33.1%         38.3%\n                  &lt;NA&gt;  95   13.5%             -\n                 Total 704  100.0%        100.0%"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#identify-missing-values",
    "href": "practice/practice_slides/slides_lab01.html#identify-missing-values",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Identify missing values",
    "text": "Identify missing values\nUse is.na to check if the 95 missing obs are the same missing for ethnicity and relation\n\nwhich(is.na(autism_pids$ethnicity)) # indices of TRUE elements in vector\n\n [1]   5  13  14  15  20  21  25  26  63  80  81  82  92 217 222 239 258 271 277\n[20] 278 286 307 316 325 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n[39] 352 353 354 355 356 362 366 370 371 373 379 380 381 382 383 384 385 386 387\n[58] 388 389 391 396 400 401 402 404 424 428 429 430 433 439 454 486 506 519 528\n[77] 535 536 537 538 557 565 572 573 589 594 637 643 646 652 653 659 660 667 702\n\nwhich(is.na(autism_pids$relation))  # indices of TRUE elements in vector\n\n [1]   5  13  14  15  20  21  25  26  63  80  81  82  92 217 222 239 258 271 277\n[20] 278 286 307 316 325 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n[39] 352 353 354 355 356 362 366 370 371 373 379 380 381 382 383 384 385 386 387\n[58] 388 389 391 396 400 401 402 404 424 428 429 430 433 439 454 486 506 519 528\n[77] 535 536 537 538 557 565 572 573 589 594 637 643 646 652 653 659 660 667 702\n\n\n‚Ä¶indeed they are the same IDs!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-logical",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-logical",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to logical",
    "text": "From character to logical\nI may prefer to code a variable as logical. For example, age_desc may be more explicit if coded as logical.\n\nI create a new column age_desc_log\n\n\n\n# observe a subset of some columns \nautism_subset &lt;- autism_pids [1:5, c(\"gender\",\"jaundice\", \"autism\",\"age_desc\",\n                                     \"Class_ASD\",\"pids\")]\n# View(autism_subset)\n\n# recode \"age_desc\" as LOGICAL new var \"age_desc_log\"\nautism_pids$age_desc_log &lt;- ifelse(autism_pids$age_desc == \"18 and more\", TRUE, FALSE )\nclass(autism_pids$age_desc)\n\n[1] \"character\"\n\nclass(autism_pids$age_desc_log)\n\n[1] \"logical\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#from-character-to-dummy-01",
    "href": "practice/practice_slides/slides_lab01.html#from-character-to-dummy-01",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "From character to dummy [0,1]",
    "text": "From character to dummy [0,1]\nI also may need binary variables expressed as [0,1] (e.g.¬†to incorporate nominal variables into regression analysis). Let‚Äôs recode autism.\n\nautism_pids$autism_dummy &lt;- ifelse(autism_pids$autism == 'yes', 1, 0)\nclass(autism_pids$autism)\n\n[1] \"character\"\n\nclass(autism_pids$autism_dummy)\n\n[1] \"numeric\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#subsetting-the-data-for-further-investigation",
    "href": "practice/practice_slides/slides_lab01.html#subsetting-the-data-for-further-investigation",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Subsetting the data for further investigation",
    "text": "Subsetting the data for further investigation\nRecall how to view the names of columns / variables\n\ncolnames(autism_pids)\n\n [1] \"id\"              \"A1_Score\"        \"A2_Score\"        \"A3_Score\"       \n [5] \"A4_Score\"        \"A5_Score\"        \"A6_Score\"        \"A7_Score\"       \n [9] \"A8_Score\"        \"A9_Score\"        \"A10_Score\"       \"age\"            \n[13] \"gender\"          \"ethnicity\"       \"jaundice\"        \"autism\"         \n[17] \"contry_of_res\"   \"used_app_before\" \"result\"          \"age_desc\"       \n[21] \"relation\"        \"Class_ASD\"       \"pids\"            \"age_desc_log\"   \n[25] \"autism_dummy\""
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils",
    "href": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "using head or tail from utils\n",
    "text": "using head or tail from utils\n\n\n\nhead or tail return the first or last parts of an object\n\n\nhead(autism_pids)   #return fist 6 obs\ntail(autism_pids)   #return last 6 obs"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils-cont.",
    "href": "practice/practice_slides/slides_lab01.html#using-head-or-tail-from-utils-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "using head or tail from utils (cont.)",
    "text": "using head or tail from utils (cont.)\n\nhead(autism_pids, n = 2) #return fist 2 obs\n\n  id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n1  1        1        1        1        1        0        0        1        1\n2  2        1        1        0        1        0        0        0        1\n  A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n1        0         0  26      f White-European       no     no United States\n2        0         1  24      m         Latino       no    yes        Brazil\n  used_app_before result    age_desc relation Class_ASD        pids\n1              no      6 18 and more     Self        NO PatientID_1\n2              no      5 18 and more     Self        NO PatientID_2\n  age_desc_log autism_dummy\n1         TRUE            0\n2         TRUE            1\n\ntail(autism_pids, n = 2) #return last 2 obs\n\n     id A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score\n703 703        1        0        0        1        1        0        1        0\n704 704        1        0        1        1        1        0        1        1\n    A9_Score A10_Score age gender      ethnicity jaundice autism contry_of_res\n703        1         1  35      m    South Asian       no     no      Pakistan\n704        1         1  26      f White-European       no     no        Cyprus\n    used_app_before result    age_desc relation Class_ASD          pids\n703              no      6 18 and more     Self        NO PatientID_703\n704              no      8 18 and more     Self       YES PatientID_704\n    age_desc_log autism_dummy\n703         TRUE            0\n704         TRUE            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#investigating-a-subset-of-observations",
    "href": "practice/practice_slides/slides_lab01.html#investigating-a-subset-of-observations",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Investigating a subset of observations",
    "text": "Investigating a subset of observations\nE.g. I learned that some patients have missing age‚Ä¶ how many are they?\n\n# run...\nsum(is.na(autism_pids$age)) \n\n[1] 2\n\n# or \nskimr::n_missing(autism_pids$age)\n\n[1] 2\n\n\n So, next, I want to ID those patients with missing age."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 1) using [] from base\n\n\nmissing_age_subset &lt;- autism_pids[is.na(autism_pids$age), \n                                  c(\"pids\", \"age\", \"autism_dummy\") ]\nmissing_age_subset\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-1",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 2) using which from base\n\n\nmissing_age_subset2 &lt;- autism_pids[which(is.na(autism_pids$age)), \n                                   c(\"pids\", \"age\", \"autism_dummy\")] \nmissing_age_subset2\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-2",
    "href": "practice/practice_slides/slides_lab01.html#new-df-patients-missing-age-as-subset-of-the-given-df-2",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (patients missing age) as SUBSET of the given df",
    "text": "New df (patients missing age) as SUBSET of the given df\nI want to extract only the obs (rows) of interest with a few useful vars (cols)\nOption 3) using subset from base\n\n\n# arguments allow me to specify rows and cols \nmissing_age_subset3 &lt;- subset(x = autism_pids, \n                              subset = is.na(autism_pids$age), # 1 logical condition\n                              select = c(\"pids\", \"age\", \"autism_dummy\") # which cols\n                              ) \nmissing_age_subset3\n\n           pids age autism_dummy\n63 PatientID_63  NA            0\n92 PatientID_92  NA            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df",
    "href": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (filtering on 2 conditions) as SUBSET of the given df",
    "text": "New df (filtering on 2 conditions) as SUBSET of the given df\nOption 1) using base::subset\n\n\n# Creates a SUBSET based on MORE conditions (`age` and `ethnicity`)\ntwocond_base_subset &lt;- subset(x = autism_pids, \n                       # 2 logical conditions      \n                       subset = age &lt; 25 & contry_of_res == \"Brazil\", \n                       # pick a few cols \n                       select = c(\"pids\", \"age\", \"contry_of_res\",\n                                  \"autism_dummy\")) \n\ntwocond_base_subset\n\n             pids age contry_of_res autism_dummy\n2     PatientID_2  24        Brazil            1\n54   PatientID_54  21        Brazil            1\n94   PatientID_94  19        Brazil            1\n429 PatientID_429  20        Brazil            0\n587 PatientID_587  21        Brazil            0\n588 PatientID_588  21        Brazil            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df-1",
    "href": "practice/practice_slides/slides_lab01.html#new-df-filtering-on-2-conditions-as-subset-of-the-given-df-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "New df (filtering on 2 conditions) as SUBSET of the given df",
    "text": "New df (filtering on 2 conditions) as SUBSET of the given df\nOption 2) using dplyr (filter + select)\nSwitching to the package dplyr and embracing the ‚Äúpipe‚Äù (%&gt;%) operator logic, in which the filtering (rows) and selecting (columns) is done in sequence\n\n## here the filtering (rows) and selecting (columns) is done in sequence\ntwocond_dplyr_subset &lt;- autism_pids %&gt;% \n  dplyr::filter(age &lt; 25 & contry_of_res == \"Brazil\") %&gt;%  # which rows\n  dplyr::select (pids, age, contry_of_res, autism_dummy)   # which cols\n\ntwocond_dplyr_subset\n\n           pids age contry_of_res autism_dummy\n1   PatientID_2  24        Brazil            1\n2  PatientID_54  21        Brazil            1\n3  PatientID_94  19        Brazil            1\n4 PatientID_429  20        Brazil            0\n5 PatientID_587  21        Brazil            0\n6 PatientID_588  21        Brazil            0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#input-values-where-missing",
    "href": "practice/practice_slides/slides_lab01.html#input-values-where-missing",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Input values where missing",
    "text": "Input values where missing\n\n‚ö†Ô∏è WARNINGÔ∏é: This is a very delicate & substantial step ‚ö†Ô∏è\n\nany modified/imputed data (beyond the original collection) can affect subsequent analysis and statistical modeling\nit will be necessary to document and justify whichever approach is used to deal with missing data.  Let‚Äôs assume we can get the missing data by cross-checking related clinical information\n\n\n# 1/2 create a new variable \nautism_pids$age_inputed &lt;- autism_pids$age\n# 2/2 replace value (presumably taken from other source) of `aged_inputed` \n  # CONDITIONAL on `pids`\nautism_pids$age_inputed[autism_pids$pids == \"PatientID_63\"] &lt;-  65\nautism_pids$age_inputed[autism_pids$pids == \"PatientID_92\"] &lt;-  45\n\n# check\nskimr::n_missing(autism_pids$age) \n\n[1] 2\n\nskimr::n_missing(autism_pids$age_inputed)  \n\n[1] 0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#summarizing-all-variables",
    "href": "practice/practice_slides/slides_lab01.html#summarizing-all-variables",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Summarizing all variables",
    "text": "Summarizing all variables\nTry these 2 options: \n\n\nbase::summary\n\nsummary(autism_pids)\n\n\nskimr::skim\n\nskimr::skim(autism_pids)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type",
    "href": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Notice summary different behavior according to the variable‚Äôs type",
    "text": "Notice summary different behavior according to the variable‚Äôs type\nThe function‚Äôs results depend on the class of the object\n\nlook at the output in case of integer (e.g.¬†A1_Score)\n\n\nsummary(autism_pids$A1_Score)     # min, max quartiles, mean, median\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.7216  1.0000  1.0000 \n\n\n\nlook at the output in case of factor (e.g.¬†ethnicity)\n\n\nsummary(autism_pids$ethnicity)    # counts of levels' frequency (included NA!)\n\n          Asian           Black        Hispanic          Latino Middle Eastern  \n            123              43              13              20              92 \n         others          Others        Pasifika     South Asian         Turkish \n              1              30              12              36               6 \n White-European            NA's \n            233              95"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type-cont.",
    "href": "practice/practice_slides/slides_lab01.html#notice-summary-different-behavior-according-to-the-variables-type-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Notice summary different behavior according to the variable‚Äôs type (cont.)",
    "text": "Notice summary different behavior according to the variable‚Äôs type (cont.)\n\nlook at the output in case of logical (e.g.¬†age_desc_log)\n\n\nsummary(autism_pids$age_desc_log) # counts of TRUE \n\n   Mode    TRUE \nlogical     704"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#frequency-distributions-with-table",
    "href": "practice/practice_slides/slides_lab01.html#frequency-distributions-with-table",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Frequency distributions with table\n",
    "text": "Frequency distributions with table\n\n\nFrequency distributions can be used for nominal, ordinal, or interval/ration variables\n\n\ntable(autism_pids$gender)\n\n\n  f   m \n337 367 \n\ntable(autism_pids$age) # automatically drops missing...\n\n\n17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \n18 31 35 46 49 37 37 34 27 28 31 24 27 30 21 18 16 12 17 13 17 13  7 16  3 15 \n43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 59 60 61 64 \n11 10  4  6  8  4  3  5  1  5  6  2  6  2  2  1  1  2  1 \n\ntable(autism_pids$age, useNA = \"ifany\") #...unless specified\n\n\n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n  18   31   35   46   49   37   37   34   27   28   31   24   27   30   21   18 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n  16   12   17   13   17   13    7   16    3   15   11   10    4    6    8    4 \n  49   50   51   52   53   54   55   56   58   59   60   61   64 &lt;NA&gt; \n   3    5    1    5    6    2    6    2    2    1    1    2    1    2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#cross-tabulation-with-table-2-vars",
    "href": "practice/practice_slides/slides_lab01.html#cross-tabulation-with-table-2-vars",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Cross tabulation with table (2 vars)",
    "text": "Cross tabulation with table (2 vars)\n\nCross tabulation\n\n\ntable(autism_pids$gender, autism_pids$age_inputed)\n\n   \n    17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41\n  f  7 11 22 22 18 14 17 10 11 14 18 15 16 13  8 14  6  7 12  7 11  6  5  9  0\n  m 11 20 13 24 31 23 20 24 16 14 13  9 11 17 13  4 10  5  5  6  6  7  2  7  3\n   \n    42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 58 59 60 61 64 65\n  f  6  5  4  5  4  3  2  2  2  0  2  4  1  1  0  1  0  1  1  0  0\n  m  9  6  6  0  2  5  2  1  3  1  3  2  1  5  2  1  1  0  1  1  1\n\ntable(autism_pids$ethnicity, autism_pids$autism_dummy)\n\n                 \n                    0   1\n  Asian           118   5\n  Black            38   5\n  Hispanic         12   1\n  Latino           12   8\n  Middle Eastern   83   9\n  others            1   0\n  Others           28   2\n  Pasifika         10   2\n  South Asian      34   2\n  Turkish           5   1\n  White-European  183  50"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with base R",
    "text": "Grouping and summarizing with base R\nE.g. I want to know the average age of men and women sub-groups.\nOption 1) using by\n\n\n# by(data$column, data$grouping_column, mean)\nby(data = autism_pids$age_inputed, INDICES = autism_pids$gender, FUN = mean)\n\nautism_pids$gender: f\n[1] 29.60237\n------------------------------------------------------------ \nautism_pids$gender: m\n[1] 28.98365"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r-1",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-base-r-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with base R",
    "text": "Grouping and summarizing with base R\n\nUsing functions from the apply() family (sapply, lapply, tapply):\n\nAll of these functions allow us to iterate over a data structure, (a list, a matrix, an array, a DataFrame, etc.) and perform the same operation at each element.\n\nOption 2) using tapply\n\n(to apply a function to subsets of a vector where subsets are defined by some other vector, usually a factor)\n\n# i.e. apply a function to subsets of a vector or array, split by one or more factors.\ntapply(X = autism_pids$age_inputed, INDEX = autism_pids$gender, FUN = mean)\n\n       f        m \n29.60237 28.98365 \n\n\nOption 3) using split + sapply\n\n(it returns a vector)\n\n# sapply(split(data$column, data$grouping_column), mean)\nsapply(X = split(autism_pids$age_inputed, autism_pids$gender),FUN = mean) # returns a vector\n\n       f        m \n29.60237 28.98365"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-dplyr",
    "href": "practice/practice_slides/slides_lab01.html#grouping-and-summarizing-with-dplyr",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Grouping and summarizing with dplyr\n",
    "text": "Grouping and summarizing with dplyr\n\n\n\nUsing functions from the dplyr() package which ‚Äúconcatenates‚Äù each step\n\nautism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarise(mean(age_inputed))  # returns a dataframe!\n\n# A tibble: 2 √ó 2\n  gender `mean(age_inputed)`\n  &lt;fct&gt;                &lt;dbl&gt;\n1 f                     29.6\n2 m                     29.0\n\n\nI could add more statistics to the grouped summary‚Ä¶\n\nautism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarise(mean_age = mean(age_inputed),  \n                   N_obs = n(), \n                   N_with_autism = sum(autism_dummy == 1)\n  ) \n\n# A tibble: 2 √ó 4\n  gender mean_age N_obs N_with_autism\n  &lt;fct&gt;     &lt;dbl&gt; &lt;int&gt;         &lt;int&gt;\n1 f          29.6   337            54\n2 m          29.0   367            37"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#mean-and-median",
    "href": "practice/practice_slides/slides_lab01.html#mean-and-median",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Mean and median",
    "text": "Mean and median\nRecall that: \nPopulation MEAN \\(\\mu=\\frac{\\sum_{i=1}^n x_{i}}n\\)Sample MEAN \\(\\bar{x}=\\frac{\\sum_{i=1}^n x_{i}}n\\)\n\nSample MEDIAN\nFor uneven \\(n\\): \\(Mdn = \\frac{x_{(n+1)}}2\\)\nFor even \\(n\\): \\(Mdn = \\frac{x_{(n/2)} + x_{(n/2+1)}}2\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#meanmedian-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#meanmedian-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Mean/Median using base R",
    "text": "Mean/Median using base R\n\n\nUsing age (original variable)\n\nYou must specify the argument na.rm = TRUE or the functions won‚Äôt work!\n\n\n\n\n## Using `age` (original variable) \nmean(autism_pids$age)\n\n[1] NA\n\nmedian(autism_pids$age)\n\n[1] NA\n\n# specify to omit NA observations \nmean(autism_pids$age, na.rm = TRUE)\n\n[1] 29.20655\n\nmedian(autism_pids$age, na.rm = TRUE)\n\n[1] 27\n\n\n\nUsing age_inputed to see what inputed missing values did\n\n\n## Using `age_inputed` to see what inputed missing values did \nmean(autism_pids$age_inputed)\n\n[1] 29.27983\n\nmedian(autism_pids$age_inputed)\n\n[1] 27"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-12",
    "href": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-12",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Create custom function to calculate statistical mode 1/2",
    "text": "Create custom function to calculate statistical mode 1/2\nR doesn‚Äôt have a built-in function for the statistical mode, so we can create a custom one: f_calc_mode\nDefine the custom function\n\nf_calc_mode  &lt;- function(x) { \n  # `unique` returns a vector of unique values \n  uni_x &lt;- unique(x)  \n  # `match` returns the index positions of 1st vector against 2nd vector\n  match_x &lt;- match(x, uni_x)\n  # `tabulate` count the occurrences of integer values in a vector.\n  tab_x  &lt;-  tabulate(match_x) \n  # returns element of uni_x that corresponds to max occurrences\n  uni_x[tab_x == max(tab_x)]\n}"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-22",
    "href": "practice/practice_slides/slides_lab01.html#create-custom-function-to-calculate-statistical-mode-22",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Create custom function to calculate statistical mode 2/2",
    "text": "Create custom function to calculate statistical mode 2/2\nCall the custom function\n\nf_calc_mode(autism_pids$age)\n\n[1] 21\n\nf_calc_mode(autism_pids$age_inputed)\n\n[1] 21\n\nf_calc_mode(autism_pids$ethnicity)\n\n[1] White-European\n11 Levels: Asian Black Hispanic Latino Middle Eastern  others ... White-European"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation",
    "href": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Variance and Standard deviation",
    "text": "Variance and Standard deviation\n\nPopulation Variance \\[\\sigma^2 = \\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}\\]Sample Variance \\[s^2 =\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}\\] Population Standard deviation \\[\\sigma = \\sqrt{\\frac{\\displaystyle\\sum_{i=1}^{n}(x_i - \\mu)^2} {n}}\\] Sample Standard deviation\\[s = \\sqrt\\frac{\\sum{(x_i-\\bar{x})^2}}{n-1}\\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation-using-base-r",
    "href": "practice/practice_slides/slides_lab01.html#variance-and-standard-deviation-using-base-r",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Variance and Standard deviation using base R",
    "text": "Variance and Standard deviation using base R\n\nImportant to specify the argument na.rm = TRUE or the functions won‚Äôt work (or use the age_inputed variable)\n\n\nvar(autism_pids$age, na.rm = TRUE)\n\n[1] 94.28966\n\nvar(autism_pids$age_inputed)\n\n[1] 96.19328\n\nsd(autism_pids$age, na.rm = TRUE)\n\n[1] 9.710286\n\nsd(autism_pids$age_inputed)\n\n[1] 9.807817"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#introducing-r-package-ggplot2-for-graphics",
    "href": "practice/practice_slides/slides_lab01.html#introducing-r-package-ggplot2-for-graphics",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Introducing R package ggplot2 for graphics",
    "text": "Introducing R package ggplot2 for graphics\n\nggplot2 provides a set of tools to map data to visual elements on a plot, to specify the kind of plot you want, and then subsequently to control the fine details of how it will be displayed. It basically allows to build a plot layer by layer (Figure¬†2).\n\n\ndata -&gt; specify what the dataset is\n\naesthetic mappings (or just aesthetics) -&gt; specify which dataset‚Äôs variables will turn into the plot elements (e.g.¬†\\(x\\) and \\(y\\) values, or categorical variable into colors, points, and shapes).\n\ngeom -&gt; the overall type of plot, e.g.¬†geom_point() makes scatterplots, geom_bar() makes barplots, geom_boxplot() makes boxplots.\n\nAdditional (optional) pieces:\n\ninformation about the scales,\nthe labels of legends and axes\nother guides that help people to read the plot,"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#r-package-ggplot2-for-graphics-cont.",
    "href": "practice/practice_slides/slides_lab01.html#r-package-ggplot2-for-graphics-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "R package ggplot2 for graphics (cont.)",
    "text": "R package ggplot2 for graphics (cont.)\na layered approach!\n\n\nFigure¬†2: ggplot2 layers Source: Mine √áetinkaya-Rundel‚Äô Data Viz class"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#save-some-colors-for-customizing-plots",
    "href": "practice/practice_slides/slides_lab01.html#save-some-colors-for-customizing-plots",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Save some colors (for customizing plots)",
    "text": "Save some colors (for customizing plots)\n\nColors are defined in the form of Hexadecimal color values\n\n\n\ntwo_col_palette &lt;-  c(\"#9b2339\", \"#005ca1\")\n\ncontrast_cols_palette &lt;- c(\"#E7B800\",\"#239b85\", \"#85239b\", \"#9b8523\",\"#23399b\",\n                \"#d8e600\", \"#0084e6\", \"#399B23\", \"#e60066\",\n                \"#00d8e6\", \"#e68000\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms",
    "href": "practice/practice_slides/slides_lab01.html#histograms",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms",
    "text": "Histograms\nHistograms (and density plots) are often used to show the distribution of a continuous variable.\n\nOption 1) data inside the ggplot() function\n\n\nggplot(data = autism_pids, mapping = aes(x=age_inputed)) + \n  geom_histogram() + \n  theme_bw()\n\n\nOption 2) data before the pipe %&gt;%\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  geom_histogram() + \n  theme_bw()\n\n\n\n\nnotice that after calling ggplot(), subsequent layers are added with +"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-output",
    "href": "practice/practice_slides/slides_lab01.html#histograms-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms",
    "text": "Histograms"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#define-bin-width",
    "href": "practice/practice_slides/slides_lab01.html#define-bin-width",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ define bin width",
    "text": "‚Ä¶ define bin width\nHistograms split the data into ranges (bins) and show the number of observations in each. Hence, it‚Äôs important to pick widths that represents the data well.\n\nThe default value is 30\nWe can change it using the argument bins = #\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  # specify to avoid warning if we fail to specify the number of bins \n  geom_histogram(bins=40) + \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#define-bin-width-output",
    "href": "practice/practice_slides/slides_lab01.html#define-bin-width-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ define bin width",
    "text": "‚Ä¶ define bin width"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines",
    "href": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ add mean and std dev vertical lines",
    "text": "‚Ä¶ add mean and std dev vertical lines\n\nusing geom_vline() to add a vertical line for the mean, and the range between -1 and +1 sd from the mean.\nusing annotate() for adding small annotations (such as text labels)\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed )) + \n  geom_histogram(bins=40) + \n  # add mean vertical line\n  geom_vline(xintercept = mean(autism_pids$age_inputed),\n             na.rm = FALSE,\n             lwd=1,\n             color=\"#9b2339\") +\n  # add annotations with the mean value\n  annotate(\"text\",                        \n           x = mean(autism_pids$age_inputed) * 1.2, # coordinates for positioning\n           y = mean(autism_pids$age_inputed) * 2.5,\n           label = paste(\"Mean =\", round(mean(autism_pids$age_inputed), digits = 2)),\n           col = \"#9b2339\",\n           size = 4)+\n  # add also sd +1 and -1 \n  geom_vline(aes(xintercept = mean(autism_pids$age_inputed) + sd(autism_pids$age_inputed)), \n             color = \"#000000\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean(autism_pids$age_inputed) - sd(autism_pids$age_inputed)), \n             color = \"#000000\", size = 1, linetype = \"dashed\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines-output",
    "href": "practice/practice_slides/slides_lab01.html#add-mean-and-std-dev-vertical-lines-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ add mean and std dev vertical lines",
    "text": "‚Ä¶ add mean and std dev vertical lines"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot",
    "href": "practice/practice_slides/slides_lab01.html#density-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot",
    "text": "Density plot\n\nspecifying x (the continuous variable)\nusing geom_density(), in which we\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed)) +\n  geom_density()+\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-output",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot",
    "text": "Density plot"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-cont.",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot (cont.)",
    "text": "Density plot (cont.)\n\nspecifying shape colors with the arguments inside geom_density(...)\n\n\ncolor for the line color\n\nfill for area color\n\n\nalpha to specify the degree of transparency in the density fill area\n\n\nautism_pids %&gt;% \n  ggplot(aes( x=age_inputed)) +\n  geom_density(fill=\"#85239b\", color=\"#4c4c4c\", alpha=0.5)+\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-plot-cont.-output",
    "href": "practice/practice_slides/slides_lab01.html#density-plot-cont.-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density plot (cont.)",
    "text": "Density plot (cont.)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks",
    "href": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ increase # of x-axis ticks",
    "text": "‚Ä¶ increase # of x-axis ticks\n\nspecifying the amount of breaks inside scale_x_continuous()\n\n\n\nautism_pids %&gt;% \n  ggplot(aes( x=age_inputed)) +\n  geom_density(fill=\"#85239b\", color=\"#4c4c4c\", alpha=0.5)+\n  theme_bw() + \n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,5 ), limits = c(16, 86))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks-output",
    "href": "practice/practice_slides/slides_lab01.html#increase-of-x-axis-ticks-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ increase # of x-axis ticks",
    "text": "‚Ä¶ increase # of x-axis ticks"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category",
    "href": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms with fill = category\n",
    "text": "Histograms with fill = category\n\n\nindicate the categorical group as fill = in the aesthetic mapping\nspecify custom colors for each group:\n\n\nuse scale_color_manual() for changing line color\nuse scale_fill_manual() for changing area fill colors.\n\n\nautism_pids %&gt;% \n  # specifying `fill` = gender\n  ggplot(mapping = aes(x = age_inputed, fill = gender )) + \n  geom_histogram(bins=40) + \n  scale_fill_manual(values = c(\"#e07689\",\"#57b7ff\")) +\n  scale_color_manual(values = c(\"#9b2339\",\"#005ca1\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category-output",
    "href": "practice/practice_slides/slides_lab01.html#histograms-with-fill-category-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Histograms with fill = category\n",
    "text": "Histograms with fill = category"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group",
    "href": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ shifting bars by group",
    "text": "‚Ä¶ shifting bars by group\n\nusing the specification position = 'dodge' inside geom_histogram()\n\n\n\n# trying to improve readability \nautism_pids %&gt;% \n  ggplot(mapping = aes(x = age_inputed, fill = gender )) + \n  # bars next to each other with `position = 'dodge'`\n  geom_histogram(bins=40, position = 'dodge')  + \n  scale_fill_manual(values = c(\"#e07689\",\"#57b7ff\")) +\n  scale_color_manual(values = c(\"#9b2339\",\"#005ca1\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group-output",
    "href": "practice/practice_slides/slides_lab01.html#shifting-bars-by-group-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ shifting bars by group",
    "text": "‚Ä¶ shifting bars by group"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender",
    "text": "‚Ä¶facet by gender\nThat‚Äôs still not very easy to digest. Instead of only filling, you can separate the data into multiple plots to improve readability\n\nadding facet_wrap() with the the specification of ~categ_var\n\nalso ncol = 1 requires the subplot to be in 1 column\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender )) + \n  geom_histogram(color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  theme_bw() + \n  # splitting the gender groups, specifying `ncol` to see one above the other\n  facet_wrap(~gender, ncol = 1)  + \n  scale_fill_cyclical(values = c(\"#9b2339\",\"#005ca1\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-output",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender",
    "text": "‚Ä¶facet by gender"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#adding-2-meanmedian-vert-lines-by-gender",
    "href": "practice/practice_slides/slides_lab01.html#adding-2-meanmedian-vert-lines-by-gender",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ adding 2 mean/median vert lines (by gender)",
    "text": "‚Ä¶ adding 2 mean/median vert lines (by gender)\nI want to see the mean vertical line for each of the subgroups, but in this case, I need to create a small dataframe of summary statistics (group_stats).\nI do so by using dplyr add a column mean_age with the group mean\n\ngroup_stats &lt;- autism_pids %&gt;% \n  dplyr::group_by(gender) %&gt;% \n  dplyr::summarize(mean_age = mean(age_inputed),\n                   median_age = median (age_inputed)) \n\ngroup_stats\n\n\n\n# A tibble: 2 √ó 3\n  gender mean_age median_age\n  &lt;fct&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 f          29.6         28\n2 m          29.0         26"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#small-digression-on-tidyrpivot_longer",
    "href": "practice/practice_slides/slides_lab01.html#small-digression-on-tidyrpivot_longer",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "(Small digression on tidyr::pivot_longer)",
    "text": "(Small digression on tidyr::pivot_longer)\n\nThe new small dataframe group_stats offers an example of reshaping, i.e.¬†turning a table from a ‚Äúwide‚Äù form (with each variable in its own column) to a ‚Äúlong‚Äù form (one column for both the measures names and another for both the measures values).\n\nThis can be done using tidyr::pivot_longer function, where these arguments must be specified:\n\n\ncols: The names of the columns to pivot\n\nnames_to: The name for the new character column\n\nvalues_to: The name for the new values column\n\n\n\n\ngroup_stats_long &lt;- group_stats %&gt;% \n  tidyr::pivot_longer(cols = mean_age:median_age, \n                      names_to = \"Stat\", \n                      values_to = \"Value\") %&gt;% \n  dplyr::mutate(label = as.character(glue::glue(\"{gender}_{Stat}\")))\n\ngroup_stats_long \n\n# A tibble: 4 √ó 4\n  gender Stat       Value label       \n  &lt;fct&gt;  &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n1 f      mean_age    29.6 f_mean_age  \n2 f      median_age  28   f_median_age\n3 m      mean_age    29.0 m_mean_age  \n4 m      median_age  26   m_median_age"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender + vert lines by group",
    "text": "‚Ä¶facet by gender + vert lines by group\nNotice that now the plot will have 2 data sources:\n\nautism_pids\ngroup_stats_long\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender)) + \n  # geom_histogram from dataframe 1\n  geom_histogram(bins=30,color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  facet_wrap(~gender, ncol = 1) + \n  scale_fill_manual(values = c(\"#9b2339\",\"#005ca1\"))  +\n  # geom_vline from dataframe 2\n  geom_vline(data = group_stats_long, \n             mapping = aes(xintercept = Value, color = Stat),\n             lwd=1,\n             linetype=1) + \n  scale_color_manual(values = c( \"#f0a441\" , \"#d8cf71\")) +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group-output",
    "href": "practice/practice_slides/slides_lab01.html#facet-by-gender-vert-lines-by-group-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶facet by gender + vert lines by group",
    "text": "‚Ä¶facet by gender + vert lines by group"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#finishing-touches",
    "href": "practice/practice_slides/slides_lab01.html#finishing-touches",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ finishing touches",
    "text": "‚Ä¶ finishing touches\n\nusing labs() and theme() layers\n\n\nhist_plot &lt;- autism_pids %&gt;% \n  ggplot(aes(x = age_inputed, fill = gender)) + \n  # geom_histogram from dataframe 1\n  geom_histogram(bins=30,color=\"#e9ecef\", alpha=0.8, position = 'dodge') + \n  facet_wrap(~gender, ncol = 1) + \n  scale_fill_manual(values = c(\"#9b2339\",\"#005ca1\"))  +\n  # geom_vline from dataframe 2\n  geom_vline(data = group_stats_long, \n             mapping = aes(xintercept = Value, color = Stat),\n             lwd=1.5,\n             linetype=6) + \n  scale_color_manual(values = c( \"#e68000\", \"#d8cf71\")) +\n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,10 ), limits = c(10,70)) +\n  # Additional theme details \n  labs(x = \"age brackets\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by gender\",\n       subtitle = \"\",\n       caption = \"Source: Thabtah,Fadi (2017) https://doi.org/10.24432/C5F019.\") +\n  theme(legend.position = \"right\",\n        plot.title = element_text(face = \"bold\")) \nhist_plot"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#finishing-touches-output",
    "href": "practice/practice_slides/slides_lab01.html#finishing-touches-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶ finishing touches",
    "text": "‚Ä¶ finishing touches"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-ggridges-package",
    "href": "practice/practice_slides/slides_lab01.html#density-ggridges-package",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density ggridges package",
    "text": "Density ggridges package\nAs an alternative, you can use the ggridges package to make ridge plots. The geom geom_density_ridges calculates density estimates from the provided data and then plots those, using the ridgeline visualization. In this case plots include a vertical median line.\n\nautism_pids %&gt;% \n  # this takes also `y` = group\n  ggplot(aes(x=age_inputed, y = gender, fill = gender)) +\n  ggridges::geom_density_ridges() +\n  # I can add quantile lines (2 is the median)\n  stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.5), alpha = 0.75)+  \n  # increase number of x axis ticks \n  scale_x_continuous(breaks = seq(10, 100,10 ), limits = c(16, 86)) + \n  scale_fill_cyclical(values = c(\"#9b2339\",\"#005ca1\")) + \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#density-ggridges-package-output",
    "href": "practice/practice_slides/slides_lab01.html#density-ggridges-package-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Density ggridges package",
    "text": "Density ggridges package"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#barchart",
    "href": "practice/practice_slides/slides_lab01.html#barchart",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Barchart",
    "text": "Barchart\nBar charts provide a visual presentation of categorical data, with geom_bar() (height of the bar proportional to the number of cases in each group)\n\n\nFigure¬†3: Difference barchart v. histogram Source: https://www.biorender.com/"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#barchart-cont.",
    "href": "practice/practice_slides/slides_lab01.html#barchart-cont.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Barchart (cont.)",
    "text": "Barchart (cont.)\n\n# Let's take a variable that we recoded as `factor`\nclass(autism_pids$ethnicity)\n\n[1] \"factor\"\n\n#### ... no formatting ---------------------------------- \nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity )) + \n  geom_bar() +   \n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-theme",
    "href": "practice/practice_slides/slides_lab01.html#improve-theme",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve theme",
    "text": "‚Ä¶improve theme\n\nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity )) + \n  geom_bar(fill = \"steelblue\") +\n  # reference line  \n  geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n  # labels, title, etc \n  labs(x = \"ethnicity\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by ethnicity\",\n       subtitle = \"\",\n       caption = \"Autism study\")  +\n  theme_bw() +\n  # specification son axis labels\n  theme(axis.text.x = element_text(angle=50, vjust=0.75), \n        axis.text.y = element_text(size=10,face=\"bold\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-theme-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-theme-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve theme",
    "text": "‚Ä¶improve theme"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (reorder bars)",
    "text": "‚Ä¶improve readability (reorder bars)\nReordering the bars by count using the package forcats and its function fct_infreq\n\n(which we can do because ethnicity was recoded as factor)\n\n\nautism_pids %&gt;% \n    # we modify our x like so \n    ggplot(aes(x = forcats::fct_infreq(ethnicity ))) + \n    geom_bar(fill = \"steelblue\") +\n    geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n    labs(x = \"ethnicity\", y = \"n of individuals\",\n         color = \"Stats\",\n         title = \"Distribution of observations by ethnicity\",\n         subtitle = \"\",\n         caption = \"Autism study\")  +\n    # --- wrap long x labels (flipped ) !!!\n    #  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 10)) +\n    theme_bw() +\n    theme(axis.text.x = element_text(angle=50, vjust=0.75), \n          axis.text.y = element_text(size=10,face=\"bold\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-reorder-bars-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (reorder bars)",
    "text": "‚Ä¶improve readability (reorder bars)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA)",
    "text": "‚Ä¶improve readability (highlight NA)\nLet‚Äôs highlight the fact that the last column (NA) represents missing values.\n\nCreate the highlight variable\nMap color to a variable (fill = highlight)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA) code",
    "text": "‚Ä¶improve readability (highlight NA) code\n\nautism_pids %&gt;%\n  ## --- prep the dataframe \n  dplyr::mutate(# Add a factor variable with two levels\n    highlight = forcats::fct_other(ethnicity, \n                                   keep = \"NA\", \n                                   other_level = \"All Groups\")) %&gt;% \n  ## --- now plot \n  # In `aes mapping` we map color to a variable (`fill = highlight`)\n  ggplot(aes(x = forcats::fct_infreq(ethnicity), fill = highlight)) + \n  geom_bar()+\n  # Use custom color palettes\n  scale_fill_manual(values=c(\"#0084e6\")) +\n  # Add a line at a significant level \n  geom_hline(yintercept=100, color = \"#9b2339\", size=0.5, ) +\n  theme_bw() +\n  # make some more theme specifications  \n  labs(x = \"ethnicity\", y = \"n of individuals\",\n       color = \"Stats\",\n       title = \"Distribution of observations by ethnicity\",\n       subtitle = \"\",\n       caption = \"Autism study\")  +\n  theme(axis.text.x = element_text(angle=50, vjust=0.75), \n        axis.text.y = element_text(size=10,face=\"bold\"))  +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code-output",
    "href": "practice/practice_slides/slides_lab01.html#improve-readability-highlight-na-code-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "‚Ä¶improve readability (highlight NA) code",
    "text": "‚Ä¶improve readability (highlight NA) code"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot",
    "href": "practice/practice_slides/slides_lab01.html#boxplot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot",
    "text": "Boxplot\nThe boxplot is one of the simplest ways of representing a distribution of a continuous variable and it is packed with information. It consists of two parts:\n\n\nBox ‚Äî Extending from the 1st to the 3rd quartile (Q1 to Q3) with a line in the middle that represents the median.\n\nWhiskers ‚Äî Lines extending from both ends of the box (minimum/maximum whisker values are calculated as Q1/Q3 -/+ 1.5 * IQR)\nEverything outside is represented as an outlier\n\n\n\n\nFigure¬†4: Boxplot Source: https://www.appsilon.com/post/ggplot2-boxplots"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-1",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-1",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 1",
    "text": "Boxplot example 1\nLet‚Äôs use a boxplot to explore how the continuous variable result is distributed in the autism dataset.\n\nin the aesthetic mapping we specify only x (continuous variable)\nswitch to vertical orientation with coord_flip()\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = result )) +\n  geom_boxplot(alpha=0.5)+\n  # switch to vertical orientation\n  coord_flip() +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-1-output",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-1-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 1",
    "text": "Boxplot example 1"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-2",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-2",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 2",
    "text": "Boxplot example 2\nLet‚Äôs also explore how the continuous variable result is distributed by the categorical variable (factor) ethnicity.\n\nin the aesthetic mapping we specify y (continuous variable), plus x and fill (categorical variable)\nmake x axis labels readable with theme(axis.text.x (...)) layer\nI specify colors that I had previously saved in a color palette contrast_cols_palette\n\n\n\nautism_pids %&gt;% \n  ggplot(aes(x = ethnicity,  y= result, fill = ethnicity)) +\n  geom_boxplot(alpha=0.5)+\n  scale_fill_manual(values =  contrast_cols_palette)   +\n  theme_bw()+\n  # make x axis labes readable\n  theme(axis.text.x = element_text(angle=50, vjust=0.75)) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#boxplot-example-2-output",
    "href": "practice/practice_slides/slides_lab01.html#boxplot-example-2-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Boxplot example 2",
    "text": "Boxplot example 2"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot",
    "text": "Violin plot\nSimilarly, the violin plot is an interesting alternative to show the distribution of a continuous variable along one or more categorical variables. Here, the kernel density plot shows the smoothed curve of the probability density function (PDF) of the data. \nCompared to the box plot, a violin plot provides more information, as it shows not only the summary statistics but also the shape and variability of the data (i.e.¬†helping to identify any skewness or multimodality in the data)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot-example",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot-example",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot example",
    "text": "Violin plot example\n\nit requires the geom_violin function\nit can be enriched by adding with other geoms, such as points, lines, or box plots, to create more complex and informative plots\nlet‚Äôs add points with the geom_point layer\n\n\nautism_pids %&gt;% \n  ggplot(mapping = aes(y = age_inputed, x = ethnicity, fill = ethnicity)) +\n  geom_violin(alpha=0.5) +\n  geom_point(position = position_jitter(width = 0.1), size = 0.5)+ \n  scale_fill_manual(values =  contrast_cols_palette)  +\n  # make x axis labes readable\n  theme(axis.text.x = element_text(angle=50, vjust=0.75)) +\n  # drop legend and Y-axis title\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#violin-plot-example-output",
    "href": "practice/practice_slides/slides_lab01.html#violin-plot-example-output",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Violin plot example",
    "text": "Violin plot example"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#saving-one-plot",
    "href": "practice/practice_slides/slides_lab01.html#saving-one-plot",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Saving one plot",
    "text": "Saving one plot\nIf I want to use these output files later, I can easily save in the output folder created at the beginning.\n\nsave a plot with ggplot2::ggsave\n\nspecifying the output directory with here::here(...)\n\n\n\nggsave (hist_plot, \n        filename = here::here(\"practice\",  \"data_output\", \"hist_plot.png\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#saving-a-.rds-data-file.",
    "href": "practice/practice_slides/slides_lab01.html#saving-a-.rds-data-file.",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Saving a .Rds data file.",
    "text": "Saving a .Rds data file.\n\nsave a dataframe with base::saveRDS\n\nspecifying the output directory with here::here(...)\n\n\n\nsaveRDS (object = autism_pids, \n         file =  here::here(\"practice\",  \"data_output\", \"autism_pids_v2.Rds\"))\n\n\n\n(later) load a saved dataframe with base::readRDS\n\n\n\n# to load it later I will use \nreadRDS(here::here(\"practice\",  \"data_output\", \"autism_pids_v2.Rds\")) \n\n\n\nnotice I renamed while saving: next time I load it it will be called ‚Äúautism_pids_v2‚Äù"
  },
  {
    "objectID": "practice/practice_slides/slides_lab01.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab01.html#final-thoughtsrecommendations",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\nAlways read the documentation (?package::function, especially the examples at the bottom)\nAlways inspect the data / variables before and after making changes\n\nIt is advisable to rename (i.e.¬†create a new R object) when you recode/manipulate a variable or a dataset\n\nthis promotes reproducibility, since you(or others) will be able to retrace your coding steps\n\n\nAlways plot distributions for visual data exploration\nMake changes in small increments (like we saw in building ggplot2 graph in subsequent layers)\n\n\n\n\nR 4 Biostatistics | MITGEST::training(2024)"
  },
  {
    "objectID": "practice/lab04_intro_ML.html",
    "href": "practice/lab04_intro_ML.html",
    "title": "Lab 4: Intro to machine learning",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "practice/lab04_intro_ML.html#practice-session-4-input-data-as-subfolder",
    "href": "practice/lab04_intro_ML.html#practice-session-4-input-data-as-subfolder",
    "title": "Lab 4: Intro to machine learning",
    "section": "Practice session 4: input data (as subfolder)",
    "text": "Practice session 4: input data (as subfolder)\n\n\n\n Download input data Lab 4"
  },
  {
    "objectID": "practice/lab04_intro_ML.html#practice-session-4-r-code-as-.r-file",
    "href": "practice/lab04_intro_ML.html#practice-session-4-r-code-as-.r-file",
    "title": "Lab 4: Intro to machine learning",
    "section": "Practice session 4: R code (as .R file)",
    "text": "Practice session 4: R code (as .R file)\n\n\n\n Download Lab session 4 as .R file"
  },
  {
    "objectID": "practice/lab02_inference.html",
    "href": "practice/lab02_inference.html",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "practice/lab02_inference.html#practice-session-2-input-data-as-subfolder",
    "href": "practice/lab02_inference.html#practice-session-2-input-data-as-subfolder",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Practice session 2: input data (as subfolder)",
    "text": "Practice session 2: input data (as subfolder)\n\n\n\n Download input data Lab 2"
  },
  {
    "objectID": "practice/lab02_inference.html#practice-session-2-r-code-as-.r-file",
    "href": "practice/lab02_inference.html#practice-session-2-r-code-as-.r-file",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Practice session 2: R code (as .R file)",
    "text": "Practice session 2: R code (as .R file)\n\n\n\n Download Lab session 2 as .R file"
  },
  {
    "objectID": "me.html",
    "href": "me.html",
    "title": "About the Instructor",
    "section": "",
    "text": "Maria Chiara Mimmi, Ph.D., is a Research Fellow at University of Pavia - Dept. of Molecular Medicine, as well as NMR Expert at Fondazione IRCCS Policlinico San Matteo. She has twenty years of experience working in life science research, with a focus on NMR and Mass Spectrometry applied to metabolomics/lipidomics.\nIn 2020, she joined the University of Pavia, at the Molecular Medicine Dept., to work with the recently acquired 700 MHz NMR spectrometer. Since then she focused on NMR applied to either metabolomics and to structure/dynamics of amyloidogenic proteins.\n\n\nUniversit√† degli Studi di Pavia | Pavia, Italy Master of Biostatistics and Epidemiology | 2018-2019\nUniversit√† degli Studi di Milano | Milano, Italy Ph.D.¬†in Chemical Sciences | 2001 - 2003\nInstitut National de la Recherche Agronomique | Versailles-Grignon, France Visiting scholar | 2003 - 2003\nUniversit√† degli Studi di Pavia | Pavia, Italy BSc Degree in Chemistry | 1994 - 2000\nUniversiteit Leiden | Leiden, The Netherlands Erasmus exchange student (6 months) | 1999 - 1999\n\n \n  \n   \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n  \n      Google Scholar\n  \n  \n      Research Gate\n  \n  \n      Orcid"
  },
  {
    "objectID": "me.html#education",
    "href": "me.html#education",
    "title": "About the Instructor",
    "section": "",
    "text": "Universit√† degli Studi di Pavia | Pavia, Italy Master of Biostatistics and Epidemiology | 2018-2019\nUniversit√† degli Studi di Milano | Milano, Italy Ph.D.¬†in Chemical Sciences | 2001 - 2003\nInstitut National de la Recherche Agronomique | Versailles-Grignon, France Visiting scholar | 2003 - 2003\nUniversit√† degli Studi di Pavia | Pavia, Italy BSc Degree in Chemistry | 1994 - 2000\nUniversiteit Leiden | Leiden, The Netherlands Erasmus exchange student (6 months) | 1999 - 1999"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#collaborators",
    "href": "lectures_slides/000_exe_mine.html#collaborators",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "collaborators",
    "text": "collaborators\n\nJohanna Hardin, Pomona College\nBenjamin S. Baumer, Smith College\nAmelia McNamara, University of St Thomas\nNicholas J. Horton, Amherst College\nColin W. Rundel, Duke University"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#setting-the-scene",
    "href": "lectures_slides/000_exe_mine.html#setting-the-scene",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "setting the scene",
    "text": "setting the scene\n\n\n\nAssumption 1:\nTeach authentic tools\n\n\nAssumption 2:\nTeach R as the authentic tool"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#takeaway",
    "href": "lectures_slides/000_exe_mine.html#takeaway",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "takeaway",
    "text": "takeaway\n\n\nThe tidyverse provides an effective and efficient pathway for undergraduate students at all levels and majors to gain computational skills and thinking needed throughout the data science cycle.\n\n\n\n√áetinkaya-Rundel, M., Hardin, J., Baumer, B. S., McNamara, A., Horton, N. J., & Rundel, C. (2021). An educator‚Äôs perspective of the tidyverse. arXiv preprint arXiv:2108.03510. arxiv.org/abs/2108.03510"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#tidyverse",
    "href": "lectures_slides/000_exe_mine.html#tidyverse",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\nmeta R package that loads eight core packages when invoked and also bundles numerous other packages upon installation\ntidyverse packages share a design philosophy, common grammar, and data structures"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#tidyverse-flow",
    "href": "lectures_slides/000_exe_mine.html#tidyverse-flow",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "tidyverse flow",
    "text": "tidyverse flow"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#setup",
    "href": "lectures_slides/000_exe_mine.html#setup",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "setup",
    "text": "setup\nData: Thousands of loans made through the Lending Club, a peer-to-peer lending platform available in the openintro package, with a few modifications.\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nloans &lt;- loans_full_schema %&gt;%\n  mutate(\n    homeownership = str_to_title(homeownership), \n    bankruptcy = if_else(public_record_bankrupt &gt;= 1, \"Yes\", \"No\")\n  ) %&gt;%\n  filter(annual_income &gt;= 10) %&gt;%\n  select(\n    loan_amount, homeownership, bankruptcy,\n    application_type, annual_income, interest_rate\n  )"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#start-with-a-data-frame",
    "href": "lectures_slides/000_exe_mine.html#start-with-a-data-frame",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "start with a data frame",
    "text": "start with a data frame\n\nloans\n\n# A tibble: 9,976 √ó 6\n  loan_amount homeownership bankruptcy application_type annual_income\n        &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;      &lt;fct&gt;                    &lt;dbl&gt;\n1       28000 Mortgage      No         individual               90000\n2        5000 Rent          Yes        individual               40000\n3        2000 Rent          No         individual               40000\n4       21600 Rent          No         individual               30000\n5       23000 Rent          No         joint                    35000\n6        5000 Own           No         individual               34000\n# ‚Ñπ 9,970 more rows\n# ‚Ñπ 1 more variable: interest_rate &lt;dbl&gt;"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#tidy-data",
    "href": "lectures_slides/000_exe_mine.html#tidy-data",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "tidy data",
    "text": "tidy data\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\n\n\nWickham, H. . (2014). Tidy Data. Journal of Statistical Software, 59(10), 1‚Äì23. doi.org/10.18637/jss.v059.i10."
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#task-calculate-a-summary-statistic",
    "href": "lectures_slides/000_exe_mine.html#task-calculate-a-summary-statistic",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "task: calculate a summary statistic",
    "text": "task: calculate a summary statistic\n\nCalculate the mean loan amount.\n\n\nloans\n\n# A tibble: 9,976 √ó 6\n  loan_amount homeownership bankruptcy application_type annual_income\n        &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;      &lt;fct&gt;                    &lt;dbl&gt;\n1       28000 Mortgage      No         individual               90000\n2        5000 Rent          Yes        individual               40000\n3        2000 Rent          No         individual               40000\n4       21600 Rent          No         individual               30000\n5       23000 Rent          No         joint                    35000\n6        5000 Own           No         individual               34000\n# ‚Ñπ 9,970 more rows\n# ‚Ñπ 1 more variable: interest_rate &lt;dbl&gt;\n\n\n\n\nmean(loan_amount)\n\n\n\n\n\nError in mean(loan_amount): object 'loan_amount' not found"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#accessing-a-variable",
    "href": "lectures_slides/000_exe_mine.html#accessing-a-variable",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "accessing a variable",
    "text": "accessing a variable\nApproach 1: With attach():\n\nattach(loans)\nmean(loan_amount)\n\n[1] 16357.53\n\n\n\n\nNot recommended. What if you had another data frame you‚Äôre working with concurrently called car_loans that also had a variable called loan_amount in it?"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#accessing-a-variable-1",
    "href": "lectures_slides/000_exe_mine.html#accessing-a-variable-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "accessing a variable",
    "text": "accessing a variable\nApproach 2: Using $:\n\nmean(loans$loan_amount)\n\n[1] 16357.53\n\n\n\n\nApproach 3: Using with():\n\nwith(loans, mean(loan_amount))\n\n[1] 16357.53"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#accessing-a-variable-2",
    "href": "lectures_slides/000_exe_mine.html#accessing-a-variable-2",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "accessing a variable",
    "text": "accessing a variable\nApproach 4: The tidyverse approach:\n\nloans %&gt;%\n  summarise(mean_loan_amount = mean(loan_amount))\n\n# A tibble: 1 √ó 1\n  mean_loan_amount\n             &lt;dbl&gt;\n1           16358.\n\n\n\n\nMore verbose\nBut also more expressive and extensible"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#the-tidyverse-approach",
    "href": "lectures_slides/000_exe_mine.html#the-tidyverse-approach",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "the tidyverse approach",
    "text": "the tidyverse approach\n\n\ntidyverse functions take a data argument that allows them to localize computations inside the specified data frame\ndoes not muddy the concept of what is in the current environment: variables always accessed from within in a data frame without the use of an additional function (like with()) or quotation marks, never as a vector"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#task-grouped-summary",
    "href": "lectures_slides/000_exe_mine.html#task-grouped-summary",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "task: grouped summary",
    "text": "task: grouped summary\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\n\n\n\n\n\n\nHomeownership\nNumber of applicants\nAverage loan amount\n\n\n\nMortgage\n$18,132\n4,778\n\n\nOwn\n$15,665\n1,350\n\n\nRent\n$14,396\n3,848"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-i",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-i",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down I",
    "text": "break it down I\n\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\nloans\n\n# A tibble: 9,976 √ó 6\n  loan_amount homeownership bankruptcy application_type annual_income\n        &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;      &lt;fct&gt;                    &lt;dbl&gt;\n1       28000 Mortgage      No         individual               90000\n2        5000 Rent          Yes        individual               40000\n3        2000 Rent          No         individual               40000\n4       21600 Rent          No         individual               30000\n5       23000 Rent          No         joint                    35000\n6        5000 Own           No         individual               34000\n# ‚Ñπ 9,970 more rows\n# ‚Ñπ 1 more variable: interest_rate &lt;dbl&gt;"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-ii",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-ii",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down II",
    "text": "break it down II\n\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\n\n[input] data frame\n\n\n\n\nloans %&gt;%\n  group_by(homeownership)\n\n# A tibble: 9,976 √ó 6\n# Groups:   homeownership [3]\n  loan_amount homeownership bankruptcy application_type annual_income\n        &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;      &lt;fct&gt;                    &lt;dbl&gt;\n1       28000 Mortgage      No         individual               90000\n2        5000 Rent          Yes        individual               40000\n3        2000 Rent          No         individual               40000\n4       21600 Rent          No         individual               30000\n5       23000 Rent          No         joint                    35000\n6        5000 Own           No         individual               34000\n# ‚Ñπ 9,970 more rows\n# ‚Ñπ 1 more variable: interest_rate &lt;dbl&gt;\n\n\n\n\n\ndata frame [output]"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-iii",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-iii",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down III",
    "text": "break it down III\n\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\nloans %&gt;%\n  group_by(homeownership) %&gt;% \n  summarize(\n    avg_loan_amount = mean(loan_amount)\n    )\n\n# A tibble: 3 √ó 2\n  homeownership avg_loan_amount\n  &lt;chr&gt;                   &lt;dbl&gt;\n1 Mortgage               18132.\n2 Own                    15665.\n3 Rent                   14396."
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-iv",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-iv",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down IV",
    "text": "break it down IV\n\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\nloans %&gt;%\n  group_by(homeownership) %&gt;% \n  summarize(\n    avg_loan_amount = mean(loan_amount),\n    n_applicants = n()\n    )\n\n# A tibble: 3 √ó 3\n  homeownership avg_loan_amount n_applicants\n  &lt;chr&gt;                   &lt;dbl&gt;        &lt;int&gt;\n1 Mortgage               18132.         4778\n2 Own                    15665.         1350\n3 Rent                   14396.         3848"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-v",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-v",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down V",
    "text": "break it down V\n\n\nBased on the applicants‚Äô home ownership status, compute the average loan amount and the number of applicants. Display the results in descending order of average loan amount.\n\n\nloans %&gt;%\n  group_by(homeownership) %&gt;% \n  summarize(\n    avg_loan_amount = mean(loan_amount),\n    n_applicants = n()\n    ) %&gt;%\n  arrange(desc(avg_loan_amount))\n\n# A tibble: 3 √ó 3\n  homeownership avg_loan_amount n_applicants\n  &lt;chr&gt;                   &lt;dbl&gt;        &lt;int&gt;\n1 Mortgage               18132.         4778\n2 Own                    15665.         1350\n3 Rent                   14396.         3848"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#putting-it-back-together",
    "href": "lectures_slides/000_exe_mine.html#putting-it-back-together",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "putting it back together",
    "text": "putting it back together\n\n[input] data frame\n\n\nloans %&gt;%\n  group_by(homeownership) %&gt;% \n  summarize(\n    avg_loan_amount = mean(loan_amount),\n    n_applicants = n()\n    ) %&gt;%\n  arrange(desc(avg_loan_amount))\n\n# A tibble: 3 √ó 3\n  homeownership avg_loan_amount n_applicants\n  &lt;chr&gt;                   &lt;dbl&gt;        &lt;int&gt;\n1 Mortgage               18132.         4778\n2 Own                    15665.         1350\n3 Rent                   14396.         3848\n\n\n\n[output] data frame"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate",
    "href": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "grouped summary with aggregate()\n",
    "text": "grouped summary with aggregate()\n\n\nres1 &lt;- aggregate(loan_amount ~ homeownership, \n                  data = loans, FUN = length)\nres1\n\n  homeownership loan_amount\n1      Mortgage        4778\n2           Own        1350\n3          Rent        3848\n\nnames(res1)[2] &lt;- \"n_applicants\"\nres1\n\n  homeownership n_applicants\n1      Mortgage         4778\n2           Own         1350\n3          Rent         3848"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate-1",
    "href": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "grouped summary with aggregate()\n",
    "text": "grouped summary with aggregate()\n\n\nres2 &lt;- aggregate(loan_amount ~ homeownership, \n                  data = loans, FUN = mean)\nnames(res2)[2] &lt;- \"avg_loan_amount\"\n\nres2\n\n  homeownership avg_loan_amount\n1      Mortgage        18132.45\n2           Own        15665.44\n3          Rent        14396.44\n\n\n\n\nres &lt;- merge(res1, res2)\nres[order(res$avg_loan_amount, decreasing = TRUE), ]\n\n  homeownership n_applicants avg_loan_amount\n1      Mortgage         4778        18132.45\n2           Own         1350        15665.44\n3          Rent         3848        14396.44"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate-2",
    "href": "lectures_slides/000_exe_mine.html#grouped-summary-with-aggregate-2",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "grouped summary with aggregate()\n",
    "text": "grouped summary with aggregate()\n\n\n\nres1 &lt;- aggregate(loan_amount ~ homeownership, data = loans, FUN = length)\nnames(res1)[2] &lt;- \"n_applicants\"\nres2 &lt;- aggregate(loan_amount ~ homeownership, data = loans, FUN = mean)\nnames(res2)[2] &lt;- \"avg_loan_amount\"\nres &lt;- merge(res1, res2)\nres[order(res$avg_loan_amount, decreasing = TRUE), ]\n\n\n\n\n\nGood: Inputs and outputs are data frames\n\nNot so good: Need to introduce\n\nformula syntax\npassing functions as arguments\nmerging datasets\nsquare bracket notation for accessing rows"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#grouped-summary-with-tapply",
    "href": "lectures_slides/000_exe_mine.html#grouped-summary-with-tapply",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "grouped summary with tapply()\n",
    "text": "grouped summary with tapply()\n\n\nsort(\n  tapply(loans$loan_amount, loans$homeownership, mean),\n  decreasing = TRUE\n  )\n\nMortgage      Own     Rent \n18132.45 15665.44 14396.44 \n\n\n\n\nNot so good:\n\npassing functions as arguments\ndistinguishing between the various apply() functions\nending up with a new data structure (array)\nreading nested functions"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#task-data-visualization",
    "href": "lectures_slides/000_exe_mine.html#task-data-visualization",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "task: data visualization",
    "text": "task: data visualization\n\nCreate side-by-side box plots that shows the relationship between loan amount and application type, faceted by homeownership."
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-i-1",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-i-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down I",
    "text": "break it down I\n\n\nCreate side-by-side box plots that shows the relationship between annual income and application type, faceted by homeownership.\n\n\nggplot(loans)"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-ii-1",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-ii-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down II",
    "text": "break it down II\n\n\nCreate side-by-side box plots that shows the relationship between annual income and application type, faceted by homeownership.\n\n\nggplot(loans, \n       aes(x = application_type))"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-iii-1",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-iii-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down III",
    "text": "break it down III\n\n\nCreate side-by-side box plots that shows the relationship between annual income and application type, faceted by homeownership.\n\n\nggplot(loans, \n       aes(x = application_type,\n           y = loan_amount))"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-iv-1",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-iv-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down IV",
    "text": "break it down IV\n\n\nCreate side-by-side box plots that shows the relationship between annual income and application type, faceted by homeownership.\n\n\nggplot(loans, \n       aes(x = application_type,\n           y = loan_amount)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#break-it-down-iv-2",
    "href": "lectures_slides/000_exe_mine.html#break-it-down-iv-2",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "break it down IV",
    "text": "break it down IV\n\n\nCreate side-by-side box plots that shows the relationship between annual income and application type, faceted by homeownership.\n\n\nggplot(loans, \n       aes(x = application_type,\n           y = loan_amount)) +\n  geom_boxplot() +\n  facet_wrap(~ homeownership)"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-ggplot",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-ggplot",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with ggplot()\n",
    "text": "plotting with ggplot()\n\n\nggplot(loans, \n       aes(x = application_type, y = loan_amount)) +\n  geom_boxplot() +\n  facet_wrap(~ homeownership)\n\n\n\nEach layer produces a valid plot\nFaceting by a third variable takes only one new function"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-boxplot",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-boxplot",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with boxplot()\n",
    "text": "plotting with boxplot()\n\n\nlevels &lt;- sort(unique(loans$homeownership))\nlevels\n\n[1] \"Mortgage\" \"Own\"      \"Rent\"    \n\nloans1 &lt;- loans[loans$homeownership == levels[1],]\nloans2 &lt;- loans[loans$homeownership == levels[2],]\nloans3 &lt;- loans[loans$homeownership == levels[3],]"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-boxplot-1",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-boxplot-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with boxplot()\n",
    "text": "plotting with boxplot()\n\n\npar(mfrow = c(1, 3))\n\nboxplot(loan_amount ~ application_type, \n        data = loans1, main = levels[1])\nboxplot(loan_amount ~ application_type, \n        data = loans2, main = levels[2])\nboxplot(loan_amount ~ application_type, \n        data = loans3, main = levels[3])"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#visualizing-a-different-relationship",
    "href": "lectures_slides/000_exe_mine.html#visualizing-a-different-relationship",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "visualizing a different relationship",
    "text": "visualizing a different relationship\n\nVisualize the relationship between interest rate and annual income, conditioned on whether the applicant had a bankruptcy."
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-ggplot-1",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-ggplot-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with ggplot()\n",
    "text": "plotting with ggplot()\n\n\nggplot(loans, \n       aes(y = interest_rate, x = annual_income, \n           color = bankruptcy)) +\n  geom_point(alpha = 0.1) + \n  geom_smooth(method = \"lm\", linewidth = 2, se = FALSE) + \n  scale_x_log10()"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#further-customizing-ggplot",
    "href": "lectures_slides/000_exe_mine.html#further-customizing-ggplot",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "further customizing ggplot()\n",
    "text": "further customizing ggplot()\n\n\nggplot(loans, \n       aes(y = interest_rate, x = annual_income, \n           color = bankruptcy)) +\n  geom_point(alpha = 0.1) + \n  geom_smooth(method = \"lm\", linewidth = 2, se = FALSE) + \n  scale_x_log10(labels = scales::label_dollar()) +\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  scale_color_OkabeIto() +\n  labs(x = \"Annual Income\", y = \"Interest Rate\", \n       color = \"Previous\\nBankruptcy\") +\n  theme_minimal(base_size = 18)"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-plot",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-plot",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with plot()\n",
    "text": "plotting with plot()\n\n\n# From the OkabeIto palette\ncols = c(No = \"#e6a003\", Yes = \"#57b4e9\")\n\nplot(\n  loans$annual_income,\n  loans$interest_rate,\n  pch = 16,\n  col = adjustcolor(cols[loans$bankruptcy], alpha.f = 0.1),\n  log = \"x\",\n  xlab = \"Annual Income ($)\",\n  ylab = \"Interest Rate (%)\",\n  xaxp = c(1000, 10000000, 1)\n)\n\nlm_b_no = lm(\n  interest_rate ~ log10(annual_income), \n  data = loans[loans$bankruptcy == \"No\",]\n)\nlm_b_yes = lm(\n  interest_rate ~ log10(annual_income), \n  data = loans[loans$bankruptcy == \"Yes\",]\n)\n\nabline(lm_b_no, col = cols[\"No\"], lwd = 3)\nabline(lm_b_yes, col = cols[\"Yes\"], lwd = 3)\n\nlegend(\n  \"topright\", \n  legend = c(\"Yes\", \"No\"), \n  title = \"Previous\\nBankruptcy\", \n  col = cols[c(\"Yes\", \"No\")], \n  pch = 16, lwd = 1\n)"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#plotting-with-plot-1",
    "href": "lectures_slides/000_exe_mine.html#plotting-with-plot-1",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "plotting with plot()\n",
    "text": "plotting with plot()"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#beyond-wrangling-summaries-visualizations",
    "href": "lectures_slides/000_exe_mine.html#beyond-wrangling-summaries-visualizations",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "beyond wrangling, summaries, visualizations",
    "text": "beyond wrangling, summaries, visualizations\nModeling and inference with tidymodels:\n\nA unified interface to modeling functions available in a large variety of packages\nSticking to the data frame in / data frame out paradigm\nGuardrails for methodology"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#consistency",
    "href": "lectures_slides/000_exe_mine.html#consistency",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "consistency",
    "text": "consistency\n\nNo matter which approach or tool you use, you should strive to be consistent in the classroom whenever possible\ntidyverse offers consistency, something we believe to be of the utmost importance, allowing students to move knowledge about function arguments to their long-term memory"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#teaching-consistently",
    "href": "lectures_slides/000_exe_mine.html#teaching-consistently",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "teaching consistently",
    "text": "teaching consistently\n\nChallenge: Google and Stack Overflow can be less useful ‚Äì demo problem solving\nCounter-proposition: teach all (or multiple) syntaxes at once ‚Äì trying to teach two (or more!) syntaxes at once will slow the pace of the course, introduce unnecessary syntactic confusion, and make it harder for students to complete their work.\n‚ÄúDisciplined in what we teach, liberal in what we accept‚Äù\n\n\n\nPostel, J. (1980). DoD standard internet protocol. ACM SIGCOMM Computer Communication Review, 10(4), 12-51. datatracker.ietf.org/doc/html/rfc760"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#mixability",
    "href": "lectures_slides/000_exe_mine.html#mixability",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "mixability",
    "text": "mixability\n\nMix with base R code or code from other packages\nIn fact, you can‚Äôt not mix with base R code!"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#scalability",
    "href": "lectures_slides/000_exe_mine.html#scalability",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "scalability",
    "text": "scalability\nAdding a new variable to a visualization or a new summary statistic doesn‚Äôt require introducing a numerous functions, interfaces, and data structures"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#user-centered-design",
    "href": "lectures_slides/000_exe_mine.html#user-centered-design",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "user-centered design",
    "text": "user-centered design\n\nInterfaces designed with user experience (and learning) in mind\nContinuous feedback collection and iterative improvements based on user experiences improve functions‚Äô and packages‚Äô usability (and learnability)"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#readability",
    "href": "lectures_slides/000_exe_mine.html#readability",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "readability",
    "text": "readability\nInterfaces that are designed to produce readable code"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#community",
    "href": "lectures_slides/000_exe_mine.html#community",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "community",
    "text": "community\n\nThe encouraging and inclusive tidyverse community is one of the benefits of the paradigm\nEach package comes with a website, each of these websites are similarly laid out, and results of example code are displayed, and extensive vignettes describe how to use various functions from the package together"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#shared-syntax",
    "href": "lectures_slides/000_exe_mine.html#shared-syntax",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "shared syntax",
    "text": "shared syntax\nGet SQL for free with dplyr verbs!"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#building-a-curriculum",
    "href": "lectures_slides/000_exe_mine.html#building-a-curriculum",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "building a curriculum",
    "text": "building a curriculum\n\nStart with library(tidyverse)\nTeach by learning goals, not packages"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#keeping-up-with-the-tidyverse",
    "href": "lectures_slides/000_exe_mine.html#keeping-up-with-the-tidyverse",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "keeping up with the tidyverse",
    "text": "keeping up with the tidyverse\n\nBlog posts highlight updates, along with the reasoning behind them and worked examples\n\nLifecycle stages and badges"
  },
  {
    "objectID": "lectures_slides/000_exe_mine.html#coda",
    "href": "lectures_slides/000_exe_mine.html#coda",
    "title": "Day 2: Inference and Hypothesis testing",
    "section": "coda",
    "text": "coda\n\n\n\nWe are all converts to the tidyverse and have made a conscious choice to use it in our research and our teaching. We each learned R without the tidyverse and have all spent quite a few years teaching without it at a variety of levels from undergraduate introductory statistics courses to graduate statistical computing courses. This paper is a synthesis of the reasons supporting our tidyverse choice, along with benefits and challenges associated with teaching statistics with the tidyverse.\n\n\n\n\n\n\n\n√áetinkaya-Rundel, M., Hardin, J., Baumer, B. S., McNamara, A., Horton, N. J., & Rundel, C. (2021). An educator‚Äôs perspective of the tidyverse. arXiv preprint arXiv:2108.03510. arxiv.org/abs/2108.03510"
  },
  {
    "objectID": "lectures/lec03_corr_regress.html",
    "href": "lectures/lec03_corr_regress.html",
    "title": "Modeling correlation and regression",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lec03_corr_regress.html#lecture-3-outline",
    "href": "lectures/lec03_corr_regress.html#lecture-3-outline",
    "title": "Modeling correlation and regression",
    "section": "Lecture 3 Outline",
    "text": "Lecture 3 Outline\n\nTesting and summarizing relationship between 2 variables (correlation)\n\nPearson \\(r\\) analysis (param)\n\n(numerical variables)\n\nSpearman‚Äôs test (no param)\n\nMeasures of association\n\nChi-Square Test of Independence\n\n(categorical variables)\n\nFisher‚Äôs Exact Test\n\nFrom correlation/association to prediction/causation\n\nThe purpose of observational and experimental studies\n\nWidely used analytical tools\n\nSimple linear regression models\nMultiple Linear Regression models\n\nShifting the emphasis on empirical prediction\n\nIntroduction to Machine Learning (ML)\nDistinction between Supervised & Unsupervised algorithms"
  },
  {
    "objectID": "lectures/lec01_data_with_R.html",
    "href": "lectures/lec01_data_with_R.html",
    "title": "Lecture 1: Intro to R and data analysis",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lec01_data_with_R.html#lecture-1-outline",
    "href": "lectures/lec01_data_with_R.html#lecture-1-outline",
    "title": "Lecture 1: Intro to R and data analysis",
    "section": "Lecture 1 Outline",
    "text": "Lecture 1 Outline\n\nIntroduction to R and R-studio\n\nWhy R?\nPrinciples of reproducible analysis with R + RStudio\n\nR objects, functions, packages\nUnderstanding different types of variables\n\nPrinciples of ‚Äútidy data‚Äù\nData cleaning and manipulation\n\nDescriptive statistics\n\nMeasures of central tendency, measures of variability (or spread), and\n\nFrequency distribution\nVisual data exploration\n\n{ggplot2}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Biostatistics with R",
    "section": "",
    "text": "Welcome!\nThis website collects the materials for a four day workshop organized by MITGEST Doctoral Network in July 2024, hosted by the Radboud Center for Mitochondrial Medicine, Nijmegen, Netherlands.\n\n\nLocation: Radboud Center for Mitochondrial Medicine, Nijmegen, Netherland\n\nTime: 9 am - 4 pm July 24th to July 27th, 2024.\nWorkshop Overview\nThis Biostatistics workshop provides an introduction to selected topics in biostatistical concepts and reasoning. This course aims to introduce to the field and gives a solid understanding of data and data types, hypothesis testing and statistical inference applied to life sciences.\nSpecific topics covered include: tools for describing central tendency and variability in data; methods for performing inference on population means and proportions via sample data; statistical hypothesis testing and its application to group comparisons; issues of power and sample size in study designs; elements of machine learning algorithms for understanding and classifying data.\nWhile there are some formulae and computational elements to the course, the emphasis is on applications of acquired concepts to ‚Äúreal life‚Äù of research scientists.\nThough the vast majority of what you will learn in this course can be applied in any software package, the seminar will use R for empirical examples and exercises.\n\n\n\n\n\n\nSchedule\n\n\n\n\n\nDay\nTime\nActivity\n\n\n\n24 July, 2024\n9am - 12am\nLesson 1 ~ Working with data (with intro to R)\n\n\n24 July, 2024\n1pm - 4pm\nPractice Session 1\n\n\n25 July, 2024\n9am - 12am\nLesson 2 ~ Inferential statistics\n\n\n25 July, 2024\n1pm - 4pm\nPractice Session 2\n\n\n26 July, 2024\n9am - 12am\nLesson 3 ~ Modeling correlation and regression\n\n\n26 July, 2024\n1pm - 4pm\nPractice Session 3\n\n\n27 July, 2024\n9am - 12am\nLesson 4 ~ Intro to machine learning (with R and MetaboAnalyst)\n\n\n27 July, 2024\n1pm - 4pm\nPractice Session 4\n\n\n\n\n\n\n\nPractical information\nParticipants will need to bring their own laptop and make sure to have the required software installed ahead of the workshop.\nStep-by-step installation instructions are provided here."
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation and setup",
    "section": "",
    "text": "This workshop showcases introductory bio statistics concepts using the open source (and free!) programming language . Each session of the workshop features exercises that will help you learn by doing.\nWe will quickly go over this at our first Practice session, but you are expected to have the required software installed on your machine before the workshop.\nBelow is a step by step process that should guide you through the needed installation steps."
  },
  {
    "objectID": "install.html#installing-packages-1st-time-you-use-an-r-package",
    "href": "install.html#installing-packages-1st-time-you-use-an-r-package",
    "title": "Installation and setup",
    "section": "Installing packages (1st time you use an R Package)",
    "text": "Installing packages (1st time you use an R Package)\nOption 1)\nYou could install one package at a time via the function install.packages()‚Ä¶\n\n# (**ONLY** the 1st time you use them)\n\n# Installing \ninstall.packages(\"name_of_package_here\" ) \n\n# [OPTIONAL ARGUMENT] Installing (with specification for dependencies)\ninstall.packages(\"name_of_package_here\" , dependencies = TRUE)\n\n‚Ä¶ or in bulk, like so (it might take a few moments more):\n\n# (**ONLY** the 1st time you use them)\n\n# ---- Installing R pckgs for 1st LAB \npkg_list_lab_1 &lt;- c(\"fs\",\"here\", \"janitor\", \"skimr\", \n                   \"dplyr\", \"forcats\", \n                   \"ggplot2\",  \"ggridges\")\n\ninstall.packages(pkg_list_lab_1)\n\n\n# ---- Installing (more) R pckgs for 2nd LAB  \npkg_list_lab_2 &lt;- c(\"tidyr\", \"patchwork\",\n                    \"ggthemes\", \"ggstatsplot\", \"ggpubr\",  \"viridis\",\n                    \"BSDA\", \"rstatix\", \"car\", \"multcomp\") \n\ninstall.packages(pkg_list_lab_2)\n\n\n# ----  Installing (more) R pckgs for 3rd LAB  \npkg_list_lab_3 &lt;- c(\"openxlsx\", \n                    \"lmtest\" , \n                    \"broom\", \n                    \"performance\")\n\ninstall.packages(pkg_list_lab_3)\n\n\n# ----  Installing (more) R pckgs for 4th LAB  \npkg_list_lab_4 &lt;- c(\"rsample\",\n                    \"MASS\",\n                    \"FactoMineR\",\n                    \"factoextra\",\n                    \"ggfortify\",\n                    \"scatterplot3d\",\n                    \"pwr\" )\n\ninstall.packages(pkg_list_lab_4)\n\nOption 2)\nIn alternative, you could install each package separately, using the RStudio GUI, from the Packages tab in the bottom right pane as indicated here:\n\n\nScreenshot Install/Update pckgs from RStudio"
  },
  {
    "objectID": "install.html#loading-a-package-at-the-beginning-of-every-r-session",
    "href": "install.html#loading-a-package-at-the-beginning-of-every-r-session",
    "title": "Installation and setup",
    "section": "Loading a package (at the beginning of every R session)",
    "text": "Loading a package (at the beginning of every R session)\nOnce packages have been installed, with the command library() loads the specific R packages that you are going to need in any given R session.\n\n# Loading a package (at the beginning of every R session) \n# --- General \nlibrary(here)       # tools find your project's files, based on working directory\nlibrary(fs)         # file/directory interactions\nlibrary(janitor)    # tools for examining and cleaning data\nlibrary(skimr)      # Compact and Flexible Summaries of Data     \nlibrary(openxlsx)   # Read, Write and Edit xlsx Files\n\n# --- Tidyverse \nlibrary(dplyr)      # {tidyverse} A Grammar of Data Manipulation     \nlibrary(tidyr)      # {tidyverse} Tools to create tidy data \nlibrary(forcats)    # {tidyverse} Tools for Categorical Var.(Factors)   \n\n# --- Plotting\nlibrary(ggplot2)    # {tidyverse} tools for plotting\nlibrary(ggstatsplot)# 'ggplot2' Based Plots with Statistical Details \nlibrary(ggpubr)     # 'ggplot2' Based Publication Ready Plots \nlibrary(patchwork)  # Functions for \"\"Grid\" Graphics\"composing\" plots \nlibrary(viridis)    # Colorblind-Friendly Color Maps for R \nlibrary(ggthemes)   # Extra Themes, Scales and Geoms for 'ggplot2'\nlibrary(ggridges)   # Ridgeline Plots in 'ggplot2' (density functions)\n\n# --- Statistics\nlibrary(BSDA)       # Basic Statistics and Data Analysis   \nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)        # Companion to Applied Regression\nlibrary(multcomp)   # Simultaneous Inference in General Parametric Models \nlibrary(lmtest)     # Testing Linear Regression Models  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles\nlibrary(performance)# Assessment of Regression Models Performance \nlibrary(pwr)        # Basic Functions for Power Analysis"
  },
  {
    "objectID": "install.html#learning-about-a-package-after-installation",
    "href": "install.html#learning-about-a-package-after-installation",
    "title": "Installation and setup",
    "section": "Learning about a package (after installation)",
    "text": "Learning about a package (after installation)\nOnce an R package is installed, you can also read the documentation about it directly inside the RStudio IDE. For example, try running in your Console:\n\n# - To ask about a package\n?here\n\n# -- To ask about a specific function\n?janitor::clean_names\n\n?dplyr::group_by\n\nCongrats! You are all done! üôåüèª"
  },
  {
    "objectID": "install.html#useful-keyboard-shortcuts-in-rstudio",
    "href": "install.html#useful-keyboard-shortcuts-in-rstudio",
    "title": "Installation and setup",
    "section": "Useful keyboard shortcuts in RStudio",
    "text": "Useful keyboard shortcuts in RStudio\n\n\n\n\n\n\nDescription\nWindows & Linux\nMac\n\n\n\nInsert code section\nCtrl+Shift+R\nShift+Command+R  or Ctrl+Shift+R\n\n\nRun current line/selection\nCtrl+Enter\nCommand+Return\n\n\nReindent lines\nCtrl+I\nCommand+I\n\n\nInsert &lt;- operator\nAlt+-\nOption+-\n\n\nInsert %&gt;% operator\nCtrl+Shift+M\nShift+Command+M\n\n\nCode completion\nTab\nTab\n\n\nFile path completion (console)\n\"+Tab\n\"+Tab\n\n\n\n\n\n\nHere you find the complete list of RStudio Keyboard Shortcuts"
  },
  {
    "objectID": "lectures/lec02_inference.html",
    "href": "lectures/lec02_inference.html",
    "title": "Statistical inference & hypothesis testing",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lec02_inference.html#lecture-2-outline",
    "href": "lectures/lec02_inference.html#lecture-2-outline",
    "title": "Statistical inference & hypothesis testing",
    "section": "Lecture 2 Outline",
    "text": "Lecture 2 Outline\n\nPurpose and foundations of inferential statistics\n\nProbability and random variables\nMeaningful probability distributions\nSampling distributions and Central Limit Theorem\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing\n\nThe null and alternative hypothesis\nThe probability of error? (Œ± or ‚Äúsignificance level‚Äù)\nThe p-value probability and tests interpretation\nConfidence Intervals\nTypes of errors (Type 1 and Type 2)\nEffective vs statistical significance\n\nHypothesis tests examples\n\nComparing sample mean to a hypothesized population mean (Z test & t test)\nComparing two independent sample means (t test)\nComparing sample means from 3 or more groups (ANOVA) \n\nA closer look at testing assumptions (with examples)\n\nTesting two groups that are not independent\nTesting if the data are not normally distributed: non-parametric tests\nTesting samples without homogeneous variance of observations"
  },
  {
    "objectID": "lectures/lec04_intro_ML.html",
    "href": "lectures/lec04_intro_ML.html",
    "title": "Introduction to machine learning",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "lectures/lec04_intro_ML.html#lecture-4-outline",
    "href": "lectures/lec04_intro_ML.html#lecture-4-outline",
    "title": "Introduction to machine learning",
    "section": "Lecture 4 Outline",
    "text": "Lecture 4 Outline\n\nPCA\n\nAn example of ‚Äúunsupervised‚Äù ML algorithm\n\n\n\n\n\n\n\nIntroduction to MetaboAnalyst software\n\nA useful R-based resources for metabolomics\n\nElements of statistical Power Analysis\nWorkshop Conclusions"
  },
  {
    "objectID": "license_etc.html#acknowledgements",
    "href": "license_etc.html#acknowledgements",
    "title": "Acknowledgments and resources",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\n\nI am genuinely grateful to many people within the Biostatistics, Epidemiology and R programming communities, who shared their valuable work, open source software, and training resources. Special thanks to Luisa M. Mimmi (my sister!) who revised the workshop content and built this dedicated website.\nBelow is a curated list of great resources (most of which free and openly accessible) you can peruse on your own.\n\nI would love to hear your feedback, questions, or suggestions about the workshop:\n\n  ¬†¬†contact us"
  },
  {
    "objectID": "license_etc.html#licensing-and-use-of-the-workshop-materials",
    "href": "license_etc.html#licensing-and-use-of-the-workshop-materials",
    "title": "Acknowledgments and resources",
    "section": "Licensing and use of the workshop materials",
    "text": "Licensing and use of the workshop materials\nThe workshop materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. All borrowed external materials (images, worked examples, etc.), are credited with proper ‚ÄúSource‚Äù statements and governed by their own licenses. To my knowledge, all the consulted materials were published under ‚Äúopen access‚Äù or ‚Äúcreative commons‚Äù frameworks. If this were not the case for any content piece displayed here, please let me know and it will be removed."
  },
  {
    "objectID": "license_etc.html#selected-resources-for-self-guided-learning",
    "href": "license_etc.html#selected-resources-for-self-guided-learning",
    "title": "Acknowledgments and resources",
    "section": "Selected resources for self-guided learning",
    "text": "Selected resources for self-guided learning\n\n\nBiostatistics/Epidemiology with R examples\n\nApplied Epi Team (2024). Applied Epi - Elevating frontline epidemiology [Course]. Training, support, tools. https://www.appliedepi.org/\nApplied Epi Team (2024). R for applied epidemiology and public health The Epidemiologist R Handbook [Course]. https://epirhandbook.com/en/\nBobbitt, Z. (2024). Statology [Course]. Statology. https://www.statology.org/\n√áetinkaya-Rundel, M., & Hardim, J. (2023). Introduction to Modern Statistics (1st Ed) [Book]. https://openintro-ims.netlify.app/\nChilds, D. Z., Hindle, B. J., & Warren, P. H. (2022). Introductory Biostatistics with R [Book]. https://github.com/rstudio/bookdown\n\nSelby, D., & 2021 (2024). Analytical Epidemiology II [Course]. David Selby. https://personalpages.manchester.ac.uk/staff/david.selby/analysis/2021-03-30-inference/\n\nVu, J., & Harrington, D. (2021). Introductory Statistics for the Life and Biomedical Sciences [Book]. https://www.openintro.org/book/biostat/\nR packages & tools\n\nPOSIT (2024). POSIT resources [R]. https://posit.co/resources/.\nRStudio, & Posit (2024). Base-r-cheat-sheet.pdf [R]. https://iqss.github.io/dss-workshops/R/Rintro/base-r-cheat-sheet.pdf\nVarious contributors (2024). Bioconductor - Open source software for Bioinformatics [R]. Bioconductor - Open source software for Bioinformatics. https://www.bioconductor.org/\nWickham, H., Fran√ßois, R., M√ºller, K., & Vaughan, D. (2023). Programming with dplyr [R]. dplyr. https://dplyr.tidyverse.org/articles/programming.html#tidy-selection\nWickham, H. (2014). Tidy Data [R]. Journal of Statistical Software, 59(10). https://doi.org/10.18637/jss.v059.i10\nSources of practice datasets\n\nVanderbilt Department of Biostatistics (2023, September 17). Vanderbilt Biostatistics Datasets [Dataset]. https://hbiostat.org/data/\nChicco, D., & Jurman, G. (2020). Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone [Dataset]. BMC Medical Informatics and Decision Making, 20(1), 16. https://doi.org/10.1186/s12911-020-1023-5\nAhmad, T., Munir, A., Bhatti, S. H., Aftab, M., & Raza, M. A. (2017). Survival analysis of heart failure patients: A case study [Dataset]. PLOS ONE, 12(7), e0181001. https://doi.org/10.1371/journal.pone.0181001"
  },
  {
    "objectID": "practice/lab01_data_with_R.html",
    "href": "practice/lab01_data_with_R.html",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "practice/lab01_data_with_R.html#practice-session-1-input-data-as-subfolder",
    "href": "practice/lab01_data_with_R.html#practice-session-1-input-data-as-subfolder",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Practice session 1: input data (as subfolder)",
    "text": "Practice session 1: input data (as subfolder)\n\n\n Download input data Lab 1"
  },
  {
    "objectID": "practice/lab01_data_with_R.html#practice-session-1-r-code-as-.r-file",
    "href": "practice/lab01_data_with_R.html#practice-session-1-r-code-as-.r-file",
    "title": "Lab 1: Intro to R and data analysis",
    "section": "Practice session 1: R code (as .R file)",
    "text": "Practice session 1: R code (as .R file)\n\n\n Download Lab session 1 as .R file"
  },
  {
    "objectID": "practice/lab03_corr_regress.html",
    "href": "practice/lab03_corr_regress.html",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "practice/lab03_corr_regress.html#practice-session-3-input-data-as-subfolder",
    "href": "practice/lab03_corr_regress.html#practice-session-3-input-data-as-subfolder",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Practice session 3: input data (as subfolder)",
    "text": "Practice session 3: input data (as subfolder)\n\n\n\n Download input data Lab 3"
  },
  {
    "objectID": "practice/lab03_corr_regress.html#practice-session-3-r-code-as-.r-file",
    "href": "practice/lab03_corr_regress.html#practice-session-3-r-code-as-.r-file",
    "title": "Lab 3: Modeling correlation and regression",
    "section": "Practice session 3: R code (as .R file)",
    "text": "Practice session 3: R code (as .R file)\n\n\n\n Download Lab session 3 as .R file"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#needed-r-packages",
    "href": "practice/practice_slides/slides_extra_01.html#needed-r-packages",
    "title": "Diving deeper into Causal Analysis",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\n\n# --- General \nlibrary(here)     # tools find your project's files, based on working directory\nlibrary(dplyr)    # A Grammar of Data Manipulation\nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(magrittr) # A Forward-Pipe Operator for R \nlibrary(readr)    # A Forward-Pipe Operator for R \n\n# Plotting & data visualization\nlibrary(ggplot2)      # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(scatterplot3d) # 3D Scatter Plot\n\n# --- Statistics\nlibrary(MASS)       # Support Functions and Datasets for Venables and Ripley's MASS\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\nlibrary(FactoMineR) # Multivariate Exploratory Data Analysis and Data Mining\nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\n\n# --- Tidymodels (meta package)\nlibrary(rsample)    # General Resampling Infrastructure  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#dataset-on-.",
    "href": "practice/practice_slides/slides_extra_01.html#dataset-on-.",
    "title": "Diving deeper into Causal Analysis",
    "section": "Dataset on ‚Ä¶.",
    "text": "Dataset on ‚Ä¶.\n\nName: ‚Ä¶. Documentation: ‚Ä¶. Sampling details: ‚Ä¶."
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#importing-dataset-....",
    "href": "practice/practice_slides/slides_extra_01.html#importing-dataset-....",
    "title": "Diving deeper into Causal Analysis",
    "section": "Importing Dataset ....",
    "text": "Importing Dataset ....\n.\n\nThe data can be interactively obtained form the MASS R package\n\n\n# (after loading pckg)\n# library(MASS)  \n\n# I can call \n# utils::data(biopsy)"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#section",
    "href": "practice/practice_slides/slides_extra_01.html#section",
    "title": "Diving deeper into Causal Analysis",
    "section": "",
    "text": "We define:\n\nthe individual treatment effect\n\nthe average treatment effect\n\nand the average treatment effect on the treated"
  },
  {
    "objectID": "practice/practice_slides/slides_extra_01.html#final-thoughts",
    "href": "practice/practice_slides/slides_extra_01.html#final-thoughts",
    "title": "Diving deeper into Causal Analysis",
    "section": "Final thoughts",
    "text": "Final thoughts\n\n\n\n‚Ä¶..\n\n‚Ä¶\n\n\n‚Ä¶\n\n\n\n\n\n\nhttps://r4biostats.com/ | R 4 stats"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#goal-of-todays-practice-session",
    "href": "practice/practice_slides/slides_lab02.html#goal-of-todays-practice-session",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "GOAL OF TODAY‚ÄôS PRACTICE SESSION",
    "text": "GOAL OF TODAY‚ÄôS PRACTICE SESSION\nConsolidate understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.\n\nLecture 2: topics\n\n\nPurpose and foundations of inferential statistics    \n\n\nGetting to know the ‚Äúlanguage‚Äù of hypothesis testing     \n\n\nHypothesis testing\n\nreview examples\n\n\n\n\nA closer look at testing assumptions\n\nmore examples dealing with assumptions‚Äô violation"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab02.html#needed-r-packages",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe will also use the packages below (specifying package::function for clarity).\n\n\n\n# Load pckgs for this R session\n\n# General \nlibrary(fs)           # file/directory interactions\nlibrary(here)         # tools find your project's files, based on working directory\nlibrary(janitor)      # tools for examining and cleaning data\nlibrary(dplyr)        # {tidyverse} tools for manipulating and summarising tidy data \nlibrary(forcats)      # {tidyverse} tool for handling factors\nlibrary(tidyr)        # Tidy Messy Data       \n\n# Statistics\nlibrary(BSDA)         # Basic Statistics and Data Analysis   \nlibrary(rstatix)      # Pipe-Friendly Framework for Basic Statistical Tests\nlibrary(car)          # Companion to Applied Regression\nlibrary(multcomp)     # Simultaneous Inference in General Parametric Models \n\n# Plotting\nlibrary(ggplot2)      # {tidyverse} tools for plotting\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details  \nlibrary(ggpubr)       # 'ggplot2' Based Publication Ready Plots \nlibrary(patchwork)    # Functions for \"\"Grid\" Graphics\"composing\" plots \nlibrary(viridis)      # Colorblind-Friendly Color Maps for R \nlibrary(ggthemes)     # Extra Themes, Scales and Geoms for 'ggplot2'"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#importing-from-project-folder-previously-downloaded-file",
    "href": "practice/practice_slides/slides_lab02.html#importing-from-project-folder-previously-downloaded-file",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Importing from project folder (previously downloaded file)",
    "text": "Importing from project folder (previously downloaded file)\nYou can access the dataset either:\n\nFrom the UC Irvine Machine Learning Repository Heart Failure Clinical Records\n\nFrom the workshop website: use function here to specify the complete path of the input data folder\n\n\n# Check my working directory location\n# here::here()\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nheart_failure &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"02_datasets\",\n                                      \"heart_failure_clinical_records_dataset.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n\n\n\n\n\n\nTip\n\n\nMake sure to match your own folder structure!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#what-are-the-variables-and-their-levels-of-measurement",
    "href": "practice/practice_slides/slides_lab02.html#what-are-the-variables-and-their-levels-of-measurement",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "What are the variables and their levels of measurement?",
    "text": "What are the variables and their levels of measurement?\n\nThe data, with medical records of 299 heart failure patient, were collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad (Punjab, Pakistan), during April‚ÄìDecember 2015. See Table¬†1.\n\n\n\nTable¬†1"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#look-into-the-dataset-just-loaded-in-the-r-environment",
    "href": "practice/practice_slides/slides_lab02.html#look-into-the-dataset-just-loaded-in-the-r-environment",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Look into the dataset just loaded in the R environment",
    "text": "Look into the dataset just loaded in the R environment\nRecall some base R functions from Lab 1\n\n# What variables are included in this dataset?\ncolnames(heart_failure)\n\n [1] \"age\"                      \"anaemia\"                 \n [3] \"creatinine_phosphokinase\" \"diabetes\"                \n [5] \"ejection_fraction\"        \"high_blood_pressure\"     \n [7] \"platelets\"                \"serum_creatinine\"        \n [9] \"serum_sodium\"             \"sex\"                     \n[11] \"smoking\"                  \"time\"                    \n[13] \"DEATH_EVENT\"             \n\n# How many observations & variables?\nnrow(heart_failure)\n\n[1] 299\n\n# How many rows & columns?\ndim(heart_failure)\n\n[1] 299  13"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-base-r",
    "href": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-base-r",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Inspect the dataframe structure (base R)",
    "text": "Inspect the dataframe structure (base R)\n\n# What does the dataframe look like?\nstr(heart_failure)\n\n'data.frame':   299 obs. of  13 variables:\n $ age                     : num  75 55 65 50 65 90 75 60 65 80 ...\n $ anaemia                 : int  0 0 0 1 1 1 1 1 0 1 ...\n $ creatinine_phosphokinase: int  582 7861 146 111 160 47 246 315 157 123 ...\n $ diabetes                : int  0 0 0 0 1 0 0 1 0 0 ...\n $ ejection_fraction       : int  20 38 20 20 20 40 15 60 65 35 ...\n $ high_blood_pressure     : int  1 0 0 0 0 1 0 0 0 1 ...\n $ platelets               : num  265000 263358 162000 210000 327000 ...\n $ serum_creatinine        : num  1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ...\n $ serum_sodium            : int  130 136 129 137 116 132 137 131 138 133 ...\n $ sex                     : int  1 1 1 1 0 1 1 1 0 1 ...\n $ smoking                 : int  0 0 1 0 0 1 0 1 0 1 ...\n $ time                    : int  4 6 7 7 8 8 10 10 10 10 ...\n $ DEATH_EVENT             : int  1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-skimr",
    "href": "practice/practice_slides/slides_lab02.html#inspect-the-dataframe-structure-skimr",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Inspect the dataframe structure (skimr)",
    "text": "Inspect the dataframe structure (skimr)\nRemember the skimr function skim?\n\n# some variables \nheart_failure %&gt;% skimr::skim( age, DEATH_EVENT ) \n\n# the whole dataframe\nheart_failure %&gt;% skimr::skim() \n\n\n\n\n\n You try‚Ä¶\n\n\nRun skimr::skim() on your own either on the whole dataset or on any specific variable\n\n\n\n\nnotice there are no (missing values) NAs in any of the variables"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#recode-some-variables-for-later-ease-of-analysis",
    "href": "practice/practice_slides/slides_lab02.html#recode-some-variables-for-later-ease-of-analysis",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Recode some variables for later ease of analysis",
    "text": "Recode some variables for later ease of analysis\n\nI may need some variables coded as factor (e.g.¬†categorical variables for plotting), and, while I am at it, I can add clearer labels for the variables‚Äô levels. Here, we are:\n\nusing tidyverse packages dplyr and forcats\n\nadding new (recoded) variables called ‚Äúoldname_f‚Äù\n\n\n\n\nheart_failure &lt;-heart_failure %&gt;% \n  dplyr::mutate(DEATH_EVENT_f = as.factor(DEATH_EVENT) %&gt;%\n                  forcats::fct_recode(\"died\" = \"1\", \"survived\" = \"0\")) %&gt;% \n  dplyr::mutate(sex_f = as.factor(sex) %&gt;%\n                  forcats::fct_recode(\"male\" = \"1\", \"female\" = \"0\"))\n\n# check \ntable(heart_failure$DEATH_EVENT_f)\n\n\nsurvived     died \n     203       96 \n\ntable(heart_failure$sex_f)\n\n\nfemale   male \n   105    194"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#some-more-dummy-variables-recoded-as-factor",
    "href": "practice/practice_slides/slides_lab02.html#some-more-dummy-variables-recoded-as-factor",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Some more dummy variables recoded as factor",
    "text": "Some more dummy variables recoded as factor\n\n[Mostly for illustration: it‚Äôs totally fine (if not preferable) to keep these as binary [0,1] variables]\n\nIt‚Äôs worth learning the useful function dplyr::across1, which allows to iteratively transform several columns at once!\n\n\n\n# Recode as factor with levels \"yes\" (= 1), \"no\" (= 0)\nfct_cols = c(\"anaemia\", \"diabetes\", \"high_blood_pressure\", \"smoking\" )\n\nheart_failure &lt;- heart_failure  %&gt;% \n  ## ---- 1st create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    # let's introduce `across` function \n    dplyr::across(\n      # Columns to transform\n      .cols = all_of(fct_cols), \n      # Functions to apply to each col  \n      .fns =  ~as.factor (.x),\n      # new name to apply where \"{.col}\" stands for the selected column\n      .names = \"{.col}_f\")) %&gt;% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      # Columns to transform 2 conditions \n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      # Functions to apply to each col(different syntax)\n      .fns = ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))\n\nThis is a bit more advanced, but it will save a lot of typing in some situations‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#small-digression-on-dplyracross",
    "href": "practice/practice_slides/slides_lab02.html#small-digression-on-dplyracross",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "(Small digression on dplyr::across)",
    "text": "(Small digression on dplyr::across)\n\nNotice how dplyr::across(.cols = ..., .fns = ..., .names = ...) has these arguments:\n\n\n.cols = to select the columns which we want to transform (i.e.¬†fct_cols)\n\nwith help from tidyselect functions: all_of, ends_with, and matches\n\n\n\n\n.fns = ~function(.x) to specify the function   \n\nwhere ~function(.x) uses the ‚Äúanonymous function‚Äù syntax of the tidyverse\n\nand .x inside the function is a ‚Äústand in‚Äù for each of the columns selected\n\n\n\n[optional] .names = to name the new cols created using {.col} in place of each of the transformed columns\n\n\n\n## ---- 1st create new cols as \"factor versions\" of old cols\nheart_failure &lt;- heart_failure  %&gt;% \n  dplyr::mutate(\n    dplyr::across(\n      .cols = all_of(fct_cols), \n      .fns = ~as.factor (.x), \n      # (optional)\n      .names = \"{.col}_f\")) %&gt;% \n  ## ---- 2nd create new cols as \"factor versions\" of old cols\n  dplyr::mutate(\n    dplyr::across(\n      .cols = ends_with(\"_f\") & !matches(c( \"DEATH_EVENT_f\", \"sex_f\" )) , \n      .fns =  ~forcats::fct_recode(.x,  yes = \"1\", no = \"0\" )))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#why-is-visual-exploration-important",
    "href": "practice/practice_slides/slides_lab02.html#why-is-visual-exploration-important",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Why is visual exploration important?",
    "text": "Why is visual exploration important?\n\n\nGaining insight on the variables (range, outliers, missing data)\nPreliminary check of assumptions for parametric hypothesis testing:\n\nnormally distributed outcome variables?\nhomogeneity of variance across groups?\n\n\n\nLet‚Äôs explore the Heart failure dataset with some data visualization‚Ä¶\n\nFollowing the referenced articles (which were mostly interested in predict mortality based on patients‚Äô characteristics), we will take the categorical, binary variable DEATH_EVENT_f as our main criterion to split the sample (into survived and dead patients) to explore any significant difference between groups in terms of means of known quantitative features.\n\nWe will look at both:\n\n\ncontinuous variables in the dataset (with the Probability Density Function (PDF))\n\ndiscrete variables in the dataset (with the Probability Mass Function (PMF))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#age",
    "href": "practice/practice_slides/slides_lab02.html#age",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Age",
    "text": "Age\nIntroducing the handy R package patchwork which lets us compose different plots in a very simple and intuitive way\n\n(check it out with ??patchwork)\n\n\nage &lt;-ggplot(heart_failure,aes(x = age ))+\n  geom_histogram(binwidth = 5, color = \"white\", fill = \"grey\",alpha = 0.5)+\n  geom_vline(aes(xintercept = mean(age)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Age Distribution\" )+\n  scale_x_continuous(breaks = seq(40,100,5))  \n\nage2 &lt;-ggplot(heart_failure, aes(x = age, fill = DEATH_EVENT_f))+\n  geom_histogram(binwidth = 5, position = \"identity\",alpha = 0.5,color = \"white\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT == 0])), color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(age[DEATH_EVENT==1])), color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  labs(title =  \"Age Distribution by group (Death Event)\")+\n  scale_x_continuous(breaks = seq(40,100,5))\n\n# patchwork\nlibrary(patchwork) # The Composer of Plots\nage + age2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#age-output",
    "href": "practice/practice_slides/slides_lab02.html#age-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Age",
    "text": "Age\n\n\nAs the age increases, the incidence of death event seems to increase"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk",
    "href": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Creatinine Phosphokinase (CPK)",
    "text": "Creatinine Phosphokinase (CPK)\n\ncpk &lt;- ggplot(heart_failure,aes(x = creatinine_phosphokinase))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title = \"Creatinine phosphokinase (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\ncpk2 &lt;- ggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\")\n\ncpk + cpk2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk-output",
    "href": "practice/practice_slides/slides_lab02.html#creatinine-phosphokinase-cpk-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Creatinine Phosphokinase (CPK)",
    "text": "Creatinine Phosphokinase (CPK)\n\n\nThis definitely doesn‚Äôt look like a normal distribution!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#ejection-fraction",
    "href": "practice/practice_slides/slides_lab02.html#ejection-fraction",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Ejection Fraction",
    "text": "Ejection Fraction\n\nejf &lt;- ggplot(heart_failure,aes(x = ejection_fraction))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  geom_vline(aes(xintercept = mean(ejection_fraction)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Ejection Fraction (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nejf2 &lt;- ggplot(heart_failure,aes(x = ejection_fraction,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,100, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(ejection_fraction[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Ejection Fraction (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nejf + ejf2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#ejection-fraction-output",
    "href": "practice/practice_slides/slides_lab02.html#ejection-fraction-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Ejection Fraction",
    "text": "Ejection Fraction\n\n\nThis also doesn‚Äôt look like a normal distribution‚Ä¶ and there is a remarkable change in the probability density function (PDF) shape when we introduce the grouping variable"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#platelets",
    "href": "practice/practice_slides/slides_lab02.html#platelets",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Platelets",
    "text": "Platelets\n\n# normalize the var for readability \nheart_failure  &lt;-  heart_failure %&gt;%  dplyr::mutate(plat_norm = platelets/1000) \n\nplat &lt;- ggplot(heart_failure,aes(x = plat_norm))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  geom_vline(aes(xintercept = mean(plat_norm)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution)\",\n       y = \"Density\", x = \"Sample platelet count (in 10^3 ¬µL)\") \n\nplat2 &lt;- ggplot(heart_failure,aes(x = plat_norm,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,800, 100))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(plat_norm[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()   + \n  labs(title =  \"Platelets (density distribution) by group (Death Event)\",\n       caption = \"(Sample platelet count in 10^3 ¬µL)\") \n \nplat + plat2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#platelets-output",
    "href": "practice/practice_slides/slides_lab02.html#platelets-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Platelets",
    "text": "Platelets\n\n\nHere the probability distributions resemble a Normal one and we observe more uniformity in the mean/variance across the 2 groups"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-creatinine",
    "href": "practice/practice_slides/slides_lab02.html#serum-creatinine",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Creatinine",
    "text": "Serum Creatinine\n\nser_cr &lt;- ggplot(heart_failure,aes(x = serum_creatinine))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  geom_vline(aes(xintercept = mean(serum_creatinine)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Creatinine (density distribution)\" )+\n  theme(plot.caption = element_text(hjust = 0.5, face = \"italic\"))\n\nser_cr2 &lt;- ggplot(heart_failure,aes(x = serum_creatinine,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_x_continuous(breaks = seq(0,10, 1))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_creatinine[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  labs(title =  \"Serum Creatinine (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_cr + ser_cr2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-creatinine-output",
    "href": "practice/practice_slides/slides_lab02.html#serum-creatinine-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Creatinine",
    "text": "Serum Creatinine\n\n\nAnother continuous random variable with a non-normal distribution (long right tails) and a seemingly important difference in variance between the groups."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-sodium",
    "href": "practice/practice_slides/slides_lab02.html#serum-sodium",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Sodium",
    "text": "Serum Sodium\n\nser_sod &lt;- ggplot(heart_failure,aes(x = serum_sodium))+\n  geom_density(fill = \"gray\", alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  geom_vline(aes(xintercept = mean(serum_sodium)), color = \"#4c4c4c\")+\n  theme_fivethirtyeight()+\n  labs(title = \"Serum Sodium (density distribution)\" )\n\nser_sod2 &lt;- ggplot(heart_failure,aes(x = serum_sodium,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+\n  scale_x_continuous(breaks = seq(0,150, 5))+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(serum_sodium[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  labs(title =  \"Serum Sodium (density distribution) by group (Death Event)\")+\n  theme_fivethirtyeight()\n\nser_sod + ser_sod2 + plot_layout(ncol = 1)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#serum-sodium-output",
    "href": "practice/practice_slides/slides_lab02.html#serum-sodium-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Serum Sodium",
    "text": "Serum Sodium\n\n\nSame as above, except for the long left tails‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#anaemia",
    "href": "practice/practice_slides/slides_lab02.html#anaemia",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Anaemia",
    "text": "Anaemia\n\nanem &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = anaemia_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\") +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Anaemia\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Anemia\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nanem"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#anaemia-output",
    "href": "practice/practice_slides/slides_lab02.html#anaemia-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Anaemia",
    "text": "Anaemia\n\n\nThere seems to be a greater incidence of anaemia in group ‚Äòdied‚Äô"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#diabetes",
    "href": "practice/practice_slides/slides_lab02.html#diabetes",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Diabetes",
    "text": "Diabetes\n\ndiab &lt;- ggplot(heart_failure, \n               aes(x = forcats::fct_infreq(DEATH_EVENT_f ), fill = diabetes_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has Diabetes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with Diabetes\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\ndiab"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#diabetes-output",
    "href": "practice/practice_slides/slides_lab02.html#diabetes-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Diabetes",
    "text": "Diabetes"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#smoking",
    "href": "practice/practice_slides/slides_lab02.html#smoking",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Smoking",
    "text": "Smoking\n\nsmok &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = smoking_f ))+\n  geom_bar(position = \"dodge\")+\n  ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Patient smokes\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients who smoke\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nsmok"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#smoking-output",
    "href": "practice/practice_slides/slides_lab02.html#smoking-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Smoking",
    "text": "Smoking"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#high-blood-pressure",
    "href": "practice/practice_slides/slides_lab02.html#high-blood-pressure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "High blood pressure",
    "text": "High blood pressure\n\nhbp &lt;- ggplot(heart_failure, aes(x = forcats::fct_infreq(DEATH_EVENT_f ), \n                                  fill = high_blood_pressure_f ))+\n  geom_bar(position = \"dodge\")+\n    ## add count labels\n  geom_text(stat = \"count\", aes(label = ..count..),\n            ## make labels suit the dodged bars \n            position=position_dodge(width = 1 ), \n            hjust=0.5, vjust=2,color = \"white\", size =4) +\n  theme_fivethirtyeight() +\n  #scale_x_discrete(labels  = c(\"Death Event:No\",\"Death Event:Yes\"))+\n  scale_fill_manual(values = c(\"#af854f\", \"#af4f78\"),\n                    name = \"Has high blood pressure\",\n                    labels = c(\"No\",\"Yes\"))+\n  labs(title = \"Number of Patients with High blood pressure\") + \n  theme(#axis.text.x = element_text(angle=50, vjust=0.75), \n    axis.text.x = element_text(size=12,face=\"bold\"))     \n\nhbp"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#high-blood-pressure-output",
    "href": "practice/practice_slides/slides_lab02.html#high-blood-pressure-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "High blood pressure",
    "text": "High blood pressure\n\n\nThere is also a greater incidence of high blood pressure in group ‚Äòdied‚Äô"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-z-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-z-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample mean to a hypothesized population mean (with Z test)",
    "text": "Comparing sample mean to a hypothesized population mean (with Z test)\n\nStating the above hypotheses more formally:\nWhat is the population Total Platelet Count (TPC) mean for all people who suffered of heart failure (\\(ùùÅ_{HF}\\))?\n\n\n\\(ùëØ_ùüé\\) : there is no difference in mean TPC between patients who suffered heart failure and the general population\n\n\n\\(ùùÅ_{HF}\\) = 236 -&gt; hypothesis of no effect or (‚Äúno difference‚Äù)\n\n\n\n\\(ùëØ_ùíÇ\\) : there is a difference in mean TPC between patients who have suffered heart failure and the general population (‚Äúsome effect‚Äù). This can be formalized as either:\n\n\n\\(ùùÅ_{HF}\\) &lt; 236 (one-sided test), or\n\n\n\\(ùùÅ_{HF}\\) &gt; 236 (one-sided test), or\n\n\\(ùùÅ_{HF}\\) ‚â† 236 (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n# compute mean & sd for plot\nmean_plat_p &lt;- round(mean(heart_failure$plat_norm), digits = 1)\nsd_plat_p &lt;- round(sd(heart_failure$plat_norm), digits = 1)\n \nheart_failure %&gt;% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.0085, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.0085, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/¬µL)\") \n\n\n\n\nGeneral population data taken from the literature (See Wongsaengsak, Dennis, Arevalo, Ball, & Nugent, 2019)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-output",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n\nFor a general population, the Total Platelet Count (TPL) has ùõç=236 (1000 /¬µL) and ùõî= 59 (1000 /¬µL). Below is the sample distribution:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.a Computation of the test statistic",
    "text": "2.a Computation of the test statistic\n\nIn this case, we have:\n\na large sample \\((n &gt; 100)\\)\n\na known \\(ùõî^ùüê\\) (of the reference population)\nthe observed sample mean \\(\\bar{x}\\) and sample sd \\(s\\).\n\nSo we can compute:\n\\(ùíÅ_{calc}=\\frac{\\bar{x}-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\)\n\n‚úçüèª Let‚Äôs do it ‚Äúby hand‚Äù first to see the steps\n\n\n# General Population of reference \nmu &lt;- 236 \nsigma  &lt;- 59\n# Sample of HF patients\nn &lt;- 299\nx_HF &lt;- mean(heart_failure$plat_norm)         #    263.358\ns_HF &lt;- sd(heart_failure$plat_norm)           #    97.80424\n# IF large sample & KNOWN pop variance \nstd_err_HF &lt;- sigma /sqrt(n)                  # 3.412058\nz_calc_HF &lt;-  (x_HF - mu) / std_err_HF        # 8.018043"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.b Computation of the p-value associated to the test statistic",
    "text": "2.b Computation of the p-value associated to the test statistic\nTo find the p-value associated with a z-score in R, we can use the pnorm() function, which uses the following syntax:\n\n\nq: The z-score\n\nmean: The mean of the normal distribution. Default is 0.\n\nsd: The standard deviation of the normal distribution. Default is 1.\n\nlower.tail:\n\nIf TRUE, the probability to the left of q in the normal distribution is returned\nIf FALSE, the probability to the right is returned. Default is TRUE.\n\n\n\n\n# Left-tailed test\np_value_l &lt;- stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = TRUE) \n# Right-tailed test\np_value_r &lt;- stats::pnorm(z_calc_HF, mean = 0, sd = 1,lower.tail = FALSE) \n# Two-tailed test  (our case)\np_value_two &lt;- 2*stats::pnorm(z_calc_HF, mean = 0, sd = 1, lower.tail = FALSE)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.c Computation of the p-value associated to the test statistic",
    "text": "2.c Computation of the p-value associated to the test statistic\n\nüë©üèª‚Äçüíª Let‚Äôs see how this could be done using an R function BSDA::z.test\n\n\n\nz_test_summary &lt;- BSDA::z.test(x = heart_failure$plat_norm,   \n             alternative='two.sided', \n             mu=236, \n             sigma.x=59, \n             conf.level=.95)\nz_test_summary\n\n\n    One-sample z-Test\n\ndata:  heart_failure$plat_norm\nz = 8.018, p-value = 1.074e-15\nalternative hypothesis: true mean is not equal to 236\n95 percent confidence interval:\n 256.6705 270.0455\nsample estimates:\nmean of x \n  263.358 \n\n\nSame results!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\n\nBased on the critical region, the calculated test statistic z_calc_HF = 8.0180 falls in the CRITICAL REGION (well beyond the critical point)\n\n\n# given \nz_critical  &lt;- c(-1.96, +1.96) # (Z score corresponding to ùõº  = 0.05)\n# Check \nz_calc_HF &gt; z_critical \n\n[1] TRUE TRUE\n\n\n\nBased on the p-value, p_value_two = 1.07443e-15 is much much smaller than \\(\\alpha\\)\n\n\n\n# Check\np_value_two &lt;  0.05\n\n[1] TRUE\n\n\nDECISION: we reject the Null Hypothesis (basically we conclude that it is extremely unlikely that the sample we drew could have occurred just by chance). So the test indicates that, indeed, there is a difference between heart failure patients and the general population in terms of average platelets count."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-t-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-mean-to-a-hypothesized-population-mean-with-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample mean to a hypothesized population mean (with t test)",
    "text": "Comparing sample mean to a hypothesized population mean (with t test)\n\nSame question, but with a smaller sample to work on (this varies, but generally it means \\(n &lt; 30\\)). Imagine the patients were only observed over a follow-up period of 21 days, and also let‚Äôs assume we don‚Äôt know the population‚Äôs variance\nStating the hypothesis more formally:\nWhat is the population Total Platelet Count (TPC) mean for all people who suffered of heart failure (\\(ùùÅ_{HF21d}\\)) in the past 21 days or less?\n\n\n\\(ùëØ_ùüé\\) : there is no difference in mean TPC between patients who suffered heart failure (visited in 21 days) and the general population\n\n\n\\(ùùÅ_{HF21d}\\) = 236 -&gt; hypothesis of no effect or (‚Äúno difference‚Äù)\n\n\n\n\\(ùëØ_ùíÇ\\) : there is a difference in mean TPC between patients who have suffered heart failure and the general population (‚Äúsome effect‚Äù). This can be formalized as:\n\n\n\\(ùùÅ_{HF21d}\\) ‚â† 236 (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n# normalize the var for readability \nheart_21d  &lt;-  heart_failure %&gt;%  dplyr::mutate(plat_norm = platelets/1000) %&gt;% \n  filter(time &lt;= 21)                                # 23 obs \n# compute mean & sd for plot\nmean_plat_p &lt;- round(mean(heart_21d$plat_norm), digits = 1)\nsd_plat_p &lt;- round(sd(heart_21d$plat_norm), digits = 1)\n \nheart_21d %&gt;% \n  ggplot(aes(x = plat_norm))+\n  geom_histogram(aes(y = ..density..), bins=30, alpha=0.25, colour = \"#4c4c4c\") + \n  geom_density(colour =\"#9b2339\", alpha=0.25, fill = \"#9b2339\") +\n  # add mean vertical line\n  geom_vline(xintercept = mean_plat_p, na.rm = FALSE,size = 1,color= \"#9b6723\") +\n  # add also +/- 1sd  \n  geom_vline(aes(xintercept = mean_plat_p + sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  geom_vline(aes(xintercept = mean_plat_p - sd_plat_p), \n             color = \"#23749b\", size = 1, linetype = \"dashed\") +\n  # add annotations with the mean value\n  geom_label(aes(x=mean_plat_p,  y=0.014, label=paste0(\"Sample mean\\n\",mean_plat_p)),\n             color = \"#9b6723\") + \n  geom_label(aes(x=361,  y=0.014, label=paste0(\"Sample sd\\n\",sd_plat_p)),\n             color = \"#23749b\") +\n  theme_bw() +  labs(y = \"Density\", x = \"Sample platelet count (x 1000/¬µL)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1-output",
    "href": "practice/practice_slides/slides_lab02.html#question-how-does-the-mean-platelets-count-in-the-patients-sample-compare-against-a-reference-population-1-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?",
    "text": "1. Question: How does the mean platelets count in the patients‚Äô sample compare against a reference population?\n\n\nFor a general population, the Total Platelet Count (TPL) has ùõç=236 (1000 /¬µL) and ùõî= 59 (1000 /¬µL). Below is the smaller sample distribution:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-picking-the-suitable-test",
    "href": "practice/practice_slides/slides_lab02.html#a-picking-the-suitable-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.a Picking the suitable test",
    "text": "2.a Picking the suitable test\nIn this case, we have:\n\na ‚Äúsmall‚Äù sample \\(n = 23\\)\n\nan unknown \\(ùõî^ùüê\\) (of the reference population)\nWe obtained the sample mean \\(\\bar{x}\\) and sample sd \\(s\\).\n\nSo we can compute:\n\\(t_{calc} =\\frac{\\bar{x}-\\mu}{\\frac{s_\\bar{x}}{\\sqrt{n-1}}}\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.b Computation of the test statistic",
    "text": "2.b Computation of the test statistic\n\n\nOption 1: Let‚Äôs compute the t test ‚Äúby hand‚Äù ‚úçüèª\n\n\n# General Population of reference \nmu_pop &lt;- 236 \n\n# SAMPLE HF patients follow up less 21 days \nheart_21d &lt;- heart_failure %&gt;% filter(time &lt;= 21) \n\nn_21d &lt;- nrow(heart_21d)                            # 23\nx_HF_21d &lt;- mean(heart_21d$plat_norm)               # 251.5094\ns_HF_21d &lt;- sd(heart_21d$plat_norm)                 # 102.7341\ndf_HF_21d &lt;- n_21d-1                                # 22   \n\n# IF SMALL sample UNKNOWN sigma\nstd_err_HF_21d &lt;- s_HF_21d /sqrt(n_21d -1)        # 21.90298\nt_calc &lt;-  (x_HF_21d - mu_pop) / std_err_HF_21d   # 0.7080951\n\n\nOption 2: Let‚Äôs compute the t test with stats::t.test üë©üèª‚Äçüíª\n\n\nt_stat_HF_21d_v2 &lt;- stats::t.test(x = heart_21d$plat_norm,\n                                  mu = mu_pop,\n                                  alternative = \"two.sided\")\n# extract t_calc from results df\nt_calc_v2  &lt;- t_stat_HF_21d_v2[[\"statistic\"]][[\"t\"]] # 0.7240093\n\n\n\n\nThere is a small difference in the t_calc ‚â† t_calc_v2 due to the fact that I use the Bessel‚Äôs correction n-1 in the sample standard deviation formula denominator, while the R function uses n"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic-1",
    "href": "practice/practice_slides/slides_lab02.html#c-computation-of-the-p-value-associated-to-the-test-statistic-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2.c Computation of the p-value associated to the test statistic",
    "text": "2.c Computation of the p-value associated to the test statistic\n\n\nOption 1: ‚Äúby hand‚Äù ‚úçüèª\n\nTo find the p-value associated with a t-score in R, we can use the pt(q, df, lower.tail = TRUE) function, which uses the following syntax:\n\n\nq: The t-score\n\ndf: The degrees of freedom\n\nlower.tail:\n\nTRUE to calculate the probability to the left of q which is called as left-tailed test\nFALSE as right-tailed test.\n\n\n\n\n# ---- Option 1 \n# -- Left-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = TRUE)\n\n# -- Right-tailed test\n#pt(t_stat_HF_21d, df_HF_21d, lower.tail = FALSE) \n\n# -- Two-tailed test  (our case)\np_value_t_test &lt;- 2*pt(t_calc, df_HF_21d, lower.tail = FALSE) # 0.4863214\n\n\nOption 2: from results of stats::t.test üë©üèª‚Äçüíª\n\n\n# ---- Option 2 \n# extract  p_value from results df\np_value_v2  &lt;- t_stat_HF_21d_v2[[\"p.value\"]] # 0.4766892"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-1",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\n\n\nBased on the critical region, t_calc ‚âÉ 0.71 is smaller than the t critical value, i.e.¬†it falls within the region of acceptance, so he null hypothesis is not rejected\n\n\n#find two-tailed t critical values\n\nt_crit_two &lt;- qt(p=.05/2, df=22, lower.tail=FALSE)    # 2.073873\n# Compare t score against t critical    \nt_calc &gt; t_crit_two  # FALSE \n\n[1] FALSE\n\n\n\nBased on the p-value, p_value ‚âÉ 0.48 is larger than \\(\\alpha\\), i.e.¬†the probability of observing a test statistic (assuming \\(H_0\\) is true) is quite large\n\n\n# Check \np_value_t_test &lt;  0.05  # FALSE \n\n[1] FALSE\n\n\nDECISION: we FAIL to reject \\(H_0\\). So the test indicates that there is not a statistically significant difference between heart failure patients visited within 21 days and the general population in terms of average platelets count.\n\n\n\n\n\n\nNote\n\n\nWhat changed testing a sample with smaller n, instead of a large one?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test)",
    "text": "Comparing two independent sample means (t test)\n\nThis time, we investigate if there might be an actual difference in the Platelet Count means between the patients who died and the patients who survived heart failure.\nStating the above hypotheses more formally:\nIs there a statistically significant difference between the mean values of two groups?\n\n\n\\(ùëØ_ùüé\\) : The two population means are equal\n\n\n\\(ùùÅ_ùüè = ùùÅ_ùüé ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé=ùüé\\)\n\n\n\n\n\\(ùëØ_ùíÇ\\) : There is a mean difference between the two groups in the population. Possible directional difference formulation (two-tailed, left-tailed, right-tailed)\n\n\n\\(ùùÅ_ùüè‚â†ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé‚â†ùüé\\) (the two population means are not equal)\n\n\\(ùùÅ_ùüè &lt; ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé&lt;ùüé\\) (population 1 mean is less than population 0 mean)\n\n\\(ùùÅ_ùüè &gt; ùùÅ_ùüé  ‚ü∫ ùùÅ_ùüè‚àíùùÅ_ùüé&gt;ùüé\\) (population 1 mean is greater than population 0 mean)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test) (cont.)",
    "text": "Comparing two independent sample means (t test) (cont.)\n1. Question: Is there a statistically significant difference between the Platelet Counts in the patients who died v. survived heart failure?\n\n# boxplot by group\nheart_failure %&gt;% \n  ggplot(mapping = aes(y = plat_norm, x = DEATH_EVENT_f, fill = DEATH_EVENT_f)) +\n  geom_boxplot(alpha=0.5)+ \n  #geom_violin(alpha=0.5) +\n  geom_point(position = position_jitter(width = 0.1), size = 0.5)+ \n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))  +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        legend.position = \"none\",\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\")) + \n  labs(title = \"Boxplot of Total Platelet Count (TPL), grouping by DEATH_EVENT [0,1]\",\n       x = \"\", y  = \"Platelet count (1000 /¬µL)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.-output",
    "href": "practice/practice_slides/slides_lab02.html#comparing-two-independent-sample-means-t-test-cont.-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing two independent sample means (t test) (cont.)",
    "text": "Comparing two independent sample means (t test) (cont.)\n\n\nThere seems to be no major difference in the two groups"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-independent-t-test",
    "href": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-independent-t-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2. Verify the assumptions for independent t-test",
    "text": "2. Verify the assumptions for independent t-test\n\nThe 2 samples (‚Äúdied‚Äù and ‚Äúsurvived‚Äù) must be independent ‚úÖ\nThe dependent variable is scaled in intervals (Platelets Count in 10^3 ‚Äú/¬µL‚Äù) ‚úÖ\nThe dependent variable is normally distributed (Platelets Count in 10^3 ‚Äú/¬µL‚Äù) ‚úÖ\n\n\n(If not, use non parametric test)\n\n\n\nThe variance within the 2 groups should be similar ‚ùì\n\n\n(If not, perform Welch‚Äôs t-test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary Fisher‚Äôs F test to check for variance equality",
    "text": "Preliminary Fisher‚Äôs F test to check for variance equality\n\nWe can compute the Fisher test ‚Äúby hand‚Äù ‚úçüèª\n\n\n## -- data by group\nn_died &lt;- nrow(heart_failure[heart_failure$DEATH_EVENT == 1 ,])\nmean_died &lt;- mean(heart_failure [ heart_failure$DEATH_EVENT == 1,  \"plat_norm\"])\nsd_died &lt;- sd(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\nvar_died &lt;- var(heart_failure [heart_failure$DEATH_EVENT == 1 ,  \"plat_norm\"])\n\nn_survived &lt;- nrow(heart_failure[heart_failure$DEATH_EVENT == 0, ])\nmean_survived &lt;- mean(heart_failure [ heart_failure$DEATH_EVENT == 0,  \"plat_norm\"])\nsd_survived &lt;- sd(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\nvar_survived &lt;- var(heart_failure [heart_failure$DEATH_EVENT == 0 ,  \"plat_norm\"])\n\n## -- F TEST\nF_ratio &lt;- var_died / var_survived\nF_ratio  # 1.020497 \n\n[1] 1.020497"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality-.cont",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-fishers-f-test-to-check-for-variance-equality-.cont",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary Fisher‚Äôs F test to check for variance equality (.cont)",
    "text": "Preliminary Fisher‚Äôs F test to check for variance equality (.cont)\n\n## -- Define the critical value of F distribution for a risk of alpha = 0.05\n# qf(p=.05, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # RIGHT-Tailed\n# qf(0.95, df1 = n_died-1, df2 = n_survived-1, lower.tail = FALSE) # LEFT- Tailed \nqf(c(0.025, 0.975), df1 = n_died-1, df2 = n_survived-1) # TWO-Tailed \n\n[1] 0.6994659 1.3987233\n\n## --Compute the exact p-value (two-tailed )\np_value_f &lt;- 2 * (1 - pf(F_ratio, df1 = (n_died-1), df2 = (n_survived-1))) \np_value_f\n\n[1] 0.8914982\n\n\nA test statistic (F) of 1.02 is obtained, with degrees of freedom 95 and 202.\nThe p-value is 0.89, greater than the p-value threshold of 0.05. This suggests we can not reject the null hypothesis of equal variances.\nThe variance within the 2 groups should be similar ‚úÖ ‚Äì&gt; we can run a t-test."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-t-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-t-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.a Computation of t test statistic",
    "text": "3.a Computation of t test statistic\n\nSince we verified the required assumptions, the test method is the independent (two-sample) t-test. In this case, we have:\n\na large sample \\((ùêß_ùüè +ùêß_ùüê &gt; 100)\\)\n\nthe population variance(s) are unknown, but we can assume = variances in 2 groups\n\n\n\\(standard\\, error\\) of the means‚Äô difference is obtained as pooled estimate standard deviation of the sampling distribution of the difference\n\n\nSo we can compute: \\(t_{calc} = \\frac{Difference\\,Between\\,Sample\\,means}{Std.\\,Err.\\,of\\,the\\,difference} = \\frac{\\bar{x_1} -\\bar{x_2}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}}+\\frac{s_{2}^{2}}{n_{2}}}}\\)\n\n\n# Step 1 - compute difference of sample means\nmean_diff &lt;- (mean_died - mean_survived) # -10.27645 \n\n# Step 2 - Compute associated t-statistics\n# pooled std error \npooled_stderror &lt;- sqrt(sd_died^2/(n_died ) + sd_survived^2/(n_survived )) \n# pooled std error corrected\npooled_stderror_corr &lt;- sqrt(sd_died^2/(n_died-1) + sd_survived^2/(n_survived-1)) \n\n###  t statistic  \nt_calc &lt;- (mean_died - mean_survived) / pooled_stderror_corr"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-t-statistic",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-the-p-value-associated-to-the-t-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.b Computation of the p-value associated to the t statistic",
    "text": "3.b Computation of the p-value associated to the t statistic\n\n# Step 3 - degrees of freedom\n# n1 + n2 - number of estimated parameters (2 means)\nd_f &lt;- n_died + n_survived - 1 - 1 # 297\n\n# Step 4 - Deduced p-value\np_value &lt;- 2 * pt(t_calc, df = d_f) # 0.4009635\np_value\n\n[1] 0.4009635"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-2",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-2",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\n\n\nLooking at the confidence interval of the difference, the sample mean_diff is well inside the 95% CI of = population mean\n\n\nmean_diff\n\n[1] -10.27645\n\n# CI of the means difference \nCI_lower &lt;- mean_diff + qt(.025, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_lower\n\n[1] -34.32074\n\nCI_upper &lt;- mean_diff + qt(.975, sum(n_died + n_survived) - 2) * pooled_stderror_corr  \nCI_upper\n\n[1] 13.76785\n\n\n\nAs for the p-value, p_value = 0.40 is bigger than threshold probability \\(\\alpha\\)\n\n\n\n# Check \np_value\n\n[1] 0.4009635\n\np_value &lt;  0.05  # FALSE \n\n[1] FALSE\n\n\nDECISION: So, we fail to reject the null hypothesis of equal populations means of TPC. So the test indicates that we do not have sufficient evidence to say that the mean counts of platelets in between these two populations is different."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#comparing-sample-means-from-3-or-more-groups-anova",
    "href": "practice/practice_slides/slides_lab02.html#comparing-sample-means-from-3-or-more-groups-anova",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Comparing sample means from 3 or more groups (ANOVA)",
    "text": "Comparing sample means from 3 or more groups (ANOVA)\nIn this example, we adopt the ANOVA (‚ÄúAnalysis Of Variance‚Äù) test, i.e.¬†an extension of the previous test, but examined how means of a variable differ across 3 or more groups. We will use ‚Äòone- way‚Äô ANOVA, which serves when there is only one explanatory variable (‚Äútreatment‚Äù) with 3 or more levels, and only one level of treatment is applied for a given subject.\nFor this particular case, we use another realistic dataset showing the survival times of 33 laboratory mice with thymic leukemia who were randomly divided into 3 groups:\n\n1st group received Treatment 1\n2nd group received Treatment 2\n3rd group as Control\n\n\n# load new dataset\nmice &lt;- readxl::read_excel(here::here(\"practice\",\"data_input\",\n                                      \"02_datasets\",\"mice_exe_ANOVA.xlsx\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between the mean values of the k populations?",
    "text": "1. Question: Is there a statistically significant difference between the mean values of the k populations?\nDefining the question formally:\n\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_ùüè = ùùÅ_ùüê =  ùùÅ_3\\) all 3 population means are equal\n\n\\(ùëØ_ùíÇ\\) : at least one of \\((ùùÅ_ùüè,ùùÅ_ùüê,ùùÅ_3)\\) is not equal to the other means\n\n\n# boxplot by group\nmice %&gt;% \nggplot(., aes(x = group, y = surv_days, fill = group)) +\n  geom_boxplot() + \n  scale_fill_viridis(discrete = TRUE, alpha=0.6, option=\"A\") +\n  geom_jitter(color=\"black\", size=0.4, alpha=0.9) +\n  # theme_minimal() +\n  # drop legend and Y-axis title\n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"),\n        axis.text.x = element_text(size=12,face=\"bold\"), \n        axis.text.y = element_text(size=12,face=\"bold\"),\n        legend.position = \"none\",\n        ) + \n  labs(title = \"Visually check mean and variance in populations' samples\" ) + \n  ylab(label = \"Survival (# days\") + xlab(label = \"\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations-output",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-the-mean-values-of-the-k-populations-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between the mean values of the k populations?",
    "text": "1. Question: Is there a statistically significant difference between the mean values of the k populations?\n\n\nThe boxplot suggests that the 3 groups might have some fairly different distributions"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-one-way-anova",
    "href": "practice/practice_slides/slides_lab02.html#verify-the-assumptions-for-one-way-anova",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2. Verify the assumptions for one-way ANOVA",
    "text": "2. Verify the assumptions for one-way ANOVA\nThe dependent variable is on a metric scale. In the case of the analysis of variance, the independent variable (factor) has at least three levels.\nAssumptions for the results of a one-way ANOVA to be valid:\n\n\nIndependence of observations ‚Äì The observations in each group are independent of each other and the observations within groups were obtained by a random sample. ‚úÖ\n\nNormally-distributed response variable ‚Äì The values of the dependent variable follow a normal distribution. ‚ùì\n\nHomogeneity of variance ‚Äì The variances of the populations that the samples come from are equal. ‚ùì"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nNormally-distributed response variable ‚úÖ\n\n\n(confirmed by visual inspection )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-statsshapiro.test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-statsshapiro.test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with stats::shapiro.test",
    "text": "Preliminary check for normality (test) with stats::shapiro.test\n\n# Shapiro-Wilk Normality Test to verify normality  \n# option 1 \nstats::shapiro.test(mice[mice$group == \"Control\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Control\", \"surv_days\", drop = TRUE]\nW = 0.99374, p-value = 0.9989\n\nstats::shapiro.test(mice[mice$group == \"Treatment 1\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 1\", \"surv_days\", drop = TRUE]\nW = 0.95716, p-value = 0.6106\n\nstats::shapiro.test(mice[mice$group == \"Treatment 2\", \"surv_days\", drop=TRUE])\n\n\n    Shapiro-Wilk normality test\n\ndata:  mice[mice$group == \"Treatment 2\", \"surv_days\", drop = TRUE]\nW = 0.97921, p-value = 0.9601"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with rstatix::shapiro_test",
    "text": "Preliminary check for normality (test) with rstatix::shapiro_test\n(same thing, but using a different R function)\n\n\nNormally-distributed response variable ‚Äì ‚úÖ\n\n\n(confirmed by Shapiro-Wilk normality test)\n\n[The null hypothesis of this test is \\(H_0\\) = ‚Äúsample distribution is normal‚Äù ]\n\n# Shapiro-Wilk Normality Test to verify normality  \n# option 2 (all 3 groups at once)\nmice %&gt;%\n  dplyr::group_by(group) %&gt;%\n  rstatix::shapiro_test(surv_days)\n\n# A tibble: 3 √ó 4\n  group       variable  statistic     p\n  &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 Control     surv_days     0.994 0.999\n2 Treatment 1 surv_days     0.957 0.611\n3 Treatment 2 surv_days     0.979 0.960"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-variance-equality",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-variance-equality",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check variance equality",
    "text": "Preliminary check variance equality\n\n\n\nHomogeneity of variance ‚Äì ‚úÖ\n\n\n(Besides visual inspection, confirmed by Levene test for variance equality)\n\n[The null hypothesis \\(H_0\\) = several groups have the same variance (possible variance differences occur only by chance, since there are small differences in each sampling)]\n\n# Levene test for variance equality\nlevene &lt;- mice %&gt;%                               # name of the data\n  car::leveneTest(surv_days ~ as.factor(group),   # continuous DV ~  group IV\n                  data = .,            # pipe the data from above\n                  center = mean)       # default is median \nlevene\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df F value Pr(&gt;F)\ngroup  2  0.1721 0.8427\n      30               \n\n\nNo evidence of violations of HOV were found, since the p-value for the Levene test (= 0.8427157) is greater than .05, then the variances are not significantly different from each other (i.e., the homogeneity assumption of the variance is met)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-anova-f-ratio",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-anova-f-ratio",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3 Computation of ANOVA F-ratio",
    "text": "3 Computation of ANOVA F-ratio\nANOVA in R can be done in several ways.\nSince it‚Äôs quite straightforward, let‚Äôs do all the steps by hand first. We need to obtain the needed ‚Äúingredients‚Äù to calculate the F-ratio:\n\\[ùë≠_{calc}=\\frac{Mean\\, Square\\, Between}{Mean, Square\\, Within}=  \\frac{MSB}{MSW} = \\frac{\\frac{SSB}{df1}}{\\frac{SSW}{df2}} \\]"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#a-computation-of-anova-f-ratio-by-hand",
    "href": "practice/practice_slides/slides_lab02.html#a-computation-of-anova-f-ratio-by-hand",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.a Computation of ANOVA F-ratio (‚Äúby hand‚Äù)",
    "text": "3.a Computation of ANOVA F-ratio (‚Äúby hand‚Äù)\n\n\nOption 1: Let‚Äôs compute the ANOVA test ‚Äúby hand‚Äù ‚úçüèª\n\n\n# Summary statistics\nmice_calc &lt;- mice %&gt;% \n  dplyr::mutate(mean_all = mean(surv_days),\n         sd_all = sd (surv_days),\n         dfw = 33-3, # df1 = n-k\n         dfb = 3-1, # df2 = K‚àí1 \n         group_f = as.factor(group)\n         ) %&gt;% \n  dplyr::group_by(group) %&gt;% \n  dplyr::mutate(n_group = n(),\n         mean_group = mean(surv_days),\n         sd_group = sd (surv_days)) %&gt;% \n  ungroup() %&gt;% \n  mutate (ST = (surv_days - mean_all)^2,\n          SW = (surv_days - mean_group)^2,\n          SB = (mean_group - mean_all)^2)\n\n# Sum of Squares \nSST &lt;- sum(mice_calc$ST)\nSSB &lt;- sum(mice_calc$SB)\nSSW &lt;- sum(mice_calc$SW)\ndfw &lt;- 33-3  # df2\ndfb &lt;- 3-1 # df1\n\n# calculated F statistic \nF_calc &lt;- (SSB/dfb)/(SSW/dfw) # 5.65\n# F critical value\nF_crit &lt;- qf(p = 0.01, df1 = 2, df2 = 30, lower.tail = FALSE) # 5.390346"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#b-computation-of-anova-f-ratio-with-r-functions",
    "href": "practice/practice_slides/slides_lab02.html#b-computation-of-anova-f-ratio-with-r-functions",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3.b Computation of ANOVA F-ratio (with R functions)",
    "text": "3.b Computation of ANOVA F-ratio (with R functions)\n\nThat was just to show how to build it step-by-step (ü§ì), but we don‚Äôt have to! We have alternative R functions that can do ANOVA for us:\n\nOption 2: With the stats::aov followed by the command summary üë©üèª‚Äçüíª\n\n\naov_1 &lt;- stats::aov(surv_days ~ group_f,\n                 data = mice_calc)\nsummary(aov_1) \n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \ngroup_f      2  434.6  217.32   5.652 0.00826 **\nResiduals   30 1153.4   38.45                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nOption 3: With the stats::oneway.test() function üë©üèª‚Äçüíª\n\n\naov_2 &lt;- stats::oneway.test(surv_days ~ group_f,\n            data = mice_calc,\n            # assuming equal variances\n            var.equal = TRUE)\naov_2\n\n\n    One-way analysis of means\n\ndata:  surv_days and group_f\nF = 5.6522, num df = 2, denom df = 30, p-value = 0.008258"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-3",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-3",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\nAll 3 options have given the same results, i.e., F-ratio = 5.652 and a p-value = 0.00826\nDECISION: Given that the p-value is smaller than 0.05, we reject the null hypothesis, so we reject the hypothesis that all means are equal. Therefore, we can conclude that at least one group is different than the others in mean number of survival days.\n\n\n\n\n\n\nNote\n\n\nHave you seen the kind of notation Pr(&gt;F) 0.00826 ** before (as in the output of the stats::aov function)?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-two-groups-that-are-not-independent",
    "href": "practice/practice_slides/slides_lab02.html#testing-two-groups-that-are-not-independent",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing two groups that are not independent",
    "text": "Testing two groups that are not independent\nLet‚Äôs introduce another toy dataset just for demonstration purposes: imagine a statistics test is administered to the same group of 12 students before and after attending a workshop üòâ.\n\n# toy dataset for paired groups\ngrades &lt;- data.frame(\n  before = c(16, 5, 15, 2, 14, 15, 4, 7, 15, 6, 7, 14),\n  after = c(19, 18, 9, 17, 8, 7, 16, 19, 20, 9, 11, 18)\n)\n\nWe may reshape the dataframe into the long form using tidyr::pivot_longer (for plotting)\n\n# reshape into long form\ngrades_long &lt;- grades %&gt;% \n  dplyr::mutate(id = row_number()) %&gt;%\n  tidyr::pivot_longer(cols = before:after, \n                      names_to = \"time\", \n                      values_to = \"grade\") %&gt;% \n  dplyr::group_by(id) %&gt;% \n  # recode time as factor \n  dplyr::mutate(time_f = as_factor(time ))  %&gt;% \n  # reorder time_ levels  \n  dplyr::mutate(time_f =  fct_relevel(time_f, \"after\", after =  1))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-the-difference-between-two-paired-samples-statistically-significant",
    "href": "practice/practice_slides/slides_lab02.html#question-is-the-difference-between-two-paired-samples-statistically-significant",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is the difference between two PAIRED samples statistically significant?",
    "text": "1. Question: Is the difference between two PAIRED samples statistically significant?\n\nWhat a successful workshop! üòÅ"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#hypotehsis-for-the-paired-t-test-for-dependent-samples",
    "href": "practice/practice_slides/slides_lab02.html#hypotehsis-for-the-paired-t-test-for-dependent-samples",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Hypotehsis for the PAIRED t-test for dependent samples",
    "text": "2 Hypotehsis for the PAIRED t-test for dependent samples\n\nIn this example, it is clear that the two samples are not independent since the same 12 students took the test before and after the workshop.\nGiven that the normality assumption is NOT violated (and given the small sample size), we use the paired t-test, with the following hypotheses:\n\n\n\\(ùëØ_ùüé\\) : mean grades before and after the workshop are equal\n\n\\(ùëØ_ùíÇ\\) : mean grades before and after the workshop are different"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-paired-t-test-for-dependent-samples",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-paired-t-test-for-dependent-samples",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Computation of the PAIRED t-test for dependent samples",
    "text": "2 Computation of the PAIRED t-test for dependent samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nt_stat_paired &lt;- stats::t.test(x = grades$before,\n                               y = grades$after, \n                               mu = 0, \n                               alternative = \"two.sided\",\n                               paired = TRUE\n)\nt_stat_paired\n\n\n    Paired t-test\n\ndata:  grades$before and grades$after\nt = -1.8777, df = 11, p-value = 0.08718\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -9.2317713  0.7317713\nsample estimates:\nmean difference \n          -4.25 \n\n# extract t_calc from results df\nt_calc_pair   &lt;- t_stat_paired[[\"statistic\"]][[\"t\"]] # -1.877683\np_value_pair   &lt;- t_stat_paired[[\"p.value\"]] # 0.08717703"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-4",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-4",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\nWe obtain the test statistic, the p-value and a reminder of the hypothesis tested.\nThe calculated t value is -1.8776829 The p-value is 0.087177. Therefore, at the 5% significance level, we do not reject the null hypothesis that the statistics‚Äô grades are similar before and after the workshop (üò≠)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#bonus-function",
    "href": "practice/practice_slides/slides_lab02.html#bonus-function",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Bonus function!",
    "text": "Bonus function!\nIt is worth mentioning the ggstatsplot package, which combines plots representing the distribution for each group‚Äîand the results of the statistical test displayed in the subtitle of the plot.\nBelow we check out the ggwithinstats() function for paired samples.\n\n# load package\nlibrary(ggstatsplot) # 'ggplot2' Based Plots with Statistical Details\n\n# plot with statistical results\ngrades_long %&gt;% \n  # must ungroup the dataframe or it will give an error\n  ungroup () %&gt;% \n  ggstatsplot::ggwithinstats(.,\n                             x = time_f ,\n                             y = grade ,\n                             type = \"parametric\", # for t test \n                             centrality.plotting = FALSE # remove median\n  )"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#bonus-function-output",
    "href": "practice/practice_slides/slides_lab02.html#bonus-function-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Bonus function!",
    "text": "Bonus function!\n\n\nThe test results are rendered with the plot!"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-samples-without-normality-assumption",
    "href": "practice/practice_slides/slides_lab02.html#testing-samples-without-normality-assumption",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing samples without normality assumption",
    "text": "Testing samples without normality assumption\nLet‚Äôs go back to the HEART FAILURE dataset but looking at the levels of Creatinine Phosphokinase (CPK) in the blood, an enzyme that might indicate a heart failure or injury"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?\nDefining the question formally:\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_{CPK-died} = ùùÅ_{CPK-surv}\\) there is no difference in mean CPK between patients who suffered heart failure and died versus patients who survived after heart failure\n\\(ùëØ_ùíÇ\\) : \\(ùùÅ_{CPK-died} ‚â† ùùÅ_{CPK-surv}\\) there is a difference in mean CPK between patients who suffered heart failure and died versus patients who survived after heart failure (two-sided test)\n\n\nggplot(heart_failure,aes(x = creatinine_phosphokinase,fill = DEATH_EVENT_f))+\n  geom_density(alpha = 0.5)+theme_fivethirtyeight()+\n  scale_fill_manual(values = c(\"#999999\", \"#d8717b\"))+\n  guides(fill = \"none\") +\n  scale_x_continuous(breaks = seq(0,8000, 500))+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT == 0])),\n             color = \"#4c4c4c\")+\n  geom_vline(aes(xintercept = mean(creatinine_phosphokinase[DEATH_EVENT==1])), \n             color = \"#d8717b\")+\n  theme_fivethirtyeight()+\n  theme(axis.text.x = element_text(angle=50, vjust=0.75))+\n  labs(title =  \"Creatinine phosphokinase (density distribution) by group (Death Event)\") + \n  theme(plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure-output",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-cpk-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between CPK levels in the blood of the survivors v. those who died after heart failure?\n\n\nThe density plot suggests non normality of the variable distribution"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nNormally-distributed response variable - ‚ùå\n\nQQ plot (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. A 45-degree reference line is also plotted. In a QQ plot, each observation is plotted as a single dot.\n\nIf the data are normal, the dots should form a straight line.\n\n\n# visual verification with QQ plot \nggpubr::ggqqplot( \n  heart_failure$creatinine_phosphokinase, \n  title = \"QQ plot for CPK levels in blood\",\n  xlab =\"Theoretical\", ylab = \"Sample (CPK)\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1-output",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-visual-1-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (visual)",
    "text": "Preliminary check for normality (visual)\n\n\nIn a QQ plot, if the data are normal, the dots should follow a straight line."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test-1",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-for-normality-test-with-rstatixshapiro_test-1",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check for normality (test) with rstatix::shapiro_test",
    "text": "Preliminary check for normality (test) with rstatix::shapiro_test\n(same thing, but using a different R function)\n\n\nNormally-distributed response variable - ‚ùå\n\n(NOT normality confirmed by Shapiro-Wilk normality test)\n\n\n\n[The null hypothesis of this test is \\(H_0\\) = ‚Äúsample distribution(s) is/are normal‚Äù ]\nGiven the p-value we reject the null hypothesis\n\n# Shapiro-Wilk Normality Test to verify normality  \nheart_failure %&gt;%\n  dplyr::group_by(DEATH_EVENT_f) %&gt;%\n  rstatix::shapiro_test(creatinine_phosphokinase)\n\n# A tibble: 2 √ó 4\n  DEATH_EVENT_f variable                 statistic        p\n  &lt;fct&gt;         &lt;chr&gt;                        &lt;dbl&gt;    &lt;dbl&gt;\n1 survived      creatinine_phosphokinase     0.628 8.51e-21\n2 died          creatinine_phosphokinase     0.439 1.99e-17"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-wilcoxon-rank-sum-test-statistic",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-wilcoxon-rank-sum-test-statistic",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Computation of the Wilcoxon Rank Sum test statistic",
    "text": "3. Computation of the Wilcoxon Rank Sum test statistic\nThe Wilcoxon Rank Sum test is considered to be the nonparametric equivalent to the two-sample independent t-test\nIts ASSUMPTIONS are:\n\nOrdinal or Continuous dependent variable: e.g.¬†CPK levels ‚úÖ\nIndependence: All of the observations from both groups are independent of each other ‚úÖ\nShape: The shapes of the distributions for the two groups are roughly the same ‚úÖ\n\n\nwrs_res &lt;- wilcox.test(creatinine_phosphokinase ~ DEATH_EVENT, # immagino 0, 1\n                   data = heart_failure ,\n                   exact = FALSE, \n                   alternative = \"two.sided\" )\nwrs_res\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  creatinine_phosphokinase by DEATH_EVENT\nW = 9460, p-value = 0.684\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\nThe Wilcoxon Rank Sum test is equivalent to the Mann-Whitney U test to compare two independent samples. Different software use one or the other."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-5",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-5",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "4. Results and interpretation",
    "text": "4. Results and interpretation\nRESULTS: since the test statistic is W = 9460 and the corresponding p-value is 0.684 &gt; 0.05, we fail to reject the null hypothesis.\nINTERPRETATION: We do not have sufficient evidence to say that CPK levels for dead patients is different than that of survived patients \\(ùùÅ_{CPK-died} ‚â† ùùÅ_{CPK-surv}\\) at some statistically significant level)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#testing-samples-without-homogeneous-variance-of-observations-assumption",
    "href": "practice/practice_slides/slides_lab02.html#testing-samples-without-homogeneous-variance-of-observations-assumption",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Testing samples without homogeneous variance of observations assumption",
    "text": "Testing samples without homogeneous variance of observations assumption"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-serum-sodium-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "href": "practice/practice_slides/slides_lab02.html#question-is-there-a-statistically-significant-difference-between-serum-sodium-levels-in-the-blood-of-the-survivors-v.-those-who-died-after-heart-failure",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "1. Question: Is there a statistically significant difference between serum sodium levels in the blood of the survivors v. those who died after heart failure?",
    "text": "1. Question: Is there a statistically significant difference between serum sodium levels in the blood of the survivors v. those who died after heart failure?\nDefining the question formally:\n\n\\(ùëØ_ùüé\\) : \\(ùùÅ_{sersod-died} = ùùÅ_{sersod-surv}\\) there is no difference in mean serum sodium between patients who suffered heart failure and died versus patients who survived after heart failure\n\\(ùëØ_ùíÇ\\) : \\(ùùÅ_{sersod-died} ‚â† ùùÅ_{sersod-surv}\\) there is a difference in mean serum sodium between patients who suffered heart failure and died versus patients who survived after heart failure (two-sided test)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)\n\n\n\nHomogeneity of Variance assumption - ‚ùå Plotting the data offers some graphical intuition that the variance of observations in the two groups seem not homogenous\n\n\n#Compute means and 95% confidence intervals\nswstats &lt;- heart_failure %&gt;%\n  group_by(DEATH_EVENT_f) %&gt;%\n  summarise(count = n(),\n    mean = mean(serum_sodium,na.rm=TRUE),\n    stddev = sd(serum_sodium, na.rm=TRUE),\n    meansd_l = mean - stddev,\n    meansd_u = mean + stddev)\n\n#The complete script with some styling added\nggplot(swstats, aes(x=DEATH_EVENT_f, y=mean)) + \n  geom_point(colour = \"black\" , size = 2) +\n  #Now plotting the individual data points before the mean values\n  geom_point(data=heart_failure, aes(x=DEATH_EVENT_f, y=serum_sodium, colour = DEATH_EVENT_f), \n             position = position_jitter() ) +\n  scale_colour_manual(values = c(\"#999999\",\"#d8717b\") ) +\n  #Add the error bars\n  geom_errorbar(aes(ymin = meansd_l, ymax = meansd_u), width=0.2, color = \"black\") +\n  labs(title = \"Mean (-/+SD) serum sodium (mEq/L) by group\", x = \"\", y = \"Serum Sodium\") +\n  guides(fill = \"none\")  +\n  coord_flip() +\n  labs(title =  \"Serum Sodium means and 95% confidence intervals by group (Death Event)\") + \n  theme(legend.position=\"none\",plot.title = element_text(size = 14,face=\"bold\", color = \"#873c4a\"))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual-output",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-visual-output",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (visual)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-test",
    "href": "practice/practice_slides/slides_lab02.html#preliminary-check-hov-assumption-test",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Preliminary check ‚ÄúHOV‚Äù assumption (test)",
    "text": "Preliminary check ‚ÄúHOV‚Äù assumption (test)\nIt is always best to use an actual test, so we use also the Fisher‚Äôs F test to verify equal variances of Serum Sodium concentration in the two groups. [In this test \\(H_0\\) = ‚Äúthe ratio of variances is equal to 1‚Äù]\n\nf_test_res &lt;- stats::var.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] ,\n                              heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0])\nf_test_res\n\n\n    F test to compare two variances\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nF = 1.5769, num df = 95, denom df = 202, p-value = 0.007646\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 1.127401 2.254466\nsample estimates:\nratio of variances \n          1.576922 \n\n\nGiven the p-value = 0.007646 (smaller than \\(\\alpha\\)) we reject the null hypothesis, hence the HOV assumption for the t test does not hold."
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#computation-of-the-t-test-with-the-welch-correction",
    "href": "practice/practice_slides/slides_lab02.html#computation-of-the-t-test-with-the-welch-correction",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "2 Computation of the t test with the Welch correction",
    "text": "2 Computation of the t test with the Welch correction\n\nWe can still run the t test but with Welch correction, i.e.¬†the unequal variance condition is compensated by lowering the df. In fact the documentation (?t.test), reads:\n\nIf var.equal = TRUE, then the pooled variance is used to estimate the variance\nOtherwise (var.equal = FALSE), the Welch approximation to the degrees of freedom is used.\n\n\n# With Welch correction (on by default) Unequal variance is compensated by lowering df\nt_test_w &lt;- t.test(heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1], \n                   heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0],\n                   # here we specify the situation\n                   var.equal = FALSE,\n                   paired = FALSE, alternative = \"two.sided\") \n\nt_test_w\n\n\n    Welch Two Sample t-test\n\ndata:  heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 1] and heart_failure$serum_sodium[heart_failure$DEATH_EVENT == 0]\nt = -3.1645, df = 154.01, p-value = 0.001872\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.9914879 -0.6920096\nsample estimates:\nmean of x mean of y \n 135.3750  137.2167"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#results-and-interpretation-6",
    "href": "practice/practice_slides/slides_lab02.html#results-and-interpretation-6",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "3. Results and interpretation",
    "text": "3. Results and interpretation\nRESULTS: since the test statistic is t = -3.1645 (with df = 154.01) and the corresponding p-value is 0.001872 &lt; 0.05, we reject the null hypothesis.\nINTERPRETATION: We therefore have sufficient evidence to say that the level of serum sodium levels for dead patients is significantly different than that of survived patients \\(ùùÅ_{sersod-died} ‚â† ùùÅ_{sersod-surv}\\)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab02.html#final-thoughtsrecommendations",
    "href": "practice/practice_slides/slides_lab02.html#final-thoughtsrecommendations",
    "title": "Lab 2: Statistical inference & hypothesis testing",
    "section": "Final thoughts/recommendations",
    "text": "Final thoughts/recommendations\n\n\n\nThere are often many ways to do the same thing in R (which is both a blessing and a curse in open source software). Which should you choose? It depends on the situation, but you may want to consider:\n\nhow recent/popular/well maintained is a {package} (this affects its stability)\nthe more a function abstracts away complexity, the easier it is to use interactively, but the harder it gets to handle inside your own custom functions\ndifferent function outputs may be more/less suitable for your analysis/publication requirements (check out your peers‚Äô choices!)\n(Always read the documentation to assess all of the above)\n\n\nWith easy equations, breaking them down ‚Äúby hand‚Äù (at least once!) can really help you understand them\nIt may seem a lot of work to write R code the first time ü•µ (e.g.¬†for a publication-ready plot), but the good news is once you wrote a script, you will be able to easily re-use it in many more instances üôåüèª üòÉ\nSample size n has a very powerful impact on classical hypothesis testing results! More on this later‚Ä¶\n\n\n\n\n\n\n\nR 4 Biostatistics | MITGEST::training(2024)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#topics-discussed-in-lecture-4",
    "href": "practice/practice_slides/slides_lab04.html#topics-discussed-in-lecture-4",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Topics discussed in Lecture # 4",
    "text": "Topics discussed in Lecture # 4\n\nLecture 4: topics    \n\nIntroduction to MetaboAnalyst software\n\nA useful R-based resources for metabolomics\n\n\nElements of statistical Power Analysis"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#needed-r-packages",
    "href": "practice/practice_slides/slides_lab04.html#needed-r-packages",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Needed R Packages",
    "text": "Needed R Packages\n\n\nWe will use functions from packages base, utils, and stats (pre-installed and pre-loaded)\nWe may also use the packages below (specifying package::function for clarity).\n\n\n# Load pckgs for this R session\n\n# --- General \nlibrary(here)     # tools find your project's files, based on working directory\nlibrary(dplyr)    # A Grammar of Data Manipulation\nlibrary(skimr)    # Compact and Flexible Summaries of Data\nlibrary(magrittr) # A Forward-Pipe Operator for R \nlibrary(readr)    # A Forward-Pipe Operator for R \n\n# Plotting & data visualization\nlibrary(ggplot2)      # Create Elegant Data Visualisations Using the Grammar of Graphics\nlibrary(ggfortify)     # Data Visualization Tools for Statistical Analysis Results\nlibrary(scatterplot3d) # 3D Scatter Plot\n\n# --- Statistics\nlibrary(MASS)       # Support Functions and Datasets for Venables and Ripley's MASS\nlibrary(factoextra) # Extract and Visualize the Results of Multivariate Data Analyses\nlibrary(FactoMineR) # Multivariate Exploratory Data Analysis and Data Mining\nlibrary(rstatix)    # Pipe-Friendly Framework for Basic Statistical Tests\n\n# --- Tidymodels (meta package)\nlibrary(rsample)    # General Resampling Infrastructure  \nlibrary(broom)      # Convert Statistical Objects into Tidy Tibbles"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#dataset-on-breast-cancer-biopsy",
    "href": "practice/practice_slides/slides_lab04.html#dataset-on-breast-cancer-biopsy",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Dataset on Breast Cancer Biopsy",
    "text": "Dataset on Breast Cancer Biopsy\n\nName: Biopsy Data on Breast Cancer PatientsDocumentation: See reference on the data downloaded and conditioned for R here https://cran.r-project.org/web/packages/MASS/MASS.pdfSampling details: This breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr.¬†William H. Wolberg. He assessed biopsies of breast tumours for 699 patients up to 15 July 1992; each of nine attributes has been scored on a scale of 1 to 10, and the outcome is also known. The dataset contains the original Wisconsin breast cancer data with 699 observations on 11 variables."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#importing-dataset-biopsy",
    "href": "practice/practice_slides/slides_lab04.html#importing-dataset-biopsy",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Importing Dataset biopsy",
    "text": "Importing Dataset biopsy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe data can be interactively obtained form the MASS R package\n\n\n# (after loading pckg)\n# library(MASS)  \n\n# I can call \nutils::data(biopsy)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biopsy-variables-with-description",
    "href": "practice/practice_slides/slides_lab04.html#biopsy-variables-with-description",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "biopsy variables with description",
    "text": "biopsy variables with description\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\nID\ncharacter\nSample ID\n\n\nV1\ninteger 1 - 10\nclump thickness\n\n\nV2\ninteger 1 - 10\nuniformity of cell size\n\n\nV3\ninteger 1 - 10\nuniformity of cell shape\n\n\nV4\ninteger 1 - 10\nmarginal adhesion\n\n\nV5\ninteger 1 - 10\nsingle epithelial cell size\n\n\nV6\ninteger 1 - 10\nbare nuclei (16 values are missing)\n\n\nV7\ninteger 1 - 10\nbland chromatin\n\n\nV8\ninteger 1 - 10\nnormal nucleoli\n\n\nV9\ninteger 1 - 10\nmitoses\n\n\nclass\nfactor\nbenign or malignant"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biopsy-variables-exploration-12",
    "href": "practice/practice_slides/slides_lab04.html#biopsy-variables-exploration-12",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "biopsy variables exploration 1/2",
    "text": "biopsy variables exploration 1/2\n\nThe biopsy data contains 699 observations of 11 variables.\nThe dataset also contains a character variable: ID, and a factor variable: class, with two levels (‚Äúbenign‚Äù and ‚Äúmalignant‚Äù).\n\n# check variable types\nstr(biopsy)\n\n'data.frame':   699 obs. of  11 variables:\n $ ID   : chr  \"1000025\" \"1002945\" \"1015425\" \"1016277\" ...\n $ V1   : int  5 5 3 6 4 8 1 2 2 4 ...\n $ V2   : int  1 4 1 8 1 10 1 1 1 2 ...\n $ V3   : int  1 4 1 8 1 10 1 2 1 1 ...\n $ V4   : int  1 5 1 1 3 8 1 1 1 1 ...\n $ V5   : int  2 7 2 3 2 7 2 2 2 2 ...\n $ V6   : int  1 10 2 4 1 10 10 1 1 1 ...\n $ V7   : int  3 3 3 3 3 9 3 3 1 2 ...\n $ V8   : int  1 2 1 7 1 7 1 1 1 1 ...\n $ V9   : int  1 1 1 1 1 1 1 1 5 1 ...\n $ class: Factor w/ 2 levels \"benign\",\"malignant\": 1 1 1 1 1 2 1 1 1 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biopsy-variables-exploration-22",
    "href": "practice/practice_slides/slides_lab04.html#biopsy-variables-exploration-22",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "biopsy variables exploration 2/2",
    "text": "biopsy variables exploration 2/2\n\nThere is also one incomplete variable V6\n\nremember the package skimr for exploring a dataframe?\n\n\n# check if vars have missing values\nbiopsy %&gt;% \n  # select only variables starting with \"V\"\n  skimr::skim(starts_with(\"V\")) %&gt;%\n  dplyr::select(skim_variable, \n                n_missing)\n\n# A tibble: 9 √ó 2\n  skim_variable n_missing\n  &lt;chr&gt;             &lt;int&gt;\n1 V1                    0\n2 V2                    0\n3 V3                    0\n4 V4                    0\n5 V5                    0\n6 V6                   16\n7 V7                    0\n8 V8                    0\n9 V9                    0"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biopsy-dataset-manipulation",
    "href": "practice/practice_slides/slides_lab04.html#biopsy-dataset-manipulation",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "biopsy dataset manipulation",
    "text": "biopsy dataset manipulation\nWe will:\n\nexclude the non-numerical variables (ID and class) before conducting the PCA.\nexclude the individuals with missing values using the na.omit() or filter(complete.cases() functions.\nWe can do both in 2 equivalent ways:\n\n\n\n\nwith base R (more compact)\n\n# new (manipulated) dataset \ndata_biopsy &lt;- na.omit(biopsy[,-c(1,11)])\n\n\nwith dplyr (more explicit)\n\n# new (manipulated) dataset \ndata_biopsy &lt;- biopsy %&gt;% \n  # drop incomplete & non-integer columns\n  dplyr::select(-ID, -class) %&gt;% \n  # drop incomplete observations (rows)\n  dplyr::filter(complete.cases(.))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biopsy-dataset-manipulation-1",
    "href": "practice/practice_slides/slides_lab04.html#biopsy-dataset-manipulation-1",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "biopsy dataset manipulation",
    "text": "biopsy dataset manipulation\nWe obtained a new dataset with 9 variables and 683 observations (instead of the original 699).\n\n# check reduced dataset \nstr(data_biopsy)\n\n'data.frame':   683 obs. of  9 variables:\n $ V1: int  5 5 3 6 4 8 1 2 2 4 ...\n $ V2: int  1 4 1 8 1 10 1 1 1 2 ...\n $ V3: int  1 4 1 8 1 10 1 2 1 1 ...\n $ V4: int  1 5 1 1 3 8 1 1 1 1 ...\n $ V5: int  2 7 2 3 2 7 2 2 2 2 ...\n $ V6: int  1 10 2 4 1 10 10 1 1 1 ...\n $ V7: int  3 3 3 3 3 9 3 3 1 2 ...\n $ V8: int  1 2 1 7 1 7 1 1 1 1 ...\n $ V9: int  1 1 1 1 1 1 1 1 5 1 ..."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#calculate-principal-components",
    "href": "practice/practice_slides/slides_lab04.html#calculate-principal-components",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Calculate Principal Components",
    "text": "Calculate Principal Components\nThe first step of PCA is to calculate the principal components. To accomplish this, we use the prcomp() function from the stats package.\n\nWith argument ‚Äúscale = TRUE‚Äù each variable in the biopsy data is scaled to have a mean of 0 and a standard deviation of 1 before calculating the principal components (just like option Autoscaling in MetaboAnalyst)\n\n\n# calculate principal component\nbiopsy_pca &lt;- prcomp(data_biopsy, \n                     # standardize variables\n                     scale = TRUE)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#analyze-principal-components",
    "href": "practice/practice_slides/slides_lab04.html#analyze-principal-components",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Analyze Principal Components",
    "text": "Analyze Principal Components\nLet‚Äôs check out the elements of our obtained biopsy_pca object\n\n(All accessible via the $ operator)\n\n\nnames(biopsy_pca)\n\n[1] \"sdev\"     \"rotation\" \"center\"   \"scale\"    \"x\"       \n\n\n‚Äúsdev‚Äù = the standard deviation of the principal components\n‚Äúsdev‚Äù^2 = the variance of the principal components (eigenvalues of the covariance/correlation matrix)\n‚Äúrotation‚Äù = the matrix of variable loadings (i.e., a matrix whose columns contain the eigenvectors).\n‚Äúcenter‚Äù and ‚Äúscale‚Äù = the means and standard deviations of the original variables before the transformation;\n‚Äúx‚Äù = the principal component scores (after PCA the observations are expressed in principal component scores)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#analyze-principal-components-cont.",
    "href": "practice/practice_slides/slides_lab04.html#analyze-principal-components-cont.",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Analyze Principal Components (cont.)",
    "text": "Analyze Principal Components (cont.)\n\nWe can see the summary of the analysis using the summary() function\n\nThe first row gives the Standard deviation of each component, which can also be retrieved via biopsy_pca$sdev.\nThe second row shows the Proportion of Variance, i.e.¬†the percentage of explained variance.\n\n\nsummary(biopsy_pca)\n\nImportance of components:\n                          PC1     PC2     PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.4289 0.88088 0.73434 0.67796 0.61667 0.54943 0.54259\nProportion of Variance 0.6555 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271\nCumulative Proportion  0.6555 0.74172 0.80163 0.85270 0.89496 0.92850 0.96121\n                           PC8     PC9\nStandard deviation     0.51062 0.29729\nProportion of Variance 0.02897 0.00982\nCumulative Proportion  0.99018 1.00000"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#proportion-of-variance-for-components",
    "href": "practice/practice_slides/slides_lab04.html#proportion-of-variance-for-components",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Proportion of Variance for components",
    "text": "Proportion of Variance for components\n\nThe row with Proportion of Variance can be either accessed from summary or calculated as follows:\n\n\n# a) Extracting Proportion of Variance from summary\nsummary(biopsy_pca)$importance[2,]\n\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9 \n0.65550 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271 0.02897 0.00982 \n\n# b) (same thing)\nround(biopsy_pca$sdev^2 / sum(biopsy_pca$sdev^2), digits = 5)\n\n[1] 0.65550 0.08622 0.05992 0.05107 0.04225 0.03354 0.03271 0.02897 0.00982\n\n\n\n\nThe output suggests the 1st principal component explains around 65% of the total variance, the 2nd principal component explains about 9% of the variance, and this goes on with diminishing proportion for each component."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#cumulative-proportion-of-variance-for-components",
    "href": "practice/practice_slides/slides_lab04.html#cumulative-proportion-of-variance-for-components",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Cumulative Proportion of variance for components",
    "text": "Cumulative Proportion of variance for components\n\nThe last row from the summary(biopsy_pca), shows the Cumulative Proportion of variance, which calculates the cumulative sum of the Proportion of Variance.\n\n\n# Extracting Cumulative Proportion from summary\nsummary(biopsy_pca)$importance[3,]\n\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8     PC9 \n0.65550 0.74172 0.80163 0.85270 0.89496 0.92850 0.96121 0.99018 1.00000 \n\n\n\n\nOnce you computed the PCA in R you must decide the number of components to retain based on the obtained results."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#scree-plot",
    "href": "practice/practice_slides/slides_lab04.html#scree-plot",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Scree plot",
    "text": "Scree plot\nThere are several ways to decide on the number of components to retain.\n\nOne helpful option is visualizing the percentage of explained variance per principal component via a scree plot.\n\nPlotting with the fviz_eig() function from the factoextra package\n\n\n\n\n# Scree plot shows the variance of each principal component \nfactoextra::fviz_eig(biopsy_pca, \n                     addlabels = TRUE, \n                     ylim = c(0, 70))\n\n\n\n\nVisualization is essential in the interpretation of PCA results. Based on the number of retained principal components, which is usually the first few, the observations expressed in component scores can be plotted in several ways."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#scree-plot-output",
    "href": "practice/practice_slides/slides_lab04.html#scree-plot-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Scree plot",
    "text": "Scree plot\n\n\nThe obtained scree plot simply visualizes the output of summary(biopsy_pca)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores",
    "text": "Principal Component Scores\nAfter a PCA, the observations are expressed as principal component scores.\n\nWe can retrieve the principal component scores for each Variable by calling biopsy_pca$x, and store them in a new dataframe PC_scores.\nNext we draw a scatterplot of the observations ‚Äì expressed in terms of principal components\n\n\n# Create new object with PC_scores\nPC_scores &lt;- as.data.frame(biopsy_pca$x)\nhead(PC_scores)\n\n\nIt is also important to visualize the observations along the new axes (principal components) to interpret the relations in the dataset:"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-output",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores",
    "text": "Principal Component Scores\n\n        PC1         PC2         PC3         PC4         PC5         PC6\n1  1.469095 -0.10419679  0.56527102 -0.03193593  0.15088743 -0.05997679\n2 -1.440990 -0.56972390 -0.23642767 -0.47779958 -1.64188188  0.48268150\n3  1.591311 -0.07606412 -0.04882192 -0.09232038  0.05969539  0.27916615\n4 -1.478728 -0.52806481  0.60260642  1.40979365  0.56032669 -0.06298211\n5  1.343877 -0.09065261 -0.02997533 -0.33803588  0.10874960 -0.43105416\n6 -5.010654 -1.53379305 -0.46067165  0.29517264 -0.39155544 -0.11527442\n         PC7        PC8          PC9\n1 -0.3491471  0.4200360  0.005687222\n2  1.1150819  0.3792992 -0.023409926\n3 -0.2325697  0.2096465 -0.013361828\n4  0.2109599 -1.6059184 -0.182642900\n5 -0.2596714  0.4463277  0.038791241\n6 -0.3842529 -0.1489917  0.042953075"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-adding-label-variable",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-adding-label-variable",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores plot (adding label variable)",
    "text": "Principal Component Scores plot (adding label variable)\n\nWhen data includes a factor variable, like in our case, it may be interesting to show the grouping on the plot as well.\n\n\nIn such cases, the label variable class can be added to the PC set as follows.\n\n\n# retrieve class variable\nbiopsy_no_na &lt;- na.omit(biopsy)\n# adding class grouping variable to PC_scores\nPC_scores$Label &lt;- biopsy_no_na$class\n\n The visualization of the observation points (point cloud) could be in 2D or 3D."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-2d",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-2d",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores plot (2D)",
    "text": "Principal Component Scores plot (2D)\nThe Scores Plot can be visualized via the ggplot2 package.\n\ngrouping is indicated by argument the color = Label;\n\ngeom_point() is used for the point cloud.\n\n\nggplot(PC_scores, \n       aes(x = PC1, \n           y = PC2, \n           color = Label)) +\n  geom_point() +\n  scale_color_manual(values=c(\"#245048\", \"#CC0066\")) +\n  ggtitle(\"Figure 1: Scores Plot\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-2d-output",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-2d-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores plot (2D)",
    "text": "Principal Component Scores plot (2D)\n\n\nFigure 1 shows the observations projected into the new data space made up of principal components"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-2d-ellipse-plot",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-2d-ellipse-plot",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores (2D Ellipse Plot)",
    "text": "Principal Component Scores (2D Ellipse Plot)\nConfidence ellipses can also be added to a grouped scatter plot visualized after a PCA. We use the ggplot2 package.\n\ngrouping is indicated by argument the color = Label;\n\ngeom_point() is used for the point cloud;\nthe stat_ellipse() function is called to add the ellipses per biopsy group.\n\n\nggplot(PC_scores, \n       aes(x = PC1, \n           y = PC2, \n           color = Label)) +\n  geom_point() +\n  scale_color_manual(values=c(\"#245048\", \"#CC0066\")) +\n  stat_ellipse() + \n  ggtitle(\"Figure 2: Ellipse Plot\") +\n  theme_bw()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-2d-ellipse-plot-output",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-2d-ellipse-plot-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores (2D Ellipse Plot)",
    "text": "Principal Component Scores (2D Ellipse Plot)\n\n\nFigure 2 shows the observations projected into the new data space made up of principal components, with 95% confidence regions displayed."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-3d",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-3d",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores plot (3D)",
    "text": "Principal Component Scores plot (3D)\n\nA 3D scatterplot of observations shows the first 3 principal components‚Äô scores.\n\nFor this one, we need the scatterplot3d() function of the scatterplot3d package;\nThe color argument assigned to the Label variable;\nTo add a legend, we use the legend() function and specify its coordinates via the xyz.convert() function.\n\n\n# 3D scatterplot ...\nplot_3d &lt;- with(PC_scores, \n                scatterplot3d::scatterplot3d(PC_scores$PC1, \n                                             PC_scores$PC2, \n                                             PC_scores$PC3, \n                                             color = as.numeric(Label), \n                                             pch = 19, \n                                             main =\"Figure 3: 3D Scatter Plot\", \n                                             xlab=\"PC1\",\n                                             ylab=\"PC2\",\n                                             zlab=\"PC3\"))\n\n# ... + legend\nlegend(plot_3d$xyz.convert(0.5, 0.7, 0.5), \n       pch = 19, \n       yjust=-0.6,\n       xjust=-0.9,\n       legend = levels(PC_scores$Label), \n       col = seq_along(levels(PC_scores$Label)))"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-3d-output",
    "href": "practice/practice_slides/slides_lab04.html#principal-component-scores-plot-3d-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Principal Component Scores plot (3D)",
    "text": "Principal Component Scores plot (3D)\n\n\nFigure 3 shows the observations projected into the new 3D data space made up of principal components."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biplot-principal-components-v.-original-variables",
    "href": "practice/practice_slides/slides_lab04.html#biplot-principal-components-v.-original-variables",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Biplot: principal components v. original variables",
    "text": "Biplot: principal components v. original variables\nNext, we create another special type of scatterplot (a biplot) to understand the relationship between the principal components and the original variables.\nIn the biplot each of the observations is projected onto a scatterplot that uses the first and second principal components as the axes.\n\nFor this plot, we use the fviz_pca_biplot() function from the factoextra package\n\nWe will specify the color for the variables, or rather, for the ‚Äúloading vectors‚Äù\nThe habillage argument allows to highlight with color the grouping by class\n\n\n\n\n\nfactoextra::fviz_pca_biplot(biopsy_pca, \n                repel = TRUE,\n                col.var = \"black\",\n                habillage = biopsy_no_na$class,\n                title = \"Figure 4: Biplot\", geom=\"point\")"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#biplot-principal-components-v.-original-variables-output",
    "href": "practice/practice_slides/slides_lab04.html#biplot-principal-components-v.-original-variables-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Biplot: principal components v. original variables",
    "text": "Biplot: principal components v. original variables\n\n\nThe axes show the principal component scores, and the vectors are the loading vectors"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#interpreting-biplot-output",
    "href": "practice/practice_slides/slides_lab04.html#interpreting-biplot-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Interpreting biplot output",
    "text": "Interpreting biplot output\n\nBiplots have two key elements: scores (the 2 axes) and loadings (the vectors). As in the scores plot, each point represents an observation projected in the space of principal components where:\n\nBiopsies of the same class are located closer to each other, which indicates that they have similar scores referred to the 2 main principal components;\nThe loading vectors show strength and direction of association of original variables with new PC variables.\n\n\nAs expected from PCA, the single PC1 accounts for variance in almost all original variables, while V9 has the major projection along PC2."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#interpreting-biplot-output-cont.",
    "href": "practice/practice_slides/slides_lab04.html#interpreting-biplot-output-cont.",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Interpreting biplot output (cont.)",
    "text": "Interpreting biplot output (cont.)\n\nscores &lt;- biopsy_pca$x\n\nloadings &lt;- biopsy_pca$rotation\n# excerpt of first 2 components\nloadings[ ,1:2] \n\n          PC1         PC2\nV1 -0.3020626 -0.14080053\nV2 -0.3807930 -0.04664031\nV3 -0.3775825 -0.08242247\nV4 -0.3327236 -0.05209438\nV5 -0.3362340  0.16440439\nV6 -0.3350675 -0.26126062\nV7 -0.3457474 -0.22807676\nV8 -0.3355914  0.03396582\nV9 -0.2302064  0.90555729"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#sample-size-determination-in-inferential-statistics",
    "href": "practice/practice_slides/slides_lab04.html#sample-size-determination-in-inferential-statistics",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Sample Size determination in Inferential statistics",
    "text": "Sample Size determination in Inferential statistics\n\n\n\n\n‚ÄúOK, so how big of a sample do I need?‚Äù  ‚Ä¶the 1,000,000 $ question‚Äù! üôÄ"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#purpose-and-challenges-of-power-analysis",
    "href": "practice/practice_slides/slides_lab04.html#purpose-and-challenges-of-power-analysis",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Purpose and challenges of Power Analysis",
    "text": "Purpose and challenges of Power Analysis\n\n\n\nPower analysis helps with the key question How many observations/subjects do I need for my experiment? (= \\(n\\))\n\n\nToo small of a sample size can under detect the effect of interest in your experiment\n\nToo large of a sample size may lead to unnecessary wasting of resources\nWe strive to have just the sufficient number of observations needed to have a good chance of detecting the effect researched. (Even more so in a very time-consuming or expensive experiment.)\n\n\n\nWhen should we do power analysis?\n\n(Ideally), before the experiment: a priori power analysis allows to determine the necessary sample size \\(n\\) of a test, given a desired \\(\\alpha\\) level, a desired power level (\\(1- \\beta\\)), and the size of the effect to be detected (a measure of difference between \\(H_o\\) and \\(H_1\\))\nIn reality, sometimes you can only do post-hoc power analysis after the experiment, so the sample size \\(n\\) is already given.\n\nIn this case, given \\(n\\), \\(\\alpha\\), and a specified effect size, the analysis will return the power (\\(1- \\beta\\)) of the test, or \\(\\beta\\) (i.e.¬†the probability of Type II error = incorrectly retaining \\(H_o\\))."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#required-inputs-to-define-the-sample-size-n",
    "href": "practice/practice_slides/slides_lab04.html#required-inputs-to-define-the-sample-size-n",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Required inputs to define the sample size n",
    "text": "Required inputs to define the sample size n\n\n\nA specified effect size (i.e.¬†the minimum deviation from \\(H_o\\) that you hope to detect for a meaningful result)\n\nThe larger the effect size, the easier it is to detect an effect and require fewer obs\n\n\n\nAs \\(standard deviation\\) gets bigger, it is harder to detect a significant difference, so you‚Äôll need a bigger sample size.\n\n\n\n\n\\(\\alpha\\) is the significance level of the test (i.e.¬†the probability of incorrectly rejecting the null hypothesis (a false positive).\n\nUnderstanding if the test is one-tailed (difference has a direction) or two-tailed\n\n\n\n\\(\\beta\\) is the probability of accepting the null hypothesis, even though it is false (a false negative), when the real difference is equal to the minimum effect size.\n\n\n\\(1- \\beta\\) is the power of a test is the probability of correctly rejecting the null hypothesis (getting a significant result) when the real difference is equal to the minimum effect size.\n\na power of 80% (equivalent to a beta of 20%) is probably the most common, while some people use 50% or 90%"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#specifying-effect-size",
    "href": "practice/practice_slides/slides_lab04.html#specifying-effect-size",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Specifying effect size",
    "text": "Specifying effect size\n\nSo (since \\(\\alpha\\) and \\(1-\\beta\\) are normally set) the key piece of information we need is the effect size, which is essentially a function of the difference between the means of the null and alternative hypotheses over the variation (standard deviation) in the data.\n\nThe tricky part is that effect size is related to biological/practical significance rather than statistical significance\n\nHow should you estimate a meaningful Effect Size?\n\nUse preliminary information in the form of pilot study\nUse background information in the form of similar studies in the literature\n(With no prior information), make an estimated guess on the effect size expected (see guidelines next)\n\n\nMost R functions for sample size only allow you to enter effect size as input"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#specifying-effect-size-general-guidelines",
    "href": "practice/practice_slides/slides_lab04.html#specifying-effect-size-general-guidelines",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Specifying effect size: general guidelines",
    "text": "Specifying effect size: general guidelines\nAs a general indicative reference, below are the ‚ÄúCohen‚Äôs Standard Effect Sizes‚Äù (from statistician Jacob Cohen who came up with a rough set of numerical measures for ‚Äúsmall‚Äù, ‚Äúmedium‚Äù and ‚Äúlarge‚Äù effect sizes that are still in use today)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#the-pwr-package",
    "href": "practice/practice_slides/slides_lab04.html#the-pwr-package",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "The pwr package",
    "text": "The pwr package\n\nThe pwr package (develped by St√©phane Champely), implements power analysis as outlined by Cohen (1988). The key arguments of the function pwr.t.test are 4 quantities, plus 2 for the test description:\n\n\nn = sample size\n\nd = effect size (based on Cohen‚Äôs)\n\nsig.level = the desired significance level\n\n\nThe significance level (\\(\\alpha\\)) defaults to 0.05. Therefore, to calculate the significance level, given an effect size, sample size, and power (\\(1- \\beta\\)), use the option \"sig.level=NULL\".\n\n\n\npower = the desired power\n\ntype = the type of t-test you will eventually be carrying out (one of two.sample, one.sample or paired)\n\nalternative = the type of alternative hypothesis you want to test (one of two.sided, less or greater)\n\n\nThe core idea behind its functions is that you enter 3 of the 4 quantities (effect size, sample size, significance level, power) and the 4th is calculated."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-sample-mean-exe-data",
    "href": "practice/practice_slides/slides_lab04.html#one-sample-mean-exe-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One Sample Mean: EXE data",
    "text": "One Sample Mean: EXE data\n\n\nGOAL: Imagine this is a pilot study, in which we tested fish is (on average) different form 20 cm in length.\nThe guanapo_data dataset contains information on fish lengths from the Guanapo river pilot\n\n# Load data on river fish length \nfishlength_data &lt;- readr::read_csv(here::here(\"practice\", \"data_input\", \"04_datasets\", \n                                              \"fishlength.csv\"),\n                              show_col_types = FALSE)\n\n# Select a portion of the data (i.e. out \"pilot\" experiment) \nguanapo_data &lt;- fishlength_data %&gt;% \n  dplyr::filter(river == \"Guanapo\")\n\n# Pilot experiment data \nnames(guanapo_data)\n\n[1] \"id\"     \"river\"  \"length\"\n\nmean_H1 &lt;-  mean(guanapo_data$length) # 18.29655\nmean_H1\n\n[1] 18.29655\n\nsd_sample &lt;- sd(guanapo_data$length)  # 2.584636\nsd_sample\n\n[1] 2.584636"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-example-cont.",
    "href": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-example-cont.",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One Sample Mean t-test: EXAMPLE cont.",
    "text": "One Sample Mean t-test: EXAMPLE cont.\n\nLet‚Äôs compute the one sample t-test with stats::t.test against a hypothetical average fish length (\\(mean\\_H_o = 20\\) )\n\n# Hypothetical fish population length mean (H0)\nmean_H0 &lt;- 20\n# one-sample mean t-test \nt_stat &lt;- stats::t.test(x = guanapo_data$length,\n                        mu = mean_H0,\n                        alternative = \"two.sided\")\n# one-sample t-test results\nt_stat\n\n\n    One Sample t-test\n\ndata:  guanapo_data$length\nt = -3.5492, df = 28, p-value = 0.001387\nalternative hypothesis: true mean is not equal to 20\n95 percent confidence interval:\n 17.31341 19.27969\nsample estimates:\nmean of x \n 18.29655 \n\n\n\nThere appear to be a statistically significant result here: the mean length of the fish appears to be different from 20 cm.\n\nQUESTION: In a new study of the same fish, what sample size n would you need to get a comparable result?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-power-analysis-n",
    "href": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-power-analysis-n",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One Sample Mean t-test: POWER ANALYSIS (n)",
    "text": "One Sample Mean t-test: POWER ANALYSIS (n)\n\n\nWe input Cohen‚Äôs d (after calculating it manually) following: \\(effect\\ size\\ \\approx \\frac{{Mean}_{H_1}\\ -{\\ Mean}_{H_0}}{Std\\ Dev}\\)\nWe use pwr::pwr.t.test to calculate the minimum sample size n required: \n\n\n# Cohen's d formula \neff_size &lt;- (mean_H1 - mean_H0) / sd_sample # -0.6590669\n\n# power analysis to actually calculate the minimum sample size required:\npwr::pwr.t.test(d = eff_size, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 20.07483\n              d = 0.6590669\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\n\nWe would need n = 21 (rounding up) observations for an experiment (e.g.¬†in different river) to detect an effect size as the pilot study at a 5% significance level and 80% power."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-power-analysis-stricter-conditions",
    "href": "practice/practice_slides/slides_lab04.html#one-sample-mean-t-test-power-analysis-stricter-conditions",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One Sample Mean t-test: POWER ANALYSIS, stricter conditions",
    "text": "One Sample Mean t-test: POWER ANALYSIS, stricter conditions\nWhat if we wanted the results to be even more stringent?\n\ne.g.¬†require higher significance level (0.01) and power (0.90) with the same effect?\n\n\n# power analysis to actually calculate the minimum sample size required:\npwr::pwr.t.test(d = eff_size, \n                sig.level = 0.01, \n                power = 0.9,\n                type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 37.62974\n              d = 0.6590669\n      sig.level = 0.01\n          power = 0.9\n    alternative = two.sided\n\n\n\nThis time, we would need n = 38 observations for an experiment to detect the same effect size at the stricter level of significance and power."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-independent-samples-exe-data",
    "href": "practice/practice_slides/slides_lab04.html#two-independent-samples-exe-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Independent Samples: EXE data",
    "text": "Two Independent Samples: EXE data\n\n\nLet‚Äôs look at the entire fishlength_data with the lengths of fish from 2 separate rivers.\n\n# Explore complete data \nfishlength_data %&gt;% \n  dplyr::group_by (river) %&gt;% \n  dplyr::summarise (N = n(), \n                    mean_len = mean(length),\n                    sd_len = sd(length)) \n\n# A tibble: 2 √ó 4\n  river       N mean_len sd_len\n  &lt;chr&gt;   &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Aripo      39     20.3   1.78\n2 Guanapo    29     18.3   2.58\n\n\nVisualize quickly the 2 samples (rivers) with a boxplot\n\n# visualize the data\nfishlength_data %&gt;% \n  ggplot(aes(x = river, y = length)) +\n  geom_boxplot()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-independent-samples-exe-data-output",
    "href": "practice/practice_slides/slides_lab04.html#two-independent-samples-exe-data-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Independent Samples: EXE data",
    "text": "Two Independent Samples: EXE data\n\n\nThe fish in the 2 samples appear to have different mean length"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-independent-samples-t-test",
    "href": "practice/practice_slides/slides_lab04.html#two-independent-samples-t-test",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Independent Samples: t-test",
    "text": "Two Independent Samples: t-test\nLet‚Äôs confirm it with a two sample t-test against \\(ùëØ_ùüé\\): The two population means are equal\n\n# Perform two-samples unpaired test\nfishlength_data %&gt;% \n  rstatix::t_test(length ~ river,\n                  paired = FALSE\n                    )\n\n# A tibble: 1 √ó 8\n  .y.    group1 group2     n1    n2 statistic    df       p\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 length Aripo  Guanapo    39    29      3.64  46.9 0.00067\n\n\n\nThe t-test analysis confirms that the difference is significant.\n\n QUESTION: Can we use this information to design a more efficient experiment? I.e. run an experiment powerful enough to pick up the same observed difference in means but with fewer observations?"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-independent-samples-power-analysis-12",
    "href": "practice/practice_slides/slides_lab04.html#two-independent-samples-power-analysis-12",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Independent Samples: POWER ANALYSIS 1/2",
    "text": "Two Independent Samples: POWER ANALYSIS 1/2\n\nLet‚Äôs work out exactly the effect size of this study by estimating Cohen‚Äôs d using this data.\n\n\n(We use a function from the package rstatix::cohens_d to estimate Cohen‚Äôs d)\n\n\n# Estimate cohen's d \nfishlength_data %&gt;%\n  rstatix::cohens_d(length ~ river, var.equal = TRUE)\n\n# A tibble: 1 √ó 7\n  .y.    group1 group2  effsize    n1    n2 magnitude\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 length Aripo  Guanapo   0.942    39    29 large    \n\n\n\nThe effsize column contains the information that we want, in this case 0.94"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-independent-samples-power-analysis-22-n",
    "href": "practice/practice_slides/slides_lab04.html#two-independent-samples-power-analysis-22-n",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Independent Samples: POWER ANALYSIS 2/2 (n)",
    "text": "Two Independent Samples: POWER ANALYSIS 2/2 (n)\n\nActually answer the question about how many fish we really need to catch in the future\n\n\n# run power analysis \npwr::pwr.t.test(d = 0.94, power = 0.8, sig.level = 0.05,\n           type = \"two.sample\", alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 18.77618\n              d = 0.94\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\nThe n output ( = 19 observations per group) -as opposed to 39 + 29- would be sufficient if we wanted to confidently detect the difference observed in the previous study"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-paired-samples-exe-data",
    "href": "practice/practice_slides/slides_lab04.html#two-paired-samples-exe-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Paired Samples: EXE data",
    "text": "Two Paired Samples: EXE data\n\nThe cortisol_data dataset contains information about cortisol levels measured on 20 participants in the morning and evening\n\n# Load data \ncortisol_data &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"04_datasets\", \n                                        \"cortisol.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n# Explore data \nnames(cortisol_data)\n\n[1] \"patient_id\" \"time\"       \"cortisol\"  \n\ncortisol_data %&gt;% \n  dplyr::group_by (time) %&gt;% \n  dplyr::summarise (\n    N = n(), \n    mean_cort = mean(cortisol),\n    sd_cort = sd(cortisol)) \n\n# A tibble: 2 √ó 4\n  time        N mean_cort sd_cort\n  &lt;chr&gt;   &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 evening    20      197.    87.5\n2 morning    20      313.    73.8\n\n\n\nNotice the difference in the paired sample means is quite large"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-visualization",
    "href": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-visualization",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Paired Samples t-test: visualization",
    "text": "Two Paired Samples t-test: visualization\nVisualize quickly the 2 paired samples (morning and evening) with a boxplot\n\n# visualize the data\ncortisol_data %&gt;% \n  ggplot(aes(x = time, y = cortisol)) +\n  geom_boxplot()\n\n\nThe cortisol levels in the 2 paired amples appear quite different"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-paired-samples-power-analysis-d",
    "href": "practice/practice_slides/slides_lab04.html#two-paired-samples-power-analysis-d",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Paired Samples: POWER ANALYSIS (d)",
    "text": "Two Paired Samples: POWER ANALYSIS (d)\n\nGOAL: Flipping the question, if we know the given n (20 patients observed twice): How big should the effect size be to be detected at power of 0.8 and significance level 0.05?\n\nWe use pwr::pwr.t.test, with the argument specification type = \"paired\", but this time to estimate the effect size \n\n\n\n# power analysis to actually calculate the effect size at the desired conditions:\npwr::pwr.t.test(n = 20, \n                #d =  eff_size, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 20\n              d = 0.6604413\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\n\nThe functions returns the effect size (Cohen‚Äôs metric): d = 0.6604413. So, with this experimental design we would be able to detect a medium-large effect size."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-power-analysis-on-given-n",
    "href": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-power-analysis-on-given-n",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Paired Samples t-test: POWER ANALYSIS on given n",
    "text": "Two Paired Samples t-test: POWER ANALYSIS on given n\nLooking instead at the actual sample data, what would be the observed effect size?\n\nTo compute ‚Äúobserved d‚Äù we can use the function rstatix::cohens_d\n\n\n\nd &lt;- cortisol_data %&gt;% \n  # estimate cohen's d\n  rstatix::cohens_d(cortisol ~ time, paired = TRUE)\n\nd\n\n# A tibble: 1 √ó 7\n  .y.      group1  group2  effsize    n1    n2 magnitude\n* &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;ord&gt;    \n1 cortisol evening morning   -1.16    20    20 large    \n\n\nThe obtained d (-1.16) is extremely large, so we likely have more participants in this study than actually needed given such a large effect."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-power-analysis-gives-sufficient-n",
    "href": "practice/practice_slides/slides_lab04.html#two-paired-samples-t-test-power-analysis-gives-sufficient-n",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Two Paired Samples t-test: POWER ANALYSIS gives sufficient n",
    "text": "Two Paired Samples t-test: POWER ANALYSIS gives sufficient n\nLet‚Äôs re-compute the power analysis, but leave n as the unknown quantity, given the effect size (d) we have observed\n\n# power analysis to calculate minimunm n given the observed effect size in the sample \npwr::pwr.t.test(# n = 20, \n                d =  -1.16, \n                sig.level = 0.05, \n                power = 0.8,\n                type = \"paired\")\n\n\n     Paired t test power calculation \n\n              n = 7.960846\n              d = 1.16\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\n\nAs a matter of fact, n = 8 pairs of observations would have sufficed in this study, given the size of effect we were trying to detect."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-exe-data",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-exe-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: EXE data",
    "text": "One-way ANOVA test: EXE data\n\nThe mussels_data dataset contains information about the length of the anterior adductor muscle scar in the mussel Mytilus trossulus across five locations around the world!\n\n# Load data \nmussels_data &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"04_datasets\", \n                                        \"mussels.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL) \n\n# Explore data \nnames(mussels_data)\n\n[1] \"length\"   \"location\"\n\nstats &lt;- mussels_data %&gt;% \n  dplyr::group_by (location) %&gt;% \n  dplyr::summarise (\n    N = n(), \n    mean_len = mean(length),\n    sd_len = sd(length)) \n\nstats\n\n# A tibble: 5 √ó 4\n  location       N mean_len  sd_len\n  &lt;chr&gt;      &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Magadan        8   0.0780 0.0129 \n2 Newport        8   0.0748 0.00860\n3 Petersburg     7   0.103  0.0162 \n4 Tillamook     10   0.0802 0.0120 \n5 Tvarminne      6   0.0957 0.0130"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-visualization",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-visualization",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: visualization",
    "text": "One-way ANOVA test: visualization\n\n\nThere appears to be a noticeable difference in lenght at average measurements at least between some of the locations\n\n\n\n\n\n\n\n\n\n\n\n# Visualize the data with a boxplot\nmussels_data %&gt;% \n  ggplot(aes(x = location, y = length)) +\n  geom_boxplot()"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-visualization-output",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-visualization-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: visualization",
    "text": "One-way ANOVA test: visualization"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-example-cont.",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-example-cont.",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: EXAMPLE cont.",
    "text": "One-way ANOVA test: EXAMPLE cont.\n\nAssuming we verified the required assumptions, let‚Äôs run the ANOVA test to confirm the visual intuition\n\nWith the stats::aov followed by the command summary\n\n\n\n# Summary of test outputs: \nsummary_ANOVA &lt;- summary(stats::aov(length ~ location,\n                   data = mussels_data))\n\n# From which we extract all the output elements \n# F value \nsummary_ANOVA[[1]][[\"F value\"]] # 7.121019\n\n[1] 7.121019       NA\n\n# p value \nsummary_ANOVA[[1]][[\"Pr(&gt;F)\"]]  # 0.0002812242\n\n[1] 0.0002812242           NA\n\n# df of numerator and denominator\nsummary_ANOVA[[1]][[\"Df\"]]      # 4, 34 \n\n[1]  4 34\n\n# Sum of Square BETWEEN groups\nSSB &lt;- summary_ANOVA[[1]][[\"Sum Sq\"]][1]  # 0.004519674\n# Sum of Square WITHIN groups\nSSW &lt;- summary_ANOVA[[1]][[\"Sum Sq\"]][2]  # 0.005394906\n\n\nA one-way ANOVA test confirms that the mean lengths of muscle scar differed significantly between locations ( F = 7.121, with df = [4, 34], and p = 0.000281)."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-power-analysis-effect",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-power-analysis-effect",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: POWER ANALYSIS (effect)",
    "text": "One-way ANOVA test: POWER ANALYSIS (effect)\n\nIn ANOVA it may be tricky to decide what kind of effect size we are looking for:\n\nif we care about an overall significance test, the sample size needed is a function of the standard deviation of the group means\nif we‚Äôre interested in the comparisons of means, there are other ways of expressing the effect size (e.g.¬†a difference between the smallest and largest means)\n\nHere let‚Äôs consider an overall test in which we could reasonably collect the same n.¬†of observations in each group\n\nn_loc &lt;- nrow(stats)\n\nmeans_by_loc &lt;- c(0.0780, 0.0748, 0.103, 0.0802, 0.0957)\noverall_mean &lt;-  mean(means_by_loc)\nsd_by_loc &lt;- c(0.0129, 0.00860, 0.0162, 0.0120, 0.0130)\noverall_sd &lt;-  mean(sd_by_loc)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#one-way-anova-test-power-analysis-effect-1",
    "href": "practice/practice_slides/slides_lab04.html#one-way-anova-test-power-analysis-effect-1",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "One-way ANOVA test: POWER ANALYSIS (effect)",
    "text": "One-way ANOVA test: POWER ANALYSIS (effect)\n\n\n# Effect Size f formula\nCohen_f = sqrt( sum( (1/n_loc) * (means_by_loc - overall_mean)^2) ) /overall_sd\nCohen_f # EXTREMELY BIG \n\n[1] 0.877622\n\n# Power analysis with given f \npwr::pwr.anova.test(k = n_loc,\n                    n = NULL,\n                    f = Cohen_f,\n                    sig.level = 0.05,\n                    power = 0.80)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 5\n              n = 4.166759\n              f = 0.877622\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\n\nThe n output ( = 5 observations per group) -as opposed to &gt;6 per group- would be sufficient if we wanted to confidently detect the difference observed in the previous study"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-exe-data",
    "href": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-exe-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Linear Regression with grouped data: EXE data",
    "text": "Linear Regression with grouped data: EXE data\n\nThe ideas covered before apply also to linear models, although here:\n\nwe use pwr.f2.test() to do the power calculation\nthe effect sizes (\\(f^2\\)) is based on \\(R^2\\)\n\n\n\\[ f^2=\\ \\frac{R^2}{1-\\ R^2}\\]\n\n# define the linear model\nlm_mussels &lt;- lm(length ~ location, \n                 data = mussels_data)\n\n\n# summarise the model\nsummary(lm_mussels)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-exe-data-output",
    "href": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-exe-data-output",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Linear Regression with grouped data: EXE data",
    "text": "Linear Regression with grouped data: EXE data\n\n\nCall:\nlm(formula = length ~ location, data = mussels_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.025400 -0.007956  0.000100  0.007000  0.031757 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.078012   0.004454  17.517  &lt; 2e-16 ***\nlocationNewport    -0.003213   0.006298  -0.510  0.61331    \nlocationPetersburg  0.025430   0.006519   3.901  0.00043 ***\nlocationTillamook   0.002187   0.005975   0.366  0.71656    \nlocationTvarminne   0.017687   0.006803   2.600  0.01370 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0126 on 34 degrees of freedom\nMultiple R-squared:  0.4559,    Adjusted R-squared:  0.3918 \nF-statistic: 7.121 on 4 and 34 DF,  p-value: 0.0002812"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-power-analysis",
    "href": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-power-analysis",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Linear Regression with grouped data: POWER ANALYSIS",
    "text": "Linear Regression with grouped data: POWER ANALYSIS\n\nFrom the linear model we get that the \\(R^2\\) value is 0.4559 and we can use this to calculate Cohen‚Äôs \\(f^2\\) value using the formula\n\n# Extract R squared\nR_2 &lt;- summary(lm_mussels)$r.squared\n# compute f squared\nf_2 &lt;- R_2 / (1 - R_2)\nf_2\n\n[1] 0.837767\n\n\nOur model has 5 parameters (because we have 5 groups) and so the numerator degrees of freedom \\(u\\) will be 4 (5‚àí1=4).\nHence, we carry out the power analysis with the function pwr.f2.test:\n\n# power analysis for overall linear model \npwr::pwr.f2.test(u = 4, v = NULL, \n                 f2 = 0.8378974,\n                 sig.level = 0.05 , power = 0.8)\n\n\n     Multiple regression power calculation \n\n              u = 4\n              v = 14.62182\n             f2 = 0.8378974\n      sig.level = 0.05\n          power = 0.8"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-power-analysis-interpret.",
    "href": "practice/practice_slides/slides_lab04.html#linear-regression-with-grouped-data-power-analysis-interpret.",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Linear Regression with grouped data: POWER ANALYSIS interpret.",
    "text": "Linear Regression with grouped data: POWER ANALYSIS interpret.\n\nRecall that, in the F statistic evaluating the model,\n\n\nu the df for the numerator: \\(df_{between} =k‚àí1 = 5-1 = 4\\)\n\n\nv the df for the denominator: \\(df_{within} = n-k = ?\\)\n\nso \\(n = v+5\\)\n\n\n\n\n\npwr::pwr.f2.test(u = 4, f2 = 0.8378974,\n            sig.level = 0.05 , power = 0.8)\n\n\n     Multiple regression power calculation \n\n              u = 4\n              v = 14.62182\n             f2 = 0.8378974\n      sig.level = 0.05\n          power = 0.8\n\n\n\nThis tells us that the denominator degrees of freedom v should be 15 (14.62 rounded up), and this means that we would only need 20 observations n = v+5 in total across all 5 groups to detect this effect size"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#different-approaches-with-different-takes-on-empirical-data",
    "href": "practice/practice_slides/slides_lab04.html#different-approaches-with-different-takes-on-empirical-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "2 different approaches with different takes on empirical data",
    "text": "2 different approaches with different takes on empirical data\n\n(Simplifying a little)\n\n\nInferential statistics\n\nGOAL: Convincingly explain\nAPPROACH: Strong emphasis on defining assumptions (about variables distributions) and/or hypotheses on the relationship between them\n\nDATA:\n\nThe collection strategy is designed ex-ante , according to the experiment goal\nUsually, ALL AVAILABLE DATA are used to estimate effect of interest (as sampling was designed to be representative of a population).\n\n\n\n\nMachine Learning\n\nGOAL: Accurately predict\nAPPROACH: Focus on labeling observations or uncovering (‚Äúlearn‚Äù) a pattern, without worrying about explaining them\n\nDATA:\n\nData drives the search for patterns, but there is a huge risk of ‚Äúoverfitting‚Äù models (too specific to initial data!)\nIt is critical to SPLIT THE DATA (usually 75% for training and 25% for testing the algorithms) leaving aside a sub-sample to test the model with unseen new data"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#data-splitting-in-ml-approaches",
    "href": "practice/practice_slides/slides_lab04.html#data-splitting-in-ml-approaches",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Data Splitting in ML approaches",
    "text": "Data Splitting in ML approaches\n\nConsistent with the ML approach (learning from (data) examples), it is critical to split the available data to obtain:\n\n60-80% ‚ûú training sample for fitting a model and making prediction on the training data itself\n20-40% ‚ûú testing sample for evaluating the performance of the selected model(s) and test it works on new data too\n\n\nSince in ML we don‚Äôt claim to know what works in advance, it is essential to ‚Äútest‚Äù a candidate predictive model on fresh new data and see if it holds"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#introducing-r-metapackage-tidymodels-for-modeling-and-ml",
    "href": "practice/practice_slides/slides_lab04.html#introducing-r-metapackage-tidymodels-for-modeling-and-ml",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Introducing R (metapackage) tidymodels for modeling and ML",
    "text": "Introducing R (metapackage) tidymodels for modeling and ML\n\n\nThe package tidymodels (much like the tidyverse) is an ecosystem of packages meant to enable a wide variety of approaches for modeling and statistical analysis.\n\nOne package in this system is rsample is one of its building blocks for resampling data"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#revisiting-nhanes-for-a-quick-demonstration-of-predictive-modeling",
    "href": "practice/practice_slides/slides_lab04.html#revisiting-nhanes-for-a-quick-demonstration-of-predictive-modeling",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Revisiting NHANES for a quick demonstration of predictive modeling",
    "text": "Revisiting NHANES for a quick demonstration of predictive modeling\n\nLet‚Äôs re-load a dataset from Lab # 3 (the NHANES dataset) for a quick demonstration of data splitting in an ML predictive modeling scenario\n\nWe can try predicting BMI from age (in years), PhysActive, and gender, using linear regression model (which is a Supervised ML algorithm)\n(we already saved this dataset)\n\n\n# (we already saved this dataset in our project folders)\n\n# Use `here` in specifying all the subfolders AFTER the working directory \nnhanes &lt;- read.csv(file = here::here(\"practice\", \"data_input\", \"03_datasets\",\n                                      \"nhanes.samp.csv\"), \n                          header = TRUE, # 1st line is the name of the variables\n                          sep = \",\", # which is the field separator character.\n                          na.strings = c(\"?\",\"NA\" ), # specific MISSING values  \n                          row.names = NULL)"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#splitting-the-dataset-into-training-and-testing-samples",
    "href": "practice/practice_slides/slides_lab04.html#splitting-the-dataset-into-training-and-testing-samples",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Splitting the dataset into training and testing samples",
    "text": "Splitting the dataset into training and testing samples\n\n\nWith this approach, it is best practice to ‚Äúhold back‚Äù some data for testing to get a better estimate of how models will perform on new data\n\nWe can easily specify training and testing sets using rsample‚Äôs function initial_split\n\n\n\n\n# ensure we always get the same result when sampling (for convenience )\nset.seed(12345)\n\nnhanes_split &lt;- nhanes %&gt;%\n  # define the training proportion as 75%\n  rsample::initial_split(prop = 0.75,\n  # ensuring both sets are balanced in gender\n                         strata = Gender)\n\n# resulting datasets\nnhanes_train &lt;- rsample::training(nhanes_split)\ndim(nhanes_train)\n\n[1] 374  77\n\nnhanes_test &lt;- rsample::testing(nhanes_split)\ndim(nhanes_test)\n\n[1] 126  77"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#fitting-a-linear-model-on-the-training-data",
    "href": "practice/practice_slides/slides_lab04.html#fitting-a-linear-model-on-the-training-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Fitting a linear model on the training data",
    "text": "Fitting a linear model on the training data\n\nIn this case the regression models serves for predicting numeric, continuous quantities\n\n# fitting  linear regression model specification\nlin_mod &lt;- lm(BMI ~ Age + Gender + PhysActive, data = nhanes_train)\n\nsummary(lin_mod)\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + PhysActive, data = nhanes_train)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-12.685  -4.674  -1.419   4.257  38.016 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   30.14217    1.30426  23.110  &lt; 2e-16 ***\nAge            0.01429    0.02198   0.650  0.51596    \nGendermale    -0.72960    0.72176  -1.011  0.31275    \nPhysActiveYes -2.26539    0.73620  -3.077  0.00225 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.903 on 367 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.03416,   Adjusted R-squared:  0.02626 \nF-statistic: 4.327 on 3 and 367 DF,  p-value: 0.005155"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#predicting-bmi-estimates-for-new-data-set",
    "href": "practice/practice_slides/slides_lab04.html#predicting-bmi-estimates-for-new-data-set",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Predicting BMI estimates for new data set",
    "text": "Predicting BMI estimates for new data set\n\nUsing the above model, we can predict the BMI for different individuals (those left in the testing data)\n\nwith the function predict, where we specify the argument newdata = nhanes_test)\nadding the prediction interval (the 95% CI), which gives uncertainty around a single value of the prediction\n\n\n# Obtain predictions from the results of a model fitting function\npred_bmi &lt;- stats::predict(lin_mod, \n               newdata = nhanes_test,\n               interval = \"confidence\" )\nhead(pred_bmi)\n\n       fit      lwr      upr\n1 28.59148 27.33499 29.84797\n2 27.70464 26.45051 28.95878\n3 30.88546 29.72888 32.04203\n4 28.01911 26.64955 29.38867\n5 29.78421 28.04027 31.52815\n6 27.60459 26.24230 28.96688"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#evaluating-the-predictive-performance-in-testing-data",
    "href": "practice/practice_slides/slides_lab04.html#evaluating-the-predictive-performance-in-testing-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Evaluating the predictive performance in testing data",
    "text": "Evaluating the predictive performance in testing data\n\nThe ultimate goal of holding data back from the model training process was to evaluate its predictive performance on new data. \n\nA common measure used is the RMSE (Root Mean Square Error) = a measure of the distance between observed values and predicted values in the testing dataset\n\n# Computing the Root Mean Square Error\nRMSE_test &lt;- sqrt(mean((nhanes_test$BMI - predict(lin_mod, nhanes_test))^2, na.rm = T))\nRMSE_test # 6.170518\n\n[1] 6.170518\n\n\n\nThe RMSE (= 6.170518) tells us, (roughly speaking) by how much, on average, the new observed BMI values differ from those predicted by our model"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#and-what-about-rmse-in-training-data",
    "href": "practice/practice_slides/slides_lab04.html#and-what-about-rmse-in-training-data",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "‚Ä¶ and what about RMSE in training data?",
    "text": "‚Ä¶ and what about RMSE in training data?\nLet‚Äôs see the RMSE in the training dataset (for comparison)\n\nRMSE_train &lt;- sqrt(mean((nhanes_train$BMI - predict(lin_mod, nhanes_train))^2, na.rm = T))\nRMSE_train # 6.866044\n\n[1] 6.866044\n\n# R squared is also quite low \nsummary(lin_mod)$r.squared     # R^2 0.0341589\n\n[1] 0.0341589\n\n\n\nThis is not what expected ü§î, since RMSE on the training data is sliglthly bigger that in the testing data!\n\nA possible explanation is that out model is underfitting in the first place (model‚Äôs \\({R}^2\\) was quite low too), so we should definitely try different models‚Ä¶"
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#recap-of-the-workshops-content",
    "href": "practice/practice_slides/slides_lab04.html#recap-of-the-workshops-content",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Recap of the workshop‚Äôs content",
    "text": "Recap of the workshop‚Äôs content\n\nTOPICS WE COVERED\n\nMotivated the choice of learning/using R for scientific quantitative analysis, and lay out some fundamental concepts in biostatistics with concrete R coding examples.\nConsolidated understanding of inferential statistic, through R coding examples conducted on real biostatistics research data.\nDiscussed the relationship between any two variables, and introduce a widely used analytical tool: regression.\nPresented a popular ML technique for dimensionality reduction (PCA), performed both with MetaboAnalyst and R.\nIntroduction to power analysis to define the correct sample size for hypotheses testing and discussion of how ML approaches deal with available data."
  },
  {
    "objectID": "practice/practice_slides/slides_lab04.html#final-thoughts",
    "href": "practice/practice_slides/slides_lab04.html#final-thoughts",
    "title": "Lab 4: Intro to Machine Learning",
    "section": "Final thoughts",
    "text": "Final thoughts\n\n\n\n\nWhile the workshop only allowed for a synthetic overview of fundamental ideas, it hopefully provided a solid foundation on the most common statistical analysis you will likely run in your daily work:\n\nThorough understanding of the input data and the data collection process\nUnivariate and bivariate exploratory analysis (accompanied by visual intuition) to form hypothesis\nUpon verifying the assumptions, we fit data to hypothesized model(s)\n\nAssessment of the model performance (\\(R^2\\), \\(Adj. R^2\\), \\(F-Statistic\\), etc.)\n\n\nYou should now have a solid grasp on the R language to keep using and exploring the huge potential of this programming ecosystem\nWe only scratched the surface in terms of ML classification and prediction models, but we got a hang of the fundamental steps and some useful tools that might serve us also in more advanced analysis\n\n\n\n\n\n\nR 4 Biostatistics | MITGEST::training(2024)"
  }
]